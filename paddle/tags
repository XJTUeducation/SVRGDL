!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.9~svn20110310	//
ACTIVATION_CLASS_NAME	gserver/activations/ActivationFunction.cpp	37;"	d	file:
ADD_TO	function/BufferArg.h	/^  ADD_TO = 2,$/;"	e	enum:paddle::ArgType
ALIGN	math/tests/test_SIMDFunctions.cpp	/^static constexpr size_t ALIGN = 32;$/;"	v	file:
ALIGN32_BEG	cuda/src/avx_mathfun.h	35;"	d
ALIGN32_END	cuda/src/avx_mathfun.h	36;"	d
ALIGN_HINT	utils/GlobalConstants.h	/^const int ALIGN_HINT = 16;$/;"	m	namespace:paddle
ALIGN_HINT	utils/GlobalConstants.h	/^const int ALIGN_HINT = 32;$/;"	m	namespace:paddle
ARRAYSIZE	utils/Util.h	128;"	d
ASSIGN_TO	function/BufferArg.h	/^  ASSIGN_TO = 1,$/;"	e	enum:paddle::ArgType
AVX2_BITOP_USING_SSE2	cuda/src/avx_mathfun.h	116;"	d
AVX2_INTOP_USING_SSE2	cuda/src/avx_mathfun.h	132;"	d
Abstract	utils/BarrierStat.h	/^struct Abstract {$/;"	s	namespace:paddle
ActivationFunction	gserver/activations/ActivationFunction.h	/^  ActivationFunction() {}$/;"	f	class:paddle::ActivationFunction
ActivationFunction	gserver/activations/ActivationFunction.h	/^class ActivationFunction {$/;"	c	namespace:paddle
Active	cuda/include/hl_activation_functions.h	/^class Active {$/;"	c	namespace:hppl
AdaDeltaParameterOptimizer	math/tests/OriginalOptimizerApi.h	/^void AdaDeltaParameterOptimizer(const VectorPtr vecs[],$/;"	f
AdaDeltaParameterOptimizer	parameter/FirstOrderOptimizer.h	/^  explicit AdaDeltaParameterOptimizer(const OptimizationConfig& optConfig)$/;"	f	class:paddle::AdaDeltaParameterOptimizer
AdaDeltaParameterOptimizer	parameter/FirstOrderOptimizer.h	/^class AdaDeltaParameterOptimizer : public ParameterOptimizer {$/;"	c	namespace:paddle
AdagradParameterOptimizer	math/tests/OriginalOptimizerApi.h	/^void AdagradParameterOptimizer(const VectorPtr vecs[],$/;"	f
AdagradParameterOptimizer	parameter/FirstOrderOptimizer.h	/^  explicit AdagradParameterOptimizer(const OptimizationConfig& optConfig)$/;"	f	class:paddle::AdagradParameterOptimizer
AdagradParameterOptimizer	parameter/FirstOrderOptimizer.h	/^class AdagradParameterOptimizer : public ParameterOptimizer {$/;"	c	namespace:paddle
AdamParameterOptimizer	math/tests/OriginalOptimizerApi.h	/^void AdamParameterOptimizer(const VectorPtr vecs[],$/;"	f
AdamParameterOptimizer	parameter/FirstOrderOptimizer.h	/^  explicit AdamParameterOptimizer(const OptimizationConfig& optConfig)$/;"	f	class:paddle::AdamParameterOptimizer
AdamParameterOptimizer	parameter/FirstOrderOptimizer.h	/^class AdamParameterOptimizer : public ParameterOptimizer {$/;"	c	namespace:paddle
AdamaxParameterOptimizer	math/tests/OriginalOptimizerApi.h	/^void AdamaxParameterOptimizer($/;"	f
AdamaxParameterOptimizer	parameter/FirstOrderOptimizer.h	/^  explicit AdamaxParameterOptimizer(const OptimizationConfig& optConfig)$/;"	f	class:paddle::AdamaxParameterOptimizer
AdamaxParameterOptimizer	parameter/FirstOrderOptimizer.h	/^class AdamaxParameterOptimizer : public ParameterOptimizer {$/;"	c	namespace:paddle
AddFilters	scripts/cpplint.py	/^    def AddFilters(self, filters):$/;"	m	class:_CppLintState
AddOptimizer	parameter/FirstOrderOptimizer.h	/^  explicit AddOptimizer(const OptimizationConfig& optConfig)$/;"	f	class:paddle::AddOptimizer
AddOptimizer	parameter/FirstOrderOptimizer.h	/^class AddOptimizer : public ParameterOptimizer {$/;"	c	namespace:paddle
AddResult	pserver/ParameterClient2.h	/^    void AddResult(CpuMatrixPtr arg) {$/;"	f	class:paddle::PreparedOperations::ResultsAdder
AddResult	pserver/ParameterClient2.h	/^    void AddResult(CpuVectorPtr arg) {$/;"	f	class:paddle::PreparedOperations::ResultsAdder
AddtoLayer	gserver/layers/AddtoLayer.h	/^  explicit AddtoLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::AddtoLayer
AddtoLayer	gserver/layers/AddtoLayer.h	/^class AddtoLayer : public Layer {$/;"	c	namespace:paddle
AgentLayer	gserver/layers/AgentLayer.h	/^  explicit AgentLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::AgentLayer
AgentLayer	gserver/layers/AgentLayer.h	/^class AgentLayer : public Layer {$/;"	c	namespace:paddle
AlignElementCount	pserver/ParameterServer2.h	/^    constexpr static size_t AlignElementCount = AlignBytes \/ sizeof(T);$/;"	m	class:paddle::ParameterServer2::ReadWriteBuffer
AlignedAllocator	utils/Util.h	/^  AlignedAllocator() {}$/;"	f	class:paddle::AlignedAllocator
AlignedAllocator	utils/Util.h	/^  AlignedAllocator(const AlignedAllocator&) {}$/;"	f	class:paddle::AlignedAllocator
AlignedAllocator	utils/Util.h	/^  AlignedAllocator(const AlignedAllocator<U, Alignment>&) {}$/;"	f	class:paddle::AlignedAllocator
AlignedAllocator	utils/Util.h	/^class AlignedAllocator {$/;"	c	namespace:paddle
Allocator	math/Allocator.h	/^class Allocator {$/;"	c	namespace:paddle
ArgType	function/BufferArg.h	/^enum ArgType {$/;"	g	namespace:paddle
Argument	parameter/Argument.h	/^  Argument()$/;"	f	struct:paddle::Argument
Argument	parameter/Argument.h	/^  Argument(const Argument& argument) {$/;"	f	struct:paddle::Argument
Argument	parameter/Argument.h	/^struct Argument {$/;"	s	namespace:paddle
Arguments	api/Arguments.cpp	/^Arguments::Arguments() : m(new ArgumentsPrivate()) {}$/;"	f	class:Arguments
Arguments	api/PaddleAPI.h	/^class Arguments {$/;"	c
ArgumentsPrivate	api/PaddleAPIPrivate.h	/^struct ArgumentsPrivate {$/;"	s
AssertEqual	math/tests/TensorCheck.h	/^  AssertEqual(real err = 0) : err_(err) {}$/;"	f	class:autotest::AssertEqual
AssertEqual	math/tests/TensorCheck.h	/^class AssertEqual {$/;"	c	namespace:autotest
AssignCpuEvaluate	math/TensorAssign.h	/^void AssignCpuEvaluate(int height,$/;"	f	namespace:paddle
AssignEvaluate	math/TensorAssign.h	/^void AssignEvaluate(Assign&& assign, AssignOp&&... args) {$/;"	f	namespace:paddle
AssignGpuEvaluate1	math/TensorAssign.h	/^__global__ void AssignGpuEvaluate1(const int border,$/;"	f	namespace:paddle
AssignGpuEvaluate2	math/TensorAssign.h	/^__global__ void AssignGpuEvaluate2(const int height,$/;"	f	namespace:paddle
AsyncGpuBlock	utils/Util.h	/^  AsyncGpuBlock() : syncFlag_(hl_get_sync_flag()) { hl_set_sync_flag(false); }$/;"	f	class:paddle::AsyncGpuBlock
AsyncGpuBlock	utils/Util.h	/^class AsyncGpuBlock {$/;"	c	namespace:paddle
AsyncParameter	parameter/ParallelParameter.cpp	/^AsyncParameter::AsyncParameter(TrainerRole role,$/;"	f	class:paddle::AsyncParameter
AsyncParameter	parameter/ParallelParameter.h	/^class AsyncParameter : public ParallelParameter {$/;"	c	namespace:paddle
AsyncSGD	utils/GlobalConstants.cpp	/^const std::string TrainAlgorithm::AsyncSGD = "async_sgd";$/;"	m	class:paddle::TrainAlgorithm	file:
AsyncSGD	utils/GlobalConstants.h	/^  static const std::string AsyncSGD;$/;"	m	class:paddle::TrainAlgorithm
AsyncThreadPool	utils/Thread.h	/^  AsyncThreadPool() { LOG(FATAL) << "Not implemented"; }$/;"	f	class:paddle::AsyncThreadPool
AsyncThreadPool	utils/Thread.h	/^  explicit AsyncThreadPool(size_t threadNum) {$/;"	f	class:paddle::AsyncThreadPool
AsyncThreadPool	utils/Thread.h	/^class AsyncThreadPool {$/;"	c	namespace:paddle
AucEvaluator	gserver/evaluators/Evaluator.h	/^  AucEvaluator() {}$/;"	f	class:paddle::AucEvaluator
AucEvaluator	gserver/evaluators/Evaluator.h	/^  AucEvaluator(int32_t colIdx)$/;"	f	class:paddle::AucEvaluator
AucEvaluator	gserver/evaluators/Evaluator.h	/^class AucEvaluator : public Evaluator {$/;"	c	namespace:paddle
AucValidation	gserver/layers/ValidationLayer.h	/^  explicit AucValidation(const LayerConfig& config)$/;"	f	class:paddle::AucValidation
AucValidation	gserver/layers/ValidationLayer.h	/^class AucValidation : public ValidationLayer {$/;"	c	namespace:paddle
AverageLayer	gserver/layers/AverageLayer.h	/^  explicit AverageLayer(const LayerConfig& config)$/;"	f	class:paddle::AverageLayer
AverageLayer	gserver/layers/AverageLayer.h	/^class AverageLayer : public SequencePoolLayer {$/;"	c	namespace:paddle
AverageOptimizer	parameter/AverageOptimizer.cpp	/^AverageOptimizer::AverageOptimizer(const OptimizationConfig& optConfig,$/;"	f	class:paddle::AverageOptimizer
AverageOptimizer	parameter/AverageOptimizer.h	/^class AverageOptimizer : public ParameterOptimizer {$/;"	c	namespace:paddle
AverageSparseOptimizer	parameter/AverageOptimizer.h	/^  AverageSparseOptimizer(const OptimizationConfig& optConfig,$/;"	f	class:paddle::AverageSparseOptimizer
AverageSparseOptimizer	parameter/AverageOptimizer.h	/^class AverageSparseOptimizer : public AverageOptimizer {$/;"	c	namespace:paddle
AverageStrategy	gserver/layers/AverageLayer.h	/^  enum AverageStrategy { kAverage = 0, kSum = 1, kAverageSquareRootN = 2 };$/;"	g	class:paddle::AverageLayer
AvgPoolProjection	gserver/layers/PoolProjection.h	/^  AvgPoolProjection(const ProjectionConfig& config,$/;"	f	class:paddle::AvgPoolProjection
AvgPoolProjection	gserver/layers/PoolProjection.h	/^class AvgPoolProjection : public PoolProjection {$/;"	c	namespace:paddle
BACKWARD_LOOP	math/Matrix.cpp	3339;"	d	file:
BARRIER_DELTA	utils/Stat.h	/^  BARRIER_DELTA = 1,$/;"	e	enum:paddle::BarrierStatType
BARRIER_END	utils/Stat.h	/^  BARRIER_END = 0,$/;"	e	enum:paddle::BarrierStatType
BATCH_SIZE	math/tests/test_SIMDFunctions.cpp	/^static constexpr size_t BATCH_SIZE = 64;$/;"	v	file:
BEGIN_DEFINE_ACTIVATION	gserver/activations/ActivationFunction.cpp	42;"	d	file:
BackupFilters	scripts/cpplint.py	/^    def BackupFilters(self):$/;"	m	class:_CppLintState
BarrierDeltaStat	utils/BarrierStat.cpp	/^BarrierDeltaStat::BarrierDeltaStat(uint16_t numConnThreads,$/;"	f	class:paddle::BarrierDeltaStat
BarrierDeltaStat	utils/BarrierStat.h	/^class BarrierDeltaStat : public BarrierStatBase {$/;"	c	namespace:paddle
BarrierEndStat	utils/BarrierStat.cpp	/^BarrierEndStat::BarrierEndStat(uint16_t numConnThreads, const std::string &name)$/;"	f	class:paddle::BarrierEndStat
BarrierEndStat	utils/BarrierStat.h	/^class BarrierEndStat : public BarrierStatBase {$/;"	c	namespace:paddle
BarrierStatBase	utils/BarrierStat.cpp	/^BarrierStatBase::BarrierStatBase(uint16_t numConnThreads,$/;"	f	class:paddle::BarrierStatBase
BarrierStatBase	utils/BarrierStat.h	/^class BarrierStatBase {$/;"	c	namespace:paddle
BarrierStatPtr	utils/Stat.h	/^typedef std::shared_ptr<BarrierStatBase> BarrierStatPtr;$/;"	t	namespace:paddle
BarrierStatType	utils/Stat.h	/^enum BarrierStatType {$/;"	g	namespace:paddle
BaseClient	pserver/BaseClient.cpp	/^BaseClient::BaseClient(bool separate, int numPorts)$/;"	f	class:paddle::BaseClient
BaseClient	pserver/BaseClient.h	/^class BaseClient {$/;"	c	namespace:paddle
BaseLRS	parameter/LearningRateScheduler.cpp	/^  explicit BaseLRS(const OptimizationConfig& config)$/;"	f	class:paddle::BaseLRS
BaseLRS	parameter/LearningRateScheduler.cpp	/^class BaseLRS : public LearningRateScheduler {$/;"	c	namespace:paddle	file:
BaseMatrix	math/BaseMatrix.h	/^typedef BaseMatrixT<real> BaseMatrix;$/;"	t	namespace:paddle
BaseMatrixT	math/BaseMatrix.h	/^  BaseMatrixT(BaseMatrixT& mat, bool useGpu)$/;"	f	class:paddle::BaseMatrixT
BaseMatrixT	math/BaseMatrix.h	/^  BaseMatrixT(size_t height, size_t width, T* data, bool trans, bool useGpu)$/;"	f	class:paddle::BaseMatrixT
BaseMatrixT	math/BaseMatrix.h	/^  BaseMatrixT(size_t height,$/;"	f	class:paddle::BaseMatrixT
BaseMatrixT	math/BaseMatrix.h	/^class BaseMatrixT : public TensorExpression<BaseMatrixT<T>, T> {$/;"	c	namespace:paddle
BaseName	scripts/cpplint.py	/^    def BaseName(self):$/;"	m	class:FileInfo
BaseVector	math/Vector.h	/^  BaseVector(size_t size, T* data, bool useGpu)$/;"	f	class:paddle::BaseVector
BaseVector	math/Vector.h	/^class BaseVector : public BaseMatrixT<T> {$/;"	c	namespace:paddle
BatchNormBaseLayer	gserver/layers/BatchNormBaseLayer.h	/^  explicit BatchNormBaseLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::BatchNormBaseLayer
BatchNormBaseLayer	gserver/layers/BatchNormBaseLayer.h	/^class BatchNormBaseLayer : public Layer {$/;"	c	namespace:paddle
BatchNormalizationLayer	gserver/layers/BatchNormalizationLayer.h	/^  explicit BatchNormalizationLayer(const LayerConfig& config)$/;"	f	class:paddle::BatchNormalizationLayer
BatchNormalizationLayer	gserver/layers/BatchNormalizationLayer.h	/^class BatchNormalizationLayer : public BatchNormBaseLayer {$/;"	c	namespace:paddle
BeamSearchCandidatesAdjustCallback	gserver/gradientmachines/RecurrentGradientMachine.h	/^      BeamSearchCandidatesAdjustCallback;$/;"	t	class:paddle::RecurrentGradientMachine
BeamSearchControlCallbacks	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^  BeamSearchControlCallbacks($/;"	f	class:paddle::BeamSearchControlCallbacks
BeamSearchControlCallbacks	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^class BeamSearchControlCallbacks {$/;"	c	namespace:paddle	file:
BeamSearchStatisticsCallbacks	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^  BeamSearchStatisticsCallbacks($/;"	f	class:paddle::BeamSearchStatisticsCallbacks
BeamSearchStatisticsCallbacks	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^class BeamSearchStatisticsCallbacks {$/;"	c	namespace:paddle	file:
Begin	scripts/cpplint.py	/^    def Begin(self, function_name):$/;"	m	class:_FunctionState
BilinearInterpLayer	gserver/layers/BilinearInterpLayer.h	/^  explicit BilinearInterpLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::BilinearInterpLayer
BilinearInterpLayer	gserver/layers/BilinearInterpLayer.h	/^class BilinearInterpLayer : public Layer {$/;"	c	namespace:paddle
BlockExpandLayer	gserver/layers/BlockExpandLayer.h	/^  explicit BlockExpandLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::BlockExpandLayer
BlockExpandLayer	gserver/layers/BlockExpandLayer.h	/^class BlockExpandLayer : public Layer {$/;"	c	namespace:paddle
BlockInfo	pserver/ParameterServer2.h	/^  struct BlockInfo {$/;"	s	class:paddle::ParameterServer2
BlockKey	pserver/ParameterServer2.h	/^  typedef std::pair<size_t, int64_t> BlockKey;$/;"	t	class:paddle::ParameterServer2
BlockKeyHash	pserver/ParameterServer2.h	/^  struct BlockKeyHash {$/;"	s	class:paddle::ParameterServer2
BlockMap	pserver/ParameterServer2.h	/^  typedef std::unordered_map<BlockKey, int64_t, BlockKeyHash> BlockMap;$/;"	t	class:paddle::ParameterServer2
BlockSegments	pserver/ParameterServer2.h	/^  typedef std::vector<std::pair<int64_t, int64_t>> BlockSegments;$/;"	t	class:paddle::ParameterServer2
BlockingQueue	utils/Queue.h	/^  explicit BlockingQueue(size_t capacity) : capacity_(capacity) {}$/;"	f	class:paddle::BlockingQueue
BlockingQueue	utils/Queue.h	/^class BlockingQueue {$/;"	c	namespace:paddle
BootBiasLayer	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^  explicit BootBiasLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::BootBiasLayer
BootBiasLayer	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^class BootBiasLayer : public Layer {$/;"	c	namespace:paddle	file:
Buffer	pserver/ParameterServer2.h	/^  struct Buffer {$/;"	s	class:paddle::ParameterServer2
BufferArg	function/BufferArg.h	/^  BufferArg(ValueType valueType,$/;"	f	class:paddle::BufferArg
BufferArg	function/BufferArg.h	/^  BufferArg(const IVector& vector, ArgType argType = UNSPECIFIED)$/;"	f	class:paddle::BufferArg
BufferArg	function/BufferArg.h	/^  BufferArg(const Matrix& matrix, ArgType argType = UNSPECIFIED)$/;"	f	class:paddle::BufferArg
BufferArg	function/BufferArg.h	/^  BufferArg(const Matrix& matrix,$/;"	f	class:paddle::BufferArg
BufferArg	function/BufferArg.h	/^  BufferArg(const Vector& vector, ArgType argType = UNSPECIFIED)$/;"	f	class:paddle::BufferArg
BufferArg	function/BufferArg.h	/^  BufferArg(void* buf, ValueType valueType) : buf_(buf), valueType_(valueType) {$/;"	f	class:paddle::BufferArg
BufferArg	function/BufferArg.h	/^  BufferArg(void* buf,$/;"	f	class:paddle::BufferArg
BufferArg	function/BufferArg.h	/^class BufferArg {$/;"	c	namespace:paddle
BufferArgPtr	function/FunctionTest.h	/^typedef std::shared_ptr<BufferArg> BufferArgPtr;$/;"	t	namespace:paddle
BufferArgs	function/Function.h	/^  BufferArgs() {}$/;"	f	class:paddle::BufferArgs
BufferArgs	function/Function.h	/^class BufferArgs {$/;"	c	namespace:paddle
BufferBatch	gserver/dataproviders/DataProvider.h	/^  BufferBatch() {$/;"	f	class:paddle::BufferBatch
BufferBatch	gserver/dataproviders/DataProvider.h	/^class BufferBatch {$/;"	c	namespace:paddle
BufferBatchPtr	gserver/dataproviders/DataProvider.h	/^typedef std::shared_ptr<BufferBatch> BufferBatchPtr;$/;"	t	namespace:paddle
BufferBatchQueue	gserver/dataproviders/DataProvider.h	/^typedef Queue<BufferBatch*> BufferBatchQueue;$/;"	t	namespace:paddle
BufferType	function/BufferArg.h	/^enum BufferType {$/;"	g	namespace:paddle
CACHE_PASS_IN_MEM	gserver/dataproviders/PyDataProvider2.cpp	/^  CACHE_PASS_IN_MEM = 1,  \/\/ First pass will load data from PyDataProvider2,$/;"	e	enum:paddle::CacheType	file:
CAL_MATRIX_START_ADDRESS	math/BaseMatrix.h	40;"	d
CBLAS_LIBRARIES	api/paddle_api_config.py	/^CBLAS_LIBRARIES="\/home\/tianbing\/baidu\/idl\/paddle\/third_party\/install\/openblas\/lib\/libopenblas.a;gfortran;pthread"$/;"	v
CHANNELS	math/tests/test_perturbation.cpp	/^const int CHANNELS = 3;$/;"	v
CHECK_BARRIER_TIMER	utils/BarrierStat.h	381;"	d
CHECK_CUBLAS	cuda/src/hl_cuda_cublas.cc	132;"	d	file:
CHECK_CUDA	cuda/src/hl_cuda_device.cc	101;"	d	file:
CHECK_CUDNN	cuda/src/hl_cuda_cudnn.cc	151;"	d	file:
CHECK_PY	utils/PythonUtil.h	86;"	d
CHECK_SYNC	cuda/include/hl_base.h	222;"	d
CHECK_VECTORPTR	math/tests/test_TrainingAlgorithm.cpp	82;"	d	file:
CHECK_VECTORPTR	math/tests/test_TrainingAlgorithm.cpp	87;"	d	file:
CHECK_WARPCTC	cuda/src/hl_warpctc_wrap.cc	73;"	d	file:
CMAKE_DL_LIBS	api/paddle_api_config.py	/^CMAKE_DL_LIBS="dl"$/;"	v
CMAKE_THREAD_LIB	api/paddle_api_config.py	/^CMAKE_THREAD_LIB="-lpthread"$/;"	v
CMRProjectionNormLayer	gserver/layers/NormProjectionLayer.h	/^  explicit CMRProjectionNormLayer(const LayerConfig& config)$/;"	f	class:paddle::CMRProjectionNormLayer
CMRProjectionNormLayer	gserver/layers/NormProjectionLayer.h	/^class CMRProjectionNormLayer : public ResponseNormLayer {$/;"	c	namespace:paddle
CONFIG_FILE	trainer/tests/test_recurrent_machine_generation.cpp	/^static const string& CONFIG_FILE = "trainer\/tests\/sample_trainer_rnn_gen.conf";$/;"	v	file:
COPY_IMM_TO_XMM	cuda/src/avx_mathfun.h	100;"	d
COPY_VECTOR_TO_CPU	math/tests/test_TrainingAlgorithm.cpp	42;"	d	file:
COPY_XMM_TO_IMM	cuda/src/avx_mathfun.h	108;"	d
CPUID	utils/CpuId.cpp	20;"	d	file:
CPUID	utils/CpuId.cpp	27;"	d	file:
CREATE_MODE_NORMAL	api/PaddleAPI.h	/^  CREATE_MODE_NORMAL = 0,$/;"	e	enum:GradientMatchineCreateMode
CREATE_MODE_TESTING	api/PaddleAPI.h	/^  CREATE_MODE_TESTING = 4$/;"	e	enum:GradientMatchineCreateMode
CRFDecodingLayer	gserver/layers/CRFDecodingLayer.h	/^  explicit CRFDecodingLayer(const LayerConfig& config) : CRFLayer(config) {}$/;"	f	class:paddle::CRFDecodingLayer
CRFDecodingLayer	gserver/layers/CRFDecodingLayer.h	/^class CRFDecodingLayer : public CRFLayer {$/;"	c	namespace:paddle
CRFLayer	gserver/layers/CRFLayer.h	/^  explicit CRFLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::CRFLayer
CRFLayer	gserver/layers/CRFLayer.h	/^class CRFLayer : public Layer {$/;"	c	namespace:paddle
CTCErrorEvaluator	gserver/evaluators/CTCErrorEvaluator.cpp	/^  CTCErrorEvaluator()$/;"	f	class:paddle::CTCErrorEvaluator
CTCErrorEvaluator	gserver/evaluators/CTCErrorEvaluator.cpp	/^class CTCErrorEvaluator : public Evaluator {$/;"	c	namespace:paddle	file:
CTCLayer	gserver/layers/CTCLayer.h	/^  explicit CTCLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::CTCLayer
CTCLayer	gserver/layers/CTCLayer.h	/^class CTCLayer : public Layer {$/;"	c	namespace:paddle
CUBLAS_BLAS_ROUTINE_EACH	cuda/src/hl_cuda_cublas.cc	60;"	d	file:
CUBLAS_BLAS_ROUTINE_EACH	cuda/src/hl_cuda_cublas.cc	85;"	d	file:
CUBLAS_GEAM	cuda/src/hl_cuda_cublas.cc	91;"	d	file:
CUBLAS_GEMM	cuda/src/hl_cuda_cublas.cc	93;"	d	file:
CUBLAS_GEMV	cuda/src/hl_cuda_cublas.cc	92;"	d	file:
CUBLAS_GETRF	cuda/src/hl_cuda_cublas.cc	94;"	d	file:
CUBLAS_GETRI	cuda/src/hl_cuda_cublas.cc	95;"	d	file:
CUDA_LIBRARIES	api/paddle_api_config.py	/^CUDA_LIBRARIES="\/usr\/local\/cuda\/lib64\/libcudart.so"$/;"	v
CUDNN_DNN_ROUTINE_EACH	cuda/src/hl_cuda_cudnn.cc	143;"	d	file:
CUDNN_DNN_ROUTINE_EACH	cuda/src/hl_cuda_cudnn.cc	72;"	d	file:
CUDNN_DNN_ROUTINE_EACH_AFTER_R3	cuda/src/hl_cuda_cudnn.cc	112;"	d	file:
CUDNN_DNN_ROUTINE_EACH_AFTER_R3	cuda/src/hl_cuda_cudnn.cc	118;"	d	file:
CUDNN_DNN_ROUTINE_EACH_AFTER_R4	cuda/src/hl_cuda_cudnn.cc	124;"	d	file:
CUDNN_DNN_ROUTINE_EACH_AFTER_R4	cuda/src/hl_cuda_cudnn.cc	129;"	d	file:
CUDNN_DNN_ROUTINE_EACH_R2	cuda/src/hl_cuda_cudnn.cc	104;"	d	file:
CUDNN_DNN_ROUTINE_EACH_R5	cuda/src/hl_cuda_cudnn.cc	134;"	d	file:
CUDNN_DNN_ROUTINE_EACH_R5	cuda/src/hl_cuda_cudnn.cc	140;"	d	file:
CURAND_RAND_ROUTINE_EACH	cuda/src/hl_cuda_device.cc	66;"	d	file:
CURAND_RAND_ROUTINE_EACH	cuda/src/hl_cuda_device.cc	76;"	d	file:
CacheOnePassInMemory	gserver/dataproviders/PyDataProvider2.cpp	/^  CacheOnePassInMemory()$/;"	f	class:paddle::CacheOnePassInMemory
CacheOnePassInMemory	gserver/dataproviders/PyDataProvider2.cpp	/^class CacheOnePassInMemory : public IPyDataProviderCache {$/;"	c	namespace:paddle	file:
CacheRowCpuMatrix	math/SparseRowMatrix.h	/^  CacheRowCpuMatrix(size_t height,$/;"	f	class:paddle::CacheRowCpuMatrix
CacheRowCpuMatrix	math/SparseRowMatrix.h	/^class CacheRowCpuMatrix : public SparseAutoGrowRowCpuMatrix {$/;"	c	namespace:paddle
CacheType	gserver/dataproviders/PyDataProvider2.cpp	/^enum CacheType {$/;"	g	namespace:paddle	file:
CaffePolyLRS	parameter/LearningRateScheduler.cpp	/^  explicit CaffePolyLRS(const OptimizationConfig& config) : BaseLRS(config) {}$/;"	f	class:paddle::CaffePolyLRS
CaffePolyLRS	parameter/LearningRateScheduler.cpp	/^class CaffePolyLRS : public BaseLRS {$/;"	c	namespace:paddle	file:
CalCost	gserver/tests/test_RecurrentGradientMachine.cpp	/^void CalCost(const string& conf,$/;"	f
CallableHelper	utils/PythonUtil.h	/^  explicit CallableHelper(const PyObjectPtr& obj) : obj_(obj) {$/;"	f	class:paddle::py::CallableHelper
CallableHelper	utils/PythonUtil.h	/^class CallableHelper {$/;"	c	namespace:paddle::py
CanonicalizeAlphabeticalOrder	scripts/cpplint.py	/^    def CanonicalizeAlphabeticalOrder(self, header_path):$/;"	m	class:_IncludeState
ChannelType	pserver/SocketChannel.h	/^enum ChannelType {$/;"	g	namespace:paddle
Check	scripts/cpplint.py	/^    def Check(self, error, filename, linenum):$/;"	m	class:_FunctionState
CheckAccess	scripts/cpplint.py	/^def CheckAccess(filename, clean_lines, linenum, nesting_state, error):$/;"	f
CheckAltTokens	scripts/cpplint.py	/^def CheckAltTokens(filename, clean_lines, linenum, error):$/;"	f
CheckBegin	scripts/cpplint.py	/^    def CheckBegin(self, filename, clean_lines, linenum, error):$/;"	m	class:_BlockInfo
CheckBegin	scripts/cpplint.py	/^    def CheckBegin(self, filename, clean_lines, linenum, error):$/;"	m	class:_ClassInfo
CheckBraces	scripts/cpplint.py	/^def CheckBraces(filename, clean_lines, linenum, error):$/;"	f
CheckBracesSpacing	scripts/cpplint.py	/^def CheckBracesSpacing(filename, clean_lines, linenum, error):$/;"	f
CheckBufferArg	function/FunctionTest.cpp	/^typedef std::function<void(const BufferArg&)> CheckBufferArg;$/;"	t	namespace:paddle	file:
CheckCStyleCast	scripts/cpplint.py	/^def CheckCStyleCast(filename, clean_lines, linenum, cast_type, pattern, error):$/;"	f
CheckCasts	scripts/cpplint.py	/^def CheckCasts(filename, clean_lines, linenum, error):$/;"	f
CheckCheck	scripts/cpplint.py	/^def CheckCheck(filename, clean_lines, linenum, error):$/;"	f
CheckCommaSpacing	scripts/cpplint.py	/^def CheckCommaSpacing(filename, clean_lines, linenum, error):$/;"	f
CheckComment	scripts/cpplint.py	/^def CheckComment(line, filename, linenum, next_line_start, error):$/;"	f
CheckCompletedBlocks	scripts/cpplint.py	/^    def CheckCompletedBlocks(self, filename, error):$/;"	m	class:NestingState
CheckDefaultLambdaCaptures	scripts/cpplint.py	/^def CheckDefaultLambdaCaptures(filename, clean_lines, linenum, error):$/;"	f
CheckEmptyBlockBody	scripts/cpplint.py	/^def CheckEmptyBlockBody(filename, clean_lines, linenum, error):$/;"	f
CheckEnd	scripts/cpplint.py	/^    def CheckEnd(self, filename, clean_lines, linenum, error):$/;"	m	class:_BlockInfo
CheckEnd	scripts/cpplint.py	/^    def CheckEnd(self, filename, clean_lines, linenum, error):$/;"	m	class:_ClassInfo
CheckEnd	scripts/cpplint.py	/^    def CheckEnd(self, filename, clean_lines, linenum, error):$/;"	m	class:_NamespaceInfo
CheckForBadCharacters	scripts/cpplint.py	/^def CheckForBadCharacters(filename, lines, error):$/;"	f
CheckForCopyright	scripts/cpplint.py	/^def CheckForCopyright(filename, lines, error):$/;"	f
CheckForFunctionLengths	scripts/cpplint.py	/^def CheckForFunctionLengths(filename, clean_lines, linenum, function_state,$/;"	f
CheckForHeaderGuard	scripts/cpplint.py	/^def CheckForHeaderGuard(filename, clean_lines, error):$/;"	f
CheckForIncludeWhatYouUse	scripts/cpplint.py	/^def CheckForIncludeWhatYouUse(filename,$/;"	f
CheckForMultilineCommentsAndStrings	scripts/cpplint.py	/^def CheckForMultilineCommentsAndStrings(filename, clean_lines, linenum, error):$/;"	f
CheckForNamespaceIndentation	scripts/cpplint.py	/^def CheckForNamespaceIndentation(filename, nesting_state, clean_lines, line,$/;"	f
CheckForNewlineAtEOF	scripts/cpplint.py	/^def CheckForNewlineAtEOF(filename, lines, error):$/;"	f
CheckForNonConstReference	scripts/cpplint.py	/^def CheckForNonConstReference(filename, clean_lines, linenum, nesting_state,$/;"	f
CheckForNonStandardConstructs	scripts/cpplint.py	/^def CheckForNonStandardConstructs(filename, clean_lines, linenum, nesting_state,$/;"	f
CheckGlobalStatic	scripts/cpplint.py	/^def CheckGlobalStatic(filename, clean_lines, linenum, error):$/;"	f
CheckHeaderFileIncluded	scripts/cpplint.py	/^def CheckHeaderFileIncluded(filename, include_state, error):$/;"	f
CheckIncludeLine	scripts/cpplint.py	/^def CheckIncludeLine(filename, clean_lines, linenum, include_state, error):$/;"	f
CheckInvalidIncrement	scripts/cpplint.py	/^def CheckInvalidIncrement(filename, clean_lines, linenum, error):$/;"	f
CheckItemIndentationInNamespace	scripts/cpplint.py	/^def CheckItemIndentationInNamespace(filename, raw_lines_no_comments, linenum,$/;"	f
CheckLanguage	scripts/cpplint.py	/^def CheckLanguage(filename, clean_lines, linenum, file_extension, include_state,$/;"	f
CheckMakePairUsesDeduction	scripts/cpplint.py	/^def CheckMakePairUsesDeduction(filename, clean_lines, linenum, error):$/;"	f
CheckNextIncludeOrder	scripts/cpplint.py	/^    def CheckNextIncludeOrder(self, header_type):$/;"	m	class:_IncludeState
CheckOperatorSpacing	scripts/cpplint.py	/^def CheckOperatorSpacing(filename, clean_lines, linenum, error):$/;"	f
CheckParenthesisSpacing	scripts/cpplint.py	/^def CheckParenthesisSpacing(filename, clean_lines, linenum, error):$/;"	f
CheckPosixThreading	scripts/cpplint.py	/^def CheckPosixThreading(filename, clean_lines, linenum, error):$/;"	f
CheckPrintf	scripts/cpplint.py	/^def CheckPrintf(filename, clean_lines, linenum, error):$/;"	f
CheckRValueReference	scripts/cpplint.py	/^def CheckRValueReference(filename, clean_lines, linenum, nesting_state, error):$/;"	f
CheckRedundantOverrideOrFinal	scripts/cpplint.py	/^def CheckRedundantOverrideOrFinal(filename, clean_lines, linenum, error):$/;"	f
CheckRedundantVirtual	scripts/cpplint.py	/^def CheckRedundantVirtual(filename, clean_lines, linenum, error):$/;"	f
CheckSectionSpacing	scripts/cpplint.py	/^def CheckSectionSpacing(filename, clean_lines, class_info, linenum, error):$/;"	f
CheckSpacing	scripts/cpplint.py	/^def CheckSpacing(filename, clean_lines, linenum, nesting_state, error):$/;"	f
CheckSpacingForFunctionCall	scripts/cpplint.py	/^def CheckSpacingForFunctionCall(filename, clean_lines, linenum, error):$/;"	f
CheckStyle	scripts/cpplint.py	/^def CheckStyle(filename, clean_lines, linenum, file_extension, nesting_state,$/;"	f
CheckTrailingSemicolon	scripts/cpplint.py	/^def CheckTrailingSemicolon(filename, clean_lines, linenum, error):$/;"	f
CheckVlogArguments	scripts/cpplint.py	/^def CheckVlogArguments(filename, clean_lines, linenum, error):$/;"	f
ChunkEvaluator	gserver/evaluators/ChunkEvaluator.cpp	/^class ChunkEvaluator : public Evaluator {$/;"	c	namespace:paddle	file:
ClassCreator	utils/ClassRegistrar.h	/^  typedef std::function<BaseClass*(CreateArgs...)> ClassCreator;$/;"	t	class:paddle::ClassRegistrar
ClassRegistrar	utils/ClassRegistrar.h	/^class ClassRegistrar {$/;"	c	namespace:paddle
ClassificationErrorEvaluator	gserver/evaluators/Evaluator.cpp	/^class ClassificationErrorEvaluator : public Evaluator {$/;"	c	namespace:paddle	file:
ClassificationErrorPrinter	gserver/evaluators/Evaluator.cpp	/^class ClassificationErrorPrinter : public ClassificationErrorEvaluator {$/;"	c	namespace:paddle	file:
CleanseComments	scripts/cpplint.py	/^def CleanseComments(line):$/;"	f
CleanseRawStrings	scripts/cpplint.py	/^def CleanseRawStrings(raw_lines):$/;"	f
CleansedLines	scripts/cpplint.py	/^class CleansedLines(object):$/;"	c
CloseExpression	scripts/cpplint.py	/^def CloseExpression(clean_lines, linenum, pos):$/;"	f
ColumnSumEvaluator	gserver/evaluators/Evaluator.cpp	/^  ColumnSumEvaluator() {}$/;"	f	class:paddle::ColumnSumEvaluator	file:
ColumnSumEvaluator	gserver/evaluators/Evaluator.cpp	/^  explicit ColumnSumEvaluator(int32_t colIdx)$/;"	f	class:paddle::ColumnSumEvaluator
ColumnSumEvaluator	gserver/evaluators/Evaluator.cpp	/^class ColumnSumEvaluator : public Evaluator {$/;"	c	namespace:paddle	file:
ComData	gserver/tests/test_SelectiveFCLayer.cpp	/^struct ComData {$/;"	s	file:
ComData	trainer/tests/test_CompareTwoNets.cpp	/^struct ComData {$/;"	s	file:
ComData	trainer/tests/test_CompareTwoOpts.cpp	/^struct ComData {$/;"	s	file:
CombinedEvaluator	gserver/gradientmachines/NeuralNetwork.cpp	/^  CombinedEvaluator() {}$/;"	f	class:paddle::CombinedEvaluator
CombinedEvaluator	gserver/gradientmachines/NeuralNetwork.cpp	/^class CombinedEvaluator : public Evaluator {$/;"	c	namespace:paddle	file:
CommonTest	parameter/tests/test_common.cpp	/^  CommonTest() : testStat_("test") {}$/;"	f	class:CommonTest
CommonTest	parameter/tests/test_common.cpp	/^class CommonTest : public ::testing::Test {$/;"	c	file:
ConcatenateLayer	gserver/layers/ConcatenateLayer.cpp	/^  explicit ConcatenateLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::ConcatenateLayer
ConcatenateLayer	gserver/layers/ConcatenateLayer.cpp	/^class ConcatenateLayer : public Layer {$/;"	c	namespace:paddle	file:
ConcatenateLayer2	gserver/layers/ConcatenateLayer.cpp	/^  explicit ConcatenateLayer2(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::ConcatenateLayer2
ConcatenateLayer2	gserver/layers/ConcatenateLayer.cpp	/^class ConcatenateLayer2 : public Layer {$/;"	c	namespace:paddle	file:
ConcurrentRemoteParameterUpdater	trainer/RemoteParameterUpdater.cpp	/^ConcurrentRemoteParameterUpdater::ConcurrentRemoteParameterUpdater($/;"	f	class:paddle::ConcurrentRemoteParameterUpdater
ConcurrentRemoteParameterUpdater	trainer/RemoteParameterUpdater.h	/^class ConcurrentRemoteParameterUpdater : public RemoteParameterUpdater {$/;"	c	namespace:paddle
ConstLRS	parameter/LearningRateScheduler.cpp	/^  explicit ConstLRS(const OptimizationConfig& config) : BaseLRS(config) {}$/;"	f	class:paddle::ConstLRS
ConstLRS	parameter/LearningRateScheduler.cpp	/^class ConstLRS : public BaseLRS {$/;"	c	namespace:paddle	file:
ContextProjection	gserver/layers/ContextProjection.cpp	/^ContextProjection::ContextProjection(const ProjectionConfig& config,$/;"	f	class:paddle::ContextProjection
ContextProjection	gserver/layers/ContextProjection.h	/^class ContextProjection : public Projection {$/;"	c	namespace:paddle
ContextProjectionBackward	function/ContextProjectionOp.cpp	/^void ContextProjectionBackward<DEVICE_TYPE_CPU>(const CpuMatrix& out_grad_mat,$/;"	f	namespace:paddle
ContextProjectionBackwardDataFunc	function/ContextProjectionOp.cpp	/^class ContextProjectionBackwardDataFunc : public FunctionBase {$/;"	c	namespace:paddle	file:
ContextProjectionBackwardFunc	function/ContextProjectionOp.cpp	/^class ContextProjectionBackwardFunc : public FunctionBase {$/;"	c	namespace:paddle	file:
ContextProjectionBackwardWeightFunc	function/ContextProjectionOp.cpp	/^class ContextProjectionBackwardWeightFunc : public FunctionBase {$/;"	c	namespace:paddle	file:
ContextProjectionForward	function/ContextProjectionOp.cpp	/^void ContextProjectionForward<DEVICE_TYPE_CPU>(CpuMatrix& out_mat,$/;"	f	namespace:paddle
ContextProjectionForwardFunc	function/ContextProjectionOp.cpp	/^class ContextProjectionForwardFunc : public FunctionBase {$/;"	c	namespace:paddle	file:
ConvBaseLayer	gserver/layers/ConvBaseLayer.h	/^  explicit ConvBaseLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::ConvBaseLayer
ConvBaseLayer	gserver/layers/ConvBaseLayer.h	/^class ConvBaseLayer : public Layer {$/;"	c	namespace:paddle
ConvOperator	gserver/layers/ConvOperator.cpp	/^ConvOperator::ConvOperator(const OperatorConfig &config, bool useGpu)$/;"	f	class:paddle::ConvOperator
ConvOperator	gserver/layers/ConvOperator.cpp	/^class ConvOperator : public Operator {$/;"	c	namespace:paddle	file:
ConvProjection	gserver/layers/ConvProjection.cpp	/^ConvProjection::ConvProjection(const ProjectionConfig &config,$/;"	f	class:paddle::ConvProjection
ConvProjection	gserver/layers/ConvProjection.h	/^class ConvProjection : public Projection {$/;"	c	namespace:paddle
ConvShiftLayer	gserver/layers/ConvShiftLayer.cpp	/^  explicit ConvShiftLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::ConvShiftLayer
ConvShiftLayer	gserver/layers/ConvShiftLayer.cpp	/^class ConvShiftLayer : public Layer {$/;"	c	namespace:paddle	file:
ConvexCombinationLayer	gserver/layers/ConvexCombinationLayer.cpp	/^  explicit ConvexCombinationLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::ConvexCombinationLayer
ConvexCombinationLayer	gserver/layers/ConvexCombinationLayer.cpp	/^class ConvexCombinationLayer : public Layer {$/;"	c	namespace:paddle	file:
CoordIterator	gserver/layers/MDLstmLayer.cpp	/^  CoordIterator(std::vector<int> dim, std::vector<bool> directions)$/;"	f	class:paddle::CoordIterator
CoordIterator	gserver/layers/MDLstmLayer.cpp	/^class CoordIterator {$/;"	c	namespace:paddle	file:
CopyInfo	gserver/layers/MultiplexLayer.cpp	/^    CopyInfo(int inStartIdx, int inLength, int inCopyIdx)$/;"	f	struct:paddle::MultiplexLayer::CopyInfo
CopyInfo	gserver/layers/MultiplexLayer.cpp	/^  struct CopyInfo {$/;"	s	class:paddle::MultiplexLayer	file:
CopyToCpu	math/ExecViaCpu.h	/^  explicit CopyToCpu(Arg& arg) : arg_(arg) {}$/;"	f	class:paddle::CopyToCpu
CopyToCpu	math/ExecViaCpu.h	/^  explicit CopyToCpu(IVector& arg) : arg_(arg) {$/;"	f	class:paddle::CopyToCpu
CopyToCpu	math/ExecViaCpu.h	/^  explicit CopyToCpu(Matrix& arg) : arg_(arg) {$/;"	f	class:paddle::CopyToCpu
CopyToCpu	math/ExecViaCpu.h	/^  explicit CopyToCpu(const IVector& arg) : arg_(arg) {$/;"	f	class:paddle::CopyToCpu
CopyToCpu	math/ExecViaCpu.h	/^  explicit CopyToCpu(const Matrix& arg) : arg_(arg) {$/;"	f	class:paddle::CopyToCpu
CopyToCpu	math/ExecViaCpu.h	/^class CopyToCpu {$/;"	c	namespace:paddle
CopyToCpu	math/ExecViaCpu.h	/^class CopyToCpu<IVector> {$/;"	c	namespace:paddle
CopyToCpu	math/ExecViaCpu.h	/^class CopyToCpu<Matrix> {$/;"	c	namespace:paddle
CopyToCpu	math/ExecViaCpu.h	/^class CopyToCpu<const IVector> {$/;"	c	namespace:paddle
CopyToCpu	math/ExecViaCpu.h	/^class CopyToCpu<const Matrix> {$/;"	c	namespace:paddle
CopyToCpu	math/tests/TensorCheck.h	/^  explicit CopyToCpu(const CpuMatrix& arg) : arg_(arg) {}$/;"	f	class:autotest::CopyToCpu
CopyToCpu	math/tests/TensorCheck.h	/^  explicit CopyToCpu(const CpuVectorT<T>& arg) : arg_(arg) {}$/;"	f	class:autotest::CopyToCpu
CopyToCpu	math/tests/TensorCheck.h	/^  explicit CopyToCpu(const GpuMatrix& arg)$/;"	f	class:autotest::CopyToCpu
CopyToCpu	math/tests/TensorCheck.h	/^  explicit CopyToCpu(const GpuVectorT<T>& arg) : arg_(arg.getSize()) {$/;"	f	class:autotest::CopyToCpu
CopyToCpu	math/tests/TensorCheck.h	/^  explicit CopyToCpu(const Matrix& arg)$/;"	f	class:autotest::CopyToCpu
CopyToCpu	math/tests/TensorCheck.h	/^  explicit CopyToCpu(const VectorT<T>& arg) : arg_(arg.getSize()) {$/;"	f	class:autotest::CopyToCpu
CopyToCpu	math/tests/TensorCheck.h	/^class CopyToCpu<CpuMatrix> {$/;"	c	namespace:autotest
CopyToCpu	math/tests/TensorCheck.h	/^class CopyToCpu<CpuVectorT<T>> {$/;"	c	namespace:autotest
CopyToCpu	math/tests/TensorCheck.h	/^class CopyToCpu<GpuMatrix> {$/;"	c	namespace:autotest
CopyToCpu	math/tests/TensorCheck.h	/^class CopyToCpu<GpuVectorT<T>> {$/;"	c	namespace:autotest
CopyToCpu	math/tests/TensorCheck.h	/^class CopyToCpu<Matrix> {$/;"	c	namespace:autotest
CopyToCpu	math/tests/TensorCheck.h	/^class CopyToCpu<VectorT<T>> {$/;"	c	namespace:autotest
CosSimBackward	function/CosSimOp.cpp	/^void CosSimBackward<DEVICE_TYPE_CPU>(const CpuMatrix& out_grad,$/;"	f	namespace:paddle
CosSimBackwardFunc	function/CosSimOp.cpp	/^class CosSimBackwardFunc : public FunctionBase {$/;"	c	namespace:paddle	file:
CosSimForward	function/CosSimOp.cpp	/^void CosSimForward<DEVICE_TYPE_CPU>(CpuMatrix& out_mat,$/;"	f	namespace:paddle
CosSimForwardFunc	function/CosSimOp.cpp	/^class CosSimForwardFunc : public FunctionBase {$/;"	c	namespace:paddle	file:
CosSimLayer	gserver/layers/CosSimLayer.h	/^  explicit CosSimLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::CosSimLayer
CosSimLayer	gserver/layers/CosSimLayer.h	/^class CosSimLayer : public Layer {$/;"	c	namespace:paddle
CosSimVecMatLayer	gserver/layers/CosSimVecMatLayer.cpp	/^  explicit CosSimVecMatLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::CosSimVecMatLayer
CosSimVecMatLayer	gserver/layers/CosSimVecMatLayer.cpp	/^class CosSimVecMatLayer : public Layer {$/;"	c	namespace:paddle	file:
CostLayer	gserver/layers/CostLayer.h	/^  explicit CostLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::CostLayer
CostLayer	gserver/layers/CostLayer.h	/^class CostLayer : public Layer {$/;"	c	namespace:paddle
CostLayerPtr	gserver/layers/CostLayer.h	/^typedef std::shared_ptr<CostLayer> CostLayerPtr;$/;"	t	namespace:paddle
Count	scripts/cpplint.py	/^    def Count(self):$/;"	m	class:_FunctionState
CpuAllocator	math/Allocator.h	/^class CpuAllocator : public Allocator {$/;"	c	namespace:paddle
CpuGpuVector	math/Vector.h	/^typedef CpuGpuVectorT<real> CpuGpuVector;$/;"	t	namespace:paddle
CpuGpuVectorPtr	math/Vector.h	/^typedef std::shared_ptr<CpuGpuVector> CpuGpuVectorPtr;$/;"	t	namespace:paddle
CpuGpuVectorT	math/Vector.cpp	/^CpuGpuVectorT<T>::CpuGpuVectorT(CpuGpuVectorT<T>& src,$/;"	f	class:paddle::CpuGpuVectorT
CpuGpuVectorT	math/Vector.cpp	/^CpuGpuVectorT<T>::CpuGpuVectorT(const std::shared_ptr<VectorT<T>>& src)$/;"	f	class:paddle::CpuGpuVectorT
CpuGpuVectorT	math/Vector.cpp	/^CpuGpuVectorT<T>::CpuGpuVectorT(size_t size, T* data, bool useGpu)$/;"	f	class:paddle::CpuGpuVectorT
CpuGpuVectorT	math/Vector.cpp	/^CpuGpuVectorT<T>::CpuGpuVectorT(size_t size, bool useGpu) : sync_(nullptr) {$/;"	f	class:paddle::CpuGpuVectorT
CpuGpuVectorT	math/Vector.h	/^class CpuGpuVectorT {$/;"	c	namespace:paddle
CpuIVector	math/Vector.h	/^typedef CpuVectorT<int> CpuIVector;$/;"	t	namespace:paddle
CpuIVectorPtr	math/Vector.h	/^typedef std::shared_ptr<CpuIVector> CpuIVectorPtr;$/;"	t	namespace:paddle
CpuMatrix	math/Matrix.cpp	/^CpuMatrix::CpuMatrix(size_t height, size_t width, bool trans)$/;"	f	class:paddle::CpuMatrix
CpuMatrix	math/Matrix.h	/^  CpuMatrix(CpuMemHandlePtr dataHandle,$/;"	f	class:paddle::CpuMatrix
CpuMatrix	math/Matrix.h	/^  CpuMatrix(real* data, size_t height, size_t width, bool trans = false)$/;"	f	class:paddle::CpuMatrix
CpuMatrix	math/Matrix.h	/^  CpuMatrix(real* data,$/;"	f	class:paddle::CpuMatrix
CpuMatrix	math/Matrix.h	/^class CpuMatrix : public Matrix {$/;"	c	namespace:paddle
CpuMatrixPtr	math/Matrix.h	/^typedef std::shared_ptr<CpuMatrix> CpuMatrixPtr;$/;"	t	namespace:paddle
CpuMemHandlePtr	math/MemoryHandle.h	/^typedef std::shared_ptr<CpuMemoryHandle> CpuMemHandlePtr;$/;"	t	namespace:paddle
CpuMemoryHandle	math/MemoryHandle.cpp	/^CpuMemoryHandle::CpuMemoryHandle(size_t size) : MemoryHandle(size) {$/;"	f	class:paddle::CpuMemoryHandle
CpuMemoryHandle	math/MemoryHandle.h	/^class CpuMemoryHandle : public MemoryHandle {$/;"	c	namespace:paddle
CpuSparseMatrix	math/CpuSparseMatrix.cpp	/^CpuSparseMatrix::CpuSparseMatrix(CpuMemHandlePtr dataHandle,$/;"	f	class:paddle::CpuSparseMatrix
CpuSparseMatrix	math/CpuSparseMatrix.cpp	/^CpuSparseMatrix::CpuSparseMatrix(real* data,$/;"	f	class:paddle::CpuSparseMatrix
CpuSparseMatrix	math/CpuSparseMatrix.cpp	/^CpuSparseMatrix::CpuSparseMatrix(size_t height,$/;"	f	class:paddle::CpuSparseMatrix
CpuSparseMatrix	math/CpuSparseMatrix.h	/^class CpuSparseMatrix : public Matrix {$/;"	c	namespace:paddle
CpuSparseMatrixPtr	math/Matrix.h	/^typedef std::shared_ptr<CpuSparseMatrix> CpuSparseMatrixPtr;$/;"	t	namespace:paddle
CpuVector	math/Vector.h	/^typedef CpuVectorT<real> CpuVector;$/;"	t	namespace:paddle
CpuVectorPtr	math/Vector.h	/^typedef std::shared_ptr<CpuVector> CpuVectorPtr;$/;"	t	namespace:paddle
CpuVectorT	math/Vector.cpp	/^CpuVectorT<T>::CpuVectorT(const VectorT<T>& src)$/;"	f	class:paddle::CpuVectorT
CpuVectorT	math/Vector.cpp	/^CpuVectorT<T>::CpuVectorT(size_t size)$/;"	f	class:paddle::CpuVectorT
CpuVectorT	math/Vector.h	/^  CpuVectorT(size_t size, MemoryHandlePtr memoryHandle, size_t offset)$/;"	f	class:paddle::CpuVectorT
CpuVectorT	math/Vector.h	/^  CpuVectorT(size_t size, T* data) : VectorT<T>(size, data, false) {}$/;"	f	class:paddle::CpuVectorT
CpuVectorT	math/Vector.h	/^class CpuVectorT : public VectorT<T> {$/;"	c	namespace:paddle
CreateMode	gserver/gradientmachines/GradientMachine.h	/^  enum CreateMode {$/;"	g	class:paddle::GradientMachine
CrossMapNormal	function/CrossMapNormalOp.cpp	/^void CrossMapNormal<DEVICE_TYPE_CPU>(real* outputs,$/;"	f	namespace:paddle
CrossMapNormalFunc	function/CrossMapNormalOp.cpp	/^class CrossMapNormalFunc : public FunctionBase {$/;"	c	namespace:paddle	file:
CrossMapNormalGrad	function/CrossMapNormalOp.cpp	/^void CrossMapNormalGrad<DEVICE_TYPE_CPU>(real* inputsGrad,$/;"	f	namespace:paddle
CrossMapNormalGradFunc	function/CrossMapNormalOp.cpp	/^class CrossMapNormalGradFunc : public FunctionBase {$/;"	c	namespace:paddle	file:
CudaHostAllocator	math/Allocator.h	/^class CudaHostAllocator : public Allocator {$/;"	c	namespace:paddle
CudnnBatchNormLayer	gserver/layers/CudnnBatchNormLayer.h	/^  explicit CudnnBatchNormLayer(const LayerConfig& config)$/;"	f	class:paddle::CudnnBatchNormLayer
CudnnBatchNormLayer	gserver/layers/CudnnBatchNormLayer.h	/^class CudnnBatchNormLayer : public BatchNormBaseLayer {$/;"	c	namespace:paddle
CudnnConvLayer	gserver/layers/CudnnConvLayer.h	/^  explicit CudnnConvLayer(const LayerConfig& config) : ConvBaseLayer(config) {}$/;"	f	class:paddle::CudnnConvLayer
CudnnConvLayer	gserver/layers/CudnnConvLayer.h	/^class CudnnConvLayer : public ConvBaseLayer {$/;"	c	namespace:paddle
CudnnPoolLayer	gserver/layers/CudnnPoolLayer.cpp	/^CudnnPoolLayer::CudnnPoolLayer(const LayerConfig &config) : PoolLayer(config) {$/;"	f	class:paddle::CudnnPoolLayer
CudnnPoolLayer	gserver/layers/CudnnPoolLayer.h	/^class CudnnPoolLayer : public PoolLayer {$/;"	c	namespace:paddle
CustomStackTrace	utils/CustomStackTrace.h	/^class CustomStackTrace {$/;"	c	namespace:paddle
DATA_AT_CPU	math/Vector.h	/^  enum SyncedFlag { DATA_AT_CPU = 0, DATA_AT_GPU = 1, SYNCED = 2 };$/;"	e	enum:paddle::CpuGpuVectorT::SyncedFlag
DATA_AT_GPU	math/Vector.h	/^  enum SyncedFlag { DATA_AT_CPU = 0, DATA_AT_GPU = 1, SYNCED = 2 };$/;"	e	enum:paddle::CpuGpuVectorT::SyncedFlag
DBG	utils/Logging.h	43;"	d
DEBUG_LEVEL	utils/Logging.h	42;"	d
DEFAULT_AVG_WIDTH	math/CpuSparseMatrix.cpp	/^const size_t CpuSparseMatrix::DEFAULT_AVG_WIDTH;$/;"	m	class:paddle::CpuSparseMatrix	file:
DEFAULT_AVG_WIDTH	math/CpuSparseMatrix.h	/^  static const size_t DEFAULT_AVG_WIDTH = 20;$/;"	m	class:paddle::CpuSparseMatrix
DEFINE_STRING_CONVERSION	utils/StringUtil.h	72;"	d
DEINIT	trainer/tests/picojson.h	247;"	d
DEINIT	trainer/tests/picojson.h	254;"	d
DEVICE_TYPE_CPU	function/TensorType.h	/^  DEVICE_TYPE_CPU = 1,$/;"	e	enum:paddle::DeviceType
DEVICE_TYPE_GPU	function/TensorType.h	/^  DEVICE_TYPE_GPU = 2$/;"	e	enum:paddle::DeviceType
DEVICE_TYPE_UNSPECIFIED	function/TensorType.h	/^  DEVICE_TYPE_UNSPECIFIED = 0,$/;"	e	enum:paddle::DeviceType
DISABLE_COPY	utils/Common.h	22;"	d
DIVUP	cuda/include/hl_base.h	42;"	d
DIY_CALC_PROB_SYMBOL_NAME	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^static const char* DIY_CALC_PROB_SYMBOL_NAME = "calc_prob";$/;"	v	file:
DIY_FINISH_CALC_PROB_SYMBOL_NAME	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^static const char* DIY_FINISH_CALC_PROB_SYMBOL_NAME = "finish_calc_prob";$/;"	v	file:
DIY_START_CALC_PROB_SYMBOL_NAME	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^static const char* DIY_START_CALC_PROB_SYMBOL_NAME = "start_calc_prob";$/;"	v	file:
DYNAMIC_LOAD_CUBLAS_V2_WRAP	cuda/src/hl_cuda_cublas.cc	56;"	d	file:
DYNAMIC_LOAD_CUBLAS_V2_WRAP	cuda/src/hl_cuda_cublas.cc	84;"	d	file:
DYNAMIC_LOAD_CUBLAS_WRAP	cuda/src/hl_cuda_cublas.cc	36;"	d	file:
DYNAMIC_LOAD_CUBLAS_WRAP	cuda/src/hl_cuda_cublas.cc	47;"	d	file:
DYNAMIC_LOAD_CUBLAS_WRAP	cuda/src/hl_cuda_cublas.cc	83;"	d	file:
DYNAMIC_LOAD_CUDNN_WRAP	cuda/src/hl_cuda_cudnn.cc	44;"	d	file:
DYNAMIC_LOAD_CUDNN_WRAP	cuda/src/hl_cuda_cudnn.cc	57;"	d	file:
DYNAMIC_LOAD_CURAND_WRAP	cuda/src/hl_cuda_device.cc	44;"	d	file:
DYNAMIC_LOAD_CURAND_WRAP	cuda/src/hl_cuda_device.cc	55;"	d	file:
DYNAMIC_LOAD_CURAND_WRAP	cuda/src/hl_cuda_device.cc	77;"	d	file:
DYNAMIC_LOAD_WARPCTC_WRAP	cuda/src/hl_warpctc_wrap.cc	32;"	d	file:
DYNAMIC_LOAD_WARPCTC_WRAP	cuda/src/hl_warpctc_wrap.cc	50;"	d	file:
DataBatch	gserver/dataproviders/DataProvider.h	/^  DataBatch() : size_(0) { data_.clear(); }$/;"	f	class:paddle::DataBatch
DataBatch	gserver/dataproviders/DataProvider.h	/^class DataBatch {$/;"	c	namespace:paddle
DataBatchPtr	gserver/dataproviders/DataProvider.h	/^typedef std::shared_ptr<DataBatch> DataBatchPtr;$/;"	t	namespace:paddle
DataIn	gserver/tests/test_NetworkCompare.cpp	/^struct DataIn {$/;"	s	file:
DataLayer	gserver/layers/DataLayer.h	/^  explicit DataLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::DataLayer
DataLayer	gserver/layers/DataLayer.h	/^class DataLayer : public Layer {$/;"	c	namespace:paddle
DataLayerPtr	gserver/layers/DataLayer.h	/^typedef std::shared_ptr<DataLayer> DataLayerPtr;$/;"	t	namespace:paddle
DataNormLayer	gserver/layers/DataNormLayer.h	/^  explicit DataNormLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::DataNormLayer
DataNormLayer	gserver/layers/DataNormLayer.h	/^class DataNormLayer : public Layer {$/;"	c	namespace:paddle
DataOut	gserver/tests/test_NetworkCompare.cpp	/^struct DataOut {$/;"	s	file:
DataProvider	gserver/dataproviders/DataProvider.h	/^  DataProvider(const DataConfig& config, bool useGpu)$/;"	f	class:paddle::DataProvider
DataProvider	gserver/dataproviders/DataProvider.h	/^class DataProvider {$/;"	c	namespace:paddle
DataProviderConverter	py_paddle/dataprovider_converter.py	/^class DataProviderConverter(object):$/;"	c
DataProviderGroup	gserver/dataproviders/DataProviderGroup.h	/^DataProviderGroup<T>::DataProviderGroup(const DataConfig& config, bool useGpu)$/;"	f	class:paddle::DataProviderGroup
DataProviderGroup	gserver/dataproviders/DataProviderGroup.h	/^class DataProviderGroup : public DataProvider {$/;"	c	namespace:paddle
DataProviderPtr	gserver/dataproviders/DataProvider.h	/^typedef std::shared_ptr<DataProvider> DataProviderPtr;$/;"	t	namespace:paddle
DataProviderWrapperConverter	py_paddle/util.py	/^class DataProviderWrapperConverter(object):$/;"	c
DataType	function/TensorType.h	/^struct DataType<double> {$/;"	s	namespace:paddle
DataType	function/TensorType.h	/^struct DataType<float> {$/;"	s	namespace:paddle
DataType	function/TensorType.h	/^struct DataType<int> {$/;"	s	namespace:paddle
DecayedAdagradParameterOptimizer	math/tests/OriginalOptimizerApi.h	/^void DecayedAdagradParameterOptimizer(const VectorPtr vecs[],$/;"	f
DecayedAdagradParameterOptimizer	parameter/FirstOrderOptimizer.h	/^  explicit DecayedAdagradParameterOptimizer(const OptimizationConfig& optConfig)$/;"	f	class:paddle::DecayedAdagradParameterOptimizer
DecayedAdagradParameterOptimizer	parameter/FirstOrderOptimizer.h	/^class DecayedAdagradParameterOptimizer : public ParameterOptimizer {$/;"	c	namespace:paddle
DenseScanner	gserver/dataproviders/PyDataProvider2.cpp	/^  explicit DenseScanner(SlotHeader* ptr) : IFieldScanner(ptr), height_(0) {}$/;"	f	class:paddle::DenseScanner
DenseScanner	gserver/dataproviders/PyDataProvider2.cpp	/^class DenseScanner : public IFieldScanner {$/;"	c	namespace:paddle	file:
DenseScanner	py_paddle/dataprovider_converter.py	/^class DenseScanner(IScanner):$/;"	c
DenseValueConverter	py_paddle/util.py	/^    class DenseValueConverter(object):$/;"	c	class:DataProviderWrapperConverter
Deprecated	utils/Util.h	/^  explicit Deprecated(const std::string& msg = "") {$/;"	f	class:paddle::Deprecated
Deprecated	utils/Util.h	/^class Deprecated {$/;"	c	namespace:paddle
DeviceType	function/TensorType.h	/^enum DeviceType {$/;"	g	namespace:paddle
DictHelper	utils/PythonUtil.h	/^  explicit DictHelper(PyObject* d) : dict_(d) {}$/;"	f	class:paddle::py::DictHelper
DictHelper	utils/PythonUtil.h	/^  explicit DictHelper(const PyObjectPtr& d) : dict_(d.get()) {}$/;"	f	class:paddle::py::DictHelper
DictHelper	utils/PythonUtil.h	/^class DictHelper {$/;"	c	namespace:paddle::py
DiscreteExpLRS	parameter/LearningRateScheduler.cpp	/^  explicit DiscreteExpLRS(const OptimizationConfig& config) : BaseLRS(config) {}$/;"	f	class:paddle::DiscreteExpLRS
DiscreteExpLRS	parameter/LearningRateScheduler.cpp	/^class DiscreteExpLRS : public BaseLRS {$/;"	c	namespace:paddle	file:
DiyCalcProbCallback	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^typedef real (*DiyCalcProbCallback)($/;"	t	namespace:paddle	file:
DiyStartCalcProbCallback	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^typedef int (*DiyStartCalcProbCallback)(size_t nNodes, int* nodes);$/;"	t	namespace:paddle	file:
DiyStopCalcProbCallback	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^typedef void (*DiyStopCalcProbCallback)(int handler);$/;"	t	namespace:paddle	file:
DotMulOperator	gserver/layers/DotMulOperator.cpp	/^DotMulOperator::DotMulOperator(const OperatorConfig& config, bool useGpu)$/;"	f	class:paddle::DotMulOperator
DotMulOperator	gserver/layers/DotMulOperator.cpp	/^class DotMulOperator : public Operator {$/;"	c	namespace:paddle	file:
DotMulProjection	gserver/layers/DotMulProjection.cpp	/^DotMulProjection::DotMulProjection(const ProjectionConfig& config,$/;"	f	class:paddle::DotMulProjection
DotMulProjection	gserver/layers/DotMulProjection.cpp	/^class DotMulProjection : public Projection {$/;"	c	namespace:paddle	file:
DoubleBuffer	gserver/dataproviders/DataProvider.cpp	/^DoubleBuffer::DoubleBuffer(DataProvider* dataPool,$/;"	f	class:paddle::DoubleBuffer
DoubleBuffer	gserver/dataproviders/DataProvider.h	/^class DoubleBuffer {$/;"	c	namespace:paddle
DropCallback	gserver/gradientmachines/RecurrentGradientMachine.h	/^      DropCallback;$/;"	t	class:paddle::RecurrentGradientMachine
DummyDataProvider	gserver/dataproviders/DataProvider.h	/^  DummyDataProvider(const DataConfig& config, bool useGpu)$/;"	f	class:paddle::DummyDataProvider
DummyDataProvider	gserver/dataproviders/DataProvider.h	/^class DummyDataProvider : public DataProvider {$/;"	c	namespace:paddle
DummyEvaluator	gserver/evaluators/Evaluator.h	/^  DummyEvaluator() {}$/;"	f	class:paddle::DummyEvaluator
DummyEvaluator	gserver/evaluators/Evaluator.h	/^class DummyEvaluator : public Evaluator {$/;"	c	namespace:paddle
DummyOptimizer	parameter/FirstOrderOptimizer.h	/^  explicit DummyOptimizer(const OptimizationConfig& optConfig)$/;"	f	class:paddle::DummyOptimizer
DummyOptimizer	parameter/FirstOrderOptimizer.h	/^class DummyOptimizer : public ParameterOptimizer {$/;"	c	namespace:paddle
DumpCallback	utils/CustomStackTrace.h	/^      DumpCallback;$/;"	t	class:paddle::CustomStackTrace
END_DEFINE_ACTIVATION	gserver/activations/ActivationFunction.cpp	53;"	d	file:
EPS	gserver/layers/BatchNormalizationLayer.cpp	/^const real BatchNormalizationLayer::EPS = 1E-5;$/;"	m	class:paddle::BatchNormalizationLayer	file:
EPS	gserver/layers/BatchNormalizationLayer.h	/^  static const real EPS;$/;"	m	class:paddle::BatchNormalizationLayer
EPS	gserver/layers/CudnnBatchNormLayer.cpp	/^const double CudnnBatchNormLayer::EPS = 1E-5;$/;"	m	class:paddle::CudnnBatchNormLayer	file:
EPS	gserver/layers/CudnnBatchNormLayer.h	/^  static const double EPS;$/;"	m	class:paddle::CudnnBatchNormLayer
EPSILON	math/tests/test_SIMDFunctions.cpp	/^static constexpr float EPSILON = 1e-5;$/;"	v	file:
EXCEPTS_H_	utils/Excepts.h	16;"	d
EXPRESSION_PERFORMANCE	math/tests/PerfUtils.h	20;"	d
EXPRESSION_PERFORMANCE	math/tests/PerfUtils.h	27;"	d
EXP_MAX	gserver/layers/LinearChainCTC.cpp	/^const real EXP_MAX = std::numeric_limits<real>::max();$/;"	m	namespace:paddle	file:
EXP_MAX_INPUT	cuda/include/hl_base.h	34;"	d
EXP_MIN	gserver/layers/LinearChainCTC.cpp	/^const real EXP_MIN = std::numeric_limits<real>::min();$/;"	m	namespace:paddle	file:
EachStepCallback	gserver/gradientmachines/RecurrentGradientMachine.h	/^  typedef std::function<void(int)> EachStepCallback;$/;"	t	class:paddle::RecurrentGradientMachine
Element	math/SparseMatrix.h	/^    Element(int rowIn, int colIn, real valIn)$/;"	f	struct:paddle::GpuSparseMatrix::Element
Element	math/SparseMatrix.h	/^  struct Element {$/;"	s	class:paddle::GpuSparseMatrix
End	scripts/cpplint.py	/^    def End(self):$/;"	m	class:_FunctionState
EosFrameLine	gserver/gradientmachines/RecurrentGradientMachine.h	/^  struct EosFrameLine {$/;"	s	class:paddle::RecurrentGradientMachine
EosIdCheckLayer	gserver/layers/EosIdCheckLayer.cpp	/^  explicit EosIdCheckLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::EosIdCheckLayer
EosIdCheckLayer	gserver/layers/EosIdCheckLayer.cpp	/^class EosIdCheckLayer : public Layer {$/;"	c	namespace:paddle	file:
Error	scripts/cpplint.py	/^def Error(filename, linenum, category, confidence, message):$/;"	f
Error	utils/Error.h	/^  Error() {}$/;"	f	class:paddle::Error
Error	utils/Error.h	/^  explicit Error(const char* fmt, ...) {$/;"	f	class:paddle::Error
Error	utils/Error.h	/^class Error {$/;"	c	namespace:paddle
Evaluator	api/Evaluator.cpp	/^Evaluator::Evaluator() : m(new EvaluatorPrivate()) {}$/;"	f	class:Evaluator
Evaluator	api/PaddleAPI.h	/^class Evaluator {$/;"	c
Evaluator	gserver/evaluators/Evaluator.h	/^  Evaluator() : numSamples_(0), totalScore_(0) {}$/;"	f	class:paddle::Evaluator
Evaluator	gserver/evaluators/Evaluator.h	/^class Evaluator {$/;"	c	namespace:paddle
EvaluatorPrivate	api/PaddleAPIPrivate.h	/^  EvaluatorPrivate() : rawPtr(nullptr) {}$/;"	f	struct:EvaluatorPrivate
EvaluatorPrivate	api/PaddleAPIPrivate.h	/^struct EvaluatorPrivate {$/;"	s
ExecFunc	math/Vector.h	/^  typedef std::function<void(CpuVectorT<T>& vec)> ExecFunc;$/;"	t	class:paddle::ParallelCpuVectorT
ExecFunc	parameter/Parameter.h	/^  typedef std::function<void(const VectorPtr vecs[])> ExecFunc;$/;"	t	class:paddle::Parameter
ExecFunc	pserver/ParameterServer2.h	/^  typedef std::function<void(int64_t blockId, const VectorPtr vecs[])> ExecFunc;$/;"	t	class:paddle::ParameterServer2
ExpLRS	parameter/LearningRateScheduler.cpp	/^  explicit ExpLRS(const OptimizationConfig& config) : BaseLRS(config) {}$/;"	f	class:paddle::ExpLRS
ExpLRS	parameter/LearningRateScheduler.cpp	/^class ExpLRS : public BaseLRS {$/;"	c	namespace:paddle	file:
ExpandConvBaseLayer	gserver/layers/ExpandConvBaseLayer.h	/^  explicit ExpandConvBaseLayer(const LayerConfig& config)$/;"	f	class:paddle::ExpandConvBaseLayer
ExpandConvBaseLayer	gserver/layers/ExpandConvBaseLayer.h	/^class ExpandConvBaseLayer : public ConvBaseLayer {$/;"	c	namespace:paddle
ExpandConvLayer	gserver/layers/ExpandConvLayer.h	/^  explicit ExpandConvLayer(const LayerConfig& config)$/;"	f	class:paddle::ExpandConvLayer
ExpandConvLayer	gserver/layers/ExpandConvLayer.h	/^class ExpandConvLayer : public ExpandConvBaseLayer {$/;"	c	namespace:paddle
ExpandConvTransLayer	gserver/layers/ExpandConvTransLayer.h	/^  explicit ExpandConvTransLayer(const LayerConfig& config)$/;"	f	class:paddle::ExpandConvTransLayer
ExpandConvTransLayer	gserver/layers/ExpandConvTransLayer.h	/^class ExpandConvTransLayer : public ExpandConvBaseLayer {$/;"	c	namespace:paddle
ExpandLayer	gserver/layers/ExpandLayer.h	/^  explicit ExpandLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::ExpandLayer
ExpandLayer	gserver/layers/ExpandLayer.h	/^class ExpandLayer : public Layer {$/;"	c	namespace:paddle
ExpandLevel	gserver/layers/ExpandLayer.h	/^  enum ExpandLevel { kNonSeq = 0, kSeq = 1 };$/;"	g	class:paddle::ExpandLayer
ExpectingFunctionArgs	scripts/cpplint.py	/^def ExpectingFunctionArgs(clean_lines, linenum):$/;"	f
Extension	scripts/cpplint.py	/^    def Extension(self):$/;"	m	class:FileInfo
FLOAT_VALUE	math/Matrix.h	/^enum SparseValueType { NO_VALUE = 0, FLOAT_VALUE = 1 };$/;"	e	enum:paddle::SparseValueType
FN	gserver/evaluators/Evaluator.h	/^    double FN;$/;"	m	struct:paddle::PrecisionRecallEvaluator::StatsInfo
FORWARD_LOOP	math/Matrix.cpp	3330;"	d	file:
FOR_EACH	utils/Util.h	45;"	d
FOR_EACH_R	utils/Util.h	59;"	d
FOR_TIMING	utils/Stat.h	252;"	d
FOR_TIMING	utils/Stat.h	256;"	d
FP	gserver/evaluators/Evaluator.h	/^    double FP;$/;"	m	struct:paddle::PrecisionRecallEvaluator::StatsInfo
FUNC_NAME	function/Function.h	188;"	d
F_RDMA	pserver/SocketChannel.h	/^  F_RDMA = 2,$/;"	e	enum:paddle::ChannelType
F_TCP	pserver/SocketChannel.h	/^  F_TCP = 1,$/;"	e	enum:paddle::ChannelType
FeatureMapExpandLayer	gserver/layers/FeatureMapExpandLayer.cpp	/^  explicit FeatureMapExpandLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::FeatureMapExpandLayer
FeatureMapExpandLayer	gserver/layers/FeatureMapExpandLayer.cpp	/^class FeatureMapExpandLayer : public Layer {$/;"	c	namespace:paddle	file:
FileInfo	scripts/cpplint.py	/^class FileInfo(object):$/;"	c
FilesBelongToSameModule	scripts/cpplint.py	/^def FilesBelongToSameModule(filename_cc, filename_h):$/;"	f
FindCheckMacro	scripts/cpplint.py	/^def FindCheckMacro(line):$/;"	f
FindEndOfExpressionInLine	scripts/cpplint.py	/^def FindEndOfExpressionInLine(line, startpos, stack):$/;"	f
FindHeader	scripts/cpplint.py	/^    def FindHeader(self, header):$/;"	m	class:_IncludeState
FindNextMultiLineCommentEnd	scripts/cpplint.py	/^def FindNextMultiLineCommentEnd(lines, lineix):$/;"	f
FindNextMultiLineCommentStart	scripts/cpplint.py	/^def FindNextMultiLineCommentStart(lines, lineix):$/;"	f
FindStartOfExpressionInLine	scripts/cpplint.py	/^def FindStartOfExpressionInLine(line, endpos, stack):$/;"	f
FlagCxx11Features	scripts/cpplint.py	/^def FlagCxx11Features(filename, clean_lines, linenum, error):$/;"	f
FloatArray	api/PaddleAPI.h	/^struct FloatArray {$/;"	s
FloatArray	api/Util.cpp	/^FloatArray::FloatArray(const float* b, const size_t l)$/;"	f	class:FloatArray
FullMatrixProjection	gserver/layers/FullMatrixProjection.cpp	/^FullMatrixProjection::FullMatrixProjection(const ProjectionConfig& config,$/;"	f	class:paddle::FullMatrixProjection
FullMatrixProjection	gserver/layers/FullMatrixProjection.h	/^class FullMatrixProjection : public Projection {$/;"	c	namespace:paddle
FullName	scripts/cpplint.py	/^    def FullName(self):$/;"	m	class:FileInfo
FullyConnectedLayer	gserver/layers/FullyConnectedLayer.h	/^  explicit FullyConnectedLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::FullyConnectedLayer
FullyConnectedLayer	gserver/layers/FullyConnectedLayer.h	/^class FullyConnectedLayer : public Layer {$/;"	c	namespace:paddle
FuncConfig	function/Function.h	/^class FuncConfig {$/;"	c	namespace:paddle
Function	function/FunctionTest.cpp	/^void Function(const BufferArgs& arguments) {$/;"	f	namespace:paddle
FunctionApi	function/FunctionTest.cpp	/^void FunctionApi<DEVICE_TYPE_CPU>(CpuMatrix& output, const CpuMatrix& input) {$/;"	f	namespace:paddle
FunctionApi	function/FunctionTest.cpp	/^void FunctionApi<DEVICE_TYPE_GPU>(GpuMatrix& output, const GpuMatrix& input) {$/;"	f	namespace:paddle
FunctionBase	function/Function.h	/^class FunctionBase {$/;"	c	namespace:paddle
FunctionCompare	function/FunctionTest.h	/^  FunctionCompare(const std::string& name, const FuncConfig& config)$/;"	f	class:paddle::FunctionCompare
FunctionCompare	function/FunctionTest.h	/^class FunctionCompare {$/;"	c	namespace:paddle
Functor	math/tests/test_ExecViaCpu.cpp	/^class Functor {$/;"	c	file:
GCC_VERSION	utils/Compiler.h	18;"	d
GCC_VERSION	utils/Compiler.h	21;"	d
GEMM	function/MulOp.cpp	23;"	d	file:
GEMM	function/MulOp.cpp	25;"	d	file:
GET	trainer/tests/picojson.h	312;"	d
GET	trainer/tests/picojson.h	338;"	d
GFLAGS_LIBRARIES	api/paddle_api_config.py	/^GFLAGS_LIBRARIES="\/home\/tianbing\/baidu\/idl\/paddle\/third_party\/install\/gflags\/lib\/libgflags.a"$/;"	v
GFLAGS_LOCATION	api/paddle_api_config.py	/^GFLAGS_LOCATION="\/home\/tianbing\/baidu\/idl\/paddle\/third_party\/install\/gflags\/lib\/libgflags.a"$/;"	v
GLOG_LIBRARIES	api/paddle_api_config.py	/^GLOG_LIBRARIES="\/home\/tianbing\/baidu\/idl\/paddle\/third_party\/install\/glog\/lib\/libglog.a"$/;"	v
GatedRecurrentLayer	gserver/layers/GatedRecurrentLayer.h	/^  explicit GatedRecurrentLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::GatedRecurrentLayer
GatedRecurrentLayer	gserver/layers/GatedRecurrentLayer.h	/^class GatedRecurrentLayer : public Layer, public GruCompute {$/;"	c	namespace:paddle
GatherAgentLayer	gserver/layers/AgentLayer.h	/^  explicit GatherAgentLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::GatherAgentLayer
GatherAgentLayer	gserver/layers/AgentLayer.h	/^class GatherAgentLayer : public Layer {$/;"	c	namespace:paddle
Generator	gserver/gradientmachines/RecurrentGradientMachine.h	/^  struct Generator {$/;"	s	class:paddle::RecurrentGradientMachine
GetCublasDsoHandle	cuda/src/hl_dso_loader.cc	/^void GetCublasDsoHandle(void** dso_handle) {$/;"	f
GetCudnnDsoHandle	cuda/src/hl_dso_loader.cc	/^void GetCudnnDsoHandle(void** dso_handle) {$/;"	f
GetCurandDsoHandle	cuda/src/hl_dso_loader.cc	/^void GetCurandDsoHandle(void** dso_handle) {$/;"	f
GetDsoHandleFromDefaultPath	cuda/src/hl_dso_loader.cc	/^static inline void GetDsoHandleFromDefaultPath(std::string& dso_path,$/;"	f	file:
GetDsoHandleFromSearchPath	cuda/src/hl_dso_loader.cc	/^static inline void GetDsoHandleFromSearchPath(const std::string& search_root,$/;"	f	file:
GetHeaderGuardCPPVariable	scripts/cpplint.py	/^def GetHeaderGuardCPPVariable(filename):$/;"	f
GetIndentLevel	scripts/cpplint.py	/^def GetIndentLevel(line):$/;"	f
GetLineWidth	scripts/cpplint.py	/^def GetLineWidth(line):$/;"	f
GetOutputLayer	gserver/layers/GetOutputLayer.cpp	/^  explicit GetOutputLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::GetOutputLayer
GetOutputLayer	gserver/layers/GetOutputLayer.cpp	/^class GetOutputLayer : public Layer {$/;"	c	namespace:paddle	file:
GetPreviousNonBlankLine	scripts/cpplint.py	/^def GetPreviousNonBlankLine(clean_lines, linenum):$/;"	f
GetTemplateArgs	scripts/cpplint.py	/^def GetTemplateArgs(clean_lines, linenum):$/;"	f
GetTraverseCallback	trainer/ThreadParameterUpdater.h	/^      GetTraverseCallback;$/;"	t	class:paddle::SgdThreadUpdater
GetWarpCTCDsoHandle	cuda/src/hl_dso_loader.cc	/^void GetWarpCTCDsoHandle(void** dso_handle) {$/;"	f
GpuAllocator	math/Allocator.h	/^class GpuAllocator : public Allocator {$/;"	c	namespace:paddle
GpuFuncWrapper	math/ExecViaCpu.h	/^class GpuFuncWrapper$/;"	c	namespace:paddle::detail
GpuFuncWrapper2	math/ExecViaCpu.h	/^class GpuFuncWrapper2$/;"	c	namespace:paddle::detail
GpuFuncWrapperBase	math/ExecViaCpu.h	/^class GpuFuncWrapperBase {$/;"	c	namespace:paddle::detail
GpuFuncWrapperImp	math/ExecViaCpu.h	/^class GpuFuncWrapperImp<false, false, true, F>$/;"	c	namespace:paddle::detail
GpuFuncWrapperImp	math/ExecViaCpu.h	/^class GpuFuncWrapperImp<false, true, false, R (*)(Args...)>$/;"	c	namespace:paddle::detail
GpuFuncWrapperImp	math/ExecViaCpu.h	/^class GpuFuncWrapperImp<true, false, false, R(Args...)>$/;"	c	namespace:paddle::detail
GpuFuncWrapperImp2	math/ExecViaCpu.h	/^class GpuFuncWrapperImp2<F, R (C::*)(Args...) const>$/;"	c	namespace:paddle::detail
GpuFuncWrapperImp2	math/ExecViaCpu.h	/^class GpuFuncWrapperImp2<F, R (C::*)(Args...)>$/;"	c	namespace:paddle::detail
GpuIVector	math/Vector.h	/^typedef GpuVectorT<int> GpuIVector;$/;"	t	namespace:paddle
GpuIVectorPtr	math/Vector.h	/^typedef std::shared_ptr<GpuIVector> GpuIVectorPtr;$/;"	t	namespace:paddle
GpuMatrix	math/Matrix.cpp	/^GpuMatrix::GpuMatrix(size_t height, size_t width, bool trans)$/;"	f	class:paddle::GpuMatrix
GpuMatrix	math/Matrix.h	/^  GpuMatrix(GpuMemHandlePtr dataHandle,$/;"	f	class:paddle::GpuMatrix
GpuMatrix	math/Matrix.h	/^  GpuMatrix(real* data, size_t height, size_t width, bool trans = false)$/;"	f	class:paddle::GpuMatrix
GpuMatrix	math/Matrix.h	/^  GpuMatrix(real* data,$/;"	f	class:paddle::GpuMatrix
GpuMatrix	math/Matrix.h	/^class GpuMatrix : public Matrix {$/;"	c	namespace:paddle
GpuMatrixPtr	math/Matrix.h	/^typedef std::shared_ptr<GpuMatrix> GpuMatrixPtr;$/;"	t	namespace:paddle
GpuMemHandlePtr	math/MemoryHandle.h	/^typedef std::shared_ptr<GpuMemoryHandle> GpuMemHandlePtr;$/;"	t	namespace:paddle
GpuMemoryHandle	math/MemoryHandle.cpp	/^GpuMemoryHandle::GpuMemoryHandle(size_t size) : MemoryHandle(size) {$/;"	f	class:paddle::GpuMemoryHandle
GpuMemoryHandle	math/MemoryHandle.h	/^class GpuMemoryHandle : public MemoryHandle {$/;"	c	namespace:paddle
GpuProfiler	utils/Stat.cpp	/^GpuProfiler::GpuProfiler(std::string statName, std::string info)$/;"	f	class:paddle::GpuProfiler
GpuSparseMatrix	math/SparseMatrix.cpp	/^GpuSparseMatrix::GpuSparseMatrix(GpuMemHandlePtr dataHandle,$/;"	f	class:paddle::GpuSparseMatrix
GpuSparseMatrix	math/SparseMatrix.cpp	/^GpuSparseMatrix::GpuSparseMatrix(hl_sparse_matrix_s_ptr sMatrix,$/;"	f	class:paddle::GpuSparseMatrix
GpuSparseMatrix	math/SparseMatrix.cpp	/^GpuSparseMatrix::GpuSparseMatrix(real* value,$/;"	f	class:paddle::GpuSparseMatrix
GpuSparseMatrix	math/SparseMatrix.cpp	/^GpuSparseMatrix::GpuSparseMatrix(size_t height,$/;"	f	class:paddle::GpuSparseMatrix
GpuSparseMatrix	math/SparseMatrix.h	/^class GpuSparseMatrix : public Matrix {$/;"	c	namespace:paddle
GpuSparseMatrixPtr	math/Matrix.h	/^typedef std::shared_ptr<GpuSparseMatrix> GpuSparseMatrixPtr;$/;"	t	namespace:paddle
GpuVector	math/Vector.h	/^typedef GpuVectorT<real> GpuVector;$/;"	t	namespace:paddle
GpuVectorPtr	math/Vector.h	/^typedef std::shared_ptr<GpuVector> GpuVectorPtr;$/;"	t	namespace:paddle
GpuVectorT	math/Vector.cpp	/^GpuVectorT<T>::GpuVectorT(size_t size)$/;"	f	class:paddle::GpuVectorT
GpuVectorT	math/Vector.h	/^  GpuVectorT(size_t size, GpuMemHandlePtr memHandle, size_t offset)$/;"	f	class:paddle::GpuVectorT
GpuVectorT	math/Vector.h	/^  GpuVectorT(size_t size, T* data) : VectorT<T>(size, data, true) {}$/;"	f	class:paddle::GpuVectorT
GpuVectorT	math/Vector.h	/^class GpuVectorT : public VectorT<T> {$/;"	c	namespace:paddle
GradBuffer	gserver/gradientmachines/MultiGradientMachine.h	/^struct GradBuffer {$/;"	s	namespace:paddle
GradientMachine	api/GradientMachine.cpp	/^GradientMachine::GradientMachine() : m(new GradientMachinePrivate()) {}$/;"	f	class:GradientMachine
GradientMachine	api/PaddleAPI.h	/^class GradientMachine {$/;"	c
GradientMachine	gserver/gradientmachines/GradientMachine.h	/^class GradientMachine {$/;"	c	namespace:paddle
GradientMachinePrivate	api/PaddleAPIPrivate.h	/^struct GradientMachinePrivate {$/;"	s
GradientMachinePtr	gserver/gradientmachines/GradientMachine.h	/^typedef std::shared_ptr<GradientMachine> GradientMachinePtr;$/;"	t	namespace:paddle
GradientMatchineCreateMode	api/PaddleAPI.h	/^enum GradientMatchineCreateMode {$/;"	g
GradientPrinter	gserver/evaluators/Evaluator.cpp	/^  GradientPrinter() {}$/;"	f	class:paddle::GradientPrinter
GradientPrinter	gserver/evaluators/Evaluator.cpp	/^class GradientPrinter : public Evaluator {$/;"	c	namespace:paddle	file:
GruCompute	gserver/layers/GruCompute.h	/^class GruCompute {$/;"	c	namespace:paddle
GruStepLayer	gserver/layers/GruStepLayer.cpp	/^  explicit GruStepLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::GruStepLayer
GruStepLayer	gserver/layers/GruStepLayer.cpp	/^class GruStepLayer : public Layer, public GruCompute {$/;"	c	namespace:paddle	file:
HAS_AVX	utils/CpuId.h	95;"	d
HAS_AVX2	utils/CpuId.h	96;"	d
HAS_AVX512	utils/CpuId.h	97;"	d
HAS_FMA3	utils/CpuId.h	93;"	d
HAS_FMA4	utils/CpuId.h	94;"	d
HAS_SIMD	utils/CpuId.h	65;"	d
HAS_SSE	utils/CpuId.h	87;"	d
HAS_SSE2	utils/CpuId.h	88;"	d
HAS_SSE3	utils/CpuId.h	89;"	d
HAS_SSE41	utils/CpuId.h	91;"	d
HAS_SSE42	utils/CpuId.h	92;"	d
HAS_SSSE3	utils/CpuId.h	90;"	d
HISTOGRAM_EXPONENT	math/Vector.h	/^    HISTOGRAM_EXPONENT = 0,$/;"	e	enum:paddle::VectorT::HistogramType
HL_ACTIVATION_END	cuda/include/hl_base.h	/^  HL_ACTIVATION_END$/;"	e	enum:__anon2
HL_ACTIVATION_FUNCTIONS_H_	cuda/include/hl_activation_functions.h	16;"	d
HL_ACTIVATION_LINEAR	cuda/include/hl_base.h	/^  HL_ACTIVATION_LINEAR = 3,$/;"	e	enum:__anon2
HL_ACTIVATION_RELU	cuda/include/hl_base.h	/^  HL_ACTIVATION_RELU = 1,$/;"	e	enum:__anon2
HL_ACTIVATION_SIGMOID	cuda/include/hl_base.h	/^  HL_ACTIVATION_SIGMOID = 0,$/;"	e	enum:__anon2
HL_ACTIVATION_TANH	cuda/include/hl_base.h	/^  HL_ACTIVATION_TANH = 2,$/;"	e	enum:__anon2
HL_AGGREGATE_H_	cuda/include/hl_aggregate.h	16;"	d
HL_AGGREGATE_STUB_H_	cuda/include/stub/hl_aggregate_stub.h	16;"	d
HL_AVX_FUNCTIONS_H_	cuda/include/hl_avx_functions.h	16;"	d
HL_BASE_H_	cuda/include/hl_base.h	16;"	d
HL_BATCH_TRANSPOSE_H_	cuda/include/hl_batch_transpose.h	16;"	d
HL_CNN_H_	cuda/include/hl_cnn.h	16;"	d
HL_CNN_STUB_H_	cuda/include/stub/hl_cnn_stub.h	16;"	d
HL_CUDA_CUBLAS_H_	cuda/include/hl_cuda_cublas.h	16;"	d
HL_CUDA_CUBLAS_STUB_H_	cuda/include/stub/hl_cuda_cublas_stub.h	16;"	d
HL_CUDA_CUDNN_H_	cuda/include/hl_cuda_cudnn.h	16;"	d
HL_CUDA_CUDNN_STUB_H_	cuda/include/stub/hl_cuda_cudnn_stub.h	16;"	d
HL_CUDA_H_	cuda/include/hl_cuda.h	16;"	d
HL_CUDA_STUB_H_	cuda/include/stub/hl_cuda_stub.h	16;"	d
HL_DSO_LOADER_H_	cuda/include/hl_dso_loader.h	16;"	d
HL_FLOAT_MAX	cuda/include/hl_base.h	21;"	d
HL_FLOAT_MIN	cuda/include/hl_base.h	22;"	d
HL_FLOAT_VALUE	cuda/include/hl_base.h	/^  HL_FLOAT_VALUE = 1,$/;"	e	enum:__anon8
HL_FUNCTIONS_H_	cuda/include/hl_functions.h	16;"	d
HL_GPU_H_	cuda/include/hl_gpu.h	16;"	d
HL_LSTM_H_	cuda/include/hl_lstm.h	16;"	d
HL_LSTM_STUB_H_	cuda/include/stub/hl_lstm_stub.h	16;"	d
HL_MATRIX_H_	cuda/include/hl_matrix.h	16;"	d
HL_MATRIX_STUB_H_	cuda/include/stub/hl_matrix_stub.h	16;"	d
HL_NO_VALUE	cuda/include/hl_base.h	/^  HL_NO_VALUE = 0, \/* matrix values only 0 or 1 *\/$/;"	e	enum:__anon8
HL_POOLING_AVERAGE	cuda/include/hl_cuda_cudnn.h	/^  HL_POOLING_AVERAGE = 1,$/;"	e	enum:__anon11
HL_POOLING_AVERAGE_EXCLUDE_PADDING	cuda/include/hl_cuda_cudnn.h	/^  HL_POOLING_AVERAGE_EXCLUDE_PADDING = 2,$/;"	e	enum:__anon11
HL_POOLING_END	cuda/include/hl_cuda_cudnn.h	/^  HL_POOLING_END$/;"	e	enum:__anon11
HL_POOLING_MAX	cuda/include/hl_cuda_cudnn.h	/^  HL_POOLING_MAX = 0,$/;"	e	enum:__anon11
HL_SEQUENCE_H_	cuda/include/hl_sequence.h	16;"	d
HL_SEQUENCE_STUB_H_	cuda/include/stub/hl_sequence_stub.h	16;"	d
HL_SPARSE_CSC	cuda/include/hl_base.h	/^  HL_SPARSE_CSC = 1,$/;"	e	enum:__anon9
HL_SPARSE_CSR	cuda/include/hl_base.h	/^  HL_SPARSE_CSR = 0,$/;"	e	enum:__anon9
HL_SPARSE_END	cuda/include/hl_base.h	/^  HL_SPARSE_END$/;"	e	enum:__anon9
HL_SPARSE_H_	cuda/include/hl_sparse.h	16;"	d
HL_SPARSE_STUB_H_	cuda/include/stub/hl_sparse_stub.h	16;"	d
HL_TABLE_APPLY_H_	cuda/include/hl_table_apply.h	16;"	d
HL_TENSOR_OPS_H_	cuda/include/hl_tensor_ops.h	16;"	d
HL_TIME_H_	cuda/include/hl_time.h	16;"	d
HL_TOP_K_H_	cuda/include/hl_top_k.h	16;"	d
HL_VALUE_END	cuda/include/hl_base.h	/^  HL_VALUE_END$/;"	e	enum:__anon8
HL_WARPCTC_WRAP_H_	cuda/include/hl_warpctc_wrap.h	16;"	d
HOSTS	scripts/cluster_train/conf.py	/^HOSTS = [$/;"	v
HPPL_ACTIVE_FUNCTION	cuda/include/hl_activation_functions.h	23;"	d
HPPL_GPU_MEMORY_SIZE	cuda/src/hl_cuda_device.cc	95;"	d	file:
HPPL_OP_END	cuda/include/hl_base.h	/^  HPPL_OP_END$/;"	e	enum:__anon3
HPPL_OP_N	cuda/include/hl_base.h	/^  HPPL_OP_N = 0, \/* transpose *\/$/;"	e	enum:__anon3
HPPL_OP_T	cuda/include/hl_base.h	/^  HPPL_OP_T = 1, \/* non transpose *\/$/;"	e	enum:__anon3
HPPL_STREAM_1	cuda/include/hl_base.h	/^  HPPL_STREAM_1 = 1,$/;"	e	enum:__anon1
HPPL_STREAM_2	cuda/include/hl_base.h	/^  HPPL_STREAM_2 = 2,$/;"	e	enum:__anon1
HPPL_STREAM_3	cuda/include/hl_base.h	/^  HPPL_STREAM_3 = 3,$/;"	e	enum:__anon1
HPPL_STREAM_4	cuda/include/hl_base.h	/^  HPPL_STREAM_4 = 4,$/;"	e	enum:__anon1
HPPL_STREAM_DEFAULT	cuda/include/hl_base.h	/^  HPPL_STREAM_DEFAULT = 0, \/* Thread Default Stream*\/$/;"	e	enum:__anon1
HPPL_STREAM_END	cuda/include/hl_base.h	/^  HPPL_STREAM_END$/;"	e	enum:__anon1
HPPL_THREAD_STREAM_1	cuda/include/hl_base.h	/^  HPPL_THREAD_STREAM_1 = 5,$/;"	e	enum:__anon1
HPPL_THREAD_STREAM_2	cuda/include/hl_base.h	/^  HPPL_THREAD_STREAM_2 = 6,$/;"	e	enum:__anon1
HPPL_THREAD_STREAM_3	cuda/include/hl_base.h	/^  HPPL_THREAD_STREAM_3 = 7,$/;"	e	enum:__anon1
HPPL_THREAD_STREAM_4	cuda/include/hl_base.h	/^  HPPL_THREAD_STREAM_4 = 8,$/;"	e	enum:__anon1
Header	parameter/Parameter.h	/^  struct Header {$/;"	s	class:paddle::Parameter
HierarchicalSigmoidLayer	gserver/layers/HierarchicalSigmoidLayer.h	/^  explicit HierarchicalSigmoidLayer(const LayerConfig& config)$/;"	f	class:paddle::HierarchicalSigmoidLayer
HierarchicalSigmoidLayer	gserver/layers/HierarchicalSigmoidLayer.h	/^class HierarchicalSigmoidLayer : public Layer {$/;"	c	namespace:paddle
HistogramType	math/Vector.h	/^  enum HistogramType {$/;"	g	class:paddle::VectorT
HuberTwoClass	gserver/layers/CostLayer.h	/^  explicit HuberTwoClass(const LayerConfig& config) : CostLayer(config) {}$/;"	f	class:paddle::HuberTwoClass
HuberTwoClass	gserver/layers/CostLayer.h	/^class HuberTwoClass : public CostLayer {$/;"	c	namespace:paddle
IBaseMatrix	math/BaseMatrix.h	/^typedef BaseMatrixT<int> IBaseMatrix;$/;"	t	namespace:paddle
ICpuGpuVector	math/Vector.h	/^typedef CpuGpuVectorT<int> ICpuGpuVector;$/;"	t	namespace:paddle
ICpuGpuVectorPtr	math/Vector.h	/^typedef std::shared_ptr<ICpuGpuVector> ICpuGpuVectorPtr;$/;"	t	namespace:paddle
IDRandomer	trainer/tests/testPyDataWrapper.py	/^class IDRandomer():  # A random generator, return unique id$/;"	c
IFieldScanner	gserver/dataproviders/PyDataProvider2.cpp	/^  explicit IFieldScanner(SlotHeader* headerPtr) : headerPtr_(headerPtr) {}$/;"	f	class:paddle::IFieldScanner
IFieldScanner	gserver/dataproviders/PyDataProvider2.cpp	/^class IFieldScanner {$/;"	c	namespace:paddle	file:
IGradientMachineMode	gserver/gradientmachines/GradientMachineMode.h	/^class IGradientMachineMode {$/;"	c	namespace:paddle
IMG_SIZE	math/tests/test_perturbation.cpp	/^const int IMG_SIZE = 41;$/;"	v
INDENT_WIDTH	trainer/tests/picojson.h	/^enum { INDENT_WIDTH = 2 };$/;"	e	enum:picojson::__anon15
INIT	trainer/tests/picojson.h	186;"	d
INIT	trainer/tests/picojson.h	198;"	d
INIT	trainer/tests/picojson.h	262;"	d
INIT	trainer/tests/picojson.h	269;"	d
INIT_VECTOR	math/tests/test_TrainingAlgorithm.cpp	119;"	d	file:
INPUT_DATA	gserver/tests/LayerGradUtil.h	/^  INPUT_DATA,         \/\/ dense vector$/;"	e	enum:paddle::InputType
INPUT_DATA	gserver/tests/test_Evaluator.cpp	/^  INPUT_DATA,         \/\/ dense vector$/;"	e	enum:InputType	file:
INPUT_DATA_TARGET	gserver/tests/LayerGradUtil.h	/^  INPUT_DATA_TARGET,  \/\/ dense vector, but no gradient$/;"	e	enum:paddle::InputType
INPUT_DATA_TARGET	gserver/tests/test_Evaluator.cpp	/^  INPUT_DATA_TARGET,  \/\/ dense vector, but no gradient$/;"	e	enum:InputType	file:
INPUT_DENSE_DIM_DATA	gserver/tests/LayerGradUtil.h	/^  INPUT_DENSE_DIM_DATA,  \/\/ using sequence length to init dense data$/;"	e	enum:paddle::InputType
INPUT_HASSUB_SEQUENCE_DATA	gserver/tests/LayerGradUtil.h	/^  INPUT_HASSUB_SEQUENCE_DATA,  \/\/ sequence has sub-sequence$/;"	e	enum:paddle::InputType
INPUT_LABEL	gserver/tests/LayerGradUtil.h	/^  INPUT_LABEL,        \/\/ id$/;"	e	enum:paddle::InputType
INPUT_LABEL	gserver/tests/test_Evaluator.cpp	/^  INPUT_LABEL,        \/\/ id$/;"	e	enum:InputType	file:
INPUT_SEQUENCE_DATA	gserver/tests/LayerGradUtil.h	/^  INPUT_SEQUENCE_DATA,$/;"	e	enum:paddle::InputType
INPUT_SEQUENCE_DATA	gserver/tests/test_Evaluator.cpp	/^  INPUT_SEQUENCE_DATA,$/;"	e	enum:InputType	file:
INPUT_SEQUENCE_LABEL	gserver/tests/LayerGradUtil.h	/^  INPUT_SEQUENCE_LABEL,$/;"	e	enum:paddle::InputType
INPUT_SEQUENCE_LABEL	gserver/tests/test_Evaluator.cpp	/^  INPUT_SEQUENCE_LABEL,$/;"	e	enum:InputType	file:
INPUT_SEQUENCE_MDIM_DATA	gserver/tests/LayerGradUtil.h	/^  INPUT_SEQUENCE_MDIM_DATA,$/;"	e	enum:paddle::InputType
INPUT_SPARSE_FLOAT_VALUE_DATA	gserver/tests/LayerGradUtil.h	/^  INPUT_SPARSE_FLOAT_VALUE_DATA,$/;"	e	enum:paddle::InputType
INPUT_SPARSE_NON_VALUE_DATA	gserver/tests/LayerGradUtil.h	/^  INPUT_SPARSE_NON_VALUE_DATA,$/;"	e	enum:paddle::InputType
INPUT_SPARSE_NON_VALUE_DATA	gserver/tests/test_Evaluator.cpp	/^  INPUT_SPARSE_NON_VALUE_DATA$/;"	e	enum:InputType	file:
IOError	api/PaddleAPI.h	/^class IOError {};$/;"	c
IParameterUpdaterHook	parameter/ParameterUpdaterHook.cpp	/^IParameterUpdaterHook::IParameterUpdaterHook() {}$/;"	f	class:paddle::IParameterUpdaterHook
IParameterUpdaterHook	parameter/ParameterUpdaterHook.h	/^class IParameterUpdaterHook {$/;"	c	namespace:paddle
IPyDataProviderCache	gserver/dataproviders/PyDataProvider2.cpp	/^class IPyDataProviderCache {$/;"	c	namespace:paddle	file:
IS	trainer/tests/picojson.h	289;"	d
IS	trainer/tests/picojson.h	302;"	d
IS	trainer/tests/picojson.h	810;"	d
IS	trainer/tests/picojson.h	820;"	d
IScanner	py_paddle/dataprovider_converter.py	/^class IScanner(object):$/;"	c
ISequenceResults	api/PaddleAPI.h	/^class ISequenceResults {$/;"	c
IVector	api/PaddleAPI.h	/^class IVector {$/;"	c
IVector	api/Vector.cpp	/^IVector::IVector() : m(new IVectorPrivate()) {}$/;"	f	class:IVector
IVector	math/Vector.h	/^typedef VectorT<int> IVector;$/;"	t	namespace:paddle
IVectorPrivate	api/Vector.cpp	/^struct IVectorPrivate {$/;"	s	file:
IVectorPtr	math/Vector.h	/^typedef std::shared_ptr<IVector> IVectorPtr;$/;"	t	namespace:paddle
IdValueConverter	py_paddle/util.py	/^    class IdValueConverter(object):$/;"	c	class:DataProviderWrapperConverter
IdentityActivation	gserver/activations/ActivationFunction.cpp	/^class IdentityActivation : public ActivationFunction {$/;"	c	namespace:paddle	file:
IdentityOffsetProjection	gserver/layers/IdentityProjection.cpp	/^IdentityOffsetProjection::IdentityOffsetProjection($/;"	f	class:paddle::IdentityOffsetProjection
IdentityOffsetProjection	gserver/layers/IdentityProjection.cpp	/^class IdentityOffsetProjection : public Projection {$/;"	c	namespace:paddle	file:
IdentityProjection	gserver/layers/IdentityProjection.cpp	/^IdentityProjection::IdentityProjection(const ProjectionConfig& config,$/;"	f	class:paddle::IdentityProjection
IdentityProjection	gserver/layers/IdentityProjection.cpp	/^class IdentityProjection : public Projection {$/;"	c	namespace:paddle	file:
InAsmBlock	scripts/cpplint.py	/^    def InAsmBlock(self):$/;"	m	class:NestingState
InClassDeclaration	scripts/cpplint.py	/^    def InClassDeclaration(self):$/;"	m	class:NestingState
InExternC	scripts/cpplint.py	/^    def InExternC(self):$/;"	m	class:NestingState
InFrameLine	gserver/gradientmachines/RecurrentGradientMachine.h	/^  struct InFrameLine {$/;"	s	class:paddle::RecurrentGradientMachine
InNamespaceBody	scripts/cpplint.py	/^    def InNamespaceBody(self):$/;"	m	class:NestingState
InTemplateArgumentList	scripts/cpplint.py	/^    def InTemplateArgumentList(self, clean_lines, linenum, pos):$/;"	m	class:NestingState
IncrementErrorCount	scripts/cpplint.py	/^    def IncrementErrorCount(self, category):$/;"	m	class:_CppLintState
IndexDict	math/SparseRowMatrix.h	/^  struct IndexDict {$/;"	s	class:paddle::SparseRowCpuMatrix
IndexDictPtr	math/SparseRowMatrix.h	/^  typedef std::shared_ptr<IndexDict> IndexDictPtr;$/;"	t	class:paddle::SparseRowCpuMatrix
IndexScanner	gserver/dataproviders/PyDataProvider2.cpp	/^  explicit IndexScanner(SlotHeader* ptr) : IFieldScanner(ptr), cnt_(0) {}$/;"	f	class:paddle::IndexScanner
IndexScanner	gserver/dataproviders/PyDataProvider2.cpp	/^class IndexScanner : public IFieldScanner {$/;"	c	namespace:paddle	file:
IndexScanner	py_paddle/dataprovider_converter.py	/^class IndexScanner(IScanner):$/;"	c
Info	gserver/gradientmachines/RecurrentGradientMachine.h	/^  struct Info {$/;"	s	class:paddle::RecurrentGradientMachine
InitFuncList	utils/Util.cpp	/^typedef std::vector<PriorityFuncPair> InitFuncList;$/;"	t	namespace:paddle	file:
InitFunction	utils/Util.h	/^  explicit InitFunction(std::function<void()> func, int priority = 0) {$/;"	f	class:paddle::InitFunction
InitFunction	utils/Util.h	/^class InitFunction {$/;"	c	namespace:paddle
InnermostClass	scripts/cpplint.py	/^    def InnermostClass(self):$/;"	m	class:NestingState
InputDef	gserver/tests/LayerGradUtil.h	/^  InputDef(InputType type, string nameIn, size_t dimIn, size_t sizeIn) {$/;"	f	struct:paddle::InputDef
InputDef	gserver/tests/LayerGradUtil.h	/^  InputDef(InputType type,$/;"	f	struct:paddle::InputDef
InputDef	gserver/tests/LayerGradUtil.h	/^struct InputDef {$/;"	s	namespace:paddle
InputDef	gserver/tests/test_Evaluator.cpp	/^struct InputDef {$/;"	s	file:
InputIovs	pserver/BaseClient.h	/^  typedef std::vector<std::vector<iovec>> InputIovs;$/;"	t	class:paddle::BaseClient
InputType	gserver/tests/LayerGradUtil.h	/^enum InputType {$/;"	g	namespace:paddle
InputType	gserver/tests/test_Evaluator.cpp	/^enum InputType {$/;"	g	file:
IntArray	api/PaddleAPI.h	/^struct IntArray {$/;"	s
IntArray	api/Util.cpp	/^IntArray::IntArray(const int* b, const size_t l, bool f)$/;"	f	class:IntArray
IntV	gserver/layers/ConvBaseLayer.h	/^  typedef std::vector<int> IntV;$/;"	t	class:paddle::ConvBaseLayer
IntWithFloatArray	api/PaddleAPI.h	/^struct IntWithFloatArray {$/;"	s
IntWithFloatArray	api/Util.cpp	/^IntWithFloatArray::IntWithFloatArray(const float* v,$/;"	f	class:IntWithFloatArray
InterpolationLayer	gserver/layers/InterpolationLayer.cpp	/^  explicit InterpolationLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::InterpolationLayer
InterpolationLayer	gserver/layers/InterpolationLayer.cpp	/^class InterpolationLayer : public Layer {$/;"	c	namespace:paddle	file:
Interval	gserver/layers/MultinomialSampler.h	/^  struct Interval {$/;"	s	class:paddle::MultinomialSampler
IsBlankLine	scripts/cpplint.py	/^def IsBlankLine(line):$/;"	f
IsBlockInNameSpace	scripts/cpplint.py	/^def IsBlockInNameSpace(nesting_state, is_forward_declaration):$/;"	f
IsBlockInfo	scripts/cpplint.py	/^    def IsBlockInfo(self):$/;"	m	class:_BlockInfo
IsCppString	scripts/cpplint.py	/^def IsCppString(line):$/;"	f
IsDecltype	scripts/cpplint.py	/^def IsDecltype(clean_lines, linenum, column):$/;"	f
IsDeletedOrDefault	scripts/cpplint.py	/^def IsDeletedOrDefault(clean_lines, linenum):$/;"	f
IsDerivedFunction	scripts/cpplint.py	/^def IsDerivedFunction(clean_lines, linenum):$/;"	f
IsErrorSuppressedByNolint	scripts/cpplint.py	/^def IsErrorSuppressedByNolint(category, linenum):$/;"	f
IsForwardClassDeclaration	scripts/cpplint.py	/^def IsForwardClassDeclaration(clean_lines, linenum):$/;"	f
IsInAlphabeticalOrder	scripts/cpplint.py	/^    def IsInAlphabeticalOrder(self, clean_lines, linenum, header_path):$/;"	m	class:_IncludeState
IsInitializerList	scripts/cpplint.py	/^def IsInitializerList(clean_lines, linenum):$/;"	f
IsMacroDefinition	scripts/cpplint.py	/^def IsMacroDefinition(clean_lines, linenum):$/;"	f
IsOutOfLineMethodDefinition	scripts/cpplint.py	/^def IsOutOfLineMethodDefinition(clean_lines, linenum):$/;"	f
IsRValueAllowed	scripts/cpplint.py	/^def IsRValueAllowed(clean_lines, linenum, typenames):$/;"	f
IsRValueType	scripts/cpplint.py	/^def IsRValueType(typenames, clean_lines, nesting_state, linenum, column):$/;"	f
IsSource	scripts/cpplint.py	/^    def IsSource(self):$/;"	m	class:FileInfo
IsTLargerThanAlign	pserver/ParameterServer2.h	/^    constexpr static bool IsTLargerThanAlign = sizeof(T) >= AlignBytes;$/;"	m	class:paddle::ParameterServer2::ReadWriteBuffer
IsTemplateParameterList	scripts/cpplint.py	/^def IsTemplateParameterList(clean_lines, linenum, column):$/;"	f
Job	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  struct Job {$/;"	s	class:paddle::ParallelThread
JobFunc	utils/Thread.h	/^  typedef std::function<ResultPtrType()> JobFunc;$/;"	t	class:paddle::MultiThreadWorker
JobFunc	utils/Thread.h	/^  typedef std::function<void()> JobFunc;$/;"	t	class:paddle::AsyncThreadPool
JobFunc	utils/Thread.h	/^  typedef std::function<void()> JobFunc;$/;"	t	class:paddle::ThreadWorker
JobFunc	utils/Thread.h	/^  typedef std::function<void(int tid, size_t numThreads)> JobFunc;$/;"	t	class:paddle::SyncThreadPool
JobQueue	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  typedef Queue<Job> JobQueue;$/;"	t	class:paddle::ParallelThread
L1L2LrRegularizer	parameter/Regularizer.h	/^class L1L2LrRegularizer : public Regularizer {$/;"	c	namespace:paddle
L1L2Regularizer	parameter/Regularizer.h	/^class L1L2Regularizer : public Regularizer {$/;"	c	namespace:paddle
L1LrRegularizer	parameter/Regularizer.h	/^class L1LrRegularizer : public Regularizer {$/;"	c	namespace:paddle
L1Regularizer	parameter/Regularizer.h	/^class L1Regularizer : public Regularizer {$/;"	c	namespace:paddle
L2LrRegularizer	parameter/Regularizer.h	/^class L2LrRegularizer : public Regularizer {$/;"	c	namespace:paddle
L2Regularizer	parameter/Regularizer.h	/^class L2Regularizer : public Regularizer {$/;"	c	namespace:paddle
LD_LIBRARY_PATH	scripts/cluster_train/conf.py	/^LD_LIBRARY_PATH = "\/usr\/local\/cuda\/lib64:\/usr\/lib64"$/;"	v
LIB_DIRS	api/paddle_ld_flags.py	/^    LIB_DIRS = [$/;"	v
LOG_INFINITY	gserver/layers/LinearChainCTC.cpp	/^const real LOG_INFINITY = std::log(EXP_MAX);$/;"	m	namespace:paddle	file:
LOG_ZERO	gserver/layers/LinearChainCTC.cpp	/^const real LOG_ZERO = std::log(EXP_MIN);$/;"	m	namespace:paddle	file:
LambdaCost	gserver/layers/CostLayer.h	/^  explicit LambdaCost(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::LambdaCost
LambdaCost	gserver/layers/CostLayer.h	/^class LambdaCost : public Layer {$/;"	c	namespace:paddle
Layer	gserver/layers/Layer.cpp	/^Layer::Layer(const LayerConfig& config, bool useGpu)$/;"	f	class:paddle::Layer
Layer	gserver/layers/Layer.h	/^class Layer {$/;"	c	namespace:paddle
LayerMap	gserver/layers/Layer.h	/^typedef std::map<std::string, LayerPtr> LayerMap;$/;"	t	namespace:paddle
LayerPtr	gserver/layers/Layer.h	/^typedef std::shared_ptr<Layer> LayerPtr;$/;"	t	namespace:paddle
LayerState	gserver/layers/Layer.h	/^struct LayerState {$/;"	s	namespace:paddle
LayerStatePtr	gserver/layers/Layer.h	/^typedef std::shared_ptr<LayerState> LayerStatePtr;$/;"	t	namespace:paddle
LearningRateScheduler	parameter/LearningRateScheduler.h	/^class LearningRateScheduler {$/;"	c	namespace:paddle
LinearChainCRF	gserver/layers/LinearChainCRF.cpp	/^LinearChainCRF::LinearChainCRF(int numClasses, real* para, real* grad)$/;"	f	class:paddle::LinearChainCRF
LinearChainCRF	gserver/layers/LinearChainCRF.h	/^class LinearChainCRF {$/;"	c	namespace:paddle
LinearChainCTC	gserver/layers/LinearChainCTC.cpp	/^LinearChainCTC::LinearChainCTC(int numClasses, bool normByTimes)$/;"	f	class:paddle::LinearChainCTC
LinearChainCTC	gserver/layers/LinearChainCTC.h	/^class LinearChainCTC {$/;"	c	namespace:paddle
LinearLRS	parameter/LearningRateScheduler.cpp	/^  explicit LinearLRS(const OptimizationConfig& config) : BaseLRS(config) {}$/;"	f	class:paddle::LinearLRS
LinearLRS	parameter/LearningRateScheduler.cpp	/^class LinearLRS : public BaseLRS {$/;"	c	namespace:paddle	file:
LocalOperationResult	pserver/ParameterClient2.h	/^  struct LocalOperationResult {$/;"	s	class:paddle::PreparedOperations
LockedCondition	utils/Locks.h	/^class LockedCondition : public std::condition_variable {$/;"	c	namespace:paddle
LstmCompute	gserver/layers/LstmCompute.h	/^class LstmCompute {$/;"	c	namespace:paddle
LstmLayer	gserver/layers/LstmLayer.h	/^  explicit LstmLayer(const LayerConfig &config) : Layer(config) {}$/;"	f	class:paddle::LstmLayer
LstmLayer	gserver/layers/LstmLayer.h	/^class LstmLayer : public Layer, public LstmCompute {$/;"	c	namespace:paddle
LstmStepLayer	gserver/layers/LstmStepLayer.cpp	/^  explicit LstmStepLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::LstmStepLayer
LstmStepLayer	gserver/layers/LstmStepLayer.cpp	/^class LstmStepLayer : public Layer, public LstmCompute {$/;"	c	namespace:paddle	file:
MAP	trainer/tests/picojson.h	456;"	d
MAP	trainer/tests/picojson.h	468;"	d
MAP	trainer/tests/picojson.h	717;"	d
MAP	trainer/tests/picojson.h	729;"	d
MATHFUNCTIONS_H_	math/MathFunctions.h	16;"	d
MAT_CACHE_ROW	parameter/Parameter.h	/^    MAT_CACHE_ROW,$/;"	e	enum:paddle::Parameter::MatType
MAT_NORMAL	parameter/Parameter.h	/^    MAT_NORMAL,$/;"	e	enum:paddle::Parameter::MatType
MAT_NORMAL_SHARED	parameter/Parameter.h	/^    MAT_NORMAL_SHARED,$/;"	e	enum:paddle::Parameter::MatType
MAT_SPARSE_ROW	parameter/Parameter.h	/^    MAT_SPARSE_ROW,$/;"	e	enum:paddle::Parameter::MatType
MAT_SPARSE_ROW_AUTO_GROW	parameter/Parameter.h	/^    MAT_SPARSE_ROW_AUTO_GROW,$/;"	e	enum:paddle::Parameter::MatType
MAT_SPARSE_ROW_IDS	parameter/Parameter.h	/^    MAT_SPARSE_ROW_IDS,$/;"	e	enum:paddle::Parameter::MatType
MAT_SPARSE_ROW_PREFETCH	parameter/Parameter.h	/^    MAT_SPARSE_ROW_PREFETCH,$/;"	e	enum:paddle::Parameter::MatType
MAT_SPARSE_ROW_PREFETCH_FULL_SIZE	parameter/Parameter.h	/^    MAT_SPARSE_ROW_PREFETCH_FULL_SIZE,$/;"	e	enum:paddle::Parameter::MatType
MAT_VALUE_SHARED	parameter/Parameter.h	/^    MAT_VALUE_SHARED,$/;"	e	enum:paddle::Parameter::MatType
MAX_VEC_SIZE	pserver/RDMANetwork.h	30;"	d
MDLstmLayer	gserver/layers/MDLstmLayer.cpp	/^  explicit MDLstmLayer(const LayerConfig& config) : LstmLayer(config) {}$/;"	f	class:paddle::MDLstmLayer
MDLstmLayer	gserver/layers/MDLstmLayer.cpp	/^class MDLstmLayer : public LstmLayer {$/;"	c	namespace:paddle	file:
MUTABLE_VECTOR_OP	math/Vector.cpp	909;"	d	file:
MachineState	gserver/gradientmachines/GradientMachine.h	/^typedef std::vector<LayerStatePtr> MachineState;$/;"	t	namespace:paddle
ManualLRS	parameter/LearningRateScheduler.cpp	/^  explicit ManualLRS(const OptimizationConfig& config)$/;"	f	class:paddle::ManualLRS
ManualLRS	parameter/LearningRateScheduler.cpp	/^class ManualLRS : public BaseLRS {$/;"	c	namespace:paddle	file:
MatType	parameter/Parameter.h	/^  enum MatType {$/;"	g	class:paddle::Parameter
Match	scripts/cpplint.py	/^def Match(pattern, s):$/;"	f
Matrix	api/Matrix.cpp	/^Matrix::Matrix() : m(new MatrixPrivate()) {}$/;"	f	class:Matrix
Matrix	api/PaddleAPI.h	/^class Matrix {$/;"	c
Matrix	function/TensorType.h	/^  typedef typename detail::MatrixT<VType, DType>::type Matrix;$/;"	t	struct:paddle::Tensor
Matrix	math/Matrix.cpp	/^Matrix::Matrix($/;"	f	class:paddle::Matrix
Matrix	math/Matrix.cpp	/^Matrix::Matrix(MemoryHandlePtr memHandle,$/;"	f	class:paddle::Matrix
Matrix	math/Matrix.cpp	/^Matrix::Matrix(real* data,$/;"	f	class:paddle::Matrix
Matrix	math/Matrix.h	/^class Matrix : public BaseMatrix {$/;"	c	namespace:paddle
MatrixCheckErr	math/tests/test_GpuProfiler.cpp	/^void MatrixCheckErr(const Matrix& matrix1, const Matrix& matrix2) {$/;"	f
MatrixOffset	math/BaseMatrix.h	/^  MatrixOffset(size_t aCol = 0,$/;"	f	class:paddle::MatrixOffset
MatrixOffset	math/BaseMatrix.h	/^class MatrixOffset {$/;"	c	namespace:paddle
MatrixPara	math/tests/test_SparseMatrix.cpp	/^struct MatrixPara {$/;"	s	file:
MatrixPrivate	api/Matrix.cpp	/^struct MatrixPrivate {$/;"	s	file:
MatrixPtr	math/Matrix.h	/^typedef std::shared_ptr<Matrix> MatrixPtr;$/;"	t	namespace:paddle
MatrixT	function/TensorType.h	/^struct MatrixT<int, DEVICE_TYPE_CPU> {$/;"	s	namespace:paddle::detail
MatrixT	function/TensorType.h	/^struct MatrixT<int, DEVICE_TYPE_GPU> {$/;"	s	namespace:paddle::detail
MatrixT	function/TensorType.h	/^struct MatrixT<real, DEVICE_TYPE_CPU> {$/;"	s	namespace:paddle::detail
MatrixT	function/TensorType.h	/^struct MatrixT<real, DEVICE_TYPE_GPU> {$/;"	s	namespace:paddle::detail
MaxFramePrinter	gserver/evaluators/Evaluator.cpp	/^  MaxFramePrinter() {$/;"	f	class:paddle::MaxFramePrinter
MaxFramePrinter	gserver/evaluators/Evaluator.cpp	/^class MaxFramePrinter : public Evaluator {$/;"	c	namespace:paddle	file:
MaxIdLayer	gserver/layers/MaxIdLayer.cpp	/^  explicit MaxIdLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::MaxIdLayer
MaxIdLayer	gserver/layers/MaxIdLayer.cpp	/^class MaxIdLayer : public Layer {$/;"	c	namespace:paddle	file:
MaxIdPrinter	gserver/evaluators/Evaluator.cpp	/^  MaxIdPrinter() {}$/;"	f	class:paddle::MaxIdPrinter
MaxIdPrinter	gserver/evaluators/Evaluator.cpp	/^class MaxIdPrinter : public Evaluator {$/;"	c	namespace:paddle	file:
MaxLayer	gserver/layers/MaxLayer.h	/^  explicit MaxLayer(const LayerConfig& config) : SequencePoolLayer(config) {}$/;"	f	class:paddle::MaxLayer
MaxLayer	gserver/layers/MaxLayer.h	/^class MaxLayer : public SequencePoolLayer {$/;"	c	namespace:paddle
MaxOutLayer	gserver/layers/MaxOutLayer.h	/^  explicit MaxOutLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::MaxOutLayer
MaxOutLayer	gserver/layers/MaxOutLayer.h	/^class MaxOutLayer : public Layer {$/;"	c	namespace:paddle
MaxPoolProjection	gserver/layers/PoolProjection.h	/^  MaxPoolProjection(const ProjectionConfig& config,$/;"	f	class:paddle::MaxPoolProjection
MaxPoolProjection	gserver/layers/PoolProjection.h	/^class MaxPoolProjection : public PoolProjection {$/;"	c	namespace:paddle
MemoryFrameLine	gserver/gradientmachines/RecurrentGradientMachine.h	/^  struct MemoryFrameLine {$/;"	s	class:paddle::RecurrentGradientMachine
MemoryHandle	math/MemoryHandle.cpp	/^MemoryHandle::MemoryHandle(size_t size) : size_(size), buf_(nullptr) {$/;"	f	class:paddle::MemoryHandle
MemoryHandle	math/MemoryHandle.h	/^class MemoryHandle {$/;"	c	namespace:paddle
MemoryHandlePtr	math/MemoryHandle.h	/^typedef std::shared_ptr<MemoryHandle> MemoryHandlePtr;$/;"	t	namespace:paddle
MessageHeader	pserver/SocketChannel.h	/^  struct MessageHeader {$/;"	s	class:paddle::SocketChannel
MessageHeader	pserver/test/SocketTest.cpp	/^struct MessageHeader {$/;"	s	file:
MixedLayer	gserver/layers/MixedLayer.h	/^  explicit MixedLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::MixedLayer
MixedLayer	gserver/layers/MixedLayer.h	/^class MixedLayer : public Layer {$/;"	c	namespace:paddle
ModelConfig	api/ConfigParser.cpp	/^ModelConfig::ModelConfig() : m(new ModelConfigPrivate()) {}$/;"	f	class:ModelConfig
ModelConfig	api/PaddleAPI.h	/^class ModelConfig {$/;"	c
ModelConfigPrivate	api/PaddleAPIPrivate.h	/^struct ModelConfigPrivate {$/;"	s
MsgReader	pserver/SocketChannel.cpp	/^MsgReader::MsgReader(SocketChannel* channel, size_t numBlocks)$/;"	f	class:paddle::MsgReader
MsgReader	pserver/SocketChannel.h	/^class MsgReader {$/;"	c	namespace:paddle
MulFunc	function/MulOp.cpp	/^class MulFunc : public FunctionBase {$/;"	c	namespace:paddle	file:
MulOp	function/MulOp.cpp	/^void MulOp<DEVICE_TYPE_CPU>(CpuMatrix& out,$/;"	f	namespace:paddle
MulOp	function/MulOp.cpp	/^void MulOp<DEVICE_TYPE_CPU>(CpuSparseMatrix& out,$/;"	f	namespace:paddle
MultiBinaryLabelCrossEntropy	gserver/layers/CostLayer.h	/^  explicit MultiBinaryLabelCrossEntropy(const LayerConfig& config)$/;"	f	class:paddle::MultiBinaryLabelCrossEntropy
MultiBinaryLabelCrossEntropy	gserver/layers/CostLayer.h	/^class MultiBinaryLabelCrossEntropy : public CostLayer {$/;"	c	namespace:paddle
MultiClassCrossEntropy	gserver/layers/CostLayer.h	/^  explicit MultiClassCrossEntropy(const LayerConfig& config)$/;"	f	class:paddle::MultiClassCrossEntropy
MultiClassCrossEntropy	gserver/layers/CostLayer.h	/^class MultiClassCrossEntropy : public CostLayer {$/;"	c	namespace:paddle
MultiClassCrossEntropyWithSelfNorm	gserver/layers/CostLayer.h	/^  explicit MultiClassCrossEntropyWithSelfNorm(const LayerConfig& config)$/;"	f	class:paddle::MultiClassCrossEntropyWithSelfNorm
MultiClassCrossEntropyWithSelfNorm	gserver/layers/CostLayer.h	/^class MultiClassCrossEntropyWithSelfNorm : public CostLayer {$/;"	c	namespace:paddle
MultiCombinedEvaluator	gserver/gradientmachines/MultiNetwork.cpp	/^  MultiCombinedEvaluator() {}$/;"	f	class:paddle::MultiCombinedEvaluator
MultiCombinedEvaluator	gserver/gradientmachines/MultiNetwork.cpp	/^class MultiCombinedEvaluator : public Evaluator {$/;"	c	namespace:paddle	file:
MultiDataProvider	gserver/dataproviders/MultiDataProvider.cpp	/^MultiDataProvider::MultiDataProvider(const DataConfig& config,$/;"	f	class:paddle::MultiDataProvider
MultiDataProvider	gserver/dataproviders/MultiDataProvider.h	/^class MultiDataProvider : public DataProvider {$/;"	c	namespace:paddle
MultiGradientMachine	gserver/gradientmachines/MultiGradientMachine.cpp	/^MultiGradientMachine::MultiGradientMachine(const ModelConfig& config,$/;"	f	class:paddle::MultiGradientMachine
MultiGradientMachine	gserver/gradientmachines/MultiGradientMachine.h	/^class MultiGradientMachine : public GradientMachine {$/;"	c	namespace:paddle
MultiNetwork	gserver/gradientmachines/MultiNetwork.h	/^  explicit MultiNetwork(std::string subModelName = "")$/;"	f	class:paddle::MultiNetwork
MultiNetwork	gserver/gradientmachines/MultiNetwork.h	/^class MultiNetwork : public NeuralNetwork {$/;"	c	namespace:paddle
MultiThreadWorker	utils/Thread.h	/^  MultiThreadWorker(size_t workerNum, size_t queueCapacity)$/;"	f	class:paddle::MultiThreadWorker
MultiThreadWorker	utils/Thread.h	/^class MultiThreadWorker {$/;"	c	namespace:paddle
MultinomialSampler	gserver/layers/MultinomialSampler.cpp	/^MultinomialSampler::MultinomialSampler(const real* prob, int size)$/;"	f	class:paddle::MultinomialSampler
MultinomialSampler	gserver/layers/MultinomialSampler.h	/^class MultinomialSampler {$/;"	c	namespace:paddle
MultinomialSamplerTester	gserver/tests/test_MultinomialSampler.cpp	/^  MultinomialSamplerTester(real* prob, int size)$/;"	f	class:MultinomialSamplerTester
MultinomialSamplerTester	gserver/tests/test_MultinomialSampler.cpp	/^class MultinomialSamplerTester : public MultinomialSampler {$/;"	c	file:
MultiplexLayer	gserver/layers/MultiplexLayer.cpp	/^  explicit MultiplexLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::MultiplexLayer
MultiplexLayer	gserver/layers/MultiplexLayer.cpp	/^class MultiplexLayer : public Layer {$/;"	c	namespace:paddle	file:
MyServer	pserver/test/test_ProtoServer.cpp	/^  explicit MyServer(int port, int rdmaCpu = -1)$/;"	f	class:MyServer
MyServer	pserver/test/test_ProtoServer.cpp	/^class MyServer : public ProtoServer {$/;"	c	file:
NCELayer	gserver/layers/NCELayer.cpp	/^  explicit NCELayer(const LayerConfig& config)$/;"	f	class:paddle::NCELayer
NCELayer	gserver/layers/NCELayer.cpp	/^class NCELayer : public Layer {$/;"	c	namespace:paddle	file:
NEST_CONFIG_FILE	trainer/tests/test_recurrent_machine_generation.cpp	/^static const string& NEST_CONFIG_FILE =$/;"	v	file:
NO_CACHE	gserver/dataproviders/PyDataProvider2.cpp	/^  NO_CACHE = 0,           \/\/ Each pass will load data from PyDataProvider2.$/;"	e	enum:paddle::CacheType	file:
NO_SPARSE_ID	api/PaddleAPI.h	/^const size_t NO_SPARSE_ID = -1UL;$/;"	v
NO_VALUE	math/Matrix.h	/^enum SparseValueType { NO_VALUE = 0, FLOAT_VALUE = 1 };$/;"	e	enum:paddle::SparseValueType
NPY_NO_DEPRECATED_API	gserver/dataproviders/PyDataProvider2.cpp	23;"	d	file:
NUMBER_OF_GLOBAL_STREAM	cuda/src/hl_cuda_device.cc	91;"	d	file:
NUMBER_OF_THREAD_STREAM	cuda/src/hl_cuda_device.cc	93;"	d	file:
NUMBER_UPDATERS	trainer/RemoteParameterUpdater.h	/^    NUMBER_UPDATERS = 2,$/;"	e	enum:paddle::SparseRemoteParameterUpdaterComposite::__anon12
NUM_IMAGES	math/tests/test_perturbation.cpp	/^const int NUM_IMAGES = 2;$/;"	v
NUM_PARAMETER_TYPES	utils/GlobalConstants.h	/^  NUM_PARAMETER_TYPES,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
NestingState	scripts/cpplint.py	/^class NestingState(object):$/;"	c
NeuralNetwork	gserver/gradientmachines/NeuralNetwork.h	/^  NeuralNetwork(std::string subModelName = "",$/;"	f	class:paddle::NeuralNetwork
NeuralNetwork	gserver/gradientmachines/NeuralNetwork.h	/^class NeuralNetwork : public GradientMachine {$/;"	c	namespace:paddle
NewRandomVector	math/tests/test_SIMDFunctions.cpp	/^inline static std::unique_ptr<float[]> NewRandomVector(size_t len = VECTOR_LEN,$/;"	f	file:
NewVector	math/tests/test_SIMDFunctions.cpp	/^inline static std::unique_ptr<float[]> NewVector(size_t len = VECTOR_LEN,$/;"	f	file:
NoCacheStrategy	gserver/dataproviders/PyDataProvider2.cpp	/^class NoCacheStrategy : public IPyDataProviderCache {$/;"	c	namespace:paddle	file:
NoExtension	scripts/cpplint.py	/^    def NoExtension(self):$/;"	m	class:FileInfo
NormLayer	gserver/layers/NormLayer.h	/^  explicit NormLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::NormLayer
NormLayer	gserver/layers/NormLayer.h	/^class NormLayer : public Layer {$/;"	c	namespace:paddle
NormOrDropNodeCallback	gserver/gradientmachines/RecurrentGradientMachine.h	/^      NormOrDropNodeCallback;$/;"	t	class:paddle::RecurrentGradientMachine
NormalizationStrategy	gserver/layers/DataNormLayer.h	/^  enum NormalizationStrategy { kZScore = 0, kMinMax = 1, kDecimalScaling = 2 };$/;"	g	class:paddle::DataNormLayer
NumLines	scripts/cpplint.py	/^    def NumLines(self):$/;"	m	class:CleansedLines
OOV_POLICY_ERROR	trainer/tests/gen_proto_data.py	/^OOV_POLICY_ERROR = 2$/;"	v
OOV_POLICY_IGNORE	trainer/tests/gen_proto_data.py	/^OOV_POLICY_IGNORE = 0$/;"	v
OOV_POLICY_USE	trainer/tests/gen_proto_data.py	/^OOV_POLICY_USE = 1$/;"	v
OUTPUT_DIR	trainer/tests/test_recurrent_machine_generation.cpp	/^static const string& OUTPUT_DIR = "trainer\/tests\/dump_text.test";$/;"	v	file:
OWLQN	utils/GlobalConstants.cpp	/^const std::string TrainAlgorithm::OWLQN = "owlqn";$/;"	m	class:paddle::TrainAlgorithm	file:
OWLQN	utils/GlobalConstants.h	/^  static const std::string OWLQN;$/;"	m	class:paddle::TrainAlgorithm
ObjectHelper	utils/PythonUtil.h	/^  explicit ObjectHelper(const PyObjectPtr& obj) : obj_(obj) {}$/;"	f	class:paddle::py::ObjectHelper
ObjectHelper	utils/PythonUtil.h	/^class ObjectHelper {$/;"	c	namespace:paddle::py
OnPoolFilled	gserver/dataproviders/PyDataProvider2.cpp	/^    OnPoolFilled;$/;"	m	namespace:paddle::unittest	file:
Operator	gserver/layers/Operator.h	/^  Operator(const OperatorConfig& config, bool useGpu)$/;"	f	class:paddle::Operator
Operator	gserver/layers/Operator.h	/^class Operator {$/;"	c	namespace:paddle
OperatorFunction	pserver/ParameterServer2.h	/^  typedef void (ParameterServer2::*OperatorFunction)(const Operation& operation,$/;"	t	class:paddle::ParameterServer2
OptimizationConfig	api/ConfigParser.cpp	/^OptimizationConfig::OptimizationConfig() : m(new OptimizationConfigPrivate()) {}$/;"	f	class:OptimizationConfig
OptimizationConfig	api/PaddleAPI.h	/^class OptimizationConfig {$/;"	c
OptimizationConfigPrivate	api/PaddleAPIPrivate.h	/^struct OptimizationConfigPrivate {$/;"	s
OptimizationConfig_createFromProto	py_paddle/util.py	/^    def OptimizationConfig_createFromProto(protoObj):$/;"	f	function:__monkey_patch_protobuf_objects__
OptimizationConfig_toProto	py_paddle/util.py	/^    def OptimizationConfig_toProto(self):$/;"	f	function:__monkey_patch_protobuf_objects__
OptimizerWithGradientClipping	parameter/FirstOrderOptimizer.h	/^  OptimizerWithGradientClipping(const OptimizationConfig& optConfig,$/;"	f	class:paddle::OptimizerWithGradientClipping
OptimizerWithGradientClipping	parameter/FirstOrderOptimizer.h	/^class OptimizerWithGradientClipping : public ParameterOptimizer {$/;"	c	namespace:paddle
OptimizerWithRegularizer	parameter/OptimizerWithRegularizer.h	/^  OptimizerWithRegularizer(const OptimizationConfig& optConfig,$/;"	f	class:paddle::OptimizerWithRegularizer
OptimizerWithRegularizer	parameter/OptimizerWithRegularizer.h	/^class OptimizerWithRegularizer : public ParameterOptimizer {$/;"	c	namespace:paddle
OptimizerWithRegularizerEveryNumBatches	parameter/OptimizerWithRegularizer.h	/^  OptimizerWithRegularizerEveryNumBatches(const OptimizationConfig& optConfig,$/;"	f	class:paddle::OptimizerWithRegularizerEveryNumBatches
OptimizerWithRegularizerEveryNumBatches	parameter/OptimizerWithRegularizer.h	/^class OptimizerWithRegularizerEveryNumBatches$/;"	c	namespace:paddle
OptimizerWithRegularizerSparse	parameter/OptimizerWithRegularizer.h	/^  OptimizerWithRegularizerSparse(const OptimizationConfig& optConfig,$/;"	f	class:paddle::OptimizerWithRegularizerSparse
OptimizerWithRegularizerSparse	parameter/OptimizerWithRegularizer.h	/^class OptimizerWithRegularizerSparse : public OptimizerWithRegularizer {$/;"	c	namespace:paddle
OutFrameLine	gserver/gradientmachines/RecurrentGradientMachine.h	/^  struct OutFrameLine {$/;"	s	class:paddle::RecurrentGradientMachine
OuterProdLayer	gserver/layers/OuterProdLayer.cpp	/^  explicit OuterProdLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::OuterProdLayer
OuterProdLayer	gserver/layers/OuterProdLayer.cpp	/^class OuterProdLayer : public Layer {$/;"	c	namespace:paddle	file:
PADDLE_BUILD_DIR	api/paddle_api_config.py	/^PADDLE_BUILD_DIR="\/home\/tianbing\/baidu\/idl\/paddle\/build\/paddle\/api\/..\/"$/;"	v
PADDLE_DISABLE_TIMER	gserver/tests/test_MultinomialSampler.cpp	20;"	d	file:
PADDLE_DISABLE_TIMER	gserver/tests/test_NetworkCompare.cpp	15;"	d	file:
PADDLE_DISABLE_TIMER	trainer/TrainerBenchmark.cpp	15;"	d	file:
PADDLE_NIC	scripts/cluster_train/conf.py	/^PADDLE_NIC = "eth0"$/;"	v
PADDLE_PORT	scripts/cluster_train/conf.py	/^PADDLE_PORT = 7164$/;"	v
PADDLE_PORTS_NUM	scripts/cluster_train/conf.py	/^PADDLE_PORTS_NUM = 2$/;"	v
PADDLE_PORTS_NUM_FOR_SPARSE	scripts/cluster_train/conf.py	/^PADDLE_PORTS_NUM_FOR_SPARSE = 2$/;"	v
PADDLE_VERSION	utils/Version.cpp	29;"	d	file:
PARAMETER_APPLY	utils/GlobalConstants.h	/^  PARAMETER_APPLY,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_COLS	utils/GlobalConstants.h	/^  PARAMETER_COLS,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_DELTA	utils/GlobalConstants.h	/^  PARAMETER_DELTA,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_GRADIENT	utils/GlobalConstants.h	/^  PARAMETER_GRADIENT,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_GRADIENT_SQURESUM	utils/GlobalConstants.h	/^  PARAMETER_GRADIENT_SQURESUM,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_GRADIENT_SQURESUM1	utils/GlobalConstants.h	/^  PARAMETER_GRADIENT_SQURESUM1,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_GRADIENT_SUM	utils/GlobalConstants.h	/^  PARAMETER_GRADIENT_SUM,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_LEARNING_RATE	utils/GlobalConstants.h	/^  PARAMETER_LEARNING_RATE,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_MOMENTUM	utils/GlobalConstants.h	/^  PARAMETER_MOMENTUM,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_MOMENTUM_UT	utils/GlobalConstants.h	/^  PARAMETER_MOMENTUM_UT,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_MOMENTUM_VT	utils/GlobalConstants.h	/^  PARAMETER_MOMENTUM_VT,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_ROWS	utils/GlobalConstants.h	/^  PARAMETER_ROWS,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_SECOND_MOMENTUM	utils/GlobalConstants.h	/^  PARAMETER_SECOND_MOMENTUM,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_SUM1	utils/GlobalConstants.h	/^  PARAMETER_SUM1,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_SUM2	utils/GlobalConstants.h	/^  PARAMETER_SUM2,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_SUM3	utils/GlobalConstants.h	/^  PARAMETER_SUM3,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_UPDATE_TIME	utils/GlobalConstants.h	/^  PARAMETER_UPDATE_TIME,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_VALUE	utils/GlobalConstants.h	/^  PARAMETER_VALUE = 0,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARAMETER_WEIGHTED_INFINITY_NORM	utils/GlobalConstants.h	/^  PARAMETER_WEIGHTED_INFINITY_NORM,$/;"	e	enum:paddle::enumeration_wrapper::ParameterType
PARENT_LIB_DIRS	api/paddle_ld_flags.py	/^    PARENT_LIB_DIRS = ['proto']$/;"	v
PASS_GC	utils/GlobalConstants.h	/^  PASS_GC,      \/\/ Gradient Check pass$/;"	e	enum:paddle::enumeration_wrapper::PassType
PASS_METRIC	utils/GlobalConstants.h	/^  PASS_METRIC,  \/\/ pass for generate template output with no drop rate.$/;"	e	enum:paddle::enumeration_wrapper::PassType
PASS_METRIC_TRAIN	utils/GlobalConstants.h	/^  PASS_METRIC_TRAIN,$/;"	e	enum:paddle::enumeration_wrapper::PassType
PASS_METRIC_TRAIN_WITH_NOERROR	utils/GlobalConstants.h	/^  PASS_METRIC_TRAIN_WITH_NOERROR,  \/\/ Pass for metric learning training$/;"	e	enum:paddle::enumeration_wrapper::PassType
PASS_TEST	utils/GlobalConstants.h	/^  PASS_TEST,    \/\/ Test pass$/;"	e	enum:paddle::enumeration_wrapper::PassType
PASS_TRAIN	utils/GlobalConstants.h	/^  PASS_TRAIN,   \/\/ Train pass$/;"	e	enum:paddle::enumeration_wrapper::PassType
PICOJSON_ASSERT	trainer/tests/picojson.h	78;"	d
PICOJSON_CMP	trainer/tests/picojson.h	1046;"	d
PICOJSON_CMP	trainer/tests/picojson.h	1053;"	d
PICOJSON_USE_LOCALE	trainer/tests/picojson.h	69;"	d
PROMPT_ERR	pserver/RDMANetwork.h	20;"	d
PROTOBUF_LIBRARY	api/paddle_api_config.py	/^PROTOBUF_LIBRARY="\/home\/tianbing\/baidu\/idl\/paddle\/third_party\/install\/protobuf\/lib\/libprotobuf.a"$/;"	v
PServerMatrix	pserver/ParameterClient2.h	/^struct PServerMatrix {$/;"	s	namespace:paddle
PServerVector	pserver/ParameterClient2.h	/^struct PServerVector {$/;"	s	namespace:paddle
PYTHON_LIBRARIES	api/paddle_api_config.py	/^PYTHON_LIBRARIES="\/usr\/lib\/x86_64-linux-gnu\/libpython2.7.so"$/;"	v
Pad	function/PadOp.cpp	/^void Pad<DEVICE_TYPE_CPU>(real* outputs,$/;"	f	namespace:paddle
PadConf	function/PadOp.h	/^struct PadConf {$/;"	s	namespace:paddle
PadFunc	function/PadOp.cpp	/^class PadFunc : public FunctionBase {$/;"	c	namespace:paddle	file:
PadGrad	function/PadOp.cpp	/^void PadGrad<DEVICE_TYPE_CPU>(real* inGrad,$/;"	f	namespace:paddle
PadGradFunc	function/PadOp.cpp	/^class PadGradFunc : public FunctionBase {$/;"	c	namespace:paddle	file:
PadLayer	gserver/layers/PadLayer.h	/^  explicit PadLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::PadLayer
PadLayer	gserver/layers/PadLayer.h	/^class PadLayer : public Layer {$/;"	c	namespace:paddle
PaddleLDFlag	api/paddle_ld_flags.py	/^    class PaddleLDFlag(object):$/;"	c
ParaSparse	gserver/tests/LayerGradUtil.h	/^  ParaSparse(const string& formatIn = "") {  \/\/ NOLINT$/;"	f	struct:paddle::ParaSparse
ParaSparse	gserver/tests/LayerGradUtil.h	/^  ParaSparse(const string& formatIn, bool equalNnz) {$/;"	f	struct:paddle::ParaSparse
ParaSparse	gserver/tests/LayerGradUtil.h	/^struct ParaSparse {$/;"	s	namespace:paddle
ParaStat	trainer/TrainerInternal.h	/^    ParaStat() : maxAbsGrad(.0), avgAbsGrad(.0) {}$/;"	f	struct:paddle::TrainerInternal::ParaStat
ParaStat	trainer/TrainerInternal.h	/^  struct ParaStat {$/;"	s	class:paddle::TrainerInternal
ParallelCpuVectorT	math/Vector.h	/^  ParallelCpuVectorT(size_t size, SyncThreadPool* pool)$/;"	f	class:paddle::ParallelCpuVectorT
ParallelCpuVectorT	math/Vector.h	/^class ParallelCpuVectorT : public CpuVectorT<T> {$/;"	c	namespace:paddle
ParallelNeuralNetwork	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  ParallelNeuralNetwork(std::string subModelName = "",$/;"	f	class:paddle::ParallelNeuralNetwork
ParallelNeuralNetwork	gserver/gradientmachines/ParallelNeuralNetwork.h	/^class ParallelNeuralNetwork : public NeuralNetwork {$/;"	c	namespace:paddle
ParallelParameter	parameter/ParallelParameter.h	/^  ParallelParameter(TrainerRole role, ParameterPtr localParam) {$/;"	f	class:paddle::ParallelParameter
ParallelParameter	parameter/ParallelParameter.h	/^class ParallelParameter {$/;"	c	namespace:paddle
ParallelParameterMap	parameter/ParallelParameter.h	/^typedef std::map<std::string, ParallelParameterPtr> ParallelParameterMap;$/;"	t	namespace:paddle
ParallelParameterPtr	parameter/ParallelParameter.h	/^typedef std::shared_ptr<ParallelParameter> ParallelParameterPtr;$/;"	t	namespace:paddle
ParallelThread	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^ParallelThread::ParallelThread(int threadId, int deviceId, bool useGpu)$/;"	f	class:paddle::ParallelThread
ParallelThread	gserver/gradientmachines/ParallelNeuralNetwork.h	/^class ParallelThread {$/;"	c	namespace:paddle
ParamInitCallback	parameter/Parameter.h	/^typedef std::function<void(int paramId, Parameter* param)> ParamInitCallback;$/;"	t	namespace:paddle
Parameter	api/PaddleAPI.h	/^class Parameter {$/;"	c
Parameter	api/Parameter.cpp	/^Parameter::Parameter() : m(new ParameterPrivate()) {}$/;"	f	class:Parameter
Parameter	parameter/Parameter.cpp	/^Parameter::Parameter(const ParameterConfig& config, bool useGpu, bool doInit)$/;"	f	class:paddle::Parameter
Parameter	parameter/Parameter.h	/^class Parameter {$/;"	c	namespace:paddle
ParameterClient2	pserver/ParameterClient2.cpp	/^ParameterClient2::ParameterClient2(bool separate, int port, int numPorts)$/;"	f	class:paddle::ParameterClient2
ParameterClient2	pserver/ParameterClient2.h	/^class ParameterClient2 : public BaseClient {$/;"	c	namespace:paddle
ParameterConfig	api/ConfigParser.cpp	/^ParameterConfig::ParameterConfig() : m(new ParameterConfigPrivate()) {}$/;"	f	class:ParameterConfig
ParameterConfig	api/PaddleAPI.h	/^class ParameterConfig {$/;"	c
ParameterConfigPrivate	api/ConfigParser.cpp	/^struct ParameterConfigPrivate {$/;"	s	file:
ParameterConfig_toProto	py_paddle/util.py	/^    def ParameterConfig_toProto(self):$/;"	f	function:__monkey_patch_protobuf_objects__
ParameterMap	parameter/Parameter.h	/^typedef std::map<std::string, ParameterPtr> ParameterMap;$/;"	t	namespace:paddle
ParameterOptimizer	api/PaddleAPI.h	/^class ParameterOptimizer {$/;"	c
ParameterOptimizer	api/ParameterOptimizer.cpp	/^ParameterOptimizer::ParameterOptimizer() : m(new ParameterOptimizerPrivate()) {}$/;"	f	class:ParameterOptimizer
ParameterOptimizer	parameter/ParameterOptimizer.h	/^  explicit ParameterOptimizer(const OptimizationConfig& optConfig)$/;"	f	class:paddle::ParameterOptimizer
ParameterOptimizer	parameter/ParameterOptimizer.h	/^class ParameterOptimizer {$/;"	c	namespace:paddle
ParameterOptimizerPrivate	api/ParameterOptimizer.cpp	/^struct ParameterOptimizerPrivate {$/;"	s	file:
ParameterPrivate	api/PaddleAPIPrivate.h	/^  ParameterPrivate() : sharedPtr(nullptr), rawPtr(nullptr) {}$/;"	f	struct:ParameterPrivate
ParameterPrivate	api/PaddleAPIPrivate.h	/^struct ParameterPrivate {$/;"	s
ParameterPtr	parameter/Parameter.h	/^typedef std::shared_ptr<Parameter> ParameterPtr;$/;"	t	namespace:paddle
ParameterReluLayer	gserver/layers/ParameterReluLayer.h	/^  explicit ParameterReluLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::ParameterReluLayer
ParameterReluLayer	gserver/layers/ParameterReluLayer.h	/^class ParameterReluLayer : public Layer {$/;"	c	namespace:paddle
ParameterSegments	pserver/ParameterClient2.h	/^struct ParameterSegments {$/;"	s	namespace:paddle
ParameterServer2	pserver/ParameterServer2.cpp	/^ParameterServer2::ParameterServer2(const std::string& addr,$/;"	f	class:paddle::ParameterServer2
ParameterServer2	pserver/ParameterServer2.h	/^class ParameterServer2 : public ProtoServer {$/;"	c	namespace:paddle
ParameterServer2Tester	pserver/test/test_ParameterServer2.cpp	/^  ParameterServer2Tester(std::string serverAddr,$/;"	f	class:ParameterServer2Tester
ParameterServer2Tester	pserver/test/test_ParameterServer2.cpp	/^class ParameterServer2Tester : public ParameterServer2 {$/;"	c	file:
ParameterServerController	pserver/ParameterServerController.cpp	/^ParameterServerController::ParameterServerController($/;"	f	class:paddle::ParameterServerController
ParameterTraverseCallback	api/PaddleAPI.h	/^class ParameterTraverseCallback {$/;"	c
ParameterTraverseCallback	api/ParameterOptimizer.cpp	/^ParameterTraverseCallback::ParameterTraverseCallback()$/;"	f	class:ParameterTraverseCallback
ParameterTraverseCallbackPrivate	api/ParameterOptimizer.cpp	/^  ParameterTraverseCallbackPrivate($/;"	f	struct:ParameterTraverseCallbackPrivate
ParameterTraverseCallbackPrivate	api/ParameterOptimizer.cpp	/^  ParameterTraverseCallbackPrivate() {}$/;"	f	struct:ParameterTraverseCallbackPrivate
ParameterTraverseCallbackPrivate	api/ParameterOptimizer.cpp	/^struct ParameterTraverseCallbackPrivate {$/;"	s	file:
ParameterType	utils/GlobalConstants.h	/^enum ParameterType {$/;"	g	namespace:paddle::enumeration_wrapper
ParameterUpdater	api/PaddleAPI.h	/^class ParameterUpdater {$/;"	c
ParameterUpdater	api/ParameterUpdater.cpp	/^ParameterUpdater::ParameterUpdater() : m(new ParameterUpdaterPrivate()) {}$/;"	f	class:ParameterUpdater
ParameterUpdater	parameter/ParameterUpdaterBase.h	/^  ParameterUpdater() : parameterTypes_{PARAMETER_VALUE, PARAMETER_GRADIENT} {}$/;"	f	class:paddle::ParameterUpdater
ParameterUpdater	parameter/ParameterUpdaterBase.h	/^class ParameterUpdater {$/;"	c	namespace:paddle
ParameterUpdaterComposite	parameter/ParameterUpdaterBase.h	/^  ParameterUpdaterComposite() {}$/;"	f	class:paddle::ParameterUpdaterComposite
ParameterUpdaterComposite	parameter/ParameterUpdaterBase.h	/^class ParameterUpdaterComposite : public ParameterUpdater {$/;"	c	namespace:paddle
ParameterUpdaterCreators	trainer/RemoteParameterUpdater.h	/^class ParameterUpdaterCreators {$/;"	c	namespace:paddle
ParameterUpdaterPrivate	api/PaddleAPIPrivate.h	/^struct ParameterUpdaterPrivate {$/;"	s
ParameterUtil	trainer/ParamUtil.cpp	/^ParameterUtil::ParameterUtil($/;"	f	class:paddle::ParameterUtil
ParameterUtil	trainer/ParamUtil.h	/^class ParameterUtil {$/;"	c	namespace:paddle
ParameterUtilConfig	trainer/ParamUtil.h	/^  ParameterUtilConfig(bool save_only_one,$/;"	f	struct:paddle::ParameterUtilConfig
ParameterUtilConfig	trainer/ParamUtil.h	/^struct ParameterUtilConfig {$/;"	s	namespace:paddle
ParseArguments	scripts/cpplint.py	/^def ParseArguments(args):$/;"	f
ParseNolintSuppressions	scripts/cpplint.py	/^def ParseNolintSuppressions(filename, raw_line, linenum, error):$/;"	f
PassManualLRS	parameter/LearningRateScheduler.cpp	/^  explicit PassManualLRS(const OptimizationConfig& config)$/;"	f	class:paddle::PassManualLRS
PassManualLRS	parameter/LearningRateScheduler.cpp	/^class PassManualLRS : public ManualLRS {$/;"	c	namespace:paddle	file:
PassType	utils/GlobalConstants.h	/^enum PassType {$/;"	g	namespace:paddle::enumeration_wrapper
Path	api/SequenceGenerator.cpp	/^  Path() { logProb = 0; }$/;"	f	struct:Path
Path	api/SequenceGenerator.cpp	/^  Path(std::vector<int>& ids, float logProb, paddle::MachineState& machineState)$/;"	f	struct:Path
Path	api/SequenceGenerator.cpp	/^struct Path {$/;"	s	file:
Path	gserver/gradientmachines/RecurrentGradientMachine.h	/^    Path() {$/;"	f	struct:paddle::RecurrentGradientMachine::Path
Path	gserver/gradientmachines/RecurrentGradientMachine.h	/^    Path(Path& old, int newId, real logProb, int machineId, int topIndex)$/;"	f	struct:paddle::RecurrentGradientMachine::Path
Path	gserver/gradientmachines/RecurrentGradientMachine.h	/^    explicit Path(size_t seqId) : seqId(seqId) { logProb = 0; }$/;"	f	struct:paddle::RecurrentGradientMachine::Path
Path	gserver/gradientmachines/RecurrentGradientMachine.h	/^  struct Path {$/;"	s	class:paddle::RecurrentGradientMachine
PathSequenceResults	api/SequenceGenerator.cpp	/^  PathSequenceResults(const std::shared_ptr<std::vector<Path>>& path,$/;"	f	class:PathSequenceResults
PathSequenceResults	api/SequenceGenerator.cpp	/^class PathSequenceResults : public ISequenceResults {$/;"	c	file:
PerturbationTest	math/tests/test_perturbation.cpp	/^class PerturbationTest : public testing::Test {$/;"	c	file:
PidQueue	gserver/gradientmachines/MultiGradientMachine.h	/^typedef Queue<int> PidQueue;$/;"	t	namespace:paddle
PnpairEvaluator	gserver/evaluators/Evaluator.h	/^  PnpairEvaluator()$/;"	f	class:paddle::PnpairEvaluator
PnpairEvaluator	gserver/evaluators/Evaluator.h	/^class PnpairEvaluator : public Evaluator {$/;"	c	namespace:paddle
PnpairValidation	gserver/layers/ValidationLayer.h	/^  explicit PnpairValidation(const LayerConfig& config)$/;"	f	class:paddle::PnpairValidation
PnpairValidation	gserver/layers/ValidationLayer.h	/^class PnpairValidation : public ValidationLayer {$/;"	c	namespace:paddle
PolyLRS	parameter/LearningRateScheduler.cpp	/^  explicit PolyLRS(const OptimizationConfig& config) : BaseLRS(config) {}$/;"	f	class:paddle::PolyLRS
PolyLRS	parameter/LearningRateScheduler.cpp	/^class PolyLRS : public BaseLRS {$/;"	c	namespace:paddle	file:
PoolAllocator	math/PoolAllocator.cpp	/^PoolAllocator::PoolAllocator(Allocator* allocator,$/;"	f	class:paddle::PoolAllocator
PoolAllocator	math/PoolAllocator.h	/^class PoolAllocator {$/;"	c	namespace:paddle
PoolLayer	gserver/layers/PoolLayer.h	/^  explicit PoolLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::PoolLayer
PoolLayer	gserver/layers/PoolLayer.h	/^class PoolLayer : public Layer {$/;"	c	namespace:paddle
PoolProjection	gserver/layers/PoolProjection.cpp	/^PoolProjection::PoolProjection(const ProjectionConfig& config,$/;"	f	class:paddle::PoolProjection
PoolProjection	gserver/layers/PoolProjection.h	/^class PoolProjection : public Projection {$/;"	c	namespace:paddle
PoolProjectionLayer	gserver/layers/PoolProjectionLayer.h	/^  explicit PoolProjectionLayer(const LayerConfig& config) : PoolLayer(config) {$/;"	f	class:paddle::PoolProjectionLayer
PoolProjectionLayer	gserver/layers/PoolProjectionLayer.h	/^class PoolProjectionLayer : public PoolLayer {$/;"	c	namespace:paddle
PositionRandom	gserver/dataproviders/PyDataProvider2.cpp	/^    inline explicit PositionRandom(bool skipRand)$/;"	f	class:paddle::PyDataProvider2::PositionRandom
PositionRandom	gserver/dataproviders/PyDataProvider2.cpp	/^  class PositionRandom {$/;"	c	class:paddle::PyDataProvider2	file:
PowerLayer	gserver/layers/PowerLayer.cpp	/^  explicit PowerLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::PowerLayer
PowerLayer	gserver/layers/PowerLayer.cpp	/^class PowerLayer : public Layer {$/;"	c	namespace:paddle	file:
PrecisionRecallEvaluator	gserver/evaluators/Evaluator.h	/^  PrecisionRecallEvaluator()$/;"	f	class:paddle::PrecisionRecallEvaluator
PrecisionRecallEvaluator	gserver/evaluators/Evaluator.h	/^class PrecisionRecallEvaluator : public Evaluator {$/;"	c	namespace:paddle
PredictionResult	gserver/evaluators/Evaluator.h	/^    PredictionResult(real __out, int __label, int __queryid, real __weight)$/;"	f	struct:paddle::PnpairEvaluator::PredictionResult
PredictionResult	gserver/evaluators/Evaluator.h	/^  struct PredictionResult {$/;"	s	class:paddle::PnpairEvaluator
PredictionResult	gserver/layers/ValidationLayer.h	/^    PredictionResult(real __out, int __label) : out(__out), label(__label) {}$/;"	f	struct:paddle::AucValidation::PredictionResult
PredictionResult	gserver/layers/ValidationLayer.h	/^  struct PredictionResult {$/;"	s	class:paddle::AucValidation
PreparedOperations	pserver/ParameterClient2.h	/^class PreparedOperations {$/;"	c	namespace:paddle
PrintCategories	scripts/cpplint.py	/^def PrintCategories():$/;"	f
PrintErrorCounts	scripts/cpplint.py	/^    def PrintErrorCounts(self):$/;"	m	class:_CppLintState
PrintLayer	gserver/layers/PrintLayer.cpp	/^  explicit PrintLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::PrintLayer
PrintLayer	gserver/layers/PrintLayer.cpp	/^class PrintLayer : public Layer {$/;"	c	namespace:paddle	file:
PrintUsage	scripts/cpplint.py	/^def PrintUsage(message):$/;"	f
PriorBoxLayer	gserver/layers/PriorBox.cpp	/^  explicit PriorBoxLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::PriorBoxLayer
PriorBoxLayer	gserver/layers/PriorBox.cpp	/^class PriorBoxLayer : public Layer {$/;"	c	namespace:paddle	file:
PriorityFuncPair	utils/Util.cpp	/^typedef std::pair<int, std::function<void()>> PriorityFuncPair;$/;"	t	namespace:paddle	file:
ProcessChannel	utils/Thread.h	/^  static AsyncThreadPool& ProcessChannel(size_t initThreadNum = 0) {$/;"	f	class:paddle::AsyncThreadPool
ProcessConfigOverrides	scripts/cpplint.py	/^def ProcessConfigOverrides(filename):$/;"	f
ProcessFile	scripts/cpplint.py	/^def ProcessFile(filename, vlevel, extra_check_functions=[]):$/;"	f
ProcessFileData	scripts/cpplint.py	/^def ProcessFileData(filename,$/;"	f
ProcessLine	scripts/cpplint.py	/^def ProcessLine(filename,$/;"	f
Projection	gserver/layers/Projection.h	/^  Projection(const ProjectionConfig& config,$/;"	f	class:paddle::Projection
Projection	gserver/layers/Projection.h	/^class Projection {$/;"	c	namespace:paddle
ProtoClient	pserver/ProtoServer.h	/^  ProtoClient(const std::string& serverAddr,$/;"	f	class:paddle::ProtoClient
ProtoClient	pserver/ProtoServer.h	/^class ProtoClient : public SocketClient {$/;"	c	namespace:paddle
ProtoDataProvider	gserver/dataproviders/ProtoDataProvider.cpp	/^ProtoDataProvider::ProtoDataProvider(const DataConfig& config,$/;"	f	class:paddle::ProtoDataProvider
ProtoDataProvider	gserver/dataproviders/ProtoDataProvider.h	/^class ProtoDataProvider : public DataProvider {$/;"	c	namespace:paddle
ProtoReader	gserver/dataproviders/ProtoReader.h	/^  explicit ProtoReader(std::istream* s, bool dataCompression = false) {$/;"	f	class:paddle::ProtoReader
ProtoReader	gserver/dataproviders/ProtoReader.h	/^class ProtoReader {$/;"	c	namespace:paddle
ProtoResponseCallback	pserver/ProtoServer.h	/^      ProtoResponseCallback;$/;"	t	class:paddle::ProtoServer
ProtoResponseCallbackEx	pserver/ProtoServer.h	/^      ProtoResponseCallbackEx;$/;"	t	class:paddle::ProtoServer
ProtoSequenceDataProvider	gserver/dataproviders/ProtoDataProvider.cpp	/^ProtoSequenceDataProvider::ProtoSequenceDataProvider(const DataConfig& config,$/;"	f	class:paddle::ProtoSequenceDataProvider
ProtoSequenceDataProvider	gserver/dataproviders/ProtoDataProvider.h	/^class ProtoSequenceDataProvider : public ProtoDataProvider {$/;"	c	namespace:paddle
ProtoServer	pserver/ProtoServer.h	/^  ProtoServer(const std::string& addr, int port, int rdmaCpu = -1)$/;"	f	class:paddle::ProtoServer
ProtoServer	pserver/ProtoServer.h	/^class ProtoServer : public SocketServer {$/;"	c	namespace:paddle
ProtoSlot	gserver/dataproviders/ProtoDataProvider.h	/^  struct ProtoSlot {$/;"	s	class:paddle::ProtoDataProvider
ProtoSlot	gserver/dataproviders/PyDataProvider.h	/^  struct ProtoSlot {$/;"	s	class:paddle::PyDataProvider
ProtoVarSlot	gserver/dataproviders/ProtoDataProvider.h	/^  struct ProtoVarSlot {$/;"	s	class:paddle::ProtoDataProvider
ProtoWriter	gserver/dataproviders/ProtoReader.h	/^  explicit ProtoWriter(std::ostream* s, bool dataCompression = false) {$/;"	f	class:paddle::ProtoWriter
ProtoWriter	gserver/dataproviders/ProtoReader.h	/^class ProtoWriter {$/;"	c	namespace:paddle
ProviderPtrType	gserver/dataproviders/DataProviderGroup.h	/^  typedef std::shared_ptr<ProviderType> ProviderPtrType;$/;"	t	class:paddle::DataProviderGroup
ProviderType	gserver/dataproviders/DataProviderGroup.h	/^  typedef T ProviderType;$/;"	t	class:paddle::DataProviderGroup
PyDataProvider	gserver/dataproviders/PyDataProvider.cpp	/^PyDataProvider::PyDataProvider(const DataConfig& config,$/;"	f	class:paddle::PyDataProvider
PyDataProvider	gserver/dataproviders/PyDataProvider.h	/^class PyDataProvider : public DataProvider {$/;"	c	namespace:paddle
PyDataProvider2	gserver/dataproviders/PyDataProvider2.cpp	/^  PyDataProvider2(const DataConfig& config,$/;"	f	class:paddle::PyDataProvider2
PyDataProvider2	gserver/dataproviders/PyDataProvider2.cpp	/^class PyDataProvider2 : public DataProvider {$/;"	c	namespace:paddle	file:
PyGuard	utils/PythonUtil.h	/^class PyGuard {$/;"	c	namespace:paddle
PyObjectDeleter	utils/PythonUtil.h	/^struct PyObjectDeleter {$/;"	s	namespace:paddle
PyObjectPtr	utils/PythonUtil.h	/^typedef std::unique_ptr<PyObject, PyObjectDeleter> PyObjectPtr;$/;"	t	namespace:paddle
Queue	utils/Queue.h	/^  Queue() : numElements_(0) {}$/;"	f	class:paddle::Queue
Queue	utils/Queue.h	/^class Queue {$/;"	c	namespace:paddle
REGISTER_BARRIER_DELTA_SERVER_SET	utils/BarrierStat.h	390;"	d
REGISTER_BARRIER_DELTA_SERVER_SET	utils/BarrierStat.h	419;"	d
REGISTER_BARRIER_TIMER_SERVER	utils/BarrierStat.h	386;"	d
REGISTER_BARRIER_TIMER_SERVER	utils/BarrierStat.h	399;"	d
REGISTER_BARRIER_TIMER_SERVER_SET	utils/BarrierStat.h	388;"	d
REGISTER_BARRIER_TIMER_SERVER_SET	utils/BarrierStat.h	411;"	d
REGISTER_DATA_PROVIDER	gserver/dataproviders/DataProvider.h	46;"	d
REGISTER_DATA_PROVIDER_EX	gserver/dataproviders/DataProvider.h	61;"	d
REGISTER_EVALUATOR	gserver/evaluators/Evaluator.h	31;"	d
REGISTER_GPU_PROFILER	utils/Stat.h	310;"	d
REGISTER_GPU_PROFILER	utils/Stat.h	314;"	d
REGISTER_LAYER	gserver/layers/Layer.h	33;"	d
REGISTER_LAYER_CREATE_FUNC	gserver/layers/Layer.h	37;"	d
REGISTER_LEARNING_RATE_SCHEDULER	parameter/LearningRateScheduler.h	22;"	d
REGISTER_OPERATOR	gserver/layers/Operator.h	27;"	d
REGISTER_PROJECTION	gserver/layers/Projection.h	25;"	d
REGISTER_PROJECTION_CREATE_FUNC	gserver/layers/Projection.h	30;"	d
REGISTER_SERVICE_FUNCTION	pserver/ProtoServer.h	190;"	d
REGISTER_SERVICE_FUNCTION_EX	pserver/ProtoServer.h	201;"	d
REGISTER_SLOW_NODES_PROBE	utils/BarrierStat.h	375;"	d
REGISTER_TIMER	utils/Stat.h	247;"	d
REGISTER_TIMER	utils/Stat.h	261;"	d
REGISTER_TIMER_DYNAMIC	utils/Stat.h	249;"	d
REGISTER_TIMER_DYNAMIC	utils/Stat.h	277;"	d
REGISTER_TIMER_DYNAMIC_SET	utils/Stat.h	250;"	d
REGISTER_TIMER_DYNAMIC_SET	utils/Stat.h	283;"	d
REGISTER_TIMER_INFO	utils/Stat.h	251;"	d
REGISTER_TIMER_INFO	utils/Stat.h	292;"	d
REGISTER_TIMER_SET	utils/Stat.h	248;"	d
REGISTER_TIMER_SET	utils/Stat.h	267;"	d
REGISTER_TYPED_FUNC	function/Function.h	190;"	d
RMSPropParameterOptimizer	math/tests/OriginalOptimizerApi.h	/^void RMSPropParameterOptimizer(const VectorPtr vecs[],$/;"	f
RMSPropParameterOptimizer	parameter/FirstOrderOptimizer.h	/^  explicit RMSPropParameterOptimizer(const OptimizationConfig& optConfig)$/;"	f	class:paddle::RMSPropParameterOptimizer
RMSPropParameterOptimizer	parameter/FirstOrderOptimizer.h	/^class RMSPropParameterOptimizer : public ParameterOptimizer {$/;"	c	namespace:paddle
ROOT_DIR	scripts/cluster_train/conf.py	/^ROOT_DIR = "\/home\/paddle"$/;"	v
RWLock	utils/Locks.h	/^  RWLock() { pthread_rwlock_init(&rwlock_, NULL); }$/;"	f	class:paddle::RWLock
RWLock	utils/Locks.h	/^class RWLock {$/;"	c	namespace:paddle
RangeError	api/PaddleAPI.h	/^class RangeError {};$/;"	c
RankAucEvaluator	gserver/evaluators/Evaluator.h	/^class RankAucEvaluator : public Evaluator {$/;"	c	namespace:paddle
RankingCost	gserver/layers/CostLayer.h	/^  explicit RankingCost(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::RankingCost
RankingCost	gserver/layers/CostLayer.h	/^class RankingCost : public Layer {$/;"	c	namespace:paddle
RdmaClient	pserver/LightNetwork.cpp	/^void SocketClient::RdmaClient(const std::string &serverAddr, int serverPort) {$/;"	f	class:paddle::SocketClient
RdmaClientDaemons	pserver/LightNetwork.cpp	/^RdmaClientDaemons::RdmaClientDaemons() {$/;"	f	class:paddle::RdmaClientDaemons
RdmaClientDaemons	pserver/LightNetwork.h	/^class RdmaClientDaemons {$/;"	c	namespace:paddle
ReadLockGuard	utils/Locks.h	/^  explicit ReadLockGuard(RWLock& rwlock) : rwlock_(&rwlock) {$/;"	f	class:paddle::ReadLockGuard
ReadLockGuard	utils/Locks.h	/^class ReadLockGuard {$/;"	c	namespace:paddle
ReadWriteBuffer	pserver/ParameterServer2.h	/^  class ReadWriteBuffer$/;"	c	class:paddle::ParameterServer2
RecurrentGradientMachine	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^RecurrentGradientMachine::RecurrentGradientMachine($/;"	f	class:paddle::RecurrentGradientMachine
RecurrentGradientMachine	gserver/gradientmachines/RecurrentGradientMachine.h	/^class RecurrentGradientMachine : public NeuralNetwork {$/;"	c	namespace:paddle
RecurrentLayer	gserver/layers/RecurrentLayer.cpp	/^  explicit RecurrentLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::RecurrentLayer
RecurrentLayer	gserver/layers/RecurrentLayer.cpp	/^class RecurrentLayer : public Layer {$/;"	c	namespace:paddle	file:
RecurrentLayerGroup	gserver/layers/RecurrentLayerGroup.cpp	/^  explicit RecurrentLayerGroup(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::RecurrentLayerGroup
RecurrentLayerGroup	gserver/layers/RecurrentLayerGroup.cpp	/^class RecurrentLayerGroup : public Layer {$/;"	c	namespace:paddle	file:
Regularizer	parameter/Regularizer.h	/^class Regularizer {$/;"	c	namespace:paddle
RemoteParameterUpdater	trainer/RemoteParameterUpdater.cpp	/^RemoteParameterUpdater::RemoteParameterUpdater($/;"	f	class:paddle::RemoteParameterUpdater
RemoteParameterUpdater	trainer/RemoteParameterUpdater.h	/^class RemoteParameterUpdater : public ParameterUpdater {$/;"	c	namespace:paddle
RemoveMultiLineComments	scripts/cpplint.py	/^def RemoveMultiLineComments(filename, lines, error):$/;"	f
RemoveMultiLineCommentsFromRange	scripts/cpplint.py	/^def RemoveMultiLineCommentsFromRange(lines, begin, end):$/;"	f
ReplaceAll	scripts/cpplint.py	/^def ReplaceAll(pattern, rep, s):$/;"	f
ReplaceType	math/tests/TestUtils.h	/^class ReplaceType {$/;"	c	namespace:autotest
ReplaceType	math/tests/TestUtils.h	/^class ReplaceType<BaseMatrix, CpuMatrix> {$/;"	c	namespace:autotest
ReplaceType	math/tests/TestUtils.h	/^class ReplaceType<BaseMatrix, GpuMatrix> {$/;"	c	namespace:autotest
ReplaceType	math/tests/TestUtils.h	/^class ReplaceType<Matrix, CpuMatrix> {$/;"	c	namespace:autotest
ReplaceType	math/tests/TestUtils.h	/^class ReplaceType<Matrix, GpuMatrix> {$/;"	c	namespace:autotest
RepositoryName	scripts/cpplint.py	/^    def RepositoryName(self):$/;"	m	class:FileInfo
ResetErrorCounts	scripts/cpplint.py	/^    def ResetErrorCounts(self):$/;"	m	class:_CppLintState
ResetNolintSuppressions	scripts/cpplint.py	/^def ResetNolintSuppressions():$/;"	f
ResetSection	scripts/cpplint.py	/^    def ResetSection(self, directive):$/;"	m	class:_IncludeState
ResizeLayer	gserver/layers/ResizeLayer.cpp	/^  explicit ResizeLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::ResizeLayer
ResizeLayer	gserver/layers/ResizeLayer.cpp	/^class ResizeLayer : public Layer {$/;"	c	namespace:paddle	file:
ResponseCallback	pserver/LightNetwork.h	/^      ResponseCallback;$/;"	t	class:paddle::SocketServer
ResponseNormLayer	gserver/layers/NormLayer.h	/^  explicit ResponseNormLayer(const LayerConfig& config) : NormLayer(config) {}$/;"	f	class:paddle::ResponseNormLayer
ResponseNormLayer	gserver/layers/NormLayer.h	/^class ResponseNormLayer : public NormLayer {$/;"	c	namespace:paddle
RestoreFilters	scripts/cpplint.py	/^    def RestoreFilters(self):$/;"	m	class:_CppLintState
ResultPtrType	utils/Thread.h	/^  typedef std::shared_ptr<ResultType> ResultPtrType;$/;"	t	class:paddle::MultiThreadWorker
ResultType	math/ExecViaCpu.h	/^  typedef R ResultType;$/;"	t	class:paddle::detail::GpuFuncWrapperBase
ResultType	utils/Thread.h	/^  typedef T ResultType;$/;"	t	class:paddle::MultiThreadWorker
ResultsAdder	pserver/ParameterClient2.h	/^    explicit ResultsAdder(LocalOperationResult* localResult)$/;"	f	class:paddle::PreparedOperations::ResultsAdder
ResultsAdder	pserver/ParameterClient2.h	/^  class ResultsAdder {$/;"	c	class:paddle::PreparedOperations
ReverseCloseExpression	scripts/cpplint.py	/^def ReverseCloseExpression(clean_lines, linenum, pos):$/;"	f
RotateLayer	gserver/layers/RotateLayer.h	/^  explicit RotateLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::RotateLayer
RotateLayer	gserver/layers/RotateLayer.h	/^class RotateLayer : public Layer {$/;"	c	namespace:paddle
RowBuffer	math/RowBuffer.h	/^  RowBuffer(const CpuMemHandlePtr& mem, size_t width)$/;"	f	class:paddle::RowBuffer
RowBuffer	math/RowBuffer.h	/^  explicit RowBuffer(size_t width) : width_(width) {}$/;"	f	class:paddle::RowBuffer
RowBuffer	math/RowBuffer.h	/^class RowBuffer {$/;"	c	namespace:paddle
SAMPLING_RATE	math/tests/test_perturbation.cpp	/^const int SAMPLING_RATE = 2;$/;"	v
SEQUENCE_LIMIT	trainer/tests/testPyDataWrapper.py	/^SEQUENCE_LIMIT = 50$/;"	v
SGD	utils/GlobalConstants.cpp	/^const std::string TrainAlgorithm::SGD = "sgd";$/;"	m	class:paddle::TrainAlgorithm	file:
SGD	utils/GlobalConstants.h	/^  static const std::string SGD;$/;"	m	class:paddle::TrainAlgorithm
SIGMOID_THRESHOLD_MAX	cuda/include/hl_functions.h	28;"	d
SIGMOID_THRESHOLD_MIN	cuda/include/hl_functions.h	23;"	d
SIMDFlags	utils/CpuId.cpp	/^SIMDFlags::SIMDFlags() {$/;"	f	class:paddle::SIMDFlags
SIMD_AVX	utils/CpuId.h	/^  SIMD_AVX    = 1 << 8,     \/\/\/< AVX$/;"	e	enum:paddle::simd_t
SIMD_AVX2	utils/CpuId.h	/^  SIMD_AVX2   = 1 << 9,     \/\/\/< AVX 2$/;"	e	enum:paddle::simd_t
SIMD_AVX512	utils/CpuId.h	/^  SIMD_AVX512 = 1 << 10,    \/\/\/< AVX 512$/;"	e	enum:paddle::simd_t
SIMD_FMA3	utils/CpuId.h	/^  SIMD_FMA3   = 1 << 6,     \/\/\/< FMA 3$/;"	e	enum:paddle::simd_t
SIMD_FMA4	utils/CpuId.h	/^  SIMD_FMA4   = 1 << 7,     \/\/\/< FMA 4$/;"	e	enum:paddle::simd_t
SIMD_INVOKE	math/SIMDFunctions.cpp	361;"	d	file:
SIMD_INVOKE	math/SIMDFunctions.cpp	363;"	d	file:
SIMD_NONE	utils/CpuId.h	/^  SIMD_NONE   = 0,          \/\/\/< None$/;"	e	enum:paddle::simd_t
SIMD_SSE	utils/CpuId.h	/^  SIMD_SSE    = 1 << 0,     \/\/\/< SSE$/;"	e	enum:paddle::simd_t
SIMD_SSE2	utils/CpuId.h	/^  SIMD_SSE2   = 1 << 1,     \/\/\/< SSE 2$/;"	e	enum:paddle::simd_t
SIMD_SSE3	utils/CpuId.h	/^  SIMD_SSE3   = 1 << 2,     \/\/\/< SSE 3$/;"	e	enum:paddle::simd_t
SIMD_SSE41	utils/CpuId.h	/^  SIMD_SSE41  = 1 << 4,     \/\/\/< SSE 4.1$/;"	e	enum:paddle::simd_t
SIMD_SSE42	utils/CpuId.h	/^  SIMD_SSE42  = 1 << 5,     \/\/\/< SSE 4.2$/;"	e	enum:paddle::simd_t
SIMD_SSSE3	utils/CpuId.h	/^  SIMD_SSSE3  = 1 << 3,     \/\/\/< SSSE 3$/;"	e	enum:paddle::simd_t
SNPRINTF	trainer/tests/picojson.h	85;"	d
SNPRINTF	trainer/tests/picojson.h	91;"	d
SPARSE_CSC	api/PaddleAPI.h	/^enum SparseFormatType { SPARSE_CSR = 0, SPARSE_CSC = 1 };$/;"	e	enum:SparseFormatType
SPARSE_CSC	math/Matrix.h	/^enum SparseFormat { SPARSE_CSR = 0, SPARSE_CSC = 1 };$/;"	e	enum:paddle::SparseFormat
SPARSE_CSR	api/PaddleAPI.h	/^enum SparseFormatType { SPARSE_CSR = 0, SPARSE_CSC = 1 };$/;"	e	enum:SparseFormatType
SPARSE_CSR	math/Matrix.h	/^enum SparseFormat { SPARSE_CSR = 0, SPARSE_CSC = 1 };$/;"	e	enum:paddle::SparseFormat
SPARSE_ID_COUNT	trainer/tests/testPyDataWrapper.py	/^SPARSE_ID_COUNT = 100$/;"	v
SPARSE_ID_LIMIT	trainer/tests/testPyDataWrapper.py	/^SPARSE_ID_LIMIT = 1000$/;"	v
SPARSE_NON_VALUE	api/PaddleAPI.h	/^enum SparseValueType { SPARSE_NON_VALUE = 0, SPARSE_VALUE = 1 };$/;"	e	enum:SparseValueType
SPARSE_VALUE	api/PaddleAPI.h	/^enum SparseValueType { SPARSE_NON_VALUE = 0, SPARSE_VALUE = 1 };$/;"	e	enum:SparseValueType
SQT_NONE	gserver/dataproviders/PyDataProvider2.cpp	/^enum SeqType { SQT_NONE = 0, SQT_SEQ, SQT_SUBSEQ };$/;"	e	enum:paddle::SeqType	file:
SQT_SEQ	gserver/dataproviders/PyDataProvider2.cpp	/^enum SeqType { SQT_NONE = 0, SQT_SEQ, SQT_SUBSEQ };$/;"	e	enum:paddle::SeqType	file:
SQT_SUBSEQ	gserver/dataproviders/PyDataProvider2.cpp	/^enum SeqType { SQT_NONE = 0, SQT_SEQ, SQT_SUBSEQ };$/;"	e	enum:paddle::SeqType	file:
STREAM_DEFAULT	cuda/include/hl_base.h	216;"	d
STRING_LIMIT	trainer/tests/testPyDataWrapper.py	/^STRING_LIMIT = 10$/;"	v
ST_DENSE	gserver/dataproviders/PyDataProvider2.cpp	/^  ST_DENSE = 0,$/;"	e	enum:paddle::SlotType	file:
ST_INDEX	gserver/dataproviders/PyDataProvider2.cpp	/^  ST_INDEX = 3$/;"	e	enum:paddle::SlotType	file:
ST_NON_SPARSE_VALUE	gserver/dataproviders/PyDataProvider2.cpp	/^  ST_NON_SPARSE_VALUE = 1,$/;"	e	enum:paddle::SlotType	file:
ST_SPARSE_VALUE	gserver/dataproviders/PyDataProvider2.cpp	/^  ST_SPARSE_VALUE = 2,$/;"	e	enum:paddle::SlotType	file:
SVectorPtr	parameter/Argument.h	/^typedef std::shared_ptr<std::vector<std::string>> SVectorPtr;$/;"	t	namespace:paddle
SYNCED	math/Vector.h	/^  enum SyncedFlag { DATA_AT_CPU = 0, DATA_AT_GPU = 1, SYNCED = 2 };$/;"	e	enum:paddle::CpuGpuVectorT::SyncedFlag
SameThreadChecker	utils/Util.h	/^  SameThreadChecker() {}$/;"	f	class:paddle::SameThreadChecker
SameThreadChecker	utils/Util.h	/^class SameThreadChecker {$/;"	c	namespace:paddle
Sample	gserver/layers/NCELayer.cpp	/^  struct Sample {$/;"	s	class:paddle::NCELayer	file:
SamplingIdLayer	gserver/layers/SamplingIdLayer.cpp	/^  explicit SamplingIdLayer(const LayerConfig& config)$/;"	f	class:paddle::SamplingIdLayer
SamplingIdLayer	gserver/layers/SamplingIdLayer.cpp	/^class SamplingIdLayer : public Layer {$/;"	c	namespace:paddle	file:
ScalingLayer	gserver/layers/ScalingLayer.cpp	/^  explicit ScalingLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::ScalingLayer
ScalingLayer	gserver/layers/ScalingLayer.cpp	/^class ScalingLayer : public Layer {$/;"	c	namespace:paddle	file:
ScalingProjection	gserver/layers/ScalingProjection.cpp	/^  ScalingProjection(const ProjectionConfig& config,$/;"	f	class:paddle::ScalingProjection
ScalingProjection	gserver/layers/ScalingProjection.cpp	/^class ScalingProjection : public Projection {$/;"	c	namespace:paddle	file:
ScatterAgentLayer	gserver/layers/AgentLayer.h	/^  explicit ScatterAgentLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::ScatterAgentLayer
ScatterAgentLayer	gserver/layers/AgentLayer.h	/^class ScatterAgentLayer : public Layer {$/;"	c	namespace:paddle
ScopedCallbacks	utils/Util.h	/^  ScopedCallbacks(CallbackType enter, CallbackType exit, Args&... args)$/;"	f	class:paddle::ScopedCallbacks
ScopedCallbacks	utils/Util.h	/^class ScopedCallbacks {$/;"	c	namespace:paddle
Search	scripts/cpplint.py	/^def Search(pattern, s):$/;"	f
SeenOpenBrace	scripts/cpplint.py	/^    def SeenOpenBrace(self):$/;"	m	class:NestingState
Segment	gserver/evaluators/ChunkEvaluator.cpp	/^  struct Segment {$/;"	s	class:paddle::ChunkEvaluator	file:
Segment	parameter/Parameter.h	/^struct Segment {$/;"	s	namespace:paddle
SelectiveFullyConnectedLayer	gserver/layers/SelectiveFullyConnectedLayer.h	/^  explicit SelectiveFullyConnectedLayer(const LayerConfig& config)$/;"	f	class:paddle::SelectiveFullyConnectedLayer
SelectiveFullyConnectedLayer	gserver/layers/SelectiveFullyConnectedLayer.h	/^class SelectiveFullyConnectedLayer : public Layer {$/;"	c	namespace:paddle
Semaphore	utils/Locks.h	/^  Semaphore(Semaphore&& other) : m(std::move(other.m)) {}$/;"	f	class:paddle::Semaphore
Semaphore	utils/Locks.h	/^class Semaphore {$/;"	c	namespace:paddle
Semaphore	utils/arch/linux/Locks.cpp	/^Semaphore::Semaphore(int initValue) : m(new SemaphorePrivate()) {$/;"	f	class:paddle::Semaphore
Semaphore	utils/arch/osx/Locks.cpp	/^Semaphore::Semaphore(int initValue) : m(new SemaphorePrivate()) {$/;"	f	class:paddle::Semaphore
SemaphorePrivate	utils/arch/linux/Locks.cpp	/^class SemaphorePrivate {$/;"	c	namespace:paddle	file:
SemaphorePrivate	utils/arch/osx/Locks.cpp	/^class SemaphorePrivate {$/;"	c	namespace:paddle	file:
SendDataRequestVec	pserver/BaseClient.h	/^  typedef std::vector<SendDataRequest> SendDataRequestVec;$/;"	t	class:paddle::BaseClient
SendJob	pserver/BaseClient.h	/^  struct SendJob {$/;"	s	class:paddle::BaseClient
SendJobPtr	pserver/BaseClient.h	/^  typedef std::shared_ptr<SendJob> SendJobPtr;$/;"	t	class:paddle::BaseClient
SendQueue	pserver/BaseClient.h	/^  typedef Queue<SendJobPtr> SendQueue;$/;"	t	class:paddle::BaseClient
SendRequest	pserver/BaseClient.h	/^  typedef std::vector<SendParameterRequest> SendRequest;$/;"	t	class:paddle::BaseClient
SeqInfo	parameter/Argument.h	/^  struct SeqInfo {$/;"	s	struct:paddle::Argument
SeqType	gserver/dataproviders/PyDataProvider2.cpp	/^enum SeqType { SQT_NONE = 0, SQT_SEQ, SQT_SUBSEQ };$/;"	g	namespace:paddle	file:
SequenceAgentLayer	gserver/layers/AgentLayer.h	/^  explicit SequenceAgentLayer(const LayerConfig& config) : AgentLayer(config) {}$/;"	f	class:paddle::SequenceAgentLayer
SequenceAgentLayer	gserver/layers/AgentLayer.h	/^class SequenceAgentLayer : public AgentLayer {$/;"	c	namespace:paddle
SequenceArg	function/BufferArg.h	/^  SequenceArg(ValueType valueType,$/;"	f	class:paddle::SequenceArg
SequenceArg	function/BufferArg.h	/^  SequenceArg(const Matrix& matrix,$/;"	f	class:paddle::SequenceArg
SequenceArg	function/BufferArg.h	/^  SequenceArg(void* buf,$/;"	f	class:paddle::SequenceArg
SequenceArg	function/BufferArg.h	/^class SequenceArg : public BufferArg {$/;"	c	namespace:paddle
SequenceClassificationErrorEvaluator	gserver/evaluators/Evaluator.cpp	/^class SequenceClassificationErrorEvaluator$/;"	c	namespace:paddle	file:
SequenceConcatLayer	gserver/layers/SequenceConcatLayer.cpp	/^  explicit SequenceConcatLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::SequenceConcatLayer
SequenceConcatLayer	gserver/layers/SequenceConcatLayer.cpp	/^class SequenceConcatLayer : public Layer {$/;"	c	namespace:paddle	file:
SequenceGatherAgentLayer	gserver/layers/AgentLayer.h	/^  explicit SequenceGatherAgentLayer(const LayerConfig& config)$/;"	f	class:paddle::SequenceGatherAgentLayer
SequenceGatherAgentLayer	gserver/layers/AgentLayer.h	/^class SequenceGatherAgentLayer : public GatherAgentLayer {$/;"	c	namespace:paddle
SequenceGenerator	api/PaddleAPI.h	/^class SequenceGenerator {$/;"	c
SequenceGenerator	api/SequenceGenerator.cpp	/^SequenceGenerator::SequenceGenerator() : m(new SequenceGeneratorPrivate()) {}$/;"	f	class:SequenceGenerator
SequenceGeneratorPrivate	api/SequenceGenerator.cpp	/^  SequenceGeneratorPrivate()$/;"	f	struct:SequenceGeneratorPrivate
SequenceGeneratorPrivate	api/SequenceGenerator.cpp	/^struct SequenceGeneratorPrivate {$/;"	s	file:
SequenceHelper	utils/PythonUtil.h	/^  explicit SequenceHelper(PyObject* seq) : seq_(seq) {$/;"	f	class:paddle::py::SequenceHelper
SequenceHelper	utils/PythonUtil.h	/^  explicit SequenceHelper(const PyObjectPtr& seq) : seq_(seq.get()) {$/;"	f	class:paddle::py::SequenceHelper
SequenceHelper	utils/PythonUtil.h	/^class SequenceHelper {$/;"	c	namespace:paddle::py
SequenceIdArg	function/BufferArg.h	/^  SequenceIdArg(const IVector& vector) : BufferArg(vector) {$/;"	f	class:paddle::SequenceIdArg
SequenceIdArg	function/BufferArg.h	/^  SequenceIdArg(const TensorShape& shape, ArgType argType = UNSPECIFIED)$/;"	f	class:paddle::SequenceIdArg
SequenceIdArg	function/BufferArg.h	/^  SequenceIdArg(void* buf,$/;"	f	class:paddle::SequenceIdArg
SequenceIdArg	function/BufferArg.h	/^class SequenceIdArg : public BufferArg {$/;"	c	namespace:paddle
SequenceLastInstanceLayer	gserver/layers/SequenceLastInstanceLayer.cpp	/^  explicit SequenceLastInstanceLayer(const LayerConfig& config)$/;"	f	class:paddle::SequenceLastInstanceLayer
SequenceLastInstanceLayer	gserver/layers/SequenceLastInstanceLayer.cpp	/^class SequenceLastInstanceLayer : public SequencePoolLayer {$/;"	c	namespace:paddle	file:
SequenceLevel	gserver/layers/SequencePoolLayer.h	/^  enum SequenceLevel { kNonSeq = 0, kSeq = 1 };$/;"	g	class:paddle::SequencePoolLayer
SequencePoolLayer	gserver/layers/SequencePoolLayer.h	/^  explicit SequencePoolLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::SequencePoolLayer
SequencePoolLayer	gserver/layers/SequencePoolLayer.h	/^class SequencePoolLayer : public Layer {$/;"	c	namespace:paddle
SequenceReshapeLayer	gserver/layers/SequenceReshapeLayer.cpp	/^  explicit SequenceReshapeLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::SequenceReshapeLayer
SequenceReshapeLayer	gserver/layers/SequenceReshapeLayer.cpp	/^class SequenceReshapeLayer : public Layer {$/;"	c	namespace:paddle	file:
SequenceScanner	gserver/dataproviders/PyDataProvider2.cpp	/^  SequenceScanner($/;"	f	class:paddle::SequenceScanner
SequenceScanner	gserver/dataproviders/PyDataProvider2.cpp	/^class SequenceScanner : public IFieldScanner {$/;"	c	namespace:paddle	file:
SequenceScanner	py_paddle/dataprovider_converter.py	/^class SequenceScanner(IScanner):$/;"	c
SequenceScatterAgentLayer	gserver/layers/AgentLayer.h	/^  explicit SequenceScatterAgentLayer(const LayerConfig& config)$/;"	f	class:paddle::SequenceScatterAgentLayer
SequenceScatterAgentLayer	gserver/layers/AgentLayer.h	/^class SequenceScatterAgentLayer : public ScatterAgentLayer {$/;"	c	namespace:paddle
SequenceTextPrinter	gserver/evaluators/Evaluator.cpp	/^  SequenceTextPrinter() {}$/;"	f	class:paddle::SequenceTextPrinter
SequenceTextPrinter	gserver/evaluators/Evaluator.cpp	/^class SequenceTextPrinter : public Evaluator {$/;"	c	namespace:paddle	file:
SequenceToBatch	gserver/layers/SequenceToBatch.h	/^  explicit SequenceToBatch(bool useGpu) : useGpu_(useGpu) {}$/;"	f	class:paddle::SequenceToBatch
SequenceToBatch	gserver/layers/SequenceToBatch.h	/^class SequenceToBatch {$/;"	c	namespace:paddle
ServiceFunction	pserver/ProtoServer.h	/^      ServiceFunction;$/;"	t	class:paddle::ProtoServer
SetCountingStyle	scripts/cpplint.py	/^    def SetCountingStyle(self, counting_style):$/;"	m	class:_CppLintState
SetDevice	utils/Util.h	/^  explicit SetDevice(int deviceId) {$/;"	f	class:paddle::SetDevice
SetDevice	utils/Util.h	/^class SetDevice {$/;"	c	namespace:paddle
SetFilters	scripts/cpplint.py	/^    def SetFilters(self, filters):$/;"	m	class:_CppLintState
SetLastHeader	scripts/cpplint.py	/^    def SetLastHeader(self, header_path):$/;"	m	class:_IncludeState
SetMaxDiff	math/tests/test_TrainingAlgorithm.cpp	/^  explicit SetMaxDiff(double max_diff) {$/;"	f	class:SetMaxDiff
SetMaxDiff	math/tests/test_TrainingAlgorithm.cpp	/^class SetMaxDiff {$/;"	c	file:
SetOutputFormat	scripts/cpplint.py	/^    def SetOutputFormat(self, output_format):$/;"	m	class:_CppLintState
SetTensorValue	math/tests/test_FPException.cpp	/^void SetTensorValue(Matrix& matrix, real value) {$/;"	f
SetUp	math/tests/test_perturbation.cpp	/^  virtual void SetUp() { generateTestImages(gpuImages_); }$/;"	f	class:PerturbationTest
SetUp	parameter/tests/test_common.cpp	/^  virtual void SetUp() {$/;"	f	class:CommonTest
SetVerboseLevel	scripts/cpplint.py	/^    def SetVerboseLevel(self, level):$/;"	m	class:_CppLintState
SgdCpuUpdater	trainer/ParameterUpdater.h	/^  explicit SgdCpuUpdater(const OptimizationConfig& optConfig)$/;"	f	class:paddle::SgdCpuUpdater
SgdCpuUpdater	trainer/ParameterUpdater.h	/^class SgdCpuUpdater : public SgdLocalUpdater, public Deprecated {$/;"	c	namespace:paddle
SgdLocalUpdater	trainer/ParameterUpdater.h	/^  explicit SgdLocalUpdater(const OptimizationConfig& optConfig,$/;"	f	class:paddle::SgdLocalUpdater
SgdLocalUpdater	trainer/ParameterUpdater.h	/^class SgdLocalUpdater : public ParameterUpdater {$/;"	c	namespace:paddle
SgdOptimizer	parameter/FirstOrderOptimizer.h	/^  explicit SgdOptimizer(const OptimizationConfig& optConfig)$/;"	f	class:paddle::SgdOptimizer
SgdOptimizer	parameter/FirstOrderOptimizer.h	/^class SgdOptimizer : public ParameterOptimizer {$/;"	c	namespace:paddle
SgdThreadUpdater	trainer/ThreadParameterUpdater.cpp	/^SgdThreadUpdater::SgdThreadUpdater(const OptimizationConfig& optConfig)$/;"	f	class:paddle::SgdThreadUpdater
SgdThreadUpdater	trainer/ThreadParameterUpdater.h	/^class SgdThreadUpdater : public ParameterUpdater {$/;"	c	namespace:paddle
SgdUpdaterWithCpuAverager	trainer/ParameterUpdater.cpp	/^SgdUpdaterWithCpuAverager::SgdUpdaterWithCpuAverager($/;"	f	class:paddle::SgdUpdaterWithCpuAverager
SgdUpdaterWithCpuAverager	trainer/ParameterUpdater.h	/^class SgdUpdaterWithCpuAverager : public SgdLocalUpdater {$/;"	c	namespace:paddle
SharedCpuMatrix	math/Matrix.h	/^  SharedCpuMatrix($/;"	f	class:paddle::SharedCpuMatrix
SharedCpuMatrix	math/Matrix.h	/^  SharedCpuMatrix(CpuMemHandlePtr dataHandle,$/;"	f	class:paddle::SharedCpuMatrix
SharedCpuMatrix	math/Matrix.h	/^  SharedCpuMatrix(int blockNum, size_t height, size_t width, bool trans = false)$/;"	f	class:paddle::SharedCpuMatrix
SharedCpuMatrix	math/Matrix.h	/^  SharedCpuMatrix(int blockNum,$/;"	f	class:paddle::SharedCpuMatrix
SharedCpuMatrix	math/Matrix.h	/^class SharedCpuMatrix : public CpuMatrix {$/;"	c	namespace:paddle
ShouldCheckNamespaceIndentation	scripts/cpplint.py	/^def ShouldCheckNamespaceIndentation(nesting_state, is_namespace_indent_item,$/;"	f
SimpleCode	math/MatrixBitCode.cpp	/^  SimpleCode(size_t code, size_t numClasses) : c_(code + numClasses) {}$/;"	f	struct:paddle::__anon17::SimpleCode
SimpleCode	math/MatrixBitCode.cpp	/^struct SimpleCode {$/;"	s	namespace:paddle::__anon17	file:
SimpleCodeTable	math/MatrixBitCode.cpp	/^  explicit SimpleCodeTable(size_t numClasses) : numClasses_(numClasses) {}$/;"	f	struct:paddle::__anon17::SimpleCodeTable
SimpleCodeTable	math/MatrixBitCode.cpp	/^struct SimpleCodeTable {$/;"	s	namespace:paddle::__anon17	file:
SimpleDataProvider	gserver/dataproviders/DataProvider.cpp	/^SimpleDataProvider::SimpleDataProvider(const DataConfig& config, bool useGpu)$/;"	f	class:paddle::SimpleDataProvider
SimpleDataProvider	gserver/dataproviders/DataProvider.h	/^class SimpleDataProvider : public SimpleDataProviderBase {$/;"	c	namespace:paddle
SimpleDataProvider	gserver/tests/pyDataProvider.py	/^class SimpleDataProvider:$/;"	c
SimpleDataProviderBase	gserver/dataproviders/DataProvider.cpp	/^SimpleDataProviderBase::SimpleDataProviderBase(const DataConfig& config,$/;"	f	class:paddle::SimpleDataProviderBase
SimpleDataProviderBase	gserver/dataproviders/DataProvider.h	/^class SimpleDataProviderBase : public DataProvider {$/;"	c	namespace:paddle
SimpleNestDataProvider	gserver/tests/pyDataProvider.py	/^class SimpleNestDataProvider:$/;"	c
SlopeInterceptLayer	gserver/layers/SlopeInterceptLayer.cpp	/^  explicit SlopeInterceptLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::SlopeInterceptLayer
SlopeInterceptLayer	gserver/layers/SlopeInterceptLayer.cpp	/^class SlopeInterceptLayer : public Layer {$/;"	c	namespace:paddle	file:
SlotHeader	gserver/dataproviders/PyDataProvider2.cpp	/^struct SlotHeader {  \/\/ Slot Header will parse from python object's slots field.$/;"	s	namespace:paddle	file:
SlotType	gserver/dataproviders/PyDataProvider2.cpp	/^enum SlotType {$/;"	g	namespace:paddle	file:
SocketChannel	pserver/SocketChannel.h	/^  SocketChannel(int socket, const std::string& peerName)$/;"	f	class:paddle::SocketChannel
SocketChannel	pserver/SocketChannel.h	/^  SocketChannel(struct sxi_sock* socket, const std::string& peerName)$/;"	f	class:paddle::SocketChannel
SocketChannel	pserver/SocketChannel.h	/^class SocketChannel {$/;"	c	namespace:paddle
SocketChannel	pserver/test/SocketTest.cpp	/^  explicit SocketChannel(int socket) : socket_(socket) {}$/;"	f	class:SocketChannel
SocketChannel	pserver/test/SocketTest.cpp	/^class SocketChannel {$/;"	c	file:
SocketClient	pserver/LightNetwork.cpp	/^SocketClient::SocketClient(const std::string &serverAddr,$/;"	f	class:paddle::SocketClient
SocketClient	pserver/LightNetwork.h	/^class SocketClient {$/;"	c	namespace:paddle
SocketClient	pserver/test/SocketTest.cpp	/^SocketClient::SocketClient(const std::string& serverAddr, int serverPort) {$/;"	f	class:SocketClient
SocketClient	pserver/test/SocketTest.cpp	/^class SocketClient {$/;"	c	file:
SocketServer	pserver/LightNetwork.cpp	/^SocketServer::SocketServer(const std::string &addr, int port, int rdmaCpu)$/;"	f	class:paddle::SocketServer
SocketServer	pserver/LightNetwork.h	/^class SocketServer : public Thread {$/;"	c	namespace:paddle
SocketServer	pserver/test/SocketTest.cpp	/^  explicit SocketServer(int port)$/;"	f	class:SocketServer
SocketServer	pserver/test/SocketTest.cpp	/^class SocketServer : public Thread {$/;"	c	file:
SocketWorker	pserver/LightNetwork.h	/^  SocketWorker(std::unique_ptr<SocketChannel>&& channel, SocketServer* server)$/;"	f	class:paddle::SocketWorker
SocketWorker	pserver/LightNetwork.h	/^class SocketWorker : public Thread {$/;"	c	namespace:paddle
SocketWorker	pserver/test/SocketTest.cpp	/^  explicit SocketWorker(int socket) : channel_(socket) {}$/;"	f	class:SocketWorker
SocketWorker	pserver/test/SocketTest.cpp	/^class SocketWorker : public Thread {$/;"	c	file:
SoftBinaryClassCrossEntropy	gserver/layers/CostLayer.h	/^  explicit SoftBinaryClassCrossEntropy(const LayerConfig& config)$/;"	f	class:paddle::SoftBinaryClassCrossEntropy
SoftBinaryClassCrossEntropy	gserver/layers/CostLayer.h	/^class SoftBinaryClassCrossEntropy : public CostLayer {$/;"	c	namespace:paddle
SparseAutoGrowRowCpuMatrix	math/SparseRowMatrix.h	/^  SparseAutoGrowRowCpuMatrix(size_t height,$/;"	f	class:paddle::SparseAutoGrowRowCpuMatrix
SparseAutoGrowRowCpuMatrix	math/SparseRowMatrix.h	/^class SparseAutoGrowRowCpuMatrix : public SparseRowCpuMatrix {$/;"	c	namespace:paddle
SparseBinaryScanner	py_paddle/dataprovider_converter.py	/^class SparseBinaryScanner(IScanner):$/;"	c
SparseDataFormat	function/TensorType.h	/^enum SparseDataFormat { T_SPARSE_CSR = 0, T_SPARSE_CSC = 1 };$/;"	g	namespace:paddle
SparseDataType	function/TensorType.h	/^enum SparseDataType { T_NO_VALUE = 0, T_FLOAT_VALUE = 1 };$/;"	g	namespace:paddle
SparseFloatScanner	py_paddle/dataprovider_converter.py	/^class SparseFloatScanner(SparseBinaryScanner):$/;"	c
SparseFormat	math/Matrix.h	/^enum SparseFormat { SPARSE_CSR = 0, SPARSE_CSC = 1 };$/;"	g	namespace:paddle
SparseFormatType	api/PaddleAPI.h	/^enum SparseFormatType { SPARSE_CSR = 0, SPARSE_CSC = 1 };$/;"	g
SparseMatrix	function/BufferArg.h	/^  typename Tensor<real, DType>::SparseMatrix SparseMatrix() const {$/;"	f	class:paddle::SparseMatrixArg
SparseMatrix	function/TensorType.h	/^  typedef typename detail::SparseMatrixT<VType, DType>::type SparseMatrix;$/;"	t	struct:paddle::Tensor
SparseMatrixArg	function/BufferArg.cpp	/^SparseMatrixArg::SparseMatrixArg(const CpuSparseMatrix& sparse, ArgType argType)$/;"	f	class:paddle::SparseMatrixArg
SparseMatrixArg	function/BufferArg.cpp	/^SparseMatrixArg::SparseMatrixArg(const GpuSparseMatrix& sparse, ArgType argType)$/;"	f	class:paddle::SparseMatrixArg
SparseMatrixArg	function/BufferArg.h	/^  SparseMatrixArg(ValueType valueType,$/;"	f	class:paddle::SparseMatrixArg
SparseMatrixArg	function/BufferArg.h	/^  SparseMatrixArg(void* buf,$/;"	f	class:paddle::SparseMatrixArg
SparseMatrixArg	function/BufferArg.h	/^class SparseMatrixArg : public BufferArg {$/;"	c	namespace:paddle
SparseMatrixT	function/TensorType.h	/^struct SparseMatrixT<int, DEVICE_TYPE_CPU> {$/;"	s	namespace:paddle::detail
SparseMatrixT	function/TensorType.h	/^struct SparseMatrixT<int, DEVICE_TYPE_GPU> {$/;"	s	namespace:paddle::detail
SparseMatrixT	function/TensorType.h	/^struct SparseMatrixT<real, DEVICE_TYPE_CPU> {$/;"	s	namespace:paddle::detail
SparseMatrixT	function/TensorType.h	/^struct SparseMatrixT<real, DEVICE_TYPE_GPU> {$/;"	s	namespace:paddle::detail
SparseMomentumParameterOptimizer	math/tests/OriginalOptimizerApi.h	/^void SparseMomentumParameterOptimizer(const VectorPtr vecs[],$/;"	f
SparseMomentumParameterOptimizer	parameter/FirstOrderOptimizer.cpp	/^SparseMomentumParameterOptimizer::SparseMomentumParameterOptimizer($/;"	f	class:paddle::SparseMomentumParameterOptimizer
SparseMomentumParameterOptimizer	parameter/FirstOrderOptimizer.h	/^class SparseMomentumParameterOptimizer : public ParameterOptimizer {$/;"	c	namespace:paddle
SparseNonValueConverter	py_paddle/util.py	/^    class SparseNonValueConverter(object):$/;"	c	class:DataProviderWrapperConverter
SparseNonValueScanner	gserver/dataproviders/PyDataProvider2.cpp	/^  explicit SparseNonValueScanner(SlotHeader* ptr)$/;"	f	class:paddle::SparseNonValueScanner
SparseNonValueScanner	gserver/dataproviders/PyDataProvider2.cpp	/^class SparseNonValueScanner : public IFieldScanner {$/;"	c	namespace:paddle	file:
SparseParameterDistribution	pserver/SparseParameterDistribution.cpp	/^SparseParameterDistribution::SparseParameterDistribution(size_t serviceNum) {$/;"	f	class:paddle::SparseParameterDistribution
SparseParameterDistribution	pserver/SparseParameterDistribution.h	/^class SparseParameterDistribution {$/;"	c	namespace:paddle
SparsePrefetchRowCpuMatrix	math/SparseRowMatrix.h	/^  SparsePrefetchRowCpuMatrix(CpuMemHandlePtr dataHandle,$/;"	f	class:paddle::SparsePrefetchRowCpuMatrix
SparsePrefetchRowCpuMatrix	math/SparseRowMatrix.h	/^class SparsePrefetchRowCpuMatrix : public SparseRowCpuMatrix {$/;"	c	namespace:paddle
SparseRemoteParameterUpdater	trainer/RemoteParameterUpdater.cpp	/^SparseRemoteParameterUpdater::SparseRemoteParameterUpdater($/;"	f	class:paddle::SparseRemoteParameterUpdater
SparseRemoteParameterUpdater	trainer/RemoteParameterUpdater.h	/^class SparseRemoteParameterUpdater : public ParameterUpdater {$/;"	c	namespace:paddle
SparseRemoteParameterUpdaterComposite	trainer/RemoteParameterUpdater.h	/^  SparseRemoteParameterUpdaterComposite($/;"	f	class:paddle::SparseRemoteParameterUpdaterComposite
SparseRemoteParameterUpdaterComposite	trainer/RemoteParameterUpdater.h	/^class SparseRemoteParameterUpdaterComposite : public ParameterUpdaterComposite {$/;"	c	namespace:paddle
SparseRowCpuMatrix	math/SparseRowMatrix.h	/^  SparseRowCpuMatrix(CpuMemHandlePtr dataHandle,$/;"	f	class:paddle::SparseRowCpuMatrix
SparseRowCpuMatrix	math/SparseRowMatrix.h	/^class SparseRowCpuMatrix : public CpuMatrix {$/;"	c	namespace:paddle
SparseRowIdsCpuMatrix	math/SparseRowMatrix.h	/^  SparseRowIdsCpuMatrix(CpuMemHandlePtr dataHandle,$/;"	f	class:paddle::SparseRowIdsCpuMatrix
SparseRowIdsCpuMatrix	math/SparseRowMatrix.h	/^class SparseRowIdsCpuMatrix : public CpuMatrix {$/;"	c	namespace:paddle
SparseValueConverter	py_paddle/util.py	/^    class SparseValueConverter(SparseNonValueConverter):$/;"	c	class:DataProviderWrapperConverter
SparseValueScanner	gserver/dataproviders/PyDataProvider2.cpp	/^  explicit SparseValueScanner(SlotHeader* ptr) : SparseNonValueScanner(ptr) {}$/;"	f	class:paddle::SparseValueScanner
SparseValueScanner	gserver/dataproviders/PyDataProvider2.cpp	/^class SparseValueScanner : public SparseNonValueScanner {$/;"	c	namespace:paddle	file:
SparseValueType	api/PaddleAPI.h	/^enum SparseValueType { SPARSE_NON_VALUE = 0, SPARSE_VALUE = 1 };$/;"	g
SparseValueType	math/Matrix.h	/^enum SparseValueType { NO_VALUE = 0, FLOAT_VALUE = 1 };$/;"	g	namespace:paddle
SpatialPyramidPoolLayer	gserver/layers/SpatialPyramidPoolLayer.h	/^  explicit SpatialPyramidPoolLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::SpatialPyramidPoolLayer
SpatialPyramidPoolLayer	gserver/layers/SpatialPyramidPoolLayer.h	/^class SpatialPyramidPoolLayer : public Layer {$/;"	c	namespace:paddle
SpinLock	utils/Locks.h	/^class SpinLock {$/;"	c	namespace:paddle
SpinLock	utils/arch/linux/Locks.cpp	/^SpinLock::SpinLock() : m(new SpinLockPrivate()) {}$/;"	f	class:paddle::SpinLock
SpinLock	utils/arch/osx/Locks.cpp	/^SpinLock::SpinLock() : m(new SpinLockPrivate()) {}$/;"	f	class:paddle::SpinLock
SpinLockPrivate	utils/arch/linux/Locks.cpp	/^  inline SpinLockPrivate() { pthread_spin_init(&lock_, 0); }$/;"	f	class:paddle::SpinLockPrivate
SpinLockPrivate	utils/arch/linux/Locks.cpp	/^class SpinLockPrivate {$/;"	c	namespace:paddle	file:
SpinLockPrivate	utils/arch/osx/Locks.cpp	/^class SpinLockPrivate {$/;"	c	namespace:paddle	file:
Split	scripts/cpplint.py	/^    def Split(self):$/;"	m	class:FileInfo
Stat	utils/Stat.h	/^  explicit Stat(const std::string& statName)$/;"	f	class:paddle::Stat
Stat	utils/Stat.h	/^class Stat {$/;"	c	namespace:paddle
StatInfo	utils/Stat.h	/^  explicit StatInfo(Stat* stat = nullptr) : stat_(stat) {$/;"	f	class:paddle::StatInfo
StatInfo	utils/Stat.h	/^class StatInfo {$/;"	c	namespace:paddle
StatPtr	utils/Stat.h	/^typedef std::shared_ptr<Stat> StatPtr;$/;"	t	namespace:paddle
StatSet	utils/Stat.h	/^  explicit StatSet(const std::string& name) : name_(name) {}$/;"	f	class:paddle::StatSet
StatSet	utils/Stat.h	/^class StatSet {$/;"	c	namespace:paddle
StaticMaskHeader	parameter/ParameterUpdaterHook.cpp	/^  struct StaticMaskHeader {$/;"	s	class:paddle::StaticPruningHook	file:
StaticPruningHook	parameter/ParameterUpdaterHook.cpp	/^  explicit StaticPruningHook(const std::string& mask_filename) : initCount_(0) {$/;"	f	class:paddle::StaticPruningHook
StaticPruningHook	parameter/ParameterUpdaterHook.cpp	/^class StaticPruningHook : public IParameterUpdaterHook {$/;"	c	namespace:paddle	file:
StatsInfo	gserver/evaluators/Evaluator.h	/^    StatsInfo() : TP(0.0), TN(0.0), FP(0.0), FN(0.0) {}$/;"	f	struct:paddle::PrecisionRecallEvaluator::StatsInfo
StatsInfo	gserver/evaluators/Evaluator.h	/^  struct StatsInfo {$/;"	s	class:paddle::PrecisionRecallEvaluator
StorageEngine	math/Storage.cpp	/^StorageEngine::StorageEngine() : cpuAllocator_(nullptr) {}$/;"	f	class:paddle::StorageEngine
StorageEngine	math/Storage.h	/^class StorageEngine {$/;"	c	namespace:paddle
StringIntPairHasher	parameter/ParameterUpdaterHook.cpp	/^class StringIntPairHasher {$/;"	c	namespace:paddle	file:
SubSequenceLayer	gserver/layers/SubSequenceLayer.cpp	/^  explicit SubSequenceLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::SubSequenceLayer
SubSequenceLayer	gserver/layers/SubSequenceLayer.cpp	/^class SubSequenceLayer : public Layer {$/;"	c	namespace:paddle	file:
SumCostLayer	gserver/layers/CostLayer.cpp	/^  explicit SumCostLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::SumCostLayer
SumCostLayer	gserver/layers/CostLayer.cpp	/^class SumCostLayer : public Layer {$/;"	c	namespace:paddle	file:
SumEvaluator	gserver/evaluators/Evaluator.cpp	/^  SumEvaluator() : cpuLabel_(nullptr), cpuWeight_(nullptr) {}$/;"	f	class:paddle::SumEvaluator
SumEvaluator	gserver/evaluators/Evaluator.cpp	/^class SumEvaluator : public Evaluator {$/;"	c	namespace:paddle	file:
SumOfSquaresCostLayer	gserver/layers/CostLayer.h	/^  explicit SumOfSquaresCostLayer(const LayerConfig& config)$/;"	f	class:paddle::SumOfSquaresCostLayer
SumOfSquaresCostLayer	gserver/layers/CostLayer.h	/^class SumOfSquaresCostLayer : public CostLayer {$/;"	c	namespace:paddle
SumToOneNormLayer	gserver/layers/SumToOneNormLayer.cpp	/^  explicit SumToOneNormLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::SumToOneNormLayer
SumToOneNormLayer	gserver/layers/SumToOneNormLayer.cpp	/^class SumToOneNormLayer : public Layer {$/;"	c	namespace:paddle	file:
SyncParameter	parameter/ParallelParameter.h	/^  SyncParameter(TrainerRole role, ParameterPtr localParam)$/;"	f	class:paddle::SyncParameter
SyncParameter	parameter/ParallelParameter.h	/^class SyncParameter : public ParallelParameter {$/;"	c	namespace:paddle
SyncThreadPool	utils/Thread.h	/^  SyncThreadPool() : jobStartBarrier_(0), jobFinishBarrier_(0) {$/;"	f	class:paddle::SyncThreadPool
SyncThreadPool	utils/Thread.h	/^  explicit SyncThreadPool(size_t numWorkers, bool checkOwner = true)$/;"	f	class:paddle::SyncThreadPool
SyncThreadPool	utils/Thread.h	/^class SyncThreadPool {$/;"	c	namespace:paddle
SyncedFlag	math/Vector.h	/^  enum SyncedFlag { DATA_AT_CPU = 0, DATA_AT_GPU = 1, SYNCED = 2 };$/;"	g	class:paddle::CpuGpuVectorT
T	pserver/ParameterServer2.h	/^    static_assert(sizeof(T) % AlignBytes == 0 || AlignBytes % sizeof(T) == 0,$/;"	m	class:paddle::ParameterServer2::ReadWriteBuffer
TASK_BACKWARD	gserver/gradientmachines/MultiGradientMachine.h	/^    TASK_BACKWARD = 2,$/;"	e	enum:paddle::MultiGradientMachine::TaskType
TASK_BACKWARD	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  TASK_BACKWARD = 1,$/;"	e	enum:paddle::TaskType
TASK_COPY_IN_ARGS	gserver/gradientmachines/MultiGradientMachine.h	/^    TASK_COPY_IN_ARGS = 3,$/;"	e	enum:paddle::MultiGradientMachine::TaskType
TASK_END_LAYER	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  TASK_END_LAYER = 2,$/;"	e	enum:paddle::TaskType
TASK_FORWARD	gserver/gradientmachines/MultiGradientMachine.h	/^    TASK_FORWARD = 1,$/;"	e	enum:paddle::MultiGradientMachine::TaskType
TASK_FORWARD	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  TASK_FORWARD = 0,$/;"	e	enum:paddle::TaskType
TASK_FORWARD_BACKWARD	gserver/gradientmachines/MultiGradientMachine.h	/^    TASK_FORWARD_BACKWARD = 0,$/;"	e	enum:paddle::MultiGradientMachine::TaskType
TASK_THREAD_FINISH	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  TASK_THREAD_FINISH = 3,$/;"	e	enum:paddle::TaskType
TENSOR_NORMAL	function/BufferArg.h	/^  TENSOR_NORMAL = 1,$/;"	e	enum:paddle::BufferType
TENSOR_SEQUENCE_DATA	function/BufferArg.h	/^  TENSOR_SEQUENCE_DATA = 3,$/;"	e	enum:paddle::BufferType
TENSOR_SEQUENCE_ID	function/BufferArg.h	/^  TENSOR_SEQUENCE_ID = 2,$/;"	e	enum:paddle::BufferType
TENSOR_SPARSE	function/BufferArg.h	/^  TENSOR_SPARSE = 4$/;"	e	enum:paddle::BufferType
TENSOR_UNKNOWN	function/BufferArg.h	/^  TENSOR_UNKNOWN = 0,$/;"	e	enum:paddle::BufferType
TEST	function/BufferArgTest.cpp	/^TEST(BufferTest, BufferArg) {$/;"	f	namespace:paddle
TEST	function/BufferArgTest.cpp	/^TEST(BufferTest, SequenceIdArg) {$/;"	f	namespace:paddle
TEST	function/ContextProjectionOpTest.cpp	/^TEST(ContextProjection, Projection) {$/;"	f
TEST	function/CosSimOpTest.cpp	/^TEST(Matrix, cosSim) {$/;"	f
TEST	function/CrossMapNormalOpTest.cpp	/^TEST(CrossMapNormal, real) {$/;"	f	namespace:paddle
TEST	function/CrossMapNormalOpTest.cpp	/^TEST(CrossMapNormalGrad, real) {$/;"	f	namespace:paddle
TEST	function/FunctionTest.cpp	/^TEST(Arguments, BufferArg) {$/;"	f	namespace:paddle
TEST	function/FunctionTest.cpp	/^TEST(Arguments, CpuSparseMatrix) {$/;"	f	namespace:paddle
TEST	function/FunctionTest.cpp	/^TEST(Arguments, Matrix) {$/;"	f	namespace:paddle
TEST	function/FunctionTest.cpp	/^TEST(Arguments, Vector) {$/;"	f	namespace:paddle
TEST	function/FunctionTest.cpp	/^TEST(Function, BufferArgs) {$/;"	f	namespace:paddle
TEST	function/MulOpTest.cpp	/^TEST(MuLOp, DSparseDMul) {$/;"	f
TEST	function/MulOpTest.cpp	/^TEST(MulOp, DDDMatrixMul) {$/;"	f
TEST	function/MulOpTest.cpp	/^TEST(MulOp, DDSparseMul) {$/;"	f
TEST	function/MulOpTest.cpp	/^TEST(MulOp, SparseDDMul) {$/;"	f
TEST	function/PadOpTest.cpp	/^TEST(Pad, real) {$/;"	f	namespace:paddle
TEST	function/PadOpTest.cpp	/^TEST(PadGrad, real) {$/;"	f	namespace:paddle
TEST	function/TensorShapeTest.cpp	/^TEST(TensorShape, Constructor) {$/;"	f	namespace:paddle
TEST	function/TensorShapeTest.cpp	/^TEST(TensorShape, GetAndSet) {$/;"	f	namespace:paddle
TEST	function/TensorTypeTest.cpp	/^TEST(TensorType, EmptyMatrix) {$/;"	f	namespace:paddle
TEST	function/TensorTypeTest.cpp	/^TEST(TensorType, Matrix) {$/;"	f	namespace:paddle
TEST	function/TensorTypeTest.cpp	/^TEST(TensorType, Vector) {$/;"	f	namespace:paddle
TEST	gserver/tests/test_ActivationGrad.cpp	/^TEST(Activation, activation) {$/;"	f
TEST	gserver/tests/test_BatchNorm.cpp	/^TEST(Layer, batchNorm) {$/;"	f
TEST	gserver/tests/test_ConvTrans.cpp	/^TEST(Layer, convTransLayerFwd) {$/;"	f
TEST	gserver/tests/test_ConvTrans.cpp	/^TEST(Layer, convTransLayerFwd2) {$/;"	f
TEST	gserver/tests/test_ConvUnify.cpp	/^TEST(Layer, convParaUnified) {$/;"	f
TEST	gserver/tests/test_Evaluator.cpp	/^TEST(Evaluator, classification_error) {$/;"	f
TEST	gserver/tests/test_Evaluator.cpp	/^TEST(Evaluator, ctc_error_evaluator) {$/;"	f
TEST	gserver/tests/test_Evaluator.cpp	/^TEST(Evaluator, last_column_auc) {$/;"	f
TEST	gserver/tests/test_Evaluator.cpp	/^TEST(Evaluator, last_column_sum) {$/;"	f
TEST	gserver/tests/test_Evaluator.cpp	/^TEST(Evaluator, precision_recall) {$/;"	f
TEST	gserver/tests/test_Evaluator.cpp	/^TEST(Evaluator, sum) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, AddtoLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, AverageLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, BatchNormalizationLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, BilinearInterpLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, CRFLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, CTCLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, ConvShiftLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, ConvexCombinationLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, CosSimVecMatLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, DataNormLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, ExpandLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, FeatureMapExpandLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, GatedRecurrentLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, GruStepLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, InterpolationLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, LstmLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, LstmStepLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, MDLstmLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, MaxLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, MultiplexLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, NCELayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, NormLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, OuterProdLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, PadLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, ParameterReluLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, PoolLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, PowerLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, RecurrentLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, ResizeLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, RotateLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, ScalingLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, SelectiveFullyConnectedLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, SequenceConcatLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, SequenceLastInstanceLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, SequenceReshapeLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, SlopeInterceptLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, SpatialPyramidPoolLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, TensorLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, blockExpandLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, concat) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, convLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, convTransLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, cosSimLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, fcLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, hsigmoidLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, huber_two_class) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, maxoutLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, multi_binary_label_sparse_mat) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, multi_cross) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, multi_cross_soft) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, multi_cross_with_selfnorm) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, rankCostLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, sparse_float_square_error) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, sparse_square_error) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, square_error) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, square_error_weighted) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, sumCostLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Layer, weightedRankCostLayer) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Operator, conv) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Operator, dot_mul) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Projection, context) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Projection, conv) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Projection, dot_mul) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Projection, fc) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Projection, identity) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Projection, scaling) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Projection, table) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(Projection, trans_fc) {$/;"	f
TEST	gserver/tests/test_LayerGrad.cpp	/^TEST(layer, multi_binary_label_id) {$/;"	f
TEST	gserver/tests/test_LinearChainCRF.cpp	/^TEST(LinearChainCRF, decoding) {$/;"	f
TEST	gserver/tests/test_MultinomialSampler.cpp	/^TEST(MultinomialSampler, gen) {$/;"	f
TEST	gserver/tests/test_NetworkCompare.cpp	/^TEST(Compare, concat_dotmul) {$/;"	f
TEST	gserver/tests/test_NetworkCompare.cpp	/^TEST(Compare, concat_fullmatrix) {$/;"	f
TEST	gserver/tests/test_NetworkCompare.cpp	/^TEST(Compare, concat_table) {$/;"	f
TEST	gserver/tests/test_NetworkCompare.cpp	/^TEST(Compare, img_conv) {$/;"	f
TEST	gserver/tests/test_NetworkCompare.cpp	/^TEST(Compare, img_conv2) {$/;"	f
TEST	gserver/tests/test_NetworkCompare.cpp	/^TEST(Compare, img_pool) {$/;"	f
TEST	gserver/tests/test_NetworkCompare.cpp	/^TEST(Compare, network) {$/;"	f
TEST	gserver/tests/test_PriorBox.cpp	/^TEST(Layer, priorBoxLayerFwd) {$/;"	f
TEST	gserver/tests/test_ProtoDataProvider.cpp	/^TEST(ProtoDataProvider, constant_slots) {$/;"	f
TEST	gserver/tests/test_ProtoDataProvider.cpp	/^TEST(ProtoDataProvider, test) {$/;"	f
TEST	gserver/tests/test_ProtoDataProvider.cpp	/^TEST(ProtoSequenceDataProvider, test) {$/;"	f
TEST	gserver/tests/test_PyDataProvider.cpp	/^TEST(PyDataProvider, py_fill_nest_slots) {$/;"	f
TEST	gserver/tests/test_PyDataProvider.cpp	/^TEST(PyDataProvider, py_fill_slots) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, can_over_batch_size) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, dense_no_seq) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, index_no_seq) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, index_seq) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, index_sub_seq) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, init_hook) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, input_order) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, minPoolSizeWithCache) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, min_pool_size) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, multiThread) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, sparse_no_value_no_seq) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, sparse_value_no_seq) {$/;"	f
TEST	gserver/tests/test_PyDataProvider2.cpp	/^TEST(PyDataProvider2, test_check) {$/;"	f
TEST	gserver/tests/test_RecurrentGradientMachine.cpp	/^TEST(RecurrentGradientMachine, HasSubSequence) {$/;"	f
TEST	gserver/tests/test_RecurrentGradientMachine.cpp	/^TEST(RecurrentGradientMachine, rnn) {$/;"	f
TEST	gserver/tests/test_RecurrentGradientMachine.cpp	/^TEST(RecurrentGradientMachine, rnn_multi_input) {$/;"	f
TEST	gserver/tests/test_RecurrentGradientMachine.cpp	/^TEST(RecurrentGradientMachine, rnn_multi_unequalength_input) {$/;"	f
TEST	gserver/tests/test_RecurrentLayer.cpp	/^TEST(Layer, GatedRecurrentLayer) {$/;"	f
TEST	gserver/tests/test_RecurrentLayer.cpp	/^TEST(Layer, LstmLayer) {$/;"	f
TEST	gserver/tests/test_RecurrentLayer.cpp	/^TEST(Layer, RecurrentLayer) {$/;"	f
TEST	gserver/tests/test_SelectiveFCLayer.cpp	/^TEST(Layer, SelectiveFcLayer_train_dense_mul) {$/;"	f
TEST	gserver/tests/test_SelectiveFCLayer.cpp	/^TEST(Layer, SelectiveFcLayer_train_sparse_mul) {$/;"	f
TEST	gserver/tests/test_WarpCTCLayer.cpp	/^TEST(Layer, WarpCTCLayer) {$/;"	f
TEST	math/tests/test_Allocator.cpp	/^TEST(Allocator, Pool) {$/;"	f
TEST	math/tests/test_Allocator.cpp	/^TEST(MemoryHandle, Cpu) {$/;"	f
TEST	math/tests/test_Allocator.cpp	/^TEST(MemoryHandle, Gpu) {$/;"	f
TEST	math/tests/test_BaseMatrix.cpp	/^TEST(BaseMatrix, BaseMatrix) {$/;"	f
TEST	math/tests/test_BaseMatrix.cpp	/^TEST(BaseMatrix, BaseMatrix_BaseMatrix) {$/;"	f
TEST	math/tests/test_BaseMatrix.cpp	/^TEST(BaseMatrix, BaseMatrix_real) {$/;"	f
TEST	math/tests/test_BaseMatrix.cpp	/^TEST(BaseMatrix, Other) {$/;"	f
TEST	math/tests/test_BaseMatrix.cpp	/^TEST(BaseMatrix, real) {$/;"	f
TEST	math/tests/test_BaseMatrix.cpp	/^TEST(BaseMatrix, real_real) {$/;"	f
TEST	math/tests/test_BaseMatrix.cpp	/^TEST(BaseMatrix, void) {$/;"	f
TEST	math/tests/test_CpuGpuVector.cpp	/^TEST(CpuGpuVector, getData) {$/;"	f
TEST	math/tests/test_CpuGpuVector.cpp	/^TEST(CpuGpuVector, subCreate) {$/;"	f
TEST	math/tests/test_ExecViaCpu.cpp	/^TEST(ExecViaCpu, test1) {$/;"	f
TEST	math/tests/test_FPException.cpp	/^TEST(fp, overflow) {$/;"	f
TEST	math/tests/test_GpuProfiler.cpp	/^TEST(Profiler, testBilinearFwdBwd) {$/;"	f
TEST	math/tests/test_Matrix.cpp	/^TEST(Matrix, AtOffset) {$/;"	f
TEST	math/tests/test_Matrix.cpp	/^TEST(Matrix, BilinearFwdBwd) {$/;"	f
TEST	math/tests/test_Matrix.cpp	/^TEST(Matrix, copyByRowIndex) {$/;"	f
TEST	math/tests/test_Matrix.cpp	/^TEST(Matrix, multiBinaryCrossEntropy) {$/;"	f
TEST	math/tests/test_Matrix.cpp	/^TEST(Matrix, paramRelu) {$/;"	f
TEST	math/tests/test_Matrix.cpp	/^TEST(Matrix, sharedBias) {$/;"	f
TEST	math/tests/test_Matrix.cpp	/^TEST(Matrix, tableProjection) {$/;"	f
TEST	math/tests/test_Matrix.cpp	/^TEST(Matrix, unary) {$/;"	f
TEST	math/tests/test_RowBuffer.cpp	/^TEST(RowBuffer, testAutoGrow) {$/;"	f
TEST	math/tests/test_RowBuffer.cpp	/^TEST(RowBuffer, testWithMemBuf) {$/;"	f
TEST	math/tests/test_SIMDFunctions.cpp	/^TEST(SIMDFunction, addTo) {$/;"	f
TEST	math/tests/test_SIMDFunctions.cpp	/^TEST(SIMDFunction, batchAddTo) {$/;"	f
TEST	math/tests/test_SIMDFunctions.cpp	/^TEST(SIMDFunction, colMax) {$/;"	f
TEST	math/tests/test_SIMDFunctions.cpp	/^TEST(SIMDFunction, decayL1_WithLR) {$/;"	f
TEST	math/tests/test_SIMDFunctions.cpp	/^TEST(SIMDFunction, decayL1_WithoutLR) {$/;"	f
TEST	math/tests/test_SparseMatrix.cpp	/^TEST(Matrix, CopyCpuMatrixToSparseMatrix) {$/;"	f
TEST	math/tests/test_SparseMatrix.cpp	/^TEST(Matrix, CopySparseMatrixToGpuSparseMatrix) {$/;"	f
TEST	math/tests/test_SparseMatrix.cpp	/^TEST(Matrix, CpuSparseMatrixCopyFrom) {$/;"	f
TEST	math/tests/test_SparseMatrix.cpp	/^TEST(Matrix, CpuSparseMatrixRandUniform) {$/;"	f
TEST	math/tests/test_SparseMatrix.cpp	/^TEST(Matrix, CpuSparseMatrixSubMatrix) {$/;"	f
TEST	math/tests/test_SparseMatrix.cpp	/^TEST(Matrix, SparseMatrixCSCFormatTrimFrom) {$/;"	f
TEST	math/tests/test_SparseMatrix.cpp	/^TEST(Matrix, SparseMatrixCSRFormatTrimFrom) {$/;"	f
TEST	math/tests/test_SparseMatrix.cpp	/^TEST(Matrix, SparseMatrixMul) {$/;"	f
TEST	math/tests/test_SparseMatrix.cpp	/^TEST(Matrix, SparseMatrixTranspose) {$/;"	f
TEST	math/tests/test_TrainingAlgorithm.cpp	/^TEST(Training, AdaDelta) { testCase(testAdaDelta); }$/;"	f
TEST	math/tests/test_TrainingAlgorithm.cpp	/^TEST(Training, Adagrad) { testCase(testAdagrad); }$/;"	f
TEST	math/tests/test_TrainingAlgorithm.cpp	/^TEST(Training, Adam) { testCase(testAdam); }$/;"	f
TEST	math/tests/test_TrainingAlgorithm.cpp	/^TEST(Training, Adamax) {$/;"	f
TEST	math/tests/test_TrainingAlgorithm.cpp	/^TEST(Training, DecayedAdagrad) {$/;"	f
TEST	math/tests/test_TrainingAlgorithm.cpp	/^TEST(Training, RMSProp) {$/;"	f
TEST	math/tests/test_TrainingAlgorithm.cpp	/^TEST(Training, SparseMomentum) { testCase(testSparseMomentum); }$/;"	f
TEST	math/tests/test_batchTranspose.cpp	/^TEST(MatrixBatchTransTest, test_batch_matrix_transpose) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Matrix, MaxOutFwdBwd) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Matrix, PoolFwdBwd) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Matrix, classificationError) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Matrix, maxSequence) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Matrix, mul) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Matrix, paramReluBackwardDiff) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Matrix, sequenceAvgForward) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Matrix, softmax) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Matrix, tableProjection) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Matrix, topK) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Matrix, unary) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(SMatrix, topK) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Vector, Equal) {$/;"	f
TEST	math/tests/test_matrixCompare.cpp	/^TEST(Vector, rowFunc) {$/;"	f
TEST	math/tests/test_sparseMatrixCompare.cpp	/^TEST(SMatrix, sMatrixCollectBias) {$/;"	f
TEST	math/tests/test_sparseMatrixCompare.cpp	/^TEST(SMatrix, sMatrixMul) {$/;"	f
TEST	math/tests/test_sparseMatrixCompare.cpp	/^TEST(SMatrix, sMatrixOp) {$/;"	f
TEST	pserver/test/test_ParameterServer2.cpp	/^TEST(ParameterServer2, mergeBlockSegment) { g_server->mergeBlockSegmentTest(); }$/;"	f
TEST	pserver/test/test_ParameterServer2.cpp	/^TEST(ParameterServer2, operation) { g_server->operationTest(); }$/;"	f
TEST	pserver/test/test_ParameterServer2.cpp	/^TEST(ParameterServer2, sendData) {$/;"	f
TEST	pserver/test/test_ParameterServer2.cpp	/^TEST(ParameterServer2, sendParameter) { g_server->sendParameterTest(); }$/;"	f
TEST	pserver/test/test_ParameterServer2.cpp	/^TEST(ParameterServer2, setConfig) { g_server->setConfigTest(); }$/;"	f
TEST	pserver/test/test_ParameterServer2.cpp	/^TEST(ParameterServer2, setStatus) { g_server->setStatusTest(); }$/;"	f
TEST	pserver/test/test_ParameterServer2.cpp	/^TEST(ParameterServer2, synchronize) { g_server->synchronizeTest(); }$/;"	f
TEST	pserver/test/test_ParameterServer2.cpp	/^TEST(ParameterServer2, waitPassFinish) { g_server->waitPassFinishTest(); }$/;"	f
TEST	pserver/test/test_ProtoServer.cpp	/^TEST(ProtoServer, extended) {$/;"	f
TEST	pserver/test/test_ProtoServer.cpp	/^TEST(ProtoServer, regular) {$/;"	f
TEST	trainer/tests/test_Compare.cpp	/^TEST(Trainer, create) {$/;"	f
TEST	trainer/tests/test_CompareSparse.cpp	/^TEST(compareSparse, NeuralNetwork) {$/;"	f
TEST	trainer/tests/test_CompareSparse.cpp	/^TEST(compareSparse, cpu) {$/;"	f
TEST	trainer/tests/test_CompareSparse.cpp	/^TEST(compareSparse, cpu10_local_vs_remote) {$/;"	f
TEST	trainer/tests/test_CompareSparse.cpp	/^TEST(compareSparse, multiGradientMachine) {$/;"	f
TEST	trainer/tests/test_CompareSparse.cpp	/^TEST(compareSparse, remote_cpu) {$/;"	f
TEST	trainer/tests/test_CompareTwoNets.cpp	/^TEST(Trainer, create) {$/;"	f
TEST	trainer/tests/test_CompareTwoOpts.cpp	/^TEST(Trainer, create) {$/;"	f
TEST	trainer/tests/test_PyDataProviderWrapper.cpp	/^TEST(PyDataProviderWrapper, HasSubSequenceData) {$/;"	f
TEST	trainer/tests/test_PyDataProviderWrapper.cpp	/^TEST(PyDataProviderWrapper, NoSequenceData) {$/;"	f
TEST	trainer/tests/test_PyDataProviderWrapper.cpp	/^TEST(PyDataProviderWrapper, SequenceData) {$/;"	f
TEST	trainer/tests/test_Trainer.cpp	/^TEST(checkGradient, chunk) {$/;"	f
TEST	trainer/tests/test_Trainer.cpp	/^TEST(checkGradient, cpu) { checkGradientTest(configFile1, false, false); }$/;"	f
TEST	trainer/tests/test_Trainer.cpp	/^TEST(checkGradient, gpu) { checkGradientTest(configFile1, true, false); }$/;"	f
TEST	trainer/tests/test_Trainer.cpp	/^TEST(checkGradient, hsigmoid) { checkGradientTest(configFile2, false, false); }$/;"	f
TEST	trainer/tests/test_Trainer.cpp	/^TEST(checkGradient, multi) {$/;"	f
TEST	trainer/tests/test_Trainer.cpp	/^TEST(checkGradient, multiGpu) {$/;"	f
TEST	trainer/tests/test_Trainer.cpp	/^TEST(checkGradient, multiParallel) {$/;"	f
TEST	trainer/tests/test_Trainer.cpp	/^TEST(checkGradient, non_parallel) {$/;"	f
TEST	trainer/tests/test_Trainer.cpp	/^TEST(checkGradient, parallel) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(SgdThreadUpdater, simpleSparseNN) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(average_window, gpu) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(average_window, gpu2) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(average_window, gpu4) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(average_window_cpu, gpu2) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(average_window_cpu, gpu4) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(checkRemoteUpdater, cpuDeltaTrainer) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(checkRemoteUpdater, cpuDeltaTrainerOldUpdater) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(checkRemoteUpdater, cpuTrainer) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(checkRemoteUpdater, cpuTrainerOldUpdater) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(checkRemoteUpdater, gpu2Trainer) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(checkRemoteUpdater, gpu2TrainerOldUpdater) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(checkRemoteUpdater, gpu4Trainer) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(checkRemoteUpdater, gpu4TrainerOldUpdater) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(checkRemoteUpdater, gpuTrainer) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(checkRemoteUpdater, gpuTrainerOldUpdater) {$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(trainerOnePass, cpu) { trainerOnePassTest(configFile1, false, false); }$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(trainerOnePass, gpu) { trainerOnePassTest(configFile1, true, false); }$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(trainerOnePass, gpu2) { trainerOnePassTest(configFile1, true, false, 2); }$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(trainerOnePass, gpu4) { trainerOnePassTest(configFile1, true, false, 4); }$/;"	f
TEST	trainer/tests/test_TrainerOnePass.cpp	/^TEST(trainerOnePass, parallel) {$/;"	f
TEST	trainer/tests/test_recurrent_machine_generation.cpp	/^TEST(RecurrentGradientMachine, test_generation) {$/;"	f
TEST	utils/tests/test_CustomStackTrace.cpp	/^TEST(CustomStackTrace, normalTest) {$/;"	f
TEST	utils/tests/test_CustomStackTrace.cpp	/^TEST(CustomStackTrace, normalTrain) {$/;"	f
TEST	utils/tests/test_Error.cpp	/^TEST(Error, testAll) {$/;"	f
TEST	utils/tests/test_SIMDFlags.cpp	/^TEST(SIMDFlags, gccTest) {$/;"	f
TEST	utils/tests/test_SIMDFlags.cpp	/^TEST(SIMDFlags, normalPrint) {$/;"	f
TEST	utils/tests/test_SpinLock.cpp	/^TEST(ThreadSpinLock, normalTest) {$/;"	f
TEST	utils/tests/test_StringUtils.cpp	/^TEST(StringUtil, to) {$/;"	f
TEST	utils/tests/test_Thread.cpp	/^TEST(AsyncThreadPool, addBatchJob) {$/;"	f
TEST	utils/tests/test_Thread.cpp	/^TEST(AsyncThreadPool, addBatchJobWithResults) {$/;"	f
TEST	utils/tests/test_Thread.cpp	/^TEST(AsyncThreadPool, addJob) {$/;"	f
TEST	utils/tests/test_Thread.cpp	/^TEST(AsyncThreadPool, multiThreadAddBatchJob) {$/;"	f
TEST	utils/tests/test_ThreadBarrier.cpp	/^TEST(ThreadBarrier, normalTest) {$/;"	f
TEST_BARRIER	parameter/tests/test_common.cpp	210;"	d	file:
TEST_BARRIER_RANDOM	parameter/tests/test_common.cpp	181;"	d	file:
TEST_F	math/tests/test_perturbation.cpp	/^TEST_F(PerturbationTest, identity_perturb) {$/;"	f
TEST_F	math/tests/test_perturbation.cpp	/^TEST_F(PerturbationTest, random_perturb) {$/;"	f
TEST_F	math/tests/test_perturbation.cpp	/^TEST_F(PerturbationTest, rotation_test) {$/;"	f
TEST_F	math/tests/test_perturbation.cpp	/^TEST_F(PerturbationTest, scale_test) {$/;"	f
TEST_F	math/tests/test_perturbation.cpp	/^TEST_F(PerturbationTest, translation_test) {$/;"	f
TEST_F	parameter/tests/test_common.cpp	/^TEST_F(CommonTest, barrierStat) {$/;"	f
TEST_F	parameter/tests/test_common.cpp	/^TEST_F(CommonTest, sgdUpdate) {$/;"	f
TEST_F	parameter/tests/test_common.cpp	/^TEST_F(CommonTest, syncThreadPool) {$/;"	f
TGT_SIZE	math/tests/test_perturbation.cpp	/^const int TGT_SIZE = 21;$/;"	v
TN	gserver/evaluators/Evaluator.h	/^    double TN;$/;"	m	struct:paddle::PrecisionRecallEvaluator::StatsInfo
TP	gserver/evaluators/Evaluator.h	/^    double TP;$/;"	m	struct:paddle::PrecisionRecallEvaluator::StatsInfo
TRAINER_ROLE_CONTROL	parameter/ParallelParameter.h	/^  TRAINER_ROLE_CONTROL,$/;"	e	enum:paddle::TrainerRole
TRAINER_ROLE_MAJOR	parameter/ParallelParameter.h	/^  TRAINER_ROLE_MAJOR,$/;"	e	enum:paddle::TrainerRole
TRAINER_ROLE_MASTER	parameter/ParallelParameter.h	/^  TRAINER_ROLE_MASTER,$/;"	e	enum:paddle::TrainerRole
TRAINER_ROLE_MINOR	parameter/ParallelParameter.h	/^  TRAINER_ROLE_MINOR,$/;"	e	enum:paddle::TrainerRole
TRAINER_ROLE_SINGLE	parameter/ParallelParameter.h	/^  TRAINER_ROLE_SINGLE,$/;"	e	enum:paddle::TrainerRole
TRAINER_ROLE_SLAVE	parameter/ParallelParameter.h	/^  TRAINER_ROLE_SLAVE$/;"	e	enum:paddle::TrainerRole
T_FLOAT_VALUE	function/TensorType.h	/^enum SparseDataType { T_NO_VALUE = 0, T_FLOAT_VALUE = 1 };$/;"	e	enum:paddle::SparseDataType
T_NO_VALUE	function/TensorType.h	/^enum SparseDataType { T_NO_VALUE = 0, T_FLOAT_VALUE = 1 };$/;"	e	enum:paddle::SparseDataType
T_SPARSE_CSC	function/TensorType.h	/^enum SparseDataFormat { T_SPARSE_CSR = 0, T_SPARSE_CSC = 1 };$/;"	e	enum:paddle::SparseDataFormat
T_SPARSE_CSR	function/TensorType.h	/^enum SparseDataFormat { T_SPARSE_CSR = 0, T_SPARSE_CSC = 1 };$/;"	e	enum:paddle::SparseDataFormat
TableProjection	gserver/layers/TableProjection.cpp	/^TableProjection::TableProjection(const ProjectionConfig& config,$/;"	f	class:paddle::TableProjection
TableProjection	gserver/layers/TableProjection.h	/^class TableProjection : public Projection {$/;"	c	namespace:paddle
TaskType	gserver/gradientmachines/MultiGradientMachine.h	/^  enum TaskType {$/;"	g	class:paddle::MultiGradientMachine
TaskType	gserver/gradientmachines/ParallelNeuralNetwork.h	/^enum TaskType {$/;"	g	namespace:paddle
TcpClient	pserver/LightNetwork.cpp	/^void SocketClient::TcpClient(const std::string &serverAddr, int serverPort) {$/;"	f	class:paddle::SocketClient
TearDown	math/tests/test_perturbation.cpp	/^  virtual void TearDown() {}$/;"	f	class:PerturbationTest
Tensor	function/TensorType.h	/^struct Tensor {$/;"	s	namespace:paddle
TensorApply	math/TensorApply.h	/^  explicit INLINE TensorApply($/;"	f	class:paddle::TensorApply
TensorApply	math/TensorApply.h	/^  explicit INLINE TensorApply(const Derived& p)$/;"	f	class:paddle::TensorApply
TensorApply	math/TensorApply.h	/^  explicit INLINE TensorApply(const TensorConstant<OP, ArgType, T>& expr)$/;"	f	class:paddle::TensorApply
TensorApply	math/TensorApply.h	/^  explicit INLINE TensorApply(const TensorUnaryOp<OP, ArgType, T>& expr)$/;"	f	class:paddle::TensorApply
TensorApply	math/TensorApply.h	/^  explicit TensorApply(const TensorExpression<Derived, T>& expr)$/;"	f	class:paddle::TensorApply
TensorApply	math/TensorApply.h	/^class TensorApply {$/;"	c	namespace:paddle
TensorApply	math/TensorApply.h	/^class TensorApply<const Derived, T> {$/;"	c	namespace:paddle
TensorApply	math/TensorApply.h	/^class TensorApply<const TensorBinaryOp<OP, LhsType, RhsType, T>, T> {$/;"	c	namespace:paddle
TensorApply	math/TensorApply.h	/^class TensorApply<const TensorConstant<OP, ArgType, T>, T> {$/;"	c	namespace:paddle
TensorApply	math/TensorApply.h	/^class TensorApply<const TensorExpression<Derived, T>, T> {$/;"	c	namespace:paddle
TensorApply	math/TensorApply.h	/^class TensorApply<const TensorTernaryOp<ArgType1, ArgType2, ArgType3, T>, T> {$/;"	c	namespace:paddle
TensorApply	math/TensorApply.h	/^class TensorApply<const TensorUnaryOp<OP, ArgType, T>, T> {$/;"	c	namespace:paddle
TensorAssignOp	math/TensorAssign.h	/^  explicit TensorAssignOp(const LhsType& lhs, const RhsType& rhs)$/;"	f	class:paddle::TensorAssignOp
TensorAssignOp	math/TensorAssign.h	/^class TensorAssignOp {$/;"	c	namespace:paddle
TensorBinaryOp	math/TensorExpression.h	/^  explicit TensorBinaryOp(const OP op, const LhsType& lhs, const RhsType& rhs)$/;"	f	class:paddle::TensorBinaryOp
TensorBinaryOp	math/TensorExpression.h	/^class TensorBinaryOp$/;"	c	namespace:paddle
TensorCheck	math/tests/TensorCheck.h	/^void TensorCheck(AssertEq compare, real args1, real args2) {$/;"	f	namespace:autotest
TensorCheck	math/tests/TensorCheck.h	/^void TensorCheck(AssertEq compare, size_t args1, size_t args2) {$/;"	f	namespace:autotest
TensorCheck	math/tests/TensorCheck.h	/^void TensorCheck(AssertEq compare,$/;"	f	namespace:autotest
TensorCheckEqual	math/tests/TensorCheck.h	/^void TensorCheckEqual(const Tensor1& tensor1, const Tensor2& tensor2) {$/;"	f	namespace:autotest
TensorCheckErr	math/tests/TensorCheck.h	/^void TensorCheckErr(const Tensor1& tensor1, const Tensor2& tensor2) {$/;"	f	namespace:autotest
TensorConstant	math/TensorExpression.h	/^  explicit TensorConstant(const OP op, const ExprType& expr)$/;"	f	class:paddle::TensorConstant
TensorConstant	math/TensorExpression.h	/^class TensorConstant$/;"	c	namespace:paddle
TensorCpuApply	math/TensorEvaluate.h	/^inline void TensorCpuApply(LeftType& lhs, const RightType& rhs) {$/;"	f	namespace:paddle
TensorElementWiseOp	math/TensorEvaluate.h	/^__global__ void TensorElementWiseOp(LeftType lhs, RightType rhs) {$/;"	f	namespace:paddle
TensorElementWiseOp	math/TensorEvaluate.h	/^__global__ void TensorElementWiseOp(LeftType lhs,$/;"	f	namespace:paddle
TensorExpression	math/TensorExpression.h	/^class TensorExpression {$/;"	c	namespace:paddle
TensorGpuApply	math/TensorEvaluate.h	/^inline void TensorGpuApply(LeftType& lhs, RightType& rhs) {}$/;"	f	namespace:paddle
TensorGpuApply	math/TensorEvaluate.h	/^inline void TensorGpuApply(LeftType& lhs, const RightType& rhs) {$/;"	f	namespace:paddle
TensorLayer	gserver/layers/TensorLayer.h	/^  explicit TensorLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::TensorLayer
TensorLayer	gserver/layers/TensorLayer.h	/^class TensorLayer : public Layer {$/;"	c	namespace:paddle
TensorShape	function/TensorShape.h	/^  TensorShape() : ndims_(0), nelements_(0) { initDims(0); }$/;"	f	class:paddle::TensorShape
TensorShape	function/TensorShape.h	/^  TensorShape(const TensorShape& t)$/;"	f	class:paddle::TensorShape
TensorShape	function/TensorShape.h	/^  TensorShape(size_t ndims) : ndims_(ndims), nelements_(1) { initDims(ndims); };$/;"	f	class:paddle::TensorShape
TensorShape	function/TensorShape.h	/^  TensorShape(std::initializer_list<size_t> dims) {$/;"	f	class:paddle::TensorShape
TensorShape	function/TensorShape.h	/^class TensorShape {$/;"	c	namespace:paddle
TensorTernaryOp	math/TensorExpression.h	/^  explicit TensorTernaryOp(const ExprType1& expr1,$/;"	f	class:paddle::TensorTernaryOp
TensorTernaryOp	math/TensorExpression.h	/^class TensorTernaryOp : public TensorExpression<$/;"	c	namespace:paddle
TensorUnaryOp	math/TensorExpression.h	/^  explicit TensorUnaryOp(const OP op, const ExprType& expr)$/;"	f	class:paddle::TensorUnaryOp
TensorUnaryOp	math/TensorExpression.h	/^class TensorUnaryOp$/;"	c	namespace:paddle
TestAggregateToCol	math/tests/test_BaseMatrix.cpp	/^void TestAggregateToCol(size_t height, size_t width) {$/;"	f
TestAggregateToRow	math/tests/test_BaseMatrix.cpp	/^void TestAggregateToRow(size_t height, size_t width) {$/;"	f
TestArguments	api/test/testArguments.py	/^class TestArguments(unittest.TestCase):$/;"	c
TestConfig	gserver/tests/LayerGradUtil.h	/^  TestConfig()$/;"	f	struct:paddle::TestConfig
TestConfig	gserver/tests/LayerGradUtil.h	/^struct TestConfig {$/;"	s	namespace:paddle
TestConfig	gserver/tests/test_Evaluator.cpp	/^  TestConfig() : testAccumulate(true) {}$/;"	f	struct:TestConfig
TestConfig	gserver/tests/test_Evaluator.cpp	/^struct TestConfig {$/;"	s	file:
TestEelementWise	math/tests/test_BaseMatrix.cpp	/^void TestEelementWise(size_t height, size_t width) {$/;"	f
TestGradientMachine	api/test/testGradientMachine.py	/^class TestGradientMachine(unittest.TestCase):$/;"	c
TestIVector	api/test/testVector.py	/^class TestIVector(unittest.TestCase):$/;"	c
TestMatrix	api/test/testMatrix.py	/^class TestMatrix(unittest.TestCase):$/;"	c
TestRecurrentLayer	gserver/tests/test_RecurrentLayer.cpp	/^  TestRecurrentLayer(const LayerConfig& config,$/;"	f	class:TestRecurrentLayer
TestRecurrentLayer	gserver/tests/test_RecurrentLayer.cpp	/^class TestRecurrentLayer {$/;"	c	file:
TestVector	api/test/testVector.py	/^class TestVector(unittest.TestCase):$/;"	c
Tester	trainer/Tester.cpp	/^Tester::Tester(const std::shared_ptr<TrainerConfigHelper>& config,$/;"	f	class:paddle::Tester
Tester	trainer/Tester.h	/^class Tester {$/;"	c	namespace:paddle
TesterConfig	trainer/TesterConfig.h	/^struct TesterConfig {$/;"	s	namespace:paddle
Thread	pserver/test/SocketTest.cpp	/^class Thread {$/;"	c	file:
Thread	utils/Thread.h	/^  Thread() { thread_ = nullptr; }$/;"	f	class:paddle::Thread
Thread	utils/Thread.h	/^class Thread {$/;"	c	namespace:paddle
ThreadBarrier	utils/Locks.h	/^class ThreadBarrier {$/;"	c	namespace:paddle
ThreadBarrier	utils/arch/linux/Locks.cpp	/^ThreadBarrier::ThreadBarrier(int count) : m(new ThreadBarrierPrivate()) {$/;"	f	class:paddle::ThreadBarrier
ThreadBarrier	utils/arch/osx/Locks.cpp	/^ThreadBarrier::ThreadBarrier(int count) : m(new ThreadBarrierPrivate(count)) {}$/;"	f	class:paddle::ThreadBarrier
ThreadBarrierPrivate	utils/arch/linux/Locks.cpp	/^class ThreadBarrierPrivate {$/;"	c	namespace:paddle	file:
ThreadBarrierPrivate	utils/arch/osx/Locks.cpp	/^  inline explicit ThreadBarrierPrivate(int cnt) : count_(0), tripCount_(cnt) {$/;"	f	class:paddle::ThreadBarrierPrivate
ThreadBarrierPrivate	utils/arch/osx/Locks.cpp	/^class ThreadBarrierPrivate {$/;"	c	namespace:paddle	file:
ThreadLocal	utils/ThreadLocal.h	/^  ThreadLocal() {$/;"	f	class:paddle::ThreadLocal
ThreadLocal	utils/ThreadLocal.h	/^class ThreadLocal {$/;"	c	namespace:paddle
ThreadLocalBuf	utils/Stat.h	/^  typedef std::list<std::pair<StatInfo*, pid_t>> ThreadLocalBuf;$/;"	t	class:paddle::Stat
ThreadLocalD	utils/ThreadLocal.h	/^  ThreadLocalD() { PCHECK(pthread_key_create(&threadSpecificKey_, NULL) == 0); }$/;"	f	class:paddle::ThreadLocalD
ThreadLocalD	utils/ThreadLocal.h	/^class ThreadLocalD {$/;"	c	namespace:paddle
ThreadLocalRand	utils/ThreadLocal.h	/^class ThreadLocalRand {$/;"	c	namespace:paddle
ThreadLocalRandomEngine	utils/ThreadLocal.h	/^class ThreadLocalRandomEngine {$/;"	c	namespace:paddle
ThreadPtr	pserver/BaseClient.h	/^  typedef std::unique_ptr<std::thread> ThreadPtr;$/;"	t	class:paddle::BaseClient
ThreadWorker	utils/Thread.h	/^  ThreadWorker() : stopping_(false), empty_(true) { start(); }$/;"	f	class:paddle::ThreadWorker
ThreadWorker	utils/Thread.h	/^class ThreadWorker : protected Thread {$/;"	c	namespace:paddle
TimeVectorDelta	utils/BarrierStat.h	/^  explicit TimeVectorDelta(uint16_t size)$/;"	f	class:paddle::TimeVectorDelta
TimeVectorDelta	utils/BarrierStat.h	/^class TimeVectorDelta {$/;"	c	namespace:paddle
TimeVectorEnd	utils/BarrierStat.h	/^  explicit TimeVectorEnd(uint16_t size) : size_(size) {$/;"	f	class:paddle::TimeVectorEnd
TimeVectorEnd	utils/BarrierStat.h	/^class TimeVectorEnd {$/;"	c	namespace:paddle
Timer	utils/Stat.h	/^  explicit Timer(bool autoStart = true) : total_(0), startStamp_(0) {$/;"	f	class:paddle::Timer
Timer	utils/Stat.h	/^class Timer {$/;"	c	namespace:paddle
TimerOnce	utils/Stat.h	/^  TimerOnce(Stat* stat,$/;"	f	class:paddle::TimerOnce
TimerOnce	utils/Stat.h	/^class TimerOnce {$/;"	c	namespace:paddle
TrainAlgorithm	utils/GlobalConstants.h	/^class TrainAlgorithm {$/;"	c	namespace:paddle
TrainPassContext	trainer/Trainer.h	/^  struct TrainPassContext {$/;"	s	class:paddle::Trainer
Trainer	api/PaddleAPI.h	/^class Trainer {$/;"	c
Trainer	api/Trainer.cpp	/^Trainer::Trainer() : m(new TrainerPrivate()) {$/;"	f	class:Trainer
Trainer	api/Trainer.cpp	/^Trainer::Trainer(TrainerConfig* config, GradientMachine* gm)$/;"	f	class:Trainer
Trainer	trainer/Trainer.h	/^  Trainer() : acceptedPassId_(0) {}$/;"	f	class:paddle::Trainer
Trainer	trainer/Trainer.h	/^class Trainer {$/;"	c	namespace:paddle
TrainerConfig	api/ConfigParser.cpp	/^TrainerConfig::TrainerConfig() : m(new TrainerConfigPrivate()) {}$/;"	f	class:TrainerConfig
TrainerConfig	api/PaddleAPI.h	/^class TrainerConfig {$/;"	c
TrainerConfigHelper	trainer/TrainerConfigHelper.cpp	/^TrainerConfigHelper::TrainerConfigHelper(const TrainerConfig &config)$/;"	f	class:paddle::TrainerConfigHelper
TrainerConfigHelper	trainer/TrainerConfigHelper.cpp	/^TrainerConfigHelper::TrainerConfigHelper(const std::string &configFilePath)$/;"	f	class:paddle::TrainerConfigHelper
TrainerConfigHelper	trainer/TrainerConfigHelper.h	/^class TrainerConfigHelper \/*final*\/ {$/;"	c	namespace:paddle
TrainerConfigHelperPrivate	trainer/TrainerConfigHelper.cpp	/^struct TrainerConfigHelperPrivate {$/;"	s	namespace:paddle	file:
TrainerConfigHelperPtr	trainer/TrainerConfigHelper.h	/^typedef std::shared_ptr<TrainerConfigHelper> TrainerConfigHelperPtr;$/;"	t	namespace:paddle
TrainerConfigPrivate	api/PaddleAPIPrivate.h	/^  TrainerConfigPrivate() {}$/;"	f	struct:TrainerConfigPrivate
TrainerConfigPrivate	api/PaddleAPIPrivate.h	/^struct TrainerConfigPrivate {$/;"	s
TrainerConfig_createFromProto	py_paddle/util.py	/^    def TrainerConfig_createFromProto(protoObj):$/;"	f	function:__monkey_patch_protobuf_objects__
TrainerForTest	gserver/tests/test_RecurrentGradientMachine.cpp	/^class TrainerForTest : public paddle::Trainer {$/;"	c	file:
TrainerForTest	trainer/tests/test_TrainerOnePass.cpp	/^class TrainerForTest : public paddle::Trainer {$/;"	c	file:
TrainerInternal	trainer/TrainerInternal.h	/^  TrainerInternal() {}$/;"	f	class:paddle::TrainerInternal
TrainerInternal	trainer/TrainerInternal.h	/^class TrainerInternal {$/;"	c	namespace:paddle
TrainerInternalConfig	trainer/TrainerInternalConfig.h	/^struct TrainerInternalConfig {$/;"	s	namespace:paddle
TrainerPrivate	api/Trainer.cpp	/^  TrainerPrivate() : paddle::Trainer() {}$/;"	f	struct:TrainerPrivate
TrainerPrivate	api/Trainer.cpp	/^struct TrainerPrivate : public paddle::Trainer {$/;"	s	file:
TrainerRole	parameter/ParallelParameter.h	/^enum TrainerRole {$/;"	g	namespace:paddle
TrainerStats	trainer/TrainerInternalConfig.h	/^  inline TrainerStats() { this->reset(); }$/;"	f	class:paddle::TrainerStats
TrainerStats	trainer/TrainerInternalConfig.h	/^class TrainerStats {$/;"	c	namespace:paddle
TrainerThread	gserver/gradientmachines/MultiGradientMachine.cpp	/^TrainerThread::TrainerThread(const ModelConfig& config,$/;"	f	class:paddle::TrainerThread
TrainerThread	gserver/gradientmachines/MultiGradientMachine.h	/^class TrainerThread {$/;"	c	namespace:paddle
TrainerThreadPtr	gserver/gradientmachines/MultiGradientMachine.h	/^typedef std::unique_ptr<TrainerThread> TrainerThreadPtr;$/;"	t	namespace:paddle
Trainer_create	py_paddle/util.py	/^    def Trainer_create(config, model=None):$/;"	f	function:__monkey_patch_trainer__
TransLayer	gserver/layers/TransLayer.h	/^  explicit TransLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::TransLayer
TransLayer	gserver/layers/TransLayer.h	/^class TransLayer : public Layer {$/;"	c	namespace:paddle
TransposedFullMatrixProjection	gserver/layers/TransposedFullMatrixProjection.cpp	/^TransposedFullMatrixProjection::TransposedFullMatrixProjection($/;"	f	class:paddle::TransposedFullMatrixProjection
TransposedFullMatrixProjection	gserver/layers/TransposedFullMatrixProjection.cpp	/^class TransposedFullMatrixProjection : public Projection {$/;"	c	namespace:paddle	file:
TraverseCallback	parameter/ParameterOptimizer.h	/^      TraverseCallback;$/;"	t	class:paddle::ParameterOptimizer
TraverseCallbackVec	parameter/ParameterOptimizer.h	/^  typedef std::vector<ParameterOptimizer::TraverseCallback> TraverseCallbackVec;$/;"	t	class:paddle::ParameterOptimizer
TreaDown	parameter/tests/test_common.cpp	/^  virtual void TreaDown() { LOG(INFO) << "All Test Finished."; }$/;"	f	class:CommonTest
UIO_MAXIOV	pserver/SocketChannel.cpp	34;"	d	file:
UNSPECIFIED	function/BufferArg.h	/^  UNSPECIFIED = 0,$/;"	e	enum:paddle::ArgType
UPDATER_NORMAL	trainer/RemoteParameterUpdater.h	/^    UPDATER_NORMAL = 1,         \/\/ execute in Owner thread(tid:1)$/;"	e	enum:paddle::SparseRemoteParameterUpdaterComposite::__anon12
UPDATER_SPARSE_REMOTE	trainer/RemoteParameterUpdater.h	/^    UPDATER_SPARSE_REMOTE = 0,  \/\/ execute in sync thread pool(tid:0)$/;"	e	enum:paddle::SparseRemoteParameterUpdaterComposite::__anon12
UPDATE_TYPE_NUM	parameter/ParallelParameter.h	/^const int UPDATE_TYPE_NUM = 32;$/;"	m	namespace:paddle
UnsupportError	api/PaddleAPI.h	/^  UnsupportError() : std::runtime_error(" "){};$/;"	f	class:UnsupportError
UnsupportError	api/PaddleAPI.h	/^  UnsupportError(const std::string& message) : std::runtime_error(message){};$/;"	f	class:UnsupportError
UnsupportError	api/PaddleAPI.h	/^class UnsupportError : public std::runtime_error {$/;"	c
Update	scripts/cpplint.py	/^    def Update(self, filename, clean_lines, linenum, error):$/;"	m	class:NestingState
UpdateCallback	api/PaddleAPI.h	/^class UpdateCallback {$/;"	c
UpdateCallback	parameter/Parameter.h	/^typedef std::function<void(Parameter* param)> UpdateCallback;$/;"	t	namespace:paddle
UpdateCallbackWrapper	api/GradientMachine.cpp	/^  explicit UpdateCallbackWrapper(const UpdateCallback& callback)$/;"	f	class:UpdateCallbackWrapper
UpdateCallbackWrapper	api/GradientMachine.cpp	/^class UpdateCallbackWrapper {$/;"	c	file:
UpdateFunction	parameter/ParallelParameter.h	/^typedef void (ParallelParameter::*UpdateFunction)(real learnRate);$/;"	t	namespace:paddle
UpdateIncludeState	scripts/cpplint.py	/^def UpdateIncludeState(filename, include_dict, io=codecs):$/;"	f
UpdatePreprocessor	scripts/cpplint.py	/^    def UpdatePreprocessor(self, line):$/;"	m	class:NestingState
UserDefinedVectorPtr	parameter/Argument.h	/^typedef std::shared_ptr<std::vector<void*>> UserDefinedVectorPtr;$/;"	t	namespace:paddle
VALUE_TYPE_BYTE	function/TensorType.h	/^  VALUE_TYPE_BYTE = 3$/;"	e	enum:paddle::ValueType
VALUE_TYPE_DOUBLE	function/TensorType.h	/^  VALUE_TYPE_DOUBLE = 2,$/;"	e	enum:paddle::ValueType
VALUE_TYPE_FLOAT	function/TensorType.h	/^  VALUE_TYPE_FLOAT = 1,$/;"	e	enum:paddle::ValueType
VALUE_TYPE_INT32	function/TensorType.h	/^  VALUE_TYPE_INT32 = 0,$/;"	e	enum:paddle::ValueType
VECTOR_LEN	math/tests/test_SIMDFunctions.cpp	/^static constexpr size_t VECTOR_LEN = 3072;$/;"	v	file:
ValidationLayer	gserver/layers/ValidationLayer.h	/^  explicit ValidationLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::ValidationLayer
ValidationLayer	gserver/layers/ValidationLayer.h	/^class ValidationLayer : public Layer {$/;"	c	namespace:paddle
ValidationLayerPtr	gserver/layers/ValidationLayer.h	/^typedef std::shared_ptr<ValidationLayer> ValidationLayerPtr;$/;"	t	namespace:paddle
ValuePrinter	gserver/evaluators/Evaluator.cpp	/^  ValuePrinter() {}$/;"	f	class:paddle::ValuePrinter
ValuePrinter	gserver/evaluators/Evaluator.cpp	/^class ValuePrinter : public Evaluator {$/;"	c	namespace:paddle	file:
ValueType	function/TensorType.h	/^enum ValueType {$/;"	g	namespace:paddle
Vector	api/PaddleAPI.h	/^class Vector {$/;"	c
Vector	api/Vector.cpp	/^Vector::Vector() : m(new VectorPrivate()) {}$/;"	f	class:Vector
Vector	function/TensorType.h	/^  typedef typename detail::VectorT<VType, DType>::type Vector;$/;"	t	struct:paddle::Tensor
Vector	math/Vector.h	/^typedef VectorT<real> Vector;$/;"	t	namespace:paddle
VectorCheckErr	math/tests/test_TrainingAlgorithm.cpp	/^int VectorCheckErr(const Vector& vector1, const Vector& vector2) {$/;"	f
VectorCheckErr	math/tests/test_TrainingAlgorithm.cpp	/^int VectorCheckErr(const VectorPtr& vector1, const VectorPtr& vector2) {$/;"	f
VectorPrivate	api/Vector.cpp	/^struct VectorPrivate {$/;"	s	file:
VectorPtr	math/Vector.h	/^typedef std::shared_ptr<Vector> VectorPtr;$/;"	t	namespace:paddle
VectorT	function/TensorType.h	/^struct VectorT<int, DEVICE_TYPE_CPU> {$/;"	s	namespace:paddle::detail
VectorT	function/TensorType.h	/^struct VectorT<int, DEVICE_TYPE_GPU> {$/;"	s	namespace:paddle::detail
VectorT	function/TensorType.h	/^struct VectorT<real, DEVICE_TYPE_CPU> {$/;"	s	namespace:paddle::detail
VectorT	function/TensorType.h	/^struct VectorT<real, DEVICE_TYPE_GPU> {$/;"	s	namespace:paddle::detail
VectorT	math/Vector.h	/^  VectorT(size_t size, MemoryHandlePtr memoryHandle, size_t offset, bool useGpu)$/;"	f	class:paddle::VectorT
VectorT	math/Vector.h	/^  VectorT(size_t size, T* data, bool useGpu)$/;"	f	class:paddle::VectorT
VectorT	math/Vector.h	/^class VectorT : public BaseVector<T> {$/;"	c	namespace:paddle
WARPCTC_COMPUTE_LOSS	cuda/src/hl_warpctc_wrap.cc	58;"	d	file:
WARPCTC_GET_STATUS_STRING	cuda/src/hl_warpctc_wrap.cc	55;"	d	file:
WARPCTC_GET_VERSION	cuda/src/hl_warpctc_wrap.cc	54;"	d	file:
WARPCTC_GET_WORKSPACE_SIZE	cuda/src/hl_warpctc_wrap.cc	59;"	d	file:
WITH_COVERALLS	api/paddle_api_config.py	/^WITH_COVERALLS="OFF"$/;"	v
WITH_GPU	api/paddle_api_config.py	/^WITH_GPU="ON"$/;"	v
WITH_PYTHON	api/paddle_api_config.py	/^WITH_PYTHON="ON"$/;"	v
WarpCTCLayer	gserver/layers/WarpCTCLayer.h	/^  explicit WarpCTCLayer(const LayerConfig& config) : Layer(config) {}$/;"	f	class:paddle::WarpCTCLayer
WarpCTCLayer	gserver/layers/WarpCTCLayer.h	/^class WarpCTCLayer : public Layer {$/;"	c	namespace:paddle
WeakKVCache	utils/Util.h	/^  WeakKVCache() {}$/;"	f	class:paddle::WeakKVCache
WeakKVCache	utils/Util.h	/^class WeakKVCache {$/;"	c	namespace:paddle
Weight	parameter/Weight.cpp	/^Weight::Weight(size_t height, size_t width, ParameterPtr param) {$/;"	f	class:paddle::Weight
Weight	parameter/Weight.cpp	/^Weight::Weight(size_t height, size_t width, ParameterPtr param, size_t offset) {$/;"	f	class:paddle::Weight
Weight	parameter/Weight.h	/^class Weight {$/;"	c	namespace:paddle
WeightList	parameter/Weight.h	/^typedef std::vector<std::unique_ptr<Weight>> WeightList;$/;"	t	namespace:paddle
ZLIB_LIBRARIES	api/paddle_api_config.py	/^ZLIB_LIBRARIES="\/home\/tianbing\/baidu\/idl\/paddle\/third_party\/install\/zlib\/lib\/libz.a"$/;"	v
_1	pserver/ProtoServer.h	/^  typedef Arg1 _1;$/;"	t	struct:paddle::service_arg_type
_ALT_TOKEN_REPLACEMENT	scripts/cpplint.py	/^_ALT_TOKEN_REPLACEMENT = {$/;"	v
_ALT_TOKEN_REPLACEMENT_PATTERN	scripts/cpplint.py	/^_ALT_TOKEN_REPLACEMENT_PATTERN = re.compile(r'[ =()](' + ('|'.join($/;"	v
_AddFilters	scripts/cpplint.py	/^def _AddFilters(filters):$/;"	f
_BLOCK_ASM	scripts/cpplint.py	/^_BLOCK_ASM = 3  # The whole block is an inline assembly block$/;"	v
_BackupFilters	scripts/cpplint.py	/^def _BackupFilters():$/;"	f
_BlockInfo	scripts/cpplint.py	/^class _BlockInfo(object):$/;"	c
_CHECK_MACROS	scripts/cpplint.py	/^_CHECK_MACROS = [$/;"	v
_CHECK_REPLACEMENT	scripts/cpplint.py	/^_CHECK_REPLACEMENT = dict([(m, {}) for m in _CHECK_MACROS])$/;"	v
_CPP_HEADERS	scripts/cpplint.py	/^_CPP_HEADERS = frozenset([$/;"	v
_CPP_SECTION	scripts/cpplint.py	/^    _CPP_SECTION = 3$/;"	v	class:_IncludeState
_CPP_SYS_HEADER	scripts/cpplint.py	/^_CPP_SYS_HEADER = 2$/;"	v
_C_SECTION	scripts/cpplint.py	/^    _C_SECTION = 2$/;"	v	class:_IncludeState
_C_SYS_HEADER	scripts/cpplint.py	/^_C_SYS_HEADER = 1$/;"	v
_ClassInfo	scripts/cpplint.py	/^class _ClassInfo(_BlockInfo):$/;"	c
_ClassifyInclude	scripts/cpplint.py	/^def _ClassifyInclude(fileinfo, include, is_system):$/;"	f
_CollapseStrings	scripts/cpplint.py	/^    def _CollapseStrings(elided):$/;"	m	class:CleansedLines
_CppLintState	scripts/cpplint.py	/^class _CppLintState(object):$/;"	c
_DEFAULT_FILTERS	scripts/cpplint.py	/^_DEFAULT_FILTERS = ['-build\/include_alpha']$/;"	v
_DropCommonSuffixes	scripts/cpplint.py	/^def _DropCommonSuffixes(filename):$/;"	f
_END_ASM	scripts/cpplint.py	/^_END_ASM = 2  # Last line of inline assembly block$/;"	v
_ERROR_CATEGORIES	scripts/cpplint.py	/^_ERROR_CATEGORIES = [$/;"	v
_ExternCInfo	scripts/cpplint.py	/^class _ExternCInfo(_BlockInfo):$/;"	c
_Filters	scripts/cpplint.py	/^def _Filters():$/;"	f
_FunctionState	scripts/cpplint.py	/^class _FunctionState(object):$/;"	c
_GetTextInside	scripts/cpplint.py	/^def _GetTextInside(text, start_pattern):$/;"	f
_HEADERS_CONTAINING_TEMPLATES	scripts/cpplint.py	/^_HEADERS_CONTAINING_TEMPLATES = ($/;"	v
_INITIAL_SECTION	scripts/cpplint.py	/^    _INITIAL_SECTION = 0$/;"	v	class:_IncludeState
_INSIDE_ASM	scripts/cpplint.py	/^_INSIDE_ASM = 1  # Inside inline assembly block$/;"	v
_IncludeError	scripts/cpplint.py	/^class _IncludeError(Exception):$/;"	c
_IncludeState	scripts/cpplint.py	/^class _IncludeState(object):$/;"	c
_IsTestFilename	scripts/cpplint.py	/^def _IsTestFilename(filename):$/;"	f
_LEGACY_ERROR_CATEGORIES	scripts/cpplint.py	/^_LEGACY_ERROR_CATEGORIES = ['readability\/streams', ]$/;"	v
_LIKELY_MY_HEADER	scripts/cpplint.py	/^_LIKELY_MY_HEADER = 3$/;"	v
_MATCH_ASM	scripts/cpplint.py	/^_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'$/;"	v
_MY_H_SECTION	scripts/cpplint.py	/^    _MY_H_SECTION = 1$/;"	v	class:_IncludeState
_NORMAL_TRIGGER	scripts/cpplint.py	/^    _NORMAL_TRIGGER = 250  # for --v=0, 500 for --v=1, etc.$/;"	v	class:_FunctionState
_NO_ASM	scripts/cpplint.py	/^_NO_ASM = 0  # Outside of inline assembly block$/;"	v
_NamespaceInfo	scripts/cpplint.py	/^class _NamespaceInfo(_BlockInfo):$/;"	c
_OTHER_HEADER	scripts/cpplint.py	/^_OTHER_HEADER = 5$/;"	v
_OTHER_H_SECTION	scripts/cpplint.py	/^    _OTHER_H_SECTION = 4$/;"	v	class:_IncludeState
_OutputFormat	scripts/cpplint.py	/^def _OutputFormat():$/;"	f
_PI32AVX_CONST	cuda/src/avx_mathfun.h	43;"	d
_PI32_CONST256	cuda/src/avx_mathfun.h	56;"	d
_POSIX_C_SOURCE	utils/PythonUtil.h	24;"	d
_POSIX_C_SOURCE	utils/PythonUtil.h	30;"	d
_POSIX_SOURCE	utils/PythonUtil.h	23;"	d
_POSSIBLE_MY_HEADER	scripts/cpplint.py	/^_POSSIBLE_MY_HEADER = 4$/;"	v
_PS256_CONST	cuda/src/avx_mathfun.h	53;"	d
_PS256_CONST_TYPE	cuda/src/avx_mathfun.h	59;"	d
_PreprocessorInfo	scripts/cpplint.py	/^class _PreprocessorInfo(object):$/;"	c
_RE_FIRST_COMPONENT	scripts/cpplint.py	/^_RE_FIRST_COMPONENT = re.compile(r'^[^-_.]+')$/;"	v
_RE_PATTERN_CLEANSE_LINE_C_COMMENTS	scripts/cpplint.py	/^_RE_PATTERN_CLEANSE_LINE_C_COMMENTS = re.compile($/;"	v
_RE_PATTERN_CLEANSE_LINE_ESCAPES	scripts/cpplint.py	/^_RE_PATTERN_CLEANSE_LINE_ESCAPES = re.compile($/;"	v
_RE_PATTERN_CONST_REF_PARAM	scripts/cpplint.py	/^_RE_PATTERN_CONST_REF_PARAM = ($/;"	v
_RE_PATTERN_C_COMMENTS	scripts/cpplint.py	/^_RE_PATTERN_C_COMMENTS = r'\/\\*(?:[^*]|\\*(?!\/))*\\*\/'$/;"	v
_RE_PATTERN_EXPLICIT_MAKEPAIR	scripts/cpplint.py	/^_RE_PATTERN_EXPLICIT_MAKEPAIR = re.compile(r'\\bmake_pair\\s*<')$/;"	v
_RE_PATTERN_IDENT	scripts/cpplint.py	/^_RE_PATTERN_IDENT = r'[_a-zA-Z]\\w*'  # =~ [[:alpha:]][[:alnum:]]*$/;"	v
_RE_PATTERN_INCLUDE	scripts/cpplint.py	/^_RE_PATTERN_INCLUDE = re.compile(r'^\\s*#\\s*include\\s*([<"])([^>"]*)[>"].*$')$/;"	v
_RE_PATTERN_INVALID_INCREMENT	scripts/cpplint.py	/^_RE_PATTERN_INVALID_INCREMENT = re.compile(r'^\\s*\\*\\w+(\\+\\+|--);')$/;"	v
_RE_PATTERN_REF_PARAM	scripts/cpplint.py	/^_RE_PATTERN_REF_PARAM = re.compile($/;"	v
_RE_PATTERN_STRING	scripts/cpplint.py	/^_RE_PATTERN_STRING = re.compile(r'\\bstring\\b')$/;"	v
_RE_PATTERN_TODO	scripts/cpplint.py	/^_RE_PATTERN_TODO = re.compile(r'^\/\/(\\s*)TODO(\\(.+?\\))?:?(\\s|$)?')$/;"	v
_RE_PATTERN_TYPE	scripts/cpplint.py	/^_RE_PATTERN_TYPE = ($/;"	v
_RestoreFilters	scripts/cpplint.py	/^def _RestoreFilters():$/;"	f
_SECTION_NAMES	scripts/cpplint.py	/^    _SECTION_NAMES = {$/;"	v	class:_IncludeState
_SetCountingStyle	scripts/cpplint.py	/^def _SetCountingStyle(level):$/;"	f
_SetFilters	scripts/cpplint.py	/^def _SetFilters(filters):$/;"	f
_SetOutputFormat	scripts/cpplint.py	/^def _SetOutputFormat(output_format):$/;"	f
_SetVerboseLevel	scripts/cpplint.py	/^def _SetVerboseLevel(level):$/;"	f
_ShouldPrintError	scripts/cpplint.py	/^def _ShouldPrintError(category, confidence, linenum):$/;"	f
_TEST_TRIGGER	scripts/cpplint.py	/^    _TEST_TRIGGER = 400  # about 50% more than _NORMAL_TRIGGER.$/;"	v	class:_FunctionState
_THIRD_PARTY_HEADERS_PATTERN	scripts/cpplint.py	/^_THIRD_PARTY_HEADERS_PATTERN = re.compile($/;"	v
_THREADING_LIST	scripts/cpplint.py	/^_THREADING_LIST = ($/;"	v
_TYPE_NAMES	scripts/cpplint.py	/^    _TYPE_NAMES = {$/;"	v	class:_IncludeState
_UNSAFE_FUNC_PREFIX	scripts/cpplint.py	/^_UNSAFE_FUNC_PREFIX = r'(?:[-+*\/=%^&|(<]\\s*|>\\s+)'$/;"	v
_USE_MATH_DEFINES	math/tests/test_perturbation.cpp	26;"	d	file:
_VerboseLevel	scripts/cpplint.py	/^def _VerboseLevel():$/;"	f
_XOPEN_SOURCE	utils/PythonUtil.h	25;"	d
_XOPEN_SOURCE	utils/PythonUtil.h	34;"	d
__CHECK_BARRIER_TIMER	utils/BarrierStat.h	347;"	d
__ParameterCallbackWrapper__	py_paddle/util.py	/^class __ParameterCallbackWrapper__(swig_paddle.UpdateCallback):$/;"	c
__REGISTER_BARRIER_DELTA_SERVER_SET	utils/BarrierStat.h	334;"	d
__REGISTER_BARRIER_TIMER_SERVER	utils/BarrierStat.h	306;"	d
__REGISTER_BARRIER_TIMER_SERVER_SET	utils/BarrierStat.h	321;"	d
__SLOT_VALUE_CONVERTER_MAP__	py_paddle/util.py	/^    __SLOT_VALUE_CONVERTER_MAP__ = {$/;"	v	class:DataProviderWrapperConverter
__STDC_FORMAT_MACROS	trainer/tests/picojson.h	62;"	d
__TEMP_POSIX_C_SOURCE	utils/PythonUtil.h	29;"	d
__TEMP_XOPEN_SOURCE	utils/PythonUtil.h	33;"	d
__activate_virtual_env__	utils/enable_virtualenv.py	/^def __activate_virtual_env__():$/;"	f	file:
__all__	py_paddle/__init__.py	/^__all__ = [$/;"	v
__all__	py_paddle/dataprovider_converter.py	/^__all__ = ['DataProviderConverter']$/;"	v
__arguments_to_numpy__	py_paddle/util.py	/^def __arguments_to_numpy__(i, arg):$/;"	f	file:
__call__	py_paddle/dataprovider_converter.py	/^    def __call__(self, dat, argument=None):$/;"	m	class:DataProviderConverter	file:
__call__	py_paddle/util.py	/^        def __call__(self, slot_idx, arg):$/;"	m	class:DataProviderWrapperConverter.DenseValueConverter	file:
__call__	py_paddle/util.py	/^        def __call__(self, slot_idx, arg):$/;"	m	class:DataProviderWrapperConverter.IdValueConverter	file:
__call__	py_paddle/util.py	/^        def __call__(self, slot_idx, arg):$/;"	m	class:DataProviderWrapperConverter.SparseNonValueConverter	file:
__call__	py_paddle/util.py	/^        def __call__(self, slot_idx, arg):$/;"	m	class:DataProviderWrapperConverter.SparseValueConverter	file:
__call__	py_paddle/util.py	/^    def __call__(self, wrapper_data, argument=None):$/;"	m	class:DataProviderWrapperConverter	file:
__call__	trainer/tests/testPyDataWrapper.py	/^    def __call__(self):$/;"	m	class:IDRandomer	file:
__create_feedback__	api/SequenceGenerator.cpp	/^  static paddle::Argument __create_feedback__() {$/;"	f	struct:SequenceGeneratorPrivate	file:
__init__	api/paddle_ld_flags.py	/^        def __init__(self):$/;"	m	class:PaddleLDFlag
__init__	gserver/tests/pyDataProvider.py	/^    def __init__(self, *file_list):$/;"	m	class:SimpleDataProvider
__init__	gserver/tests/pyDataProvider.py	/^    def __init__(self, *file_list):$/;"	m	class:SimpleNestDataProvider
__init__	py_paddle/dataprovider_converter.py	/^    def __init__(self, input_type, pos):$/;"	m	class:DenseScanner
__init__	py_paddle/dataprovider_converter.py	/^    def __init__(self, input_type, pos):$/;"	m	class:IScanner
__init__	py_paddle/dataprovider_converter.py	/^    def __init__(self, input_type, pos):$/;"	m	class:IndexScanner
__init__	py_paddle/dataprovider_converter.py	/^    def __init__(self, input_type, pos):$/;"	m	class:SparseBinaryScanner
__init__	py_paddle/dataprovider_converter.py	/^    def __init__(self, input_type, pos):$/;"	m	class:SparseFloatScanner
__init__	py_paddle/dataprovider_converter.py	/^    def __init__(self, input_type, pos, inner_scanner, setter):$/;"	m	class:SequenceScanner
__init__	py_paddle/dataprovider_converter.py	/^    def __init__(self, input_types):$/;"	m	class:DataProviderConverter
__init__	py_paddle/util.py	/^        def __init__(self, *args):$/;"	m	class:DataProviderWrapperConverter.IdValueConverter
__init__	py_paddle/util.py	/^        def __init__(self, header_def):$/;"	m	class:DataProviderWrapperConverter.DenseValueConverter
__init__	py_paddle/util.py	/^        def __init__(self, slot_def):$/;"	m	class:DataProviderWrapperConverter.SparseNonValueConverter
__init__	py_paddle/util.py	/^        def __init__(self, slot_def):$/;"	m	class:DataProviderWrapperConverter.SparseValueConverter
__init__	py_paddle/util.py	/^    def __init__(self, callback):$/;"	m	class:__ParameterCallbackWrapper__
__init__	py_paddle/util.py	/^    def __init__(self, use_seq, header):$/;"	m	class:DataProviderWrapperConverter
__init__	scripts/cpplint.py	/^    def __init__(self):$/;"	m	class:NestingState
__init__	scripts/cpplint.py	/^    def __init__(self):$/;"	m	class:_CppLintState
__init__	scripts/cpplint.py	/^    def __init__(self):$/;"	m	class:_ExternCInfo
__init__	scripts/cpplint.py	/^    def __init__(self):$/;"	m	class:_FunctionState
__init__	scripts/cpplint.py	/^    def __init__(self):$/;"	m	class:_IncludeState
__init__	scripts/cpplint.py	/^    def __init__(self, filename):$/;"	m	class:FileInfo
__init__	scripts/cpplint.py	/^    def __init__(self, lines):$/;"	m	class:CleansedLines
__init__	scripts/cpplint.py	/^    def __init__(self, name, class_or_struct, clean_lines, linenum):$/;"	m	class:_ClassInfo
__init__	scripts/cpplint.py	/^    def __init__(self, name, linenum):$/;"	m	class:_NamespaceInfo
__init__	scripts/cpplint.py	/^    def __init__(self, seen_open_brace):$/;"	m	class:_BlockInfo
__init__	scripts/cpplint.py	/^    def __init__(self, stack_before_if):$/;"	m	class:_PreprocessorInfo
__init__	trainer/tests/testPyDataWrapper.py	/^    def __init__(self):$/;"	m	class:IDRandomer
__matrix_to_numpy__	py_paddle/util.py	/^    def __matrix_to_numpy__(m):$/;"	f	function:__monkeypatch_gradient_machine__	file:
__monkey_patch_parameter__	py_paddle/util.py	/^def __monkey_patch_parameter__():$/;"	f	file:
__monkey_patch_protobuf_objects__	py_paddle/util.py	/^def __monkey_patch_protobuf_objects__():$/;"	f	file:
__monkey_patch_trainer__	py_paddle/util.py	/^def __monkey_patch_trainer__():$/;"	f	file:
__monkeypatch_gradient_machine__	py_paddle/util.py	/^def __monkeypatch_gradient_machine__():$/;"	f	file:
__monkeypatch_init_paddle__	py_paddle/util.py	/^def __monkeypatch_init_paddle__():$/;"	f	file:
__must_check	utils/Compiler.h	30;"	d
__must_check	utils/Compiler.h	32;"	d
__readFromFile	api/test/util.py	/^def __readFromFile():$/;"	f	file:
__values_mapper__	trainer/tests/testPyDataWrapper.py	/^            def __values_mapper__(s):$/;"	f	function:processNonSequenceData	file:
_args_	function/Function.h	/^  std::vector<BufferArg*> _args_;$/;"	m	class:paddle::BufferArgs
_cpplint_state	scripts/cpplint.py	/^_cpplint_state = _CppLintState()$/;"	v
_error_suppressions	scripts/cpplint.py	/^_error_suppressions = {}$/;"	v
_hl_sparse_matrix_s	cuda/include/hl_base.h	/^} _hl_sparse_matrix_s, *hl_sparse_matrix_s;$/;"	t	typeref:struct:__anon10
_indent	trainer/tests/picojson.h	/^void value::_indent(Iter oi, int indent) {$/;"	f	class:picojson::value
_line_length	scripts/cpplint.py	/^_line_length = 80$/;"	v
_parse	trainer/tests/picojson.h	/^inline Iter _parse(Context& ctx,$/;"	f	namespace:picojson
_parse	trainer/tests/picojson.h	/^inline bool _parse(Context& ctx, input<Iter>& in) {$/;"	f	namespace:picojson
_parse_array	trainer/tests/picojson.h	/^inline bool _parse_array(Context& ctx, input<Iter>& in) {$/;"	f	namespace:picojson
_parse_codepoint	trainer/tests/picojson.h	/^inline bool _parse_codepoint(String& out, input<Iter>& in) {$/;"	f	namespace:picojson
_parse_number	trainer/tests/picojson.h	/^inline std::string _parse_number(input<Iter>& in) {$/;"	f	namespace:picojson
_parse_object	trainer/tests/picojson.h	/^inline bool _parse_object(Context& ctx, input<Iter>& in) {$/;"	f	namespace:picojson
_parse_quadhex	trainer/tests/picojson.h	/^inline int _parse_quadhex(input<Iter>& in) {$/;"	f	namespace:picojson
_parse_string	trainer/tests/picojson.h	/^inline bool _parse_string(String& out, input<Iter>& in) {$/;"	f	namespace:picojson
_pow	math/Matrix.cpp	/^inline real _pow(real a, real beta) { return std::pow(a, beta); }$/;"	f	namespace:paddle
_re_pattern_algorithm_header	scripts/cpplint.py	/^_re_pattern_algorithm_header = []$/;"	v
_re_pattern_templates	scripts/cpplint.py	/^_re_pattern_templates = []$/;"	v
_regexp_compile_cache	scripts/cpplint.py	/^_regexp_compile_cache = {}$/;"	v
_root	scripts/cpplint.py	/^_root = None$/;"	v
_safelog	math/Matrix.cpp	/^inline real _safelog(real a) { return a > 0.0f ? std::log(a) : -40.0f; }$/;"	f	namespace:paddle
_serialize	trainer/tests/picojson.h	/^inline std::string value::_serialize(int indent) const {$/;"	f	class:picojson::value
_serialize	trainer/tests/picojson.h	/^void value::_serialize(Iter oi, int indent) const {$/;"	f	class:picojson::value
_square	math/Matrix.cpp	/^inline real _square(real a) { return a * a; }$/;"	f	namespace:paddle
_storage	trainer/tests/picojson.h	/^  union _storage {$/;"	u	class:picojson::value
_trainOneBatch	api/Trainer.cpp	/^bool TrainerPrivate::_trainOneBatch(size_t batchSize) {$/;"	f	class:TrainerPrivate
_valid_extensions	scripts/cpplint.py	/^_valid_extensions = set(['cc', 'h', 'cpp', 'cu', 'cuh'])$/;"	v
a	gserver/activations/ActivationFunction.cpp	/^real a, b;$/;"	m	namespace:paddle	file:
aCol_	math/BaseMatrix.h	/^  size_t aCol_;$/;"	m	class:paddle::MatrixOffset
aRow_	math/BaseMatrix.h	/^  size_t aRow_;$/;"	m	class:paddle::MatrixOffset
aTrans_	function/MulOp.cpp	/^  bool aTrans_;$/;"	m	class:paddle::MulFunc	file:
a_	gserver/layers/LinearChainCRF.h	/^  MatrixPtr a_;$/;"	m	class:paddle::LinearChainCRF
a_	math/tests/test_ExecViaCpu.cpp	/^  real a_;$/;"	m	class:Functor	file:
a_	parameter/LearningRateScheduler.cpp	/^  real a_;$/;"	m	class:paddle::BaseLRS	file:
abort	scripts/docker/build.sh	/^function abort(){$/;"	f
abort	scripts/travis/precommit.sh	/^function abort(){$/;"	f
abs	cuda/include/hl_tensor_ops.h	/^class abs {$/;"	c	namespace:hppl::unary
abs	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::abs<T>, const Derived, T> abs() const {$/;"	f	class:paddle::TensorExpression
abstractLock_	utils/BarrierStat.h	/^  std::mutex abstractLock_;  \/\/ see note on updaterStat$/;"	m	class:paddle::BarrierStatBase
abstract_	utils/BarrierStat.h	/^  std::vector<struct Abstract> abstract_;$/;"	m	class:paddle::BarrierStatBase
accept	pserver/RDMANetwork.h	/^inline sxi_sock* accept(sxi_socket* s) {$/;"	f	namespace:paddle::rdma
acceptedPassId_	trainer/Trainer.h	/^  int acceptedPassId_;$/;"	m	class:paddle::Trainer
accessSubNetwork	gserver/layers/Layer.h	/^  virtual void accessSubNetwork($/;"	f	class:paddle::Layer
accumCounter_	parameter/ParallelParameter.h	/^  int accumCounter_;$/;"	m	class:paddle::AsyncParameter
accumulateColSum	math/Matrix.cpp	/^void CpuMatrix::accumulateColSum(Matrix& src) {$/;"	f	class:paddle::CpuMatrix
accumulateColSum	math/Matrix.cpp	/^void GpuMatrix::accumulateColSum(Matrix& src) {$/;"	f	class:paddle::GpuMatrix
accumulateColSum	math/Matrix.h	/^  virtual void accumulateColSum(Matrix& src) {$/;"	f	class:paddle::Matrix
acquire_ports	.common_test_util.sh	/^acquire_ports(){$/;"	f
activationGate_	gserver/layers/GatedRecurrentLayer.h	/^  std::unique_ptr<ActivationFunction> activationGate_;$/;"	m	class:paddle::GatedRecurrentLayer
activationGate_	gserver/layers/MDLstmLayer.cpp	/^  std::unique_ptr<ActivationFunction> activationGate_;$/;"	m	class:paddle::MDLstmLayer	file:
activationState_	gserver/layers/MDLstmLayer.cpp	/^  std::unique_ptr<ActivationFunction> activationState_;$/;"	m	class:paddle::MDLstmLayer	file:
activation_	gserver/layers/Layer.h	/^  std::unique_ptr<ActivationFunction> activation_;$/;"	m	class:paddle::Layer
activeGate_	gserver/layers/GruCompute.h	/^  hl_activation_mode_t activeGate_;$/;"	m	class:paddle::GruCompute
activeGate_	gserver/layers/LstmCompute.h	/^  hl_activation_mode_t activeGate_;$/;"	m	class:paddle::LstmCompute
activeNode_	gserver/layers/GruCompute.h	/^  hl_activation_mode_t activeNode_;$/;"	m	class:paddle::GruCompute
activeNode_	gserver/layers/LstmCompute.h	/^  hl_activation_mode_t activeNode_;$/;"	m	class:paddle::LstmCompute
activeState_	gserver/layers/LstmCompute.h	/^  hl_activation_mode_t activeState_;$/;"	m	class:paddle::LstmCompute
add	cuda/include/hl_tensor_ops.h	/^class add {$/;"	c	namespace:hppl::binary
add	gserver/layers/SequenceToBatch.cpp	/^void SequenceToBatch::add(Matrix &seqValue,$/;"	f	class:paddle::SequenceToBatch
add	math/Matrix.cpp	/^void SharedCpuMatrix::add(Matrix& b, real p1, real p2) {$/;"	f	class:paddle::SharedCpuMatrix
add	math/Matrix.cpp	/^void SharedCpuMatrix::add(real p1, real p2) {$/;"	f	class:paddle::SharedCpuMatrix
add3	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::add3(CpuMatrix* b) {$/;"	f	class:paddle::CpuSparseMatrix
add3	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::add3(MatrixPtr b) {$/;"	f	class:paddle::CpuSparseMatrix
add3	math/Matrix.h	/^  virtual void add3(MatrixPtr b) { LOG(FATAL) << "Not implemented"; }$/;"	f	class:paddle::Matrix
add3	math/SparseMatrix.cpp	/^void GpuSparseMatrix::add3(GpuMatrix* b) {$/;"	f	class:paddle::GpuSparseMatrix
add3	math/SparseMatrix.cpp	/^void GpuSparseMatrix::add3(MatrixPtr b) {$/;"	f	class:paddle::GpuSparseMatrix
addArg	function/Function.cpp	/^void BufferArgs::addArg(const CpuSparseMatrix& arg, ArgType argType) {$/;"	f	class:paddle::BufferArgs
addArg	function/Function.cpp	/^void BufferArgs::addArg(const GpuSparseMatrix& arg, ArgType argType) {$/;"	f	class:paddle::BufferArgs
addArg	function/Function.cpp	/^void BufferArgs::addArg(const Matrix& arg,$/;"	f	class:paddle::BufferArgs
addArg	function/Function.cpp	/^void BufferArgs::addArg(const Matrix& matrix,$/;"	f	class:paddle::BufferArgs
addArg	function/Function.h	/^  void addArg(BufferArg& arg) { args_.push_back(&arg); }$/;"	f	class:paddle::BufferArgs
addArg	function/Function.h	/^  void addArg(SequenceArg& arg) { args_.push_back(&arg); }$/;"	f	class:paddle::BufferArgs
addArg	function/Function.h	/^  void addArg(SequenceIdArg& arg) { args_.push_back(&arg); }$/;"	f	class:paddle::BufferArgs
addArg	function/Function.h	/^  void addArg(SparseMatrixArg& arg) { args_.push_back(&arg); }$/;"	f	class:paddle::BufferArgs
addArg	function/Function.h	/^  void addArg(const IVector& arg, ArgType argType = UNSPECIFIED) {$/;"	f	class:paddle::BufferArgs
addArg	function/Function.h	/^  void addArg(const Matrix& arg, ArgType argType = UNSPECIFIED) {$/;"	f	class:paddle::BufferArgs
addArg	function/Function.h	/^  void addArg(const Vector& arg, ArgType argType = UNSPECIFIED) {$/;"	f	class:paddle::BufferArgs
addBatchJobs	utils/Thread.h	/^  void addBatchJobs(const std::vector<F>& jobs) {$/;"	f	class:paddle::AsyncThreadPool
addBatchJobs	utils/Thread.h	/^  void addBatchJobs(const std::vector<F>& jobs,$/;"	f	class:paddle::AsyncThreadPool
addBias	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::addBias(Matrix& b, real scale) {$/;"	f	class:paddle::CpuSparseMatrix
addBias	math/Matrix.cpp	/^void CpuMatrix::addBias(Matrix& b, real scale) {$/;"	f	class:paddle::CpuMatrix
addBias	math/Matrix.cpp	/^void GpuMatrix::addBias(Matrix& b, real scale) {$/;"	f	class:paddle::GpuMatrix
addBias	math/Matrix.h	/^  virtual void addBias(Matrix& b, real scale) {$/;"	f	class:paddle::Matrix
addBias	math/Matrix.h	/^  void addBias(Matrix& b, real scale, bool sharedBias) {$/;"	f	class:paddle::Matrix
addBias	math/SparseMatrix.cpp	/^void GpuSparseMatrix::addBias(Matrix& b, real scale) {$/;"	f	class:paddle::GpuSparseMatrix
addByBitCode	math/Matrix.h	/^  virtual void addByBitCode(size_t numClasses,$/;"	f	class:paddle::Matrix
addByBitCode	math/MatrixBitCode.cpp	/^void CpuMatrix::addByBitCode(size_t numClasses,$/;"	f	class:paddle::CpuMatrix
addByBitCodeBackward	math/Matrix.h	/^  virtual void addByBitCodeBackward(size_t numClasses,$/;"	f	class:paddle::Matrix
addByBitCodeBackward	math/MatrixBitCode.cpp	/^void CpuMatrix::addByBitCodeBackward(size_t numClasses,$/;"	f	class:paddle::CpuMatrix
addByBitCodeT	math/MatrixBitCode.cpp	/^static void addByBitCodeT($/;"	f	namespace:paddle
addColumnVector	math/Matrix.cpp	/^void CpuMatrix::addColumnVector(const Matrix& b) {$/;"	f	class:paddle::CpuMatrix
addColumnVector	math/Matrix.cpp	/^void GpuMatrix::addColumnVector(const Matrix& b) {$/;"	f	class:paddle::GpuMatrix
addColumnVector	math/Matrix.h	/^  virtual void addColumnVector(const Matrix& b) {$/;"	f	class:paddle::Matrix
addComputeThread	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^void ParallelNeuralNetwork::addComputeThread(int deviceId) {$/;"	f	class:paddle::ParallelNeuralNetwork
addCost	trainer/TrainerInternalConfig.h	/^  inline void addCost(int64_t numProcessed, real cost) {$/;"	f	class:paddle::TrainerStats
addCreator	trainer/RemoteParameterUpdater.h	/^  static void addCreator($/;"	f	class:paddle::ParameterUpdaterCreators
addElements	math/Matrix.cpp	/^void CpuMatrix::addElements(Matrix& table, IVector& ids) {$/;"	f	class:paddle::CpuMatrix
addElements	math/Matrix.h	/^  virtual void addElements(Matrix& table, IVector& ids) {$/;"	f	class:paddle::Matrix
addEvaluator	gserver/gradientmachines/MultiNetwork.cpp	/^  void addEvaluator(std::unique_ptr<Evaluator>&& evaluator) {$/;"	f	class:paddle::MultiCombinedEvaluator
addEvaluator	gserver/gradientmachines/NeuralNetwork.cpp	/^  void addEvaluator(std::unique_ptr<Evaluator>&& evaluator) {$/;"	f	class:paddle::CombinedEvaluator
addGradBegin_	pserver/ParameterServer2.h	/^  ThreadLocal<struct timeval> addGradBegin_;$/;"	m	class:paddle::ParameterServer2
addGradient	pserver/ParameterServer2.cpp	/^void ParameterServer2::addGradient(const SendParameterRequest& request,$/;"	f	class:paddle::ParameterServer2
addInputs	function/FunctionTest.h	/^  void addInputs(const BufferArg& input) {$/;"	f	class:paddle::FunctionCompare
addInputs	function/FunctionTest.h	/^  void addInputs(const SequenceArg& input) {$/;"	f	class:paddle::FunctionCompare
addInputs	function/FunctionTest.h	/^  void addInputs(const SparseMatrixArg& input) {$/;"	f	class:paddle::FunctionCompare
addJob	utils/Thread.h	/^  void addJob(JobFunc func) {$/;"	f	class:paddle::MultiThreadWorker
addJob	utils/Thread.h	/^  void addJob(JobFunc func) {$/;"	f	class:paddle::ThreadWorker
addOperation	pserver/ParameterClient2.h	/^  ResultsAdder addOperation(MatrixVectorOperation operation, Args... args) {$/;"	f	class:paddle::PreparedOperations
addOperationHelper	pserver/ParameterClient2.cpp	/^void PreparedOperations::addOperationHelper(Operation* op, CpuMatrixPtr mat) {$/;"	f	class:paddle::PreparedOperations
addOperationHelper	pserver/ParameterClient2.cpp	/^void PreparedOperations::addOperationHelper(Operation* op, CpuVectorPtr vec) {$/;"	f	class:paddle::PreparedOperations
addOperationHelper	pserver/ParameterClient2.h	/^  void addOperationHelper(Operation* op) {}$/;"	f	class:paddle::PreparedOperations
addOperationHelper	pserver/ParameterClient2.h	/^  void addOperationHelper(Operation* op, Arg arg, Args... args) {$/;"	f	class:paddle::PreparedOperations
addOperationHelper	pserver/ParameterClient2.h	/^  void addOperationHelper(Operation* op, PServerMatrix arg) {$/;"	f	class:paddle::PreparedOperations
addOperationHelper	pserver/ParameterClient2.h	/^  void addOperationHelper(Operation* op, PServerVector arg) {$/;"	f	class:paddle::PreparedOperations
addOperationHelper	pserver/ParameterClient2.h	/^  void addOperationHelper(Operation* op, real arg) { op->add_scalars(arg); }$/;"	f	class:paddle::PreparedOperations
addOutputArgument	gserver/layers/Layer.cpp	/^void Layer::addOutputArgument(int deviceId) {$/;"	f	class:paddle::Layer
addOutputs	function/FunctionTest.h	/^  void addOutputs(const BufferArg& output, ArgType argType = ASSIGN_TO) {$/;"	f	class:paddle::FunctionCompare
addOutputs	function/FunctionTest.h	/^  void addOutputs(const SequenceArg& output, ArgType argType = ASSIGN_TO) {$/;"	f	class:paddle::FunctionCompare
addOutputs	function/FunctionTest.h	/^  void addOutputs(const SparseMatrixArg& output, ArgType argType = ASSIGN_TO) {$/;"	f	class:paddle::FunctionCompare
addParameterType	parameter/ParameterOptimizer.h	/^  void addParameterType(ParameterType type) {$/;"	f	class:paddle::ParameterOptimizer
addParameterType	parameter/ParameterUpdaterBase.h	/^  void addParameterType(ParameterType type) {$/;"	f	class:paddle::ParameterUpdater
addPrev	gserver/layers/Layer.h	/^  void addPrev(LayerPtr l) { inputLayers_.push_back(l); }$/;"	f	class:paddle::Layer
addRealLayer	gserver/layers/AgentLayer.h	/^  void addRealLayer(LayerPtr layer) { realLayers_.push_back(layer); }$/;"	f	class:paddle::GatherAgentLayer
addResult	pserver/ParameterClient2.h	/^    void addResult() {}$/;"	f	class:paddle::PreparedOperations::ResultsAdder
addResult	pserver/ParameterClient2.h	/^    void addResult(Arg arg, Args... args) {$/;"	f	class:paddle::PreparedOperations::ResultsAdder
addResult	pserver/ParameterClient2.h	/^    void addResult(real* arg) { localResult_->resultScalars.push_back(arg); }$/;"	f	class:paddle::PreparedOperations::ResultsAdder
addRows	math/SparseRowMatrix.cpp	/^void SparsePrefetchRowCpuMatrix::addRows(IVectorPtr ids) {$/;"	f	class:paddle::SparsePrefetchRowCpuMatrix
addRows	math/SparseRowMatrix.cpp	/^void SparsePrefetchRowCpuMatrix::addRows(MatrixPtr input) {$/;"	f	class:paddle::SparsePrefetchRowCpuMatrix
addRows	math/SparseRowMatrix.cpp	/^void SparsePrefetchRowCpuMatrix::addRows(const unsigned int* ids, size_t len) {$/;"	f	class:paddle::SparsePrefetchRowCpuMatrix
addSample	utils/Stat.cpp	/^void Stat::addSample(uint64_t value) {$/;"	f	class:paddle::Stat
addSequence	function/FunctionTest.h	/^  void addSequence(const SequenceIdArg& input) {$/;"	f	class:paddle::FunctionCompare
addSharedBias	gserver/layers/ExpandConvBaseLayer.cpp	/^void ExpandConvBaseLayer::addSharedBias() {$/;"	f	class:paddle::ExpandConvBaseLayer
addSharedBias	math/Matrix.cpp	/^void CpuMatrix::addSharedBias(Matrix& b, real scale) {$/;"	f	class:paddle::CpuMatrix
addSharedBias	math/Matrix.cpp	/^void GpuMatrix::addSharedBias(Matrix& b, real scale) {$/;"	f	class:paddle::GpuMatrix
addSharedBias	math/Matrix.h	/^  virtual void addSharedBias(Matrix& b, real scale) {$/;"	f	class:paddle::Matrix
addTimeval	utils/BarrierStat.h	/^  void addTimeval(struct timeval time, int32_t trainerId) {$/;"	f	class:paddle::TimeVectorEnd
addTimeval	utils/BarrierStat.h	/^  void addTimeval(uint64_t delta, int32_t trainerId) {$/;"	f	class:paddle::TimeVectorDelta
addTo	math/SIMDFunctions.h	/^inline void addTo(Type* a, const Type* b, size_t len) {$/;"	f	namespace:paddle::simd
addTo	math/SIMDFunctions.h	/^inline void addTo(Type* a, const Type* b, size_t len) {$/;"	f	namespace:paddle::simd::naive
addTo	math/SIMDFunctions.h	/^inline void addTo(float* a, const float* b, size_t len) {$/;"	f	namespace:paddle::simd
addTo	math/SparseRowMatrix.cpp	/^void SparseRowCpuMatrix::addTo(BaseMatrix& dest,$/;"	f	class:paddle::SparseRowCpuMatrix
addTo	math/SparseRowMatrix.cpp	/^void SparseRowCpuMatrix::addTo(SparseRowCpuMatrix& dest,$/;"	f	class:paddle::SparseRowCpuMatrix
addToImpl	math/SIMDFunctions.cpp	/^void addToImpl(float* a, const float* b, size_t len) {$/;"	f	namespace:paddle::simd::internal
addToRows	math/Matrix.cpp	/^void CpuMatrix::addToRows(Matrix& table, IVector& ids) {$/;"	f	class:paddle::CpuMatrix
addToRows	math/Matrix.cpp	/^void GpuMatrix::addToRows(Matrix& table, IVector& ids) {$/;"	f	class:paddle::GpuMatrix
addToRows	math/Matrix.h	/^  virtual void addToRows(Matrix& table, IVector& ids) {$/;"	f	class:paddle::Matrix
addToRowsImp	math/Matrix.cpp	/^void CpuMatrix::addToRowsImp(TableMatType& table, IVector& ids) {$/;"	f	class:paddle::CpuMatrix
addTwo	pserver/ParameterClient2.cpp	/^static inline real addTwo(real a, double b) { return a + b; }$/;"	f	namespace:paddle
addUnsharedBias	gserver/layers/ExpandConvBaseLayer.cpp	/^void ExpandConvBaseLayer::addUnsharedBias() {$/;"	f	class:paddle::ExpandConvBaseLayer
add_scale	cuda/include/hl_tensor_ops.h	/^  INLINE add_scale(const T s) : p(s) {}$/;"	f	class:hppl::unary::add_scale
add_scale	cuda/include/hl_tensor_ops.h	/^  INLINE add_scale(const T s1, const T s2) : p1(s1), p2(s2) {}$/;"	f	class:hppl::binary::add_scale
add_scale	cuda/include/hl_tensor_ops.h	/^class add_scale {$/;"	c	namespace:hppl::binary
add_scale	cuda/include/hl_tensor_ops.h	/^class add_scale {$/;"	c	namespace:hppl::unary
add_to_dict	trainer/tests/gen_proto_data.py	/^    def add_to_dict(sequence, dicts):$/;"	f	function:create_dictionaries
addr_	pserver/LightNetwork.h	/^  std::string addr_;$/;"	m	class:paddle::SocketServer
address	utils/Util.h	/^  T* address(T& r) const { return &r; }$/;"	f	class:paddle::AlignedAllocator
address	utils/Util.h	/^  const T* address(const T& r) const { return &r; }$/;"	f	class:paddle::AlignedAllocator
addto_avx	math/SIMDFunctions.cpp	/^static void addto_avx(float* a, const float* b, size_t len) {$/;"	f	file:
addto_sse	math/SIMDFunctions.cpp	/^static void addto_sse(float* a, const float* b, size_t len) {$/;"	f	file:
adjustProb	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::Path::adjustProb(int calc_id, bool atEos) {$/;"	f	class:paddle::RecurrentGradientMachine::Path
agentLayer	gserver/gradientmachines/RecurrentGradientMachine.h	/^    LayerPtr agentLayer;$/;"	m	struct:paddle::RecurrentGradientMachine::OutFrameLine
agents	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::vector<LayerPtr> agents;  \/\/ Scatter Agents to reform batch input$/;"	m	struct:paddle::RecurrentGradientMachine::InFrameLine
agents	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::vector<LayerPtr> agents;$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
allBarrier_	gserver/gradientmachines/MultiGradientMachine.h	/^  ThreadBarrier allBarrier_;$/;"	m	class:paddle::MultiGradientMachine
allClientPassFinish_	pserver/ParameterServer2.h	/^  bool allClientPassFinish_;$/;"	m	class:paddle::ParameterServer2
allCount	parameter/Argument.h	/^  int allCount;            \/\/ the number of output layers using this argument$/;"	m	struct:paddle::Argument
allIds	gserver/gradientmachines/RecurrentGradientMachine.h	/^    IVectorPtr allIds;         \/\/ scattered id of realLayer$/;"	m	struct:paddle::RecurrentGradientMachine::Info
allIds	gserver/gradientmachines/RecurrentGradientMachine.h	/^    IVectorPtr allIds;  \/\/ scattered id of realLayer$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
allIds_	gserver/layers/AgentLayer.h	/^  IVectorPtr allIds_;$/;"	m	class:paddle::GatherAgentLayer
allSegments_	pserver/ParameterClient2.h	/^  std::vector<ParameterSegments> allSegments_;$/;"	m	class:paddle::ParameterClient2
alloc	math/Allocator.h	/^  virtual void* alloc(size_t size) {$/;"	f	class:paddle::CpuAllocator
alloc	math/Allocator.h	/^  virtual void* alloc(size_t size) {$/;"	f	class:paddle::CudaHostAllocator
alloc	math/Allocator.h	/^  virtual void* alloc(size_t size) {$/;"	f	class:paddle::GpuAllocator
alloc	math/PoolAllocator.cpp	/^void* PoolAllocator::alloc(size_t size) {$/;"	f	class:paddle::PoolAllocator
allocConvWorkSpace	gserver/layers/ConvOperator.cpp	/^void ConvOperator::allocConvWorkSpace(size_t maxWorkSpace) {$/;"	f	class:paddle::ConvOperator
allocGradBufs	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::allocGradBufs() {$/;"	f	class:paddle::MultiGradientMachine
allocSize_	math/MemoryHandle.h	/^  size_t allocSize_;  \/\/ the allocated size$/;"	m	class:paddle::MemoryHandle
allocate	utils/Util.h	/^  T* allocate(const size_type n) const {$/;"	f	class:paddle::AlignedAllocator
allocate	utils/Util.h	/^  T* allocate(const std::size_t n, const U* \/* const hint *\/) const {$/;"	f	class:paddle::AlignedAllocator
allocateMem	math/tests/test_perturbation.cpp	/^  void allocateMem(real*& gpuAngle,$/;"	f	class:PerturbationTest
allocator_	math/MemoryHandle.h	/^  PoolAllocator* allocator_;$/;"	m	class:paddle::MemoryHandle
allocator_	math/PoolAllocator.h	/^  std::unique_ptr<Allocator> allocator_;$/;"	m	class:paddle::PoolAllocator
allow_only_one_model_on_one_gpu	trainer/tests/test_Trainer.cpp	/^DECLARE_bool(allow_only_one_model_on_one_gpu);$/;"	v
alpha_	gserver/layers/LinearChainCRF.h	/^  MatrixPtr alpha_;$/;"	m	class:paddle::LinearChainCRF
alpha_	parameter/FirstOrderOptimizer.h	/^  real alpha_;$/;"	m	class:paddle::SparseMomentumParameterOptimizer
and_op	cuda/include/hl_tensor_ops.h	/^  INLINE and_op(const T s) : p(s) {}$/;"	f	class:hppl::unary::and_op
and_op	cuda/include/hl_tensor_ops.h	/^class and_op {$/;"	c	namespace:hppl::binary
and_op	cuda/include/hl_tensor_ops.h	/^class and_op {$/;"	c	namespace:hppl::unary
append	py_paddle/util.py	/^        def append(self, other):$/;"	m	class:DataProviderWrapperConverter.DenseValueConverter
append	py_paddle/util.py	/^        def append(self, other):$/;"	m	class:DataProviderWrapperConverter.IdValueConverter
append	py_paddle/util.py	/^        def append(self, other):$/;"	m	class:DataProviderWrapperConverter.SparseNonValueConverter
append	py_paddle/util.py	/^        def append(self, other):$/;"	m	class:DataProviderWrapperConverter.SparseValueConverter
appendArguments	gserver/dataproviders/DataProvider.h	/^  void appendArguments(const std::vector<Argument>& argus,$/;"	f	class:paddle::DataBatch
appendData	gserver/dataproviders/DataProvider.h	/^  void appendData(MatrixPtr data) {$/;"	f	class:paddle::DataBatch
appendData	gserver/dataproviders/DataProvider.h	/^  void appendData(const MatrixPtr& data,$/;"	f	class:paddle::DataBatch
appendLabel	gserver/dataproviders/DataProvider.h	/^  void appendLabel(IVectorPtr label, MatrixPtr value = nullptr) {$/;"	f	class:paddle::DataBatch
appendUserDefinedPtr	gserver/dataproviders/DataProvider.h	/^  void appendUserDefinedPtr(UserDefinedVectorPtr ptr) {$/;"	f	class:paddle::DataBatch
apply	api/GradientMachine.cpp	/^void UpdateCallback::apply(Parameter* p) {$/;"	f	class:UpdateCallback
apply	api/ParameterOptimizer.cpp	/^  void apply(const std::vector<Vector*>& vecs,$/;"	f	struct:ParameterTraverseCallbackPrivate
apply	api/ParameterOptimizer.cpp	/^void ParameterTraverseCallback::apply(const std::vector<Vector*>& vecs,$/;"	f	class:ParameterTraverseCallback
apply	api/ParameterUpdater.cpp	/^void ParameterUpdater::apply() { m->updater->apply(); }$/;"	f	class:ParameterUpdater
apply	math/SparseRowMatrix.h	/^  void apply(Func f) {$/;"	f	class:paddle::SparseRowCpuMatrix
apply	math/TensorApply.h	/^  INLINE T apply(int i, int j) const { return data_[i * stride_ + j]; }$/;"	f	class:paddle::TensorApply
apply	math/TensorApply.h	/^  INLINE T apply(int i, int j) const { return expr_.apply(i, j); }$/;"	f	class:paddle::TensorApply
apply	math/TensorApply.h	/^  INLINE T apply(int i, int j) const { return op_(expr_.apply(i, j)); }$/;"	f	class:paddle::TensorApply
apply	math/TensorApply.h	/^  INLINE T apply(int i, int j) const { return op_(i, j); }$/;"	f	class:paddle::TensorApply
apply	math/TensorApply.h	/^  INLINE T apply(int i, int j) const {$/;"	f	class:paddle::TensorApply
apply	math/TensorApply.h	/^  INLINE T apply(int index) const { return data_[index]; }$/;"	f	class:paddle::TensorApply
apply	math/TensorApply.h	/^  INLINE T apply(int index) const { return expr_.apply(index); }$/;"	f	class:paddle::TensorApply
apply	math/TensorApply.h	/^  INLINE T apply(int index) const { return op_(expr_.apply(index)); }$/;"	f	class:paddle::TensorApply
apply	math/TensorApply.h	/^  INLINE T apply(int index) const { return op_(index); }$/;"	f	class:paddle::TensorApply
apply	math/TensorApply.h	/^  INLINE T apply(int index) const {$/;"	f	class:paddle::TensorApply
apply	math/TensorAssign.h	/^  INLINE void apply(const int i, const int j) {$/;"	f	class:paddle::TensorAssignOp
apply	math/TensorAssign.h	/^  INLINE void apply(const int index) {$/;"	f	class:paddle::TensorAssignOp
apply	parameter/AverageOptimizer.cpp	/^ParameterOptimizer::TraverseCallback AverageOptimizer::apply() {$/;"	f	class:paddle::AverageOptimizer
apply	parameter/ParameterOptimizer.h	/^  virtual TraverseCallback apply() { return nullptr; }$/;"	f	class:paddle::ParameterOptimizer
apply	parameter/ParameterUpdaterBase.h	/^  virtual void apply() {$/;"	f	class:paddle::ParameterUpdaterComposite
apply	parameter/ParameterUpdaterBase.h	/^  virtual void apply() {}$/;"	f	class:paddle::ParameterUpdater
apply	py_paddle/util.py	/^    def apply(self, param):$/;"	m	class:__ParameterCallbackWrapper__
apply	trainer/ParameterUpdater.cpp	/^void SgdUpdaterWithCpuAverager::apply() {$/;"	f	class:paddle::SgdUpdaterWithCpuAverager
apply	trainer/ParameterUpdater.h	/^  virtual void apply() {$/;"	f	class:paddle::SgdLocalUpdater
apply	trainer/RemoteParameterUpdater.cpp	/^void RemoteParameterUpdater::apply() {$/;"	f	class:paddle::RemoteParameterUpdater
apply	trainer/RemoteParameterUpdater.cpp	/^void SparseRemoteParameterUpdater::apply() {$/;"	f	class:paddle::SparseRemoteParameterUpdater
apply	trainer/ThreadParameterUpdater.cpp	/^void SgdThreadUpdater::apply() {$/;"	f	class:paddle::SgdThreadUpdater
applyDecay_	parameter/ParameterOptimizer.h	/^  bool applyDecay_;$/;"	m	class:paddle::ParameterOptimizer
applyL1Decay	math/SparseRowMatrix.cpp	/^void SparseRowCpuMatrix::applyL1Decay(real learningRate, real decayRate) {$/;"	f	class:paddle::SparseRowCpuMatrix
applyRef	math/TensorApply.h	/^  INLINE T& applyRef(int i, int j) { return data_[i * stride_ + j]; }$/;"	f	class:paddle::TensorApply
applyRef	math/TensorApply.h	/^  INLINE T& applyRef(int index) { return data_[index]; }$/;"	f	class:paddle::TensorApply
approximateReadedBytes_	gserver/dataproviders/ProtoReader.h	/^  int approximateReadedBytes_;$/;"	m	class:paddle::ProtoReader
approximatelyEqual	testing/TestUtil.h	/^inline bool approximatelyEqual(float a, float b, float epsilon) {$/;"	f	namespace:paddle
arg_	math/ExecViaCpu.h	/^  Arg& arg_;$/;"	m	class:paddle::CopyToCpu
arg_	math/ExecViaCpu.h	/^  IVector& arg_;$/;"	m	class:paddle::CopyToCpu
arg_	math/ExecViaCpu.h	/^  Matrix& arg_;$/;"	m	class:paddle::CopyToCpu
arg_	math/ExecViaCpu.h	/^  const IVector& arg_;$/;"	m	class:paddle::CopyToCpu
arg_	math/ExecViaCpu.h	/^  const Matrix& arg_;$/;"	m	class:paddle::CopyToCpu
arg_	math/tests/TensorCheck.h	/^  CpuMatrix arg_;$/;"	m	class:autotest::CopyToCpu
arg_	math/tests/TensorCheck.h	/^  CpuVectorT<T> arg_;$/;"	m	class:autotest::CopyToCpu
arg_	math/tests/TensorCheck.h	/^  const CpuMatrix& arg_;$/;"	m	class:autotest::CopyToCpu
arg_	math/tests/TensorCheck.h	/^  const CpuVectorT<T>& arg_;$/;"	m	class:autotest::CopyToCpu
args	utils/PythonUtil.h	/^  PyObjectPtr args;$/;"	m	class:paddle::py::CallableHelper
args_	function/Function.h	/^  std::vector<BufferArg*> args_;$/;"	m	class:paddle::BufferArgs
argument_	gserver/activations/ActivationFunction.cpp	/^Argument argument_;$/;"	m	namespace:paddle	file:
array	trainer/tests/picojson.h	/^  typedef std::vector<value> array;$/;"	t	class:picojson::value
array	trainer/tests/picojson.h	/^typedef value::array array;$/;"	t	namespace:picojson
array_	trainer/tests/picojson.h	/^    array* array_;$/;"	m	union:picojson::value::_storage
array_type	trainer/tests/picojson.h	/^  array_type,$/;"	e	enum:picojson::__anon14
asSequenceGenerator	api/GradientMachine.cpp	/^SequenceGenerator* GradientMachine::asSequenceGenerator($/;"	f	class:GradientMachine
aspectRatio_	gserver/layers/PriorBox.cpp	/^  std::vector<real> aspectRatio_;$/;"	m	class:paddle::PriorBoxLayer	file:
assertKVArraySame	api/test/testMatrix.py	/^        def assertKVArraySame(actual, expect):$/;"	f	function:TestMatrix.test_sparse_value
asyncCount_	parameter/ParallelParameter.h	/^  int asyncCount_;$/;"	m	class:paddle::AsyncParameter
asyncFinishPass	pserver/ParameterClient2.cpp	/^void ParameterClient2::asyncFinishPass(SyncObject syncObjectId) {$/;"	f	class:paddle::ParameterClient2
asyncFinishPass	pserver/ParameterServer2.cpp	/^void ParameterServer2::asyncFinishPass(const SynchronizeRequest& request,$/;"	f	class:paddle::ParameterServer2
asyncGrdientCommitCheckAndStat	pserver/ParameterServer2.cpp	/^bool ParameterServer2::asyncGrdientCommitCheckAndStat($/;"	f	class:paddle::ParameterServer2
asyncLaggedGradientsNum_	pserver/ParameterServer2.h	/^  size_t asyncLaggedGradientsNum_;$/;"	m	class:paddle::ParameterServer2
asyncLaggedThreshold_	pserver/ParameterServer2.h	/^  int64_t asyncLaggedThreshold_;$/;"	m	class:paddle::ParameterServer2
asyncLoadBatch	gserver/dataproviders/DataProvider.cpp	/^void DoubleBuffer::asyncLoadBatch() {$/;"	f	class:paddle::DoubleBuffer
asyncLoader_	gserver/dataproviders/DataProvider.h	/^  std::unique_ptr<std::thread> asyncLoader_;$/;"	m	class:paddle::DoubleBuffer
asyncSGD	pserver/ParameterServer2.cpp	/^void ParameterServer2::asyncSGD(const SendParameterRequest& request,$/;"	f	class:paddle::ParameterServer2
asyncStartPass	pserver/ParameterClient2.h	/^  void asyncStartPass(SyncObject syncObjectId = SYNC_DEFAULT) {$/;"	f	class:paddle::ParameterClient2
asyncTrainerCommitStat_	pserver/ParameterServer2.h	/^  std::vector<size_t> asyncTrainerCommitStat_;$/;"	m	class:paddle::ParameterServer2
asyncTrainerDiscardStat_	pserver/ParameterServer2.h	/^  std::vector<size_t> asyncTrainerDiscardStat_;$/;"	m	class:paddle::ParameterServer2
asyncTrainerSteps_	pserver/ParameterServer2.h	/^  std::vector<int64_t> asyncTrainerSteps_;$/;"	m	class:paddle::ParameterServer2
asyncUpdateStat_	pserver/ParameterServer2.h	/^  std::vector<size_t> asyncUpdateStat_;$/;"	m	class:paddle::ParameterServer2
asyncUpdateSteps_	pserver/ParameterServer2.h	/^  std::atomic<int64_t> asyncUpdateSteps_;$/;"	m	class:paddle::ParameterServer2
async_count	utils/Flags.h	/^DECLARE_int32(async_count);$/;"	v
attachControlParam	parameter/ParallelParameter.cpp	/^void SyncParameter::attachControlParam(ParallelParameterPtr controler) {$/;"	f	class:paddle::SyncParameter
attachMajorParam	parameter/ParallelParameter.cpp	/^void SyncParameter::attachMajorParam(ParallelParameterPtr partner) {$/;"	f	class:paddle::SyncParameter
attachMinorParam	parameter/ParallelParameter.cpp	/^void SyncParameter::attachMinorParam(ParallelParameterPtr partner,$/;"	f	class:paddle::SyncParameter
autotest	math/tests/TensorCheck.h	/^namespace autotest {$/;"	n
autotest	math/tests/TestUtils.h	/^namespace autotest {$/;"	n
averageEvaluator_	trainer/Trainer.h	/^  std::unique_ptr<Evaluator> averageEvaluator_;$/;"	m	class:paddle::Trainer
averager_	trainer/ParameterUpdater.h	/^  std::unique_ptr<ParameterOptimizer> averager_;$/;"	m	class:paddle::SgdUpdaterWithCpuAverager
avgAbsGrad	trainer/TrainerInternal.h	/^    real avgAbsGrad;$/;"	m	struct:paddle::TrainerInternal::ParaStat
avgPoolBackward	math/Matrix.cpp	/^void CpuMatrix::avgPoolBackward(Matrix& input,$/;"	f	class:paddle::CpuMatrix
avgPoolBackward	math/Matrix.cpp	/^void GpuMatrix::avgPoolBackward(Matrix& outGrad,$/;"	f	class:paddle::GpuMatrix
avgPoolBackward	math/Matrix.h	/^  virtual void avgPoolBackward(Matrix& input,$/;"	f	class:paddle::Matrix
avgPoolForward	math/Matrix.cpp	/^void CpuMatrix::avgPoolForward(Matrix& input,$/;"	f	class:paddle::CpuMatrix
avgPoolForward	math/Matrix.cpp	/^void GpuMatrix::avgPoolForward(Matrix& inputMat,$/;"	f	class:paddle::GpuMatrix
avgPoolForward	math/Matrix.h	/^  virtual void avgPoolForward(Matrix& input,$/;"	f	class:paddle::Matrix
avgTestCost	trainer/Trainer.h	/^    real avgTestCost;$/;"	m	struct:paddle::Trainer::TrainPassContext
avx2_mm256_and_si256	cuda/src/avx_mathfun.h	152;"	d
avx2_mm256_andnot_si256	cuda/src/avx_mathfun.h	153;"	d
axpy	math/MathFunctions.cpp	/^void axpy<double>(const int n, const double alpha, const double* x, double* y) {$/;"	f	namespace:paddle
axpy	math/MathFunctions.cpp	/^void axpy<float>(const int n, const float alpha, const float* x, float* y) {$/;"	f	namespace:paddle
b	function/Function.h	/^    bool b;$/;"	m	union:paddle::FuncConfig::value
b	gserver/activations/ActivationFunction.cpp	/^real a, b;$/;"	m	namespace:paddle	file:
bCol_	math/BaseMatrix.h	/^  size_t bCol_;$/;"	m	class:paddle::MatrixOffset
bRow_	math/BaseMatrix.h	/^  size_t bRow_;$/;"	m	class:paddle::MatrixOffset
bTrans_	function/MulOp.cpp	/^  bool bTrans_;$/;"	m	class:paddle::MulFunc	file:
b_	gserver/layers/LinearChainCRF.h	/^  MatrixPtr b_;$/;"	m	class:paddle::LinearChainCRF
b_	parameter/LearningRateScheduler.cpp	/^  real b_;$/;"	m	class:paddle::BaseLRS	file:
backward	api/GradientMachine.cpp	/^void GradientMachine::backward(const UpdateCallback& callback) {$/;"	f	class:GradientMachine
backward	cuda/include/hl_activation_functions.h	/^  typedef T (*backward)(T, T);$/;"	t	class:hppl::Active
backward	cuda/include/hl_activation_functions.h	/^static __device__ Active<real>::backward backward[] = HPPL_ACTIVE_FUNCTION;$/;"	m	namespace:hppl::gpu
backward	gserver/activations/ActivationFunction.cpp	/^  Error __must_check backward(Argument& act) {$/;"	f	class:paddle::IdentityActivation
backward	gserver/activations/ActivationFunction.cpp	/^Error __must_check backward(Argument& act) {$/;"	f	namespace:paddle
backward	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::MultiGradientMachine
backward	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::backward() {$/;"	f	class:paddle::TrainerThread
backward	gserver/gradientmachines/MultiNetwork.cpp	/^void MultiNetwork::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::MultiNetwork
backward	gserver/gradientmachines/NeuralNetwork.cpp	/^void NeuralNetwork::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::NeuralNetwork
backward	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^void ParallelNeuralNetwork::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ParallelNeuralNetwork
backward	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::RecurrentGradientMachine
backward	gserver/layers/AddtoLayer.cpp	/^void AddtoLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::AddtoLayer
backward	gserver/layers/AgentLayer.cpp	/^void GatherAgentLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::GatherAgentLayer
backward	gserver/layers/AgentLayer.cpp	/^void ScatterAgentLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ScatterAgentLayer
backward	gserver/layers/AgentLayer.h	/^  void backward(const UpdateCallback& callback) {$/;"	f	class:paddle::SequenceGatherAgentLayer
backward	gserver/layers/AgentLayer.h	/^  void backward(const UpdateCallback& callback) {$/;"	f	class:paddle::SequenceScatterAgentLayer
backward	gserver/layers/AverageLayer.cpp	/^void AverageLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::AverageLayer
backward	gserver/layers/BatchNormalizationLayer.cpp	/^void BatchNormalizationLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::BatchNormalizationLayer
backward	gserver/layers/BilinearInterpLayer.cpp	/^void BilinearInterpLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::BilinearInterpLayer
backward	gserver/layers/BlockExpandLayer.cpp	/^void BlockExpandLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::BlockExpandLayer
backward	gserver/layers/CRFDecodingLayer.cpp	/^void CRFDecodingLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::CRFDecodingLayer
backward	gserver/layers/CRFLayer.cpp	/^void CRFLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::CRFLayer
backward	gserver/layers/CTCLayer.cpp	/^void CTCLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::CTCLayer
backward	gserver/layers/ConcatenateLayer.cpp	/^void ConcatenateLayer2::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ConcatenateLayer2
backward	gserver/layers/ConcatenateLayer.cpp	/^void ConcatenateLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ConcatenateLayer
backward	gserver/layers/ContextProjection.cpp	/^void ContextProjection::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ContextProjection
backward	gserver/layers/ConvOperator.cpp	/^void ConvOperator::backward() {$/;"	f	class:paddle::ConvOperator
backward	gserver/layers/ConvProjection.cpp	/^void ConvProjection::backward(const UpdateCallback &callback) {$/;"	f	class:paddle::ConvProjection
backward	gserver/layers/ConvShiftLayer.cpp	/^void ConvShiftLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ConvShiftLayer
backward	gserver/layers/ConvexCombinationLayer.cpp	/^void ConvexCombinationLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ConvexCombinationLayer
backward	gserver/layers/CosSimLayer.cpp	/^void CosSimLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::CosSimLayer
backward	gserver/layers/CosSimVecMatLayer.cpp	/^void CosSimVecMatLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::CosSimVecMatLayer
backward	gserver/layers/CostLayer.cpp	/^void CostLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::CostLayer
backward	gserver/layers/CostLayer.cpp	/^void LambdaCost::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::LambdaCost
backward	gserver/layers/CostLayer.cpp	/^void RankingCost::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::RankingCost
backward	gserver/layers/CudnnBatchNormLayer.cpp	/^void CudnnBatchNormLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::CudnnBatchNormLayer
backward	gserver/layers/CudnnConvLayer.cpp	/^void CudnnConvLayer::backward(const UpdateCallback &callback) {$/;"	f	class:paddle::CudnnConvLayer
backward	gserver/layers/CudnnPoolLayer.cpp	/^void CudnnPoolLayer::backward(const UpdateCallback &callback) {$/;"	f	class:paddle::CudnnPoolLayer
backward	gserver/layers/DataNormLayer.cpp	/^void DataNormLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::DataNormLayer
backward	gserver/layers/DotMulOperator.cpp	/^void DotMulOperator::backward() {$/;"	f	class:paddle::DotMulOperator
backward	gserver/layers/DotMulProjection.cpp	/^void DotMulProjection::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::DotMulProjection
backward	gserver/layers/ExpandConvLayer.cpp	/^void ExpandConvLayer::backward(const UpdateCallback &callback) {$/;"	f	class:paddle::ExpandConvLayer
backward	gserver/layers/ExpandConvTransLayer.cpp	/^void ExpandConvTransLayer::backward(const UpdateCallback &callback) {$/;"	f	class:paddle::ExpandConvTransLayer
backward	gserver/layers/ExpandLayer.cpp	/^void ExpandLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ExpandLayer
backward	gserver/layers/FeatureMapExpandLayer.cpp	/^void FeatureMapExpandLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::FeatureMapExpandLayer
backward	gserver/layers/FullMatrixProjection.cpp	/^void FullMatrixProjection::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::FullMatrixProjection
backward	gserver/layers/FullyConnectedLayer.cpp	/^void FullyConnectedLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::FullyConnectedLayer
backward	gserver/layers/GatedRecurrentLayer.cpp	/^void GatedRecurrentLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::GatedRecurrentLayer
backward	gserver/layers/GruCompute.cpp	/^void GruCompute::backward<0>(hl_gru_value value,$/;"	f	class:paddle::GruCompute
backward	gserver/layers/GruStepLayer.cpp	/^void GruStepLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::GruStepLayer
backward	gserver/layers/HierarchicalSigmoidLayer.cpp	/^void HierarchicalSigmoidLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::HierarchicalSigmoidLayer
backward	gserver/layers/IdentityProjection.cpp	/^void IdentityOffsetProjection::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::IdentityOffsetProjection
backward	gserver/layers/IdentityProjection.cpp	/^void IdentityProjection::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::IdentityProjection
backward	gserver/layers/InterpolationLayer.cpp	/^void InterpolationLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::InterpolationLayer
backward	gserver/layers/LinearChainCRF.cpp	/^void LinearChainCRF::backward(real* x, real* dx, int* s, int length) {$/;"	f	class:paddle::LinearChainCRF
backward	gserver/layers/LinearChainCTC.cpp	/^void LinearChainCTC::backward(real* softmaxSeq,$/;"	f	class:paddle::LinearChainCTC
backward	gserver/layers/LstmLayer.cpp	/^void LstmLayer::backward(const UpdateCallback &callback) {$/;"	f	class:paddle::LstmLayer
backward	gserver/layers/LstmStepLayer.cpp	/^void LstmStepLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::LstmStepLayer
backward	gserver/layers/MDLstmLayer.cpp	/^void MDLstmLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::MDLstmLayer
backward	gserver/layers/MaxLayer.cpp	/^void MaxLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::MaxLayer
backward	gserver/layers/MaxOutLayer.cpp	/^void MaxOutLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::MaxOutLayer
backward	gserver/layers/MixedLayer.cpp	/^void MixedLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::MixedLayer
backward	gserver/layers/MultiplexLayer.cpp	/^void MultiplexLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::MultiplexLayer
backward	gserver/layers/NormProjectionLayer.cpp	/^void CMRProjectionNormLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::CMRProjectionNormLayer
backward	gserver/layers/OuterProdLayer.cpp	/^void OuterProdLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::OuterProdLayer
backward	gserver/layers/PadLayer.cpp	/^void PadLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::PadLayer
backward	gserver/layers/ParameterReluLayer.cpp	/^void ParameterReluLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ParameterReluLayer
backward	gserver/layers/PoolProjection.cpp	/^void AvgPoolProjection::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::AvgPoolProjection
backward	gserver/layers/PoolProjection.cpp	/^void MaxPoolProjection::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::MaxPoolProjection
backward	gserver/layers/PoolProjectionLayer.cpp	/^void PoolProjectionLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::PoolProjectionLayer
backward	gserver/layers/PowerLayer.cpp	/^void PowerLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::PowerLayer
backward	gserver/layers/RecurrentLayer.cpp	/^void RecurrentLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::RecurrentLayer
backward	gserver/layers/ResizeLayer.cpp	/^void ResizeLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ResizeLayer
backward	gserver/layers/RotateLayer.cpp	/^void RotateLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::RotateLayer
backward	gserver/layers/ScalingLayer.cpp	/^void ScalingLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ScalingLayer
backward	gserver/layers/ScalingProjection.cpp	/^  void backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ScalingProjection
backward	gserver/layers/SelectiveFullyConnectedLayer.cpp	/^void SelectiveFullyConnectedLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::SelectiveFullyConnectedLayer
backward	gserver/layers/SequenceConcatLayer.cpp	/^void SequenceConcatLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::SequenceConcatLayer
backward	gserver/layers/SequenceLastInstanceLayer.cpp	/^void SequenceLastInstanceLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::SequenceLastInstanceLayer
backward	gserver/layers/SequencePoolLayer.cpp	/^void SequencePoolLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::SequencePoolLayer
backward	gserver/layers/SequenceReshapeLayer.cpp	/^void SequenceReshapeLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::SequenceReshapeLayer
backward	gserver/layers/SlopeInterceptLayer.cpp	/^void SlopeInterceptLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::SlopeInterceptLayer
backward	gserver/layers/SpatialPyramidPoolLayer.cpp	/^void SpatialPyramidPoolLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::SpatialPyramidPoolLayer
backward	gserver/layers/SubSequenceLayer.cpp	/^void SubSequenceLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::SubSequenceLayer
backward	gserver/layers/SumToOneNormLayer.cpp	/^void SumToOneNormLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::SumToOneNormLayer
backward	gserver/layers/TableProjection.cpp	/^void TableProjection::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::TableProjection
backward	gserver/layers/TensorLayer.cpp	/^void TensorLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::TensorLayer
backward	gserver/layers/TransLayer.cpp	/^void TransLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::TransLayer
backward	gserver/layers/TransposedFullMatrixProjection.cpp	/^void TransposedFullMatrixProjection::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::TransposedFullMatrixProjection
backward	gserver/layers/ValidationLayer.cpp	/^void ValidationLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::ValidationLayer
backward	gserver/layers/WarpCTCLayer.cpp	/^void WarpCTCLayer::backward(const UpdateCallback& callback) {$/;"	f	class:paddle::WarpCTCLayer
backward	gserver/tests/test_RecurrentLayer.cpp	/^  void backward() {$/;"	f	class:TestRecurrentLayer
backward	py_paddle/util.py	/^    def backward(self, callback):$/;"	f	function:__monkeypatch_gradient_machine__
backwardActivation	gserver/layers/Layer.cpp	/^void Layer::backwardActivation() {$/;"	f	class:paddle::Layer
backwardBatch	gserver/layers/GatedRecurrentLayer.cpp	/^void GatedRecurrentLayer::backwardBatch(int batchSize, MatrixPtr inputGrad) {$/;"	f	class:paddle::GatedRecurrentLayer
backwardBatch	gserver/layers/LstmCompute.cpp	/^void LstmCompute::backwardBatch<0>(hl_lstm_value value,$/;"	f	class:paddle::LstmCompute
backwardBatch	gserver/layers/LstmLayer.cpp	/^void LstmLayer::backwardBatch(int batchSize,$/;"	f	class:paddle::LstmLayer
backwardBatch	gserver/layers/RecurrentLayer.cpp	/^void RecurrentLayer::backwardBatch(int batchSize,$/;"	f	class:paddle::RecurrentLayer
backwardBias	gserver/layers/NCELayer.cpp	/^  void backwardBias(const UpdateCallback& callback) {$/;"	f	class:paddle::NCELayer
backwardCallback	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::backwardCallback(Parameter* para) {$/;"	f	class:paddle::TrainerThread
backwardCallback_	gserver/gradientmachines/MultiGradientMachine.h	/^  UpdateCallback backwardCallback_;$/;"	m	class:paddle::MultiGradientMachine
backwardCallback_	gserver/gradientmachines/MultiGradientMachine.h	/^  UpdateCallback backwardCallback_;$/;"	m	class:paddle::TrainerThread
backwardCallback_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  UpdateCallback backwardCallback_;$/;"	m	class:paddle::ParallelThread
backwardCost	gserver/layers/NCELayer.cpp	/^  void backwardCost() {$/;"	f	class:paddle::NCELayer
backwardGate2OutputSequence	gserver/layers/MDLstmLayer.cpp	/^void MDLstmLayer::backwardGate2OutputSequence(int start,$/;"	f	class:paddle::MDLstmLayer
backwardImp	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::backwardImp(const UpdateCallback& callback) {$/;"	f	class:paddle::MultiGradientMachine
backwardImp	gserver/layers/CTCLayer.cpp	/^void CTCLayer::backwardImp(const UpdateCallback& callback,$/;"	f	class:paddle::CTCLayer
backwardImp	gserver/layers/CostLayer.cpp	/^void HuberTwoClass::backwardImp(Matrix& outputValue,$/;"	f	class:paddle::HuberTwoClass
backwardImp	gserver/layers/CostLayer.cpp	/^void MultiBinaryLabelCrossEntropy::backwardImp(Matrix& output,$/;"	f	class:paddle::MultiBinaryLabelCrossEntropy
backwardImp	gserver/layers/CostLayer.cpp	/^void MultiClassCrossEntropy::backwardImp(Matrix& output,$/;"	f	class:paddle::MultiClassCrossEntropy
backwardImp	gserver/layers/CostLayer.cpp	/^void MultiClassCrossEntropyWithSelfNorm::backwardImp(Matrix& output,$/;"	f	class:paddle::MultiClassCrossEntropyWithSelfNorm
backwardImp	gserver/layers/CostLayer.cpp	/^void SoftBinaryClassCrossEntropy::backwardImp(Matrix& output,$/;"	f	class:paddle::SoftBinaryClassCrossEntropy
backwardImp	gserver/layers/CostLayer.cpp	/^void SumOfSquaresCostLayer::backwardImp(Matrix& output,$/;"	f	class:paddle::SumOfSquaresCostLayer
backwardImp	gserver/layers/CostLayer.h	/^  void backwardImp(Matrix& outputValue, Argument& label, Matrix& outputGrad) {$/;"	f	class:paddle::RankingCost
backwardImpIn	gserver/layers/CostLayer.cpp	/^void HuberTwoClass::backwardImpIn(Matrix& output,$/;"	f	class:paddle::HuberTwoClass
backwardOneInput	gserver/layers/NCELayer.cpp	/^  void backwardOneInput(int layerId, const UpdateCallback& callback) {$/;"	f	class:paddle::NCELayer
backwardOneSequence	gserver/layers/LstmCompute.cpp	/^void LstmCompute::backwardOneSequence<0>(hl_lstm_value value,$/;"	f	class:paddle::LstmCompute
backwardOneSequence	gserver/layers/MDLstmLayer.cpp	/^void MDLstmLayer::backwardOneSequence(int start, CoordIterator& coordIter) {$/;"	f	class:paddle::MDLstmLayer
backwardOneSequence	gserver/layers/RecurrentLayer.cpp	/^void RecurrentLayer::backwardOneSequence(int start, int length) {$/;"	f	class:paddle::RecurrentLayer
backwardSeqParallel	gserver/layers/LstmLayer.cpp	/^void LstmLayer::backwardSeqParallel(int batchSize,$/;"	f	class:paddle::LstmLayer
backwardSequence	gserver/layers/GatedRecurrentLayer.cpp	/^void GatedRecurrentLayer::backwardSequence(int batchSize,$/;"	f	class:paddle::GatedRecurrentLayer
backwardSequence	gserver/layers/LstmLayer.cpp	/^void LstmLayer::backwardSequence(int batchSize,$/;"	f	class:paddle::LstmLayer
backwardSequence	gserver/layers/RecurrentLayer.cpp	/^void RecurrentLayer::backwardSequence(int batchSize,$/;"	f	class:paddle::RecurrentLayer
backwardVars_	gserver/layers/LinearChainCTC.h	/^  MatrixPtr logActs_, forwardVars_, backwardVars_, gradTerms_;$/;"	m	class:paddle::LinearChainCTC
backward_	gserver/layers/Layer.h	/^  std::vector<std::shared_ptr<FunctionBase>> backward_;$/;"	m	class:paddle::Layer
backward_	gserver/layers/Projection.h	/^  std::vector<std::shared_ptr<FunctionBase>> backward_;$/;"	m	class:paddle::Projection
backward_callback	api/test/testGradientMachine.py	/^        def backward_callback(param_):$/;"	f	function:TestGradientMachine.test_create_gradient_machine
barrierStatSet_	utils/Stat.h	/^  std::unordered_map<std::string, BarrierStatPtr> barrierStatSet_;$/;"	m	class:paddle::StatSet
barrier_	utils/arch/linux/Locks.cpp	/^  pthread_barrier_t barrier_;$/;"	m	class:paddle::ThreadBarrierPrivate	file:
base	pserver/ParameterServer2.h	/^    real* base;$/;"	m	struct:paddle::ParameterServer2::Buffer
baseTimer_	parameter/OptimizerWithRegularizer.h	/^  int baseTimer_;$/;"	m	class:paddle::OptimizerWithRegularizerEveryNumBatches
basename	utils/Util.cpp	/^std::string basename(const std::string& path) {$/;"	f	namespace:paddle::path
batch2seqPadding	gserver/layers/WarpCTCLayer.cpp	/^void WarpCTCLayer::batch2seqPadding(const MatrixPtr& seqValue,$/;"	f	class:paddle::WarpCTCLayer
batchAddTo	math/SIMDFunctions.h	/^inline void batchAddTo(Type* a, const Type* b[], int batch, size_t len) {$/;"	f	namespace:paddle::simd
batchAddTo	math/SIMDFunctions.h	/^inline void batchAddTo(Type* a, const Type* b[], int batch, size_t len) {$/;"	f	namespace:paddle::simd::naive
batchAddTo	math/SIMDFunctions.h	/^inline void batchAddTo(float* a, const float* b[], int batch, size_t len) {$/;"	f	namespace:paddle::simd
batchAddToImpl	math/SIMDFunctions.cpp	/^void batchAddToImpl(float* a, const float* b[], int batch, size_t len) {$/;"	f	namespace:paddle::simd::internal
batchData_	gserver/dataproviders/DataProvider.h	/^  DataBatch* batchData_;$/;"	m	class:paddle::BufferBatch
batchGrad_	gserver/layers/GatedRecurrentLayer.h	/^  std::unique_ptr<SequenceToBatch> batchGrad_;$/;"	m	class:paddle::GatedRecurrentLayer
batchGrad_	gserver/layers/LstmLayer.h	/^  std::unique_ptr<SequenceToBatch> batchGrad_;$/;"	m	class:paddle::LstmLayer
batchGrad_	gserver/layers/RecurrentLayer.cpp	/^  std::unique_ptr<SequenceToBatch> batchGrad_;$/;"	m	class:paddle::RecurrentLayer	file:
batchGrad_	gserver/layers/WarpCTCLayer.h	/^  MatrixPtr batchGrad_;$/;"	m	class:paddle::WarpCTCLayer
batchId	trainer/Trainer.h	/^    int64_t batchId;$/;"	m	struct:paddle::Trainer::TrainPassContext
batchId_	pserver/ParameterServer2.h	/^  std::atomic<int64_t> batchId_;$/;"	m	class:paddle::ParameterServer2
batchMachineIdVec_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<int> batchMachineIdVec_;$/;"	m	class:paddle::RecurrentGradientMachine
batchNum_	gserver/layers/ConvProjection.h	/^  int batchNum_;$/;"	m	class:paddle::ConvProjection
batchPassed_	pserver/SparseParameterDistribution.h	/^  int batchPassed_;$/;"	m	class:paddle::SparseParameterDistribution
batchSize_	gserver/dataproviders/DataProvider.h	/^  int32_t batchSize_;$/;"	m	class:paddle::DoubleBuffer
batchSize_	gserver/dataproviders/PyDataProvider.h	/^  unsigned int batchSize_;$/;"	m	class:paddle::PyDataProvider
batchSize_	gserver/layers/RotateLayer.h	/^  int batchSize_;$/;"	m	class:paddle::RotateLayer
batchSize_	trainer/RemoteParameterUpdater.h	/^  int64_t batchSize_;$/;"	m	class:paddle::RemoteParameterUpdater
batchSize_	trainer/RemoteParameterUpdater.h	/^  int64_t batchSize_;$/;"	m	class:paddle::SparseRemoteParameterUpdater
batchStartPositions_	gserver/layers/SequenceToBatch.h	/^  IVectorPtr batchStartPositions_;$/;"	m	class:paddle::SequenceToBatch
batchStatus_	trainer/RemoteParameterUpdater.h	/^  BatchStatus batchStatus_;$/;"	m	class:paddle::RemoteParameterUpdater
batchValue_	gserver/layers/GatedRecurrentLayer.h	/^  std::unique_ptr<SequenceToBatch> batchValue_;$/;"	m	class:paddle::GatedRecurrentLayer
batchValue_	gserver/layers/LstmLayer.h	/^  std::unique_ptr<SequenceToBatch> batchValue_;$/;"	m	class:paddle::LstmLayer
batchValue_	gserver/layers/RecurrentLayer.cpp	/^  std::unique_ptr<SequenceToBatch> batchValue_;$/;"	m	class:paddle::RecurrentLayer	file:
batchValue_	gserver/layers/SequenceToBatch.h	/^  MatrixPtr batchValue_;$/;"	m	class:paddle::SequenceToBatch
batchValue_	gserver/layers/WarpCTCLayer.h	/^  MatrixPtr batchValue_;$/;"	m	class:paddle::WarpCTCLayer
batch_addto_avx	math/SIMDFunctions.cpp	/^static void batch_addto_avx(float* a, const float* b[], int batch, size_t len) {$/;"	f	file:
batch_addto_sse	math/SIMDFunctions.cpp	/^static void batch_addto_sse(float* a, const float* b[], int batch, size_t len) {$/;"	f	file:
beamExpand	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::beamExpand(std::vector<Path>& paths,$/;"	f	class:paddle::RecurrentGradientMachine
beamSearch	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::beamSearch(size_t batchSize) {$/;"	f	class:paddle::RecurrentGradientMachine
beamSearchCandidateAdjust	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^      beamSearchCandidateAdjust;$/;"	m	class:paddle::BeamSearchControlCallbacks	file:
beamSearchCtrlCallbacks_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  BeamSearchControlCallbacks* beamSearchCtrlCallbacks_;$/;"	m	class:paddle::RecurrentGradientMachine
beamSearchStatistics_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  BeamSearchStatisticsCallbacks* beamSearchStatistics_;$/;"	m	class:paddle::RecurrentGradientMachine
beamShrink	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^size_t RecurrentGradientMachine::beamShrink(std::vector<Path>& newPaths,$/;"	f	class:paddle::RecurrentGradientMachine
beamSize_	gserver/layers/MaxIdLayer.cpp	/^  size_t beamSize_;$/;"	m	class:paddle::MaxIdLayer	file:
beam_size	utils/Flags.h	/^DECLARE_int32(beam_size);$/;"	v
begin	gserver/evaluators/ChunkEvaluator.cpp	/^    int begin;$/;"	m	struct:paddle::ChunkEvaluator::Segment	file:
begin	gserver/layers/MDLstmLayer.cpp	/^  std::vector<int>& begin() {$/;"	f	class:paddle::CoordIterator
beginDim	parameter/Parameter.h	/^  int64_t beginDim;$/;"	m	struct:paddle::Segment
beginPad_	gserver/layers/ContextProjection.h	/^  size_t beginPad_;$/;"	m	class:paddle::ContextProjection
beginPos	api/SequenceGenerator.cpp	/^  size_t beginPos;$/;"	m	struct:SequenceGeneratorPrivate	file:
beginPos	parameter/Parameter.h	/^  int64_t beginPos;  \/\/ beginning position in the local value or grad buffer$/;"	m	struct:paddle::Segment
begin_pad_	function/ContextProjectionOp.cpp	/^  size_t begin_pad_;$/;"	m	class:paddle::ContextProjectionBackwardFunc	file:
begin_pad_	function/ContextProjectionOp.cpp	/^  size_t begin_pad_;$/;"	m	class:paddle::ContextProjectionBackwardWeightFunc	file:
begin_pad_	function/ContextProjectionOp.cpp	/^  size_t begin_pad_;$/;"	m	class:paddle::ContextProjectionForwardFunc	file:
benchmarkRandom	gserver/tests/test_MultinomialSampler.cpp	/^void benchmarkRandom() {$/;"	f
bestLabelSeq	gserver/evaluators/CTCErrorEvaluator.cpp	/^  std::vector<int> bestLabelSeq() {$/;"	f	class:paddle::CTCErrorEvaluator	file:
beta1_	parameter/FirstOrderOptimizer.h	/^  real beta1_;$/;"	m	class:paddle::AdamParameterOptimizer
beta1_	parameter/FirstOrderOptimizer.h	/^  real beta1_;$/;"	m	class:paddle::AdamaxParameterOptimizer
beta2_	parameter/FirstOrderOptimizer.h	/^  real beta2_;$/;"	m	class:paddle::AdamParameterOptimizer
beta2_	parameter/FirstOrderOptimizer.h	/^  real beta2_;$/;"	m	class:paddle::AdamaxParameterOptimizer
beta_	gserver/layers/LinearChainCRF.h	/^  MatrixPtr beta_;$/;"	m	class:paddle::LinearChainCRF
beta_	parameter/FirstOrderOptimizer.h	/^  real beta_;$/;"	m	class:paddle::SparseMomentumParameterOptimizer
biasDesc_	gserver/layers/CudnnConvLayer.h	/^  hl_tensor_descriptor biasDesc_;$/;"	m	class:paddle::CudnnConvLayer
biasLayer	gserver/gradientmachines/RecurrentGradientMachine.h	/^    LayerPtr biasLayer;$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
biasOffset_	gserver/layers/CudnnConvLayer.h	/^  int biasOffset_;$/;"	m	class:paddle::CudnnConvLayer
biasParameter_	gserver/layers/Layer.h	/^  ParameterPtr biasParameter_;$/;"	m	class:paddle::Layer
biasSize	gserver/tests/LayerGradUtil.h	/^  size_t biasSize;$/;"	m	struct:paddle::TestConfig
bias_	gserver/layers/ConvProjection.h	/^  bool bias_;$/;"	m	class:paddle::ConvProjection
bias_	gserver/layers/GatedRecurrentLayer.h	/^  std::unique_ptr<Weight> bias_;$/;"	m	class:paddle::GatedRecurrentLayer
bias_	gserver/layers/GruStepLayer.cpp	/^  std::unique_ptr<Weight> bias_;$/;"	m	class:paddle::GruStepLayer	file:
bias_	gserver/layers/LstmLayer.h	/^  std::unique_ptr<Weight> bias_;$/;"	m	class:paddle::LstmLayer
bias_	gserver/layers/RecurrentLayer.cpp	/^  std::unique_ptr<Weight> bias_;$/;"	m	class:paddle::RecurrentLayer	file:
bias_	gserver/tests/test_RecurrentLayer.cpp	/^  ParameterPtr bias_;$/;"	m	class:TestRecurrentLayer	file:
biases_	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::BootBiasLayer	file:
biases_	gserver/layers/AddtoLayer.h	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::AddtoLayer
biases_	gserver/layers/BatchNormBaseLayer.h	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::BatchNormBaseLayer
biases_	gserver/layers/ConcatenateLayer.cpp	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::ConcatenateLayer2	file:
biases_	gserver/layers/ConvBaseLayer.h	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::ConvBaseLayer
biases_	gserver/layers/ExpandLayer.h	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::ExpandLayer
biases_	gserver/layers/FullyConnectedLayer.h	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::FullyConnectedLayer
biases_	gserver/layers/HierarchicalSigmoidLayer.h	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::HierarchicalSigmoidLayer
biases_	gserver/layers/MixedLayer.h	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::MixedLayer
biases_	gserver/layers/NCELayer.cpp	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::NCELayer	file:
biases_	gserver/layers/SelectiveFullyConnectedLayer.h	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
biases_	gserver/layers/SequenceConcatLayer.cpp	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::SequenceConcatLayer	file:
biases_	gserver/layers/SequencePoolLayer.h	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::SequencePoolLayer
biases_	gserver/layers/SequenceReshapeLayer.cpp	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::SequenceReshapeLayer	file:
biases_	gserver/layers/SubSequenceLayer.cpp	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::SubSequenceLayer	file:
biases_	gserver/layers/TensorLayer.h	/^  std::unique_ptr<Weight> biases_;$/;"	m	class:paddle::TensorLayer
bilinearBackward	math/Matrix.cpp	/^void CpuMatrix::bilinearBackward(const Matrix& out,$/;"	f	class:paddle::CpuMatrix
bilinearBackward	math/Matrix.cpp	/^void GpuMatrix::bilinearBackward(const Matrix& out,$/;"	f	class:paddle::GpuMatrix
bilinearBackward	math/Matrix.h	/^  virtual void bilinearBackward(const Matrix& out,$/;"	f	class:paddle::Matrix
bilinearForward	math/Matrix.cpp	/^void CpuMatrix::bilinearForward(const Matrix& in,$/;"	f	class:paddle::CpuMatrix
bilinearForward	math/Matrix.cpp	/^void GpuMatrix::bilinearForward(const Matrix& in,$/;"	f	class:paddle::GpuMatrix
bilinearForward	math/Matrix.h	/^  virtual void bilinearForward(const Matrix& in,$/;"	f	class:paddle::Matrix
binary	cuda/include/hl_tensor_ops.h	/^namespace binary {$/;"	n	namespace:hppl
binaryExpression	math/TensorExpression.h	/^  binaryExpression(const BinaryOp& op, const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
bind	pserver/RDMANetwork.h	/^inline int bind(sxi_socket* s, const char* str) {$/;"	f	namespace:paddle::rdma
blank_	gserver/evaluators/CTCErrorEvaluator.cpp	/^  int numTimes_, numClasses_, numSequences_, blank_;$/;"	m	class:paddle::CTCErrorEvaluator	file:
blank_	gserver/layers/LinearChainCTC.h	/^  int numClasses_, blank_, totalSegments_, totalTime_;$/;"	m	class:paddle::LinearChainCTC
blank_	gserver/layers/WarpCTCLayer.h	/^  size_t blank_;$/;"	m	class:paddle::WarpCTCLayer
blockH_	gserver/layers/BlockExpandLayer.h	/^  size_t blockH_, blockW_, strideH_, strideW_, paddingH_, paddingW_;$/;"	m	class:paddle::BlockExpandLayer
blockIdMap_	pserver/ParameterServer2.h	/^  BlockMap blockIdMap_;$/;"	m	class:paddle::ParameterServer2
blockInfos_	pserver/ParameterServer2.h	/^  std::vector<BlockInfo> blockInfos_;$/;"	m	class:paddle::ParameterServer2
blockLengths_	pserver/SocketChannel.h	/^  std::vector<size_t> blockLengths_;$/;"	m	class:paddle::MsgReader
blockLocks_	math/Matrix.h	/^  std::vector<std::unique_ptr<std::mutex>> blockLocks_;$/;"	m	class:paddle::SharedCpuMatrix
blockNum_	math/Matrix.h	/^  int blockNum_;$/;"	m	class:paddle::SharedCpuMatrix
blockOffsetMap_	pserver/ParameterServer2.h	/^  BlockMap blockOffsetMap_;$/;"	m	class:paddle::ParameterServer2
blockSeq_	math/Matrix.h	/^  ThreadLocal<std::vector<int>> blockSeq_;$/;"	m	class:paddle::SharedCpuMatrix
blockTraverse	pserver/ParameterServer2.cpp	/^void ParameterServer2::blockTraverse($/;"	f	class:paddle::ParameterServer2
blockW_	gserver/layers/BlockExpandLayer.h	/^  size_t blockH_, blockW_, strideH_, strideW_, paddingH_, paddingW_;$/;"	m	class:paddle::BlockExpandLayer
bnParamDesc_	gserver/layers/CudnnBatchNormLayer.h	/^  hl_tensor_descriptor bnParamDesc_;$/;"	m	class:paddle::CudnnBatchNormLayer
bool_constant	math/BaseMatrix.h	/^struct bool_constant {$/;"	s	namespace:paddle
boolean_	trainer/tests/picojson.h	/^    bool boolean_;$/;"	m	union:picojson::value::_storage
boolean_type	trainer/tests/picojson.h	/^  boolean_type,$/;"	e	enum:picojson::__anon14
bootLayer	gserver/gradientmachines/RecurrentGradientMachine.h	/^    LayerPtr bootLayer;  \/\/ actually used biasLayer or rootAgent$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
bpropActs	gserver/layers/ExpandConvBaseLayer.cpp	/^void ExpandConvBaseLayer::bpropActs(MatrixPtr out,$/;"	f	class:paddle::ExpandConvBaseLayer
bpropBiases	gserver/layers/ExpandConvBaseLayer.cpp	/^void ExpandConvBaseLayer::bpropBiases(MatrixPtr v) {$/;"	f	class:paddle::ExpandConvBaseLayer
bpropSharedBias	gserver/layers/ExpandConvBaseLayer.cpp	/^void ExpandConvBaseLayer::bpropSharedBias(MatrixPtr biases, MatrixPtr v) {$/;"	f	class:paddle::ExpandConvBaseLayer
bpropWeights	gserver/layers/ExpandConvBaseLayer.cpp	/^void ExpandConvBaseLayer::bpropWeights(MatrixPtr image,$/;"	f	class:paddle::ExpandConvBaseLayer
buf	api/PaddleAPI.h	/^  const float* buf;$/;"	m	struct:FloatArray
buf	api/PaddleAPI.h	/^  const int* buf;$/;"	m	struct:IntArray
buf_	function/BufferArg.h	/^  void* buf_;$/;"	m	class:paddle::BufferArg
buf_	math/MemoryHandle.h	/^  void* buf_;$/;"	m	class:paddle::MemoryHandle
buf_	math/SparseRowMatrix.h	/^  std::unique_ptr<RowBuffer> buf_;$/;"	m	class:paddle::SparseRowCpuMatrix
bufferCapacity_	gserver/dataproviders/DataProvider.h	/^  int64_t bufferCapacity_;$/;"	m	class:paddle::SimpleDataProviderBase
bufferQueue_	gserver/dataproviders/DataProvider.h	/^  BufferBatchQueue* bufferQueue_;$/;"	m	class:paddle::DoubleBuffer
bufferSizes_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<size_t> bufferSizes_;$/;"	m	class:paddle::MultiGradientMachine
bufferSum	pserver/ParameterServer2.cpp	/^real bufferSum(const std::vector<ParameterServer2::Buffer>& buffers) {$/;"	f	namespace:paddle
bufferType	function/BufferArg.h	/^  BufferType bufferType() const { return bufferType_; }$/;"	f	class:paddle::BufferArg
buffer_	gserver/layers/PriorBox.cpp	/^  MatrixPtr buffer_;$/;"	m	class:paddle::PriorBoxLayer	file:
buffer_	pserver/test/SocketTest.cpp	/^  std::string buffer_;$/;"	m	class:SocketWorker	file:
buffer_	pserver/test/test_ProtoServer.cpp	/^  std::string buffer_;$/;"	m	class:MyServer	file:
bufs	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<VectorPtr> bufs;$/;"	m	struct:paddle::GradBuffer
bufs_	parameter/Parameter.h	/^  VectorPtr bufs_[NUM_PARAMETER_TYPES];$/;"	m	class:paddle::Parameter
bwdDataAlgo_	gserver/layers/ConvOperator.cpp	/^  int fwdAlgo_, bwdFilterAlgo_, bwdDataAlgo_;$/;"	m	class:paddle::ConvOperator	file:
bwdDataAlgo_	gserver/layers/ConvProjection.h	/^  int bwdDataAlgo_;$/;"	m	class:paddle::ConvProjection
bwdDataLimitBytes_	gserver/layers/ConvOperator.cpp	/^  size_t fwdLimitBytes_, bwdDataLimitBytes_, bwdFilterLimitBytes_;$/;"	m	class:paddle::ConvOperator	file:
bwdDataLimitBytes_	gserver/layers/ConvProjection.h	/^  size_t bwdDataLimitBytes_;$/;"	m	class:paddle::ConvProjection
bwdFilterAlgo_	gserver/layers/ConvOperator.cpp	/^  int fwdAlgo_, bwdFilterAlgo_, bwdDataAlgo_;$/;"	m	class:paddle::ConvOperator	file:
bwdFilterAlgo_	gserver/layers/ConvProjection.h	/^  int bwdFilterAlgo_;$/;"	m	class:paddle::ConvProjection
bwdFilterLimitBytes_	gserver/layers/ConvOperator.cpp	/^  size_t fwdLimitBytes_, bwdDataLimitBytes_, bwdFilterLimitBytes_;$/;"	m	class:paddle::ConvOperator	file:
bwdFilterLimitBytes_	gserver/layers/ConvProjection.h	/^  size_t bwdFilterLimitBytes_;$/;"	m	class:paddle::ConvProjection
cCol_	math/BaseMatrix.h	/^  size_t cCol_;$/;"	m	class:paddle::MatrixOffset
cRow_	math/BaseMatrix.h	/^  size_t cRow_;$/;"	m	class:paddle::MatrixOffset
c_	math/MatrixBitCode.cpp	/^  size_t c_;$/;"	m	struct:paddle::__anon17::SimpleCode	file:
c_flag	api/paddle_ld_flags.py	/^        def c_flag(self):$/;"	m	class:PaddleLDFlag
cache	gserver/tests/test_PyDataProvider2.py	/^    cache=CacheType.CACHE_PASS_IN_MEM, )$/;"	v
cache_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::unique_ptr<IPyDataProviderCache> cache_;$/;"	m	class:paddle::PyDataProvider2	file:
caffeMode_	gserver/layers/ConvBaseLayer.h	/^  bool caffeMode_;$/;"	m	class:paddle::ConvBaseLayer
caffeMode_	gserver/layers/ConvOperator.cpp	/^  bool caffeMode_;$/;"	m	class:paddle::ConvOperator	file:
calFeatureMapSize	gserver/layers/BatchNormBaseLayer.cpp	/^void BatchNormBaseLayer::calFeatureMapSize() {$/;"	f	class:paddle::BatchNormBaseLayer
calMeanAndStd	gserver/layers/BatchNormalizationLayer.cpp	/^void BatchNormalizationLayer::calMeanAndStd(const MatrixPtr& mat) {$/;"	f	class:paddle::BatchNormalizationLayer
calMovingMeanAndVar	gserver/layers/BatchNormalizationLayer.cpp	/^void BatchNormalizationLayer::calMovingMeanAndVar() {$/;"	f	class:paddle::BatchNormalizationLayer
calOutputSize	gserver/layers/ConvBaseLayer.cpp	/^size_t ConvBaseLayer::calOutputSize() {$/;"	f	class:paddle::ConvBaseLayer
calOutputSize	gserver/layers/ConvProjection.h	/^  size_t calOutputSize() {$/;"	f	class:paddle::ConvProjection
calc	function/Function.h	/^  virtual void calc(const BufferArgs& inputs, const BufferArgs& outputs) {}$/;"	f	class:paddle::FunctionBase
calc	gserver/evaluators/Evaluator.cpp	/^void PnpairEvaluator::calc(std::vector<PredictionResult>& predictArray) {$/;"	f	class:paddle::PnpairEvaluator
calc	parameter/LearningRateScheduler.cpp	/^  real calc(int64_t num) {$/;"	f	class:paddle::ManualLRS
calcAuc	gserver/evaluators/Evaluator.cpp	/^double AucEvaluator::calcAuc() const {$/;"	f	class:paddle::AucEvaluator
calcBatchSize_	gserver/dataproviders/PyDataProvider2.cpp	/^  PyObjectPtr calcBatchSize_;$/;"	m	class:paddle::PyDataProvider2	file:
calcBit	math/MatrixBitCode.cpp	/^  inline bool calcBit(int bit) const { return c_ & (1 << bit); }$/;"	f	struct:paddle::__anon17::SimpleCode
calcClientId	pserver/BaseClient.h	/^  int calcClientId(int i, int serviceNum) {$/;"	f	class:paddle::BaseClient
calcError	gserver/evaluators/Evaluator.cpp	/^  MatrixPtr calcError(std::vector<Argument>& arguments) {$/;"	f	class:paddle::ClassificationErrorEvaluator
calcF1Score	gserver/evaluators/Evaluator.h	/^  inline static double calcF1Score(double precision, double recall) {$/;"	f	class:paddle::PrecisionRecallEvaluator
calcGrad	gserver/layers/CostLayer.cpp	/^void LambdaCost::calcGrad(const real* outputScore,$/;"	f	class:paddle::LambdaCost
calcGradient	gserver/tests/test_NetworkCompare.cpp	/^void calcGradient(DataIn& in, DataOut& out, const std::string& configPath) {$/;"	f
calcGradient	trainer/Trainer.cpp	/^real Trainer::calcGradient(const DataBatch& dataBatch,$/;"	f	class:paddle::Trainer
calcGradient	trainer/tests/test_Compare.cpp	/^void calcGradient(bool useGpu, comData& Data) {$/;"	f
calcGradient	trainer/tests/test_CompareTwoNets.cpp	/^void calcGradient(ComData& data, const string configFile) {$/;"	f
calcGradient	trainer/tests/test_CompareTwoOpts.cpp	/^void calcGradient(ComData& data, const string configFile) {$/;"	f
calcIndex	math/MatrixBitCode.cpp	/^  inline size_t calcIndex(int bit) const { return (c_ >> (bit + 1)) - 1; }$/;"	f	struct:paddle::__anon17::SimpleCode
calcLearningRate	parameter/LearningRateScheduler.cpp	/^  virtual real calcLearningRate(int64_t numSamplesProcessed, int64_t pass) {$/;"	f	class:paddle::CaffePolyLRS
calcLearningRate	parameter/LearningRateScheduler.cpp	/^  virtual real calcLearningRate(int64_t numSamplesProcessed, int64_t pass) {$/;"	f	class:paddle::ConstLRS
calcLearningRate	parameter/LearningRateScheduler.cpp	/^  virtual real calcLearningRate(int64_t numSamplesProcessed, int64_t pass) {$/;"	f	class:paddle::DiscreteExpLRS
calcLearningRate	parameter/LearningRateScheduler.cpp	/^  virtual real calcLearningRate(int64_t numSamplesProcessed, int64_t pass) {$/;"	f	class:paddle::ExpLRS
calcLearningRate	parameter/LearningRateScheduler.cpp	/^  virtual real calcLearningRate(int64_t numSamplesProcessed, int64_t pass) {$/;"	f	class:paddle::LinearLRS
calcLearningRate	parameter/LearningRateScheduler.cpp	/^  virtual real calcLearningRate(int64_t numSamplesProcessed, int64_t pass) {$/;"	f	class:paddle::ManualLRS
calcLearningRate	parameter/LearningRateScheduler.cpp	/^  virtual real calcLearningRate(int64_t numSamplesProcessed, int64_t pass) {$/;"	f	class:paddle::PassManualLRS
calcLearningRate	parameter/LearningRateScheduler.cpp	/^  virtual real calcLearningRate(int64_t numSamplesProcessed, int64_t pass) {$/;"	f	class:paddle::PolyLRS
calcLearningRate	parameter/ParameterOptimizer.h	/^  real calcLearningRate(int64_t numSamplesProcessed, int64_t pass) {$/;"	f	class:paddle::ParameterOptimizer
calcNDCG	gserver/layers/CostLayer.cpp	/^real LambdaCost::calcNDCG(const real* outputScore,$/;"	f	class:paddle::LambdaCost
calcOutput	gserver/tests/test_SelectiveFCLayer.cpp	/^void calcOutput(ComData& comData,$/;"	f
calcParameterBlockSize	pserver/ParameterClient2.cpp	/^int ParameterClient2::calcParameterBlockSize($/;"	f	class:paddle::ParameterClient2
calcPrecision	gserver/evaluators/Evaluator.h	/^  inline static double calcPrecision(double TP, double FP) {$/;"	f	class:paddle::PrecisionRecallEvaluator
calcRankAuc	gserver/evaluators/Evaluator.cpp	/^double RankAucEvaluator::calcRankAuc(real* outputData,$/;"	f	class:paddle::RankAucEvaluator
calcRecall	gserver/evaluators/Evaluator.h	/^  inline static double calcRecall(double TP, double FN) {$/;"	f	class:paddle::PrecisionRecallEvaluator
calcSplitArrayInterval	utils/Util.h	/^inline std::pair<size_t, size_t> calcSplitArrayInterval(size_t totalSize,$/;"	f	namespace:paddle
calcStatsInfo	gserver/evaluators/Evaluator.cpp	/^void PrecisionRecallEvaluator::calcStatsInfo(const MatrixPtr& output,$/;"	f	class:paddle::PrecisionRecallEvaluator
calcStatsInfoMulti	gserver/evaluators/Evaluator.cpp	/^void PrecisionRecallEvaluator::calcStatsInfoMulti(const MatrixPtr& output,$/;"	f	class:paddle::PrecisionRecallEvaluator
calculateCopySchedule	gserver/layers/MultiplexLayer.cpp	/^void MultiplexLayer::calculateCopySchedule(const IVectorPtr& copyIds,$/;"	f	class:paddle::MultiplexLayer
calculateServiceNum	utils/Util.cpp	/^size_t calculateServiceNum(const std::string& pservers, int ports_num) {$/;"	f	namespace:paddle
callPythonFunc	utils/PythonUtil.cpp	/^std::string callPythonFunc(const std::string& moduleName,$/;"	f	namespace:paddle
callback	api/GradientMachine.cpp	/^  UpdateCallback& callback;$/;"	m	class:UpdateCallbackWrapper	file:
callback	api/ParameterOptimizer.cpp	/^  paddle::ParameterOptimizer::TraverseCallback callback;$/;"	m	struct:ParameterTraverseCallbackPrivate	file:
callbackVec_	pserver/ParameterServer2.h	/^  ThreadLocal<std::vector<ProtoResponseCallbackEx>> callbackVec_;$/;"	m	class:paddle::ParameterServer2
callingContextCreated_	gserver/dataproviders/PyDataProvider2.cpp	/^  ThreadBarrier callingContextCreated_;$/;"	m	class:paddle::PyDataProvider2	file:
callingContexts_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::deque<PyObjectPtr> callingContexts_;$/;"	m	class:paddle::PyDataProvider2	file:
calrnn	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^    def calrnn(y):$/;"	f	function:step
canOverBatchSize_	gserver/dataproviders/PyDataProvider2.cpp	/^  bool canOverBatchSize_;$/;"	m	class:paddle::PyDataProvider2	file:
capacity_	utils/Queue.h	/^  size_t capacity_;$/;"	m	class:paddle::BlockingQueue
cast	api/PaddleAPIPrivate.h	/^  inline T& cast(void* ptr) {$/;"	f	struct:GradientMachinePrivate
cast	api/PaddleAPIPrivate.h	/^  std::shared_ptr<T>& cast(void* rawPtr) const {$/;"	f	struct:ArgumentsPrivate
cast	api/SequenceGenerator.cpp	/^  inline T& cast(void* ptr) {$/;"	f	struct:SequenceGeneratorPrivate
castInt	utils/PythonUtil.h	/^T castInt(PyObject* obj, bool* ok = nullptr) {$/;"	f	namespace:paddle::py
catchUpWith	api/ParameterUpdater.cpp	/^void ParameterUpdater::catchUpWith() { m->updater->catchUpWith(); }$/;"	f	class:ParameterUpdater
catchUpWith	parameter/AverageOptimizer.cpp	/^void AverageSparseOptimizer::catchUpWith(const VectorPtr vecs[],$/;"	f	class:paddle::AverageSparseOptimizer
catchUpWith	parameter/OptimizerWithRegularizer.cpp	/^void OptimizerWithRegularizerEveryNumBatches::catchUpWith($/;"	f	class:paddle::OptimizerWithRegularizerEveryNumBatches
catchUpWith	parameter/OptimizerWithRegularizer.cpp	/^void OptimizerWithRegularizerSparse::catchUpWith(const VectorPtr vecs[],$/;"	f	class:paddle::OptimizerWithRegularizerSparse
catchUpWith	parameter/ParameterUpdaterBase.h	/^  virtual void catchUpWith() {$/;"	f	class:paddle::ParameterUpdaterComposite
catchUpWith	parameter/ParameterUpdaterBase.h	/^  virtual void catchUpWith() {}$/;"	f	class:paddle::ParameterUpdater
catchUpWith	trainer/ThreadParameterUpdater.cpp	/^void SgdThreadUpdater::catchUpWith() {$/;"	f	class:paddle::SgdThreadUpdater
channelEnd	function/PadOp.h	/^  int channelEnd;$/;"	m	struct:paddle::PadConf
channelStart	function/PadOp.h	/^  int channelStart;$/;"	m	struct:paddle::PadConf
channel_	pserver/LightNetwork.h	/^  std::unique_ptr<SocketChannel> channel_;$/;"	m	class:paddle::SocketClient
channel_	pserver/LightNetwork.h	/^  std::unique_ptr<SocketChannel> channel_;$/;"	m	class:paddle::SocketWorker
channel_	pserver/SocketChannel.h	/^  SocketChannel* channel_;$/;"	m	class:paddle::MsgReader
channel_	pserver/test/SocketTest.cpp	/^  SocketChannel channel_;$/;"	m	class:SocketWorker	file:
channel_	pserver/test/SocketTest.cpp	/^  std::unique_ptr<SocketChannel> channel_;$/;"	m	class:SocketClient	file:
channels_	gserver/layers/BatchNormBaseLayer.h	/^  int channels_;$/;"	m	class:paddle::BatchNormBaseLayer
channels_	gserver/layers/BlockExpandLayer.h	/^  size_t imgSizeH_, imgSizeW_, outputH_, outputW_, channels_;$/;"	m	class:paddle::BlockExpandLayer
channels_	gserver/layers/ConvBaseLayer.h	/^  IntV channels_;$/;"	m	class:paddle::ConvBaseLayer
channels_	gserver/layers/ConvOperator.cpp	/^  int padding_, stride_, filterSize_, channels_, imgSize_, imgSizeY_;$/;"	m	class:paddle::ConvOperator	file:
channels_	gserver/layers/ConvProjection.h	/^  int channels_, numFilters_;$/;"	m	class:paddle::ConvProjection
channels_	gserver/layers/MaxOutLayer.h	/^  size_t channels_, outputChannels_;$/;"	m	class:paddle::MaxOutLayer
channels_	gserver/layers/NormLayer.h	/^  size_t channels_, size_, outputX_, imgSize_, outputY_, imgSizeY_;$/;"	m	class:paddle::ResponseNormLayer
channels_	gserver/layers/PoolLayer.h	/^  size_t channels_, sizeX_, stride_, outputX_, imgSize_;$/;"	m	class:paddle::PoolLayer
channels_	gserver/layers/PoolProjection.h	/^  size_t channels_;$/;"	m	class:paddle::PoolProjection
channels_	gserver/layers/RotateLayer.h	/^  int channels_;$/;"	m	class:paddle::RotateLayer
channels_	gserver/layers/SpatialPyramidPoolLayer.h	/^  size_t channels_;$/;"	m	class:paddle::SpatialPyramidPoolLayer
check	function/Function.h	/^  virtual void check(const BufferArgs& inputs, const BufferArgs& outputs) {}$/;"	f	class:paddle::FunctionBase
check	math/Matrix.cpp	/^void CpuMatrix::check(std::ostream& os, Matrix& refMat, bool printDiff) {$/;"	f	class:paddle::CpuMatrix
check	math/Matrix.cpp	/^void GpuMatrix::check(std::ostream& os, Matrix& refMat, bool printDiff) {$/;"	f	class:paddle::GpuMatrix
check	math/Matrix.h	/^  virtual void check(std::ostream& os, Matrix& refMat, bool printDiff = true) {}$/;"	f	class:paddle::Matrix
check	utils/CpuId.h	/^  inline bool check(int flags) const {$/;"	f	class:paddle::final
check	utils/Error.h	/^  void check() const { CHECK(*this) << msg(); }$/;"	f	class:paddle::Error
check	utils/Util.h	/^  void check() {$/;"	f	class:paddle::SameThreadChecker
checkAndResetDistribution	pserver/SparseParameterDistribution.cpp	/^void SparseParameterDistribution::checkAndResetDistribution() {$/;"	f	class:paddle::SparseParameterDistribution
checkBuffer	gserver/tests/test_NetworkCompare.cpp	/^void checkBuffer(real* A,$/;"	f
checkBuffer	trainer/tests/test_Compare.cpp	/^double checkBuffer(real* A, real* B, size_t len) {$/;"	f
checkBuffer	trainer/tests/test_CompareSparse.cpp	/^void checkBuffer(real* A,$/;"	f
checkBuffer	trainer/tests/test_CompareTwoNets.cpp	/^void checkBuffer(real* A,$/;"	f
checkBuffer	trainer/tests/test_CompareTwoOpts.cpp	/^void checkBuffer(real* A,$/;"	f
checkDataEqual	math/tests/test_matrixUtil.h	/^void checkDataEqual(const real* a, const real* b, size_t size) {$/;"	f	namespace:paddle
checkDataHeader	gserver/dataproviders/ProtoDataProvider.cpp	/^void ProtoDataProvider::checkDataHeader(const DataHeader& header) {$/;"	f	class:paddle::ProtoDataProvider
checkDict	utils/PythonUtil.h	/^  inline void checkDict() { CHECK(PyDict_Check(this->dict_)); }$/;"	f	class:paddle::py::DictHelper
checkEqual	trainer/tests/test_PyDataProviderWrapper.cpp	/^void checkEqual(const paddle::Argument& expect,$/;"	f
checkError	gserver/tests/test_RecurrentLayer.cpp	/^void checkError(const CpuVector& vector1, const CpuVector& vector2) {$/;"	f
checkError	gserver/tests/test_RecurrentLayer.cpp	/^void checkError(const Matrix& matrix1, const Matrix& matrix2) {$/;"	f
checkError	gserver/tests/test_WarpCTCLayer.cpp	/^int checkError(const Matrix& matrix1, const Matrix& matrix2) {$/;"	f
checkFg	cuda/include/hl_base.h	/^  real *checkFg;$/;"	m	struct:__anon4
checkFgGrad	cuda/include/hl_base.h	/^  real *checkFgGrad;$/;"	m	struct:__anon5
checkFgGrad_	gserver/layers/LstmLayer.h	/^  MatrixPtr checkFgGrad_;$/;"	m	class:paddle::LstmLayer
checkFgGrad_	gserver/layers/LstmStepLayer.cpp	/^  MatrixPtr checkIgGrad_, checkFgGrad_, checkOgGrad_;$/;"	m	class:paddle::LstmStepLayer	file:
checkFg_	gserver/layers/LstmLayer.h	/^  MatrixPtr checkFg_;$/;"	m	class:paddle::LstmLayer
checkFg_	gserver/layers/LstmStepLayer.cpp	/^  MatrixPtr checkIg_, checkFg_, checkOg_;$/;"	m	class:paddle::LstmStepLayer	file:
checkFilterSize	gserver/layers/ConvOperator.cpp	/^  void checkFilterSize(const MatrixPtr &filter) {$/;"	f	class:paddle::ConvOperator	file:
checkGradient	trainer/Trainer.cpp	/^real Trainer::checkGradient() {$/;"	f	class:paddle::Trainer
checkGradientTest	trainer/tests/test_Trainer.cpp	/^void checkGradientTest(const string& configFile,$/;"	f
checkIg	cuda/include/hl_base.h	/^  real *checkIg;$/;"	m	struct:__anon4
checkIgGrad	cuda/include/hl_base.h	/^  real *checkIgGrad;$/;"	m	struct:__anon5
checkIgGrad_	gserver/layers/LstmLayer.h	/^  MatrixPtr checkIgGrad_;$/;"	m	class:paddle::LstmLayer
checkIgGrad_	gserver/layers/LstmStepLayer.cpp	/^  MatrixPtr checkIgGrad_, checkFgGrad_, checkOgGrad_;$/;"	m	class:paddle::LstmStepLayer	file:
checkIg_	gserver/layers/LstmLayer.h	/^  MatrixPtr checkIg_;$/;"	m	class:paddle::LstmLayer
checkIg_	gserver/layers/LstmStepLayer.cpp	/^  MatrixPtr checkIg_, checkFg_, checkOg_;$/;"	m	class:paddle::LstmStepLayer	file:
checkIndex	math/SparseRowMatrix.h	/^  void checkIndex(size_t i) {$/;"	f	class:paddle::SparseRowCpuMatrix
checkIndices	math/SparseRowMatrix.cpp	/^void SparseRowCpuMatrix::checkIndices() {$/;"	f	class:paddle::SparseRowCpuMatrix
checkMatrix	gserver/tests/test_SelectiveFCLayer.cpp	/^void checkMatrix(real* A, real* B, size_t matSize) {$/;"	f
checkMatrixEqual	math/tests/test_matrixUtil.h	/^void checkMatrixEqual(const MatrixPtr& a, const MatrixPtr& b) {$/;"	f	namespace:paddle
checkMatrixEqual	testing/TestUtil.cpp	/^void checkMatrixEqual(const MatrixPtr& a, const MatrixPtr& b) {$/;"	f	namespace:paddle
checkMatrixErr	math/tests/test_matrixUtil.h	/^void checkMatrixErr(const Matrix& matrix1, const Matrix& matrix2) {$/;"	f	namespace:paddle
checkOg	cuda/include/hl_base.h	/^  real *checkOg;$/;"	m	struct:__anon4
checkOgGrad	cuda/include/hl_base.h	/^  real *checkOgGrad;$/;"	m	struct:__anon5
checkOgGrad_	gserver/layers/LstmLayer.h	/^  MatrixPtr checkOgGrad_;$/;"	m	class:paddle::LstmLayer
checkOgGrad_	gserver/layers/LstmStepLayer.cpp	/^  MatrixPtr checkIgGrad_, checkFgGrad_, checkOgGrad_;$/;"	m	class:paddle::LstmStepLayer	file:
checkOg_	gserver/layers/LstmLayer.h	/^  MatrixPtr checkOg_;$/;"	m	class:paddle::LstmLayer
checkOg_	gserver/layers/LstmStepLayer.cpp	/^  MatrixPtr checkIg_, checkFg_, checkOg_;$/;"	m	class:paddle::LstmStepLayer	file:
checkOutput	trainer/tests/test_recurrent_machine_generation.cpp	/^void checkOutput(const string& expRetFile) {$/;"	f
checkOwner_	utils/Thread.h	/^  bool checkOwner_;$/;"	m	class:paddle::SyncThreadPool
checkPassBarrier	utils/BarrierStat.h	/^  virtual bool checkPassBarrier() { return timeVector_->empty(); }$/;"	f	class:paddle::BarrierDeltaStat
checkPassBarrier	utils/BarrierStat.h	/^  virtual bool checkPassBarrier() { return timeVector_->empty(); }$/;"	f	class:paddle::BarrierEndStat
checkPassBarrier	utils/BarrierStat.h	/^  virtual bool checkPassBarrier() {$/;"	f	class:paddle::BarrierStatBase
checkRecurrentLayer	gserver/tests/test_RecurrentLayer.cpp	/^void checkRecurrentLayer(LayerConfig layerConfig,$/;"	f
checkRecurrentLayer	gserver/tests/test_RecurrentLayer.cpp	/^void checkRecurrentLayer(LayerPtr testLayer) {$/;"	f
checkRemoteParameterUpdater	trainer/tests/test_TrainerOnePass.cpp	/^double checkRemoteParameterUpdater(TrainerForTest& trainer) {$/;"	f
checkRemoteParameterUpdaterTest	trainer/tests/test_TrainerOnePass.cpp	/^void checkRemoteParameterUpdaterTest(const string& configFile,$/;"	f
checkSMatrixEqual	math/tests/test_matrixUtil.h	/^void checkSMatrixEqual(const CpuSparseMatrix& a, const CpuSparseMatrix& b) {$/;"	f	namespace:paddle
checkSMatrixEqual	math/tests/test_matrixUtil.h	/^void checkSMatrixEqual(const CpuSparseMatrixPtr& a,$/;"	f	namespace:paddle
checkSMatrixEqual2	math/tests/test_matrixUtil.h	/^void checkSMatrixEqual2(const CpuSparseMatrixPtr& a,$/;"	f	namespace:paddle
checkSMatrixEqual2Dense	math/tests/test_matrixUtil.h	/^void checkSMatrixEqual2Dense(const CpuSparseMatrix& a, const CpuMatrix& b) {$/;"	f	namespace:paddle
checkSMatrixEqual2Dense	math/tests/test_matrixUtil.h	/^void checkSMatrixEqual2Dense(const CpuSparseMatrixPtr& a,$/;"	f	namespace:paddle
checkSMatrixErr	math/tests/test_matrixUtil.h	/^void checkSMatrixErr(const CpuSparseMatrixPtr& a, const CpuSparseMatrixPtr& b) {$/;"	f	namespace:paddle
checkSample	gserver/dataproviders/ProtoDataProvider.cpp	/^void ProtoDataProvider::checkSample(const DataSample& sample) {$/;"	f	class:paddle::ProtoDataProvider
checkSample	gserver/tests/test_ProtoDataProvider.cpp	/^void checkSample(const vector<Argument>& args1,$/;"	f
checkSampleSequence	gserver/tests/test_ProtoDataProvider.cpp	/^void checkSampleSequence(const vector<Argument>& args1,$/;"	f
checkSegments	pserver/test/test_ParameterServer2.cpp	/^void ParameterServer2Tester::checkSegments(const BlockSegments& expected,$/;"	f	class:ParameterServer2Tester
checkStoreSize	math/SparseRowMatrix.h	/^  inline void checkStoreSize() {$/;"	f	class:paddle::SparseRowCpuMatrix
checkSubset	parameter/Argument.cpp	/^void Argument::checkSubset() const {$/;"	f	class:paddle::Argument
checkTranspose	gserver/tests/test_SelectiveFCLayer.cpp	/^void checkTranspose(real* matrix,$/;"	f
checkValue	trainer/tests/test_PyDataProviderWrapper.cpp	/^void checkValue(std::vector<paddle::Argument>& arguments,$/;"	f
checkVectorEqual	testing/TestUtil.cpp	/^void checkVectorEqual(const IVectorPtr& a, const IVectorPtr& b) {$/;"	f	namespace:paddle
checkgrad_eps	gserver/tests/test_BatchNorm.cpp	/^DECLARE_double(checkgrad_eps);$/;"	v
checkgrad_eps	gserver/tests/test_ConvTrans.cpp	/^DECLARE_double(checkgrad_eps);$/;"	v
checkgrad_eps	gserver/tests/test_ConvUnify.cpp	/^DECLARE_double(checkgrad_eps);$/;"	v
checkgrad_eps	gserver/tests/test_LayerGrad.cpp	/^DECLARE_double(checkgrad_eps);$/;"	v
checkgrad_eps	gserver/tests/test_NetworkCompare.cpp	/^DECLARE_double(checkgrad_eps);$/;"	v
checkgrad_eps	utils/Flags.h	/^DECLARE_double(checkgrad_eps);$/;"	v
circularConv	math/Matrix.cpp	/^void CpuMatrix::circularConv(Matrix& in0, Matrix& in1) {$/;"	f	class:paddle::CpuMatrix
circularConv	math/Matrix.h	/^  virtual void circularConv(Matrix& b, Matrix& c) {$/;"	f	class:paddle::Matrix
circularConvDerivative	math/Matrix.cpp	/^void CpuMatrix::circularConvDerivative($/;"	f	class:paddle::CpuMatrix
circularConvDerivative	math/Matrix.h	/^  virtual void circularConvDerivative(Matrix& output,$/;"	f	class:paddle::Matrix
classInstance_	gserver/dataproviders/PyDataProvider.h	/^  PyObjectPtr classInstance_;$/;"	m	class:paddle::PyDataProvider
classificationError	math/Matrix.cpp	/^void CpuMatrix::classificationError(Matrix& output, IVector& label) {$/;"	f	class:paddle::CpuMatrix
classificationError	math/Matrix.cpp	/^void GpuMatrix::classificationError(Matrix& output, IVector& label) {$/;"	f	class:paddle::GpuMatrix
classificationError	math/Matrix.h	/^  virtual void classificationError(Matrix& output, IVector& label) {$/;"	f	class:paddle::Matrix
classificationErrorMulti	math/Matrix.cpp	/^void CpuMatrix::classificationErrorMulti(Matrix& output,$/;"	f	class:paddle::CpuMatrix
classificationErrorMulti	math/Matrix.h	/^  virtual void classificationErrorMulti(Matrix& output,$/;"	f	class:paddle::Matrix
clear	gserver/dataproviders/DataProvider.h	/^  void clear() {$/;"	f	class:paddle::DataBatch
clear	math/Matrix.h	/^  virtual void clear() {$/;"	f	class:paddle::Matrix
clear	math/RowBuffer.h	/^  inline void clear() { rowStore_.clear(); }$/;"	f	class:paddle::RowBuffer
clear	utils/CustomStackTrace.h	/^  void clear() {$/;"	f	class:paddle::CustomStackTrace
clearCounter	parameter/ParallelParameter.h	/^  void clearCounter() { accumCounter_ = 0; }$/;"	f	class:paddle::AsyncParameter
clearGradient	parameter/Parameter.h	/^  void clearGradient() {$/;"	f	class:paddle::Parameter
clearGradient	trainer/Trainer.cpp	/^void Trainer::clearGradient() {$/;"	f	class:paddle::Trainer
clearIndices	math/SparseRowMatrix.h	/^  void clearIndices() { clearRows(); }$/;"	f	class:paddle::SparseRowCpuMatrix
clearOnPoolFilledHook	gserver/dataproviders/PyDataProvider2.cpp	/^void clearOnPoolFilledHook() { OnPoolFilled.reset(); }$/;"	f	namespace:paddle::unittest::pydp2
clearRows	math/SparseRowMatrix.h	/^  void clearRows() {$/;"	f	class:paddle::SparseRowCpuMatrix
clearUnusedSegments	pserver/ParameterServer2.cpp	/^void ParameterServer2::clearUnusedSegments(CpuVector* vec) {$/;"	f	class:paddle::ParameterServer2
clearUpdate	parameter/Parameter.h	/^  void clearUpdate() { updateCounter_ = 0; }$/;"	f	class:paddle::Parameter
clearValueUpdated	parameter/Parameter.h	/^  void clearValueUpdated() { updated_ = false; }$/;"	f	class:paddle::Parameter
click_	gserver/evaluators/Evaluator.h	/^  MatrixPtr click_;$/;"	m	class:paddle::RankAucEvaluator
clientConfigs_	pserver/test/test_ParameterServer2.cpp	/^  vector<ParameterConfig> clientConfigs_;$/;"	m	class:ParameterServer2Tester	file:
client_	pserver/test/test_ParameterServer2.cpp	/^  ParameterClient2 client_;$/;"	m	class:ParameterServer2Tester	file:
clients_	pserver/BaseClient.h	/^  std::vector<ProtoClient> clients_;$/;"	m	class:paddle::BaseClient
clone	gserver/dataproviders/DataProvider.cpp	/^void BufferBatch::clone(DataBatch* srcBatch, bool useGpu) {$/;"	f	class:paddle::BufferBatch
clone	math/CpuSparseMatrix.cpp	/^MatrixPtr CpuSparseMatrix::clone(size_t height, size_t width, bool useGpu) {$/;"	f	class:paddle::CpuSparseMatrix
clone	math/Matrix.cpp	/^MatrixPtr CpuMatrix::clone(size_t height, size_t width, bool useGpu) {$/;"	f	class:paddle::CpuMatrix
clone	math/Matrix.cpp	/^MatrixPtr GpuMatrix::clone(size_t height, size_t width, bool useGpu) {$/;"	f	class:paddle::GpuMatrix
clone	math/Matrix.h	/^  virtual MatrixPtr clone(size_t height = 0,$/;"	f	class:paddle::Matrix
close	pserver/RDMANetwork.h	/^inline int close(sxi_sock* sock) {$/;"	f	namespace:paddle::rdma
close	pserver/RDMANetwork.h	/^inline int close(sxi_socket* sock) {$/;"	f	namespace:paddle::rdma
cmake_bool	api/paddle_ld_flags.py	/^        def cmake_bool(cmake_str):$/;"	m	class:PaddleLDFlag
cmp_eq	cuda/include/hl_tensor_ops.h	/^  INLINE cmp_eq(const T s) : p(s) {}$/;"	f	class:hppl::unary::cmp_eq
cmp_eq	cuda/include/hl_tensor_ops.h	/^class cmp_eq {$/;"	c	namespace:hppl::binary
cmp_eq	cuda/include/hl_tensor_ops.h	/^class cmp_eq {$/;"	c	namespace:hppl::unary
cmp_ge	cuda/include/hl_tensor_ops.h	/^  INLINE cmp_ge(const T s) : p(s) {}$/;"	f	class:hppl::unary::cmp_ge
cmp_ge	cuda/include/hl_tensor_ops.h	/^class cmp_ge {$/;"	c	namespace:hppl::binary
cmp_ge	cuda/include/hl_tensor_ops.h	/^class cmp_ge {$/;"	c	namespace:hppl::unary
cmp_gt	cuda/include/hl_tensor_ops.h	/^  INLINE cmp_gt(const T s) : p(s) {}$/;"	f	class:hppl::unary::cmp_gt
cmp_gt	cuda/include/hl_tensor_ops.h	/^class cmp_gt {$/;"	c	namespace:hppl::binary
cmp_gt	cuda/include/hl_tensor_ops.h	/^class cmp_gt {$/;"	c	namespace:hppl::unary
cmp_le	cuda/include/hl_tensor_ops.h	/^  INLINE cmp_le(const T s) : p(s) {}$/;"	f	class:hppl::unary::cmp_le
cmp_le	cuda/include/hl_tensor_ops.h	/^class cmp_le {$/;"	c	namespace:hppl::binary
cmp_le	cuda/include/hl_tensor_ops.h	/^class cmp_le {$/;"	c	namespace:hppl::unary
cmp_lt	cuda/include/hl_tensor_ops.h	/^  INLINE cmp_lt(const T s) : p(s) {}$/;"	f	class:hppl::unary::cmp_lt
cmp_lt	cuda/include/hl_tensor_ops.h	/^class cmp_lt {$/;"	c	namespace:hppl::binary
cmp_lt	cuda/include/hl_tensor_ops.h	/^class cmp_lt {$/;"	c	namespace:hppl::unary
cmp_ne	cuda/include/hl_tensor_ops.h	/^  INLINE cmp_ne(const T s) : p(s) {}$/;"	f	class:hppl::unary::cmp_ne
cmp_ne	cuda/include/hl_tensor_ops.h	/^class cmp_ne {$/;"	c	namespace:hppl::binary
cmp_ne	cuda/include/hl_tensor_ops.h	/^class cmp_ne {$/;"	c	namespace:hppl::unary
cnt_	gserver/dataproviders/PyDataProvider2.cpp	/^  size_t cnt_;$/;"	m	class:paddle::IndexScanner	file:
cnt_	gserver/dataproviders/PyDataProvider2.cpp	/^  size_t cnt_;$/;"	m	class:paddle::SequenceScanner	file:
codeLength_	gserver/layers/HierarchicalSigmoidLayer.h	/^  int codeLength_;$/;"	m	class:paddle::HierarchicalSigmoidLayer
codedInput_	gserver/dataproviders/ProtoReader.h	/^  std::unique_ptr<google::protobuf::io::CodedInputStream> codedInput_;$/;"	m	class:paddle::ProtoReader
codedOutput_	gserver/dataproviders/ProtoReader.h	/^  std::unique_ptr<google::protobuf::io::CodedOutputStream> codedOutput_;$/;"	m	class:paddle::ProtoWriter
coeff_	gserver/layers/CRFLayer.h	/^  real coeff_;            \/\/ weight for the layer$/;"	m	class:paddle::CRFLayer
coeff_	gserver/layers/CostLayer.h	/^  real coeff_;$/;"	m	class:paddle::CostLayer
col	math/Matrix.h	/^  unsigned int col;$/;"	m	struct:paddle::__anon19
col	math/Matrix.h	/^typedef struct { unsigned int col; } sparse_non_value_t;$/;"	m	struct:paddle::__anon18
col	math/SparseMatrix.h	/^    int col;$/;"	m	struct:paddle::GpuSparseMatrix::Element
colIdx_	gserver/evaluators/Evaluator.cpp	/^  int32_t colIdx_;$/;"	m	class:paddle::ColumnSumEvaluator	file:
colIdx_	gserver/evaluators/Evaluator.h	/^  int32_t colIdx_;$/;"	m	class:paddle::AucEvaluator
colMax	math/Matrix.cpp	/^void CpuMatrix::colMax(IVector& maxIds, Matrix& maxVal) {$/;"	f	class:paddle::CpuMatrix
colMax	math/Matrix.cpp	/^void CpuMatrix::colMax(Matrix& max) {$/;"	f	class:paddle::CpuMatrix
colMax	math/Matrix.cpp	/^void GpuMatrix::colMax(IVector& maxIds, Matrix& maxVal) {$/;"	f	class:paddle::GpuMatrix
colMax	math/Matrix.cpp	/^void GpuMatrix::colMax(Matrix& max) {$/;"	f	class:paddle::GpuMatrix
colMax	math/Matrix.h	/^  virtual void colMax(IVector& maxIds, Matrix& maxVal) {$/;"	f	class:paddle::Matrix
colMax	math/Matrix.h	/^  virtual void colMax(Matrix& max) { LOG(FATAL) << "not implemented"; }$/;"	f	class:paddle::Matrix
colMax	math/SIMDFunctions.h	/^inline void colMax(Type* result, const Type* data, int dim, int numSamples) {$/;"	f	namespace:paddle::simd
colMax	math/SIMDFunctions.h	/^inline void colMax(Type* result, const Type* data, int dim, int numSamples) {$/;"	f	namespace:paddle::simd::naive
colMax	math/SIMDFunctions.h	/^inline void colMax(float* result, const float* data, int dim, int numSamples) {$/;"	f	namespace:paddle::simd
colMaxImpl	math/SIMDFunctions.cpp	/^void colMaxImpl(float* result, const float* data, int dim, int numSamples) {$/;"	f	namespace:paddle::simd::internal
colMerge	math/Matrix.cpp	/^void CpuMatrix::colMerge(Matrix& src) { src.rowSum(*this); }$/;"	f	class:paddle::CpuMatrix
colMerge	math/Matrix.cpp	/^void GpuMatrix::colMerge(Matrix& src) {$/;"	f	class:paddle::GpuMatrix
colMerge	math/Matrix.h	/^  virtual void colMerge(Matrix& src) { LOG(FATAL) << "Not implemented"; }$/;"	f	class:paddle::Matrix
colNum_	gserver/evaluators/Evaluator.cpp	/^  size_t colNum_;$/;"	m	class:paddle::ColumnSumEvaluator	file:
colVecAddTo	function/MulOp.cpp	/^inline void colVecAddTo($/;"	f	namespace:__anon16
colVecAddTo	math/Matrix.cpp	/^inline void colVecAddTo($/;"	f	namespace:paddle
col_	function/BufferArg.h	/^  BufferArg col_;$/;"	m	class:paddle::SparseMatrixArg
col_max_avx	math/SIMDFunctions.cpp	/^static void col_max_avx(float* result,$/;"	f	file:
col_max_sse	math/SIMDFunctions.cpp	/^static void col_max_sse(float* result,$/;"	f	file:
collectBias	math/Matrix.cpp	/^void CpuMatrix::collectBias(Matrix& a, real scale) {$/;"	f	class:paddle::CpuMatrix
collectBias	math/Matrix.cpp	/^void GpuMatrix::collectBias(Matrix& a, real scale) {$/;"	f	class:paddle::GpuMatrix
collectBias	math/Matrix.h	/^  virtual void collectBias(Matrix& a, real scale) {$/;"	f	class:paddle::Matrix
collectBias	math/Matrix.h	/^  void collectBias(Matrix& a, real scale, bool sharedBias) {$/;"	f	class:paddle::Matrix
collectSharedBias	math/Matrix.cpp	/^void CpuMatrix::collectSharedBias(Matrix& a, real scale) {$/;"	f	class:paddle::CpuMatrix
collectSharedBias	math/Matrix.cpp	/^void GpuMatrix::collectSharedBias(Matrix& a, real scale) {$/;"	f	class:paddle::GpuMatrix
collectSharedBias	math/Matrix.h	/^  virtual void collectSharedBias(Matrix& a, real scale) {$/;"	f	class:paddle::Matrix
cols	cuda/include/hl_base.h	/^  int cols;$/;"	m	struct:__anon10
cols_	math/CpuSparseMatrix.h	/^  int* cols_;$/;"	m	class:paddle::CpuSparseMatrix
cols_	math/SparseMatrix.h	/^  int* cols_;$/;"	m	class:paddle::GpuSparseMatrix
comData	trainer/tests/test_Compare.cpp	/^struct comData {$/;"	s	file:
comment	utils/Flags.h	/^DECLARE_string(comment);$/;"	v
compareGradient	gserver/tests/test_NetworkCompare.cpp	/^void compareGradient(DataOut& outA, DataOut& outB) {$/;"	f
compareGradient	trainer/tests/test_Compare.cpp	/^void compareGradient(comData& comDataCpu, comData& comDataGpu) {$/;"	f
compareGradient	trainer/tests/test_CompareTwoNets.cpp	/^void compareGradient(ComData& comDataA, ComData& comDataB) {$/;"	f
compareGradient	trainer/tests/test_CompareTwoOpts.cpp	/^void compareGradient(ComData& comDataA, ComData& comDataB) {$/;"	f
compareNetwork	gserver/tests/test_NetworkCompare.cpp	/^void compareNetwork(const std::string& config_file_a,$/;"	f
compareOutput	gserver/tests/test_SelectiveFCLayer.cpp	/^void compareOutput(ComData& fcData, ComData& selFcData) {$/;"	f
compareOutputs	function/FunctionTest.h	/^  void compareOutputs() {$/;"	f	class:paddle::FunctionCompare
compareSparseMulOutput	gserver/tests/test_SelectiveFCLayer.cpp	/^void compareSparseMulOutput($/;"	f
compareValue	trainer/tests/test_CompareSparse.cpp	/^void compareValue(const vector<ParameterPtr>& parametersA,$/;"	f
composeCallbacks	parameter/ParameterOptimizer.h	/^  static TraverseCallback composeCallbacks($/;"	f	class:paddle::ParameterOptimizer
computeConvSizes	gserver/layers/ConvOperator.cpp	/^void ConvOperator::computeConvSizes() {$/;"	f	class:paddle::ConvOperator
computeThread	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::computeThread() {$/;"	f	class:paddle::TrainerThread
computeThread	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^void ParallelThread::computeThread() {$/;"	f	class:paddle::ParallelThread
computeThread_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::unique_ptr<std::thread> computeThread_;$/;"	m	class:paddle::TrainerThread
computeThread_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  std::unique_ptr<std::thread> computeThread_;$/;"	m	class:paddle::ParallelThread
concat	parameter/Argument.cpp	/^void Argument::concat(const std::vector<Argument>& args,$/;"	f	class:paddle::Argument
cond_	utils/arch/osx/Locks.cpp	/^  pthread_cond_t cond_;$/;"	m	class:paddle::ThreadBarrierPrivate	file:
condition	math/TensorExpression.h	/^  condition(T p, const ExprType& expr) const {$/;"	f	class:paddle::TensorExpression
condition	math/TensorExpression.h	/^  condition(T p1, T p2) const {$/;"	f	class:paddle::TensorExpression
condition	math/TensorExpression.h	/^  condition(const ExprType& expr, T p) const {$/;"	f	class:paddle::TensorExpression
condition	math/TensorExpression.h	/^  condition(const ExprType1& expr1, const ExprType2& expr2) const {$/;"	f	class:paddle::TensorExpression
conf	api/PaddleAPIPrivate.h	/^  std::shared_ptr<paddle::TrainerConfigHelper> conf;$/;"	m	struct:ModelConfigPrivate
conf	api/PaddleAPIPrivate.h	/^  std::shared_ptr<paddle::TrainerConfigHelper> conf;$/;"	m	struct:TrainerConfigPrivate
conf	trainer/TrainerConfigHelper.cpp	/^  TrainerConfig conf;$/;"	m	struct:paddle::TrainerConfigHelperPrivate	file:
confPaddingY_	gserver/layers/PoolLayer.h	/^  int confPaddingY_;$/;"	m	class:paddle::PoolLayer
confPaddingY_	gserver/layers/PoolProjection.h	/^  int confPaddingY_, confPadding_;$/;"	m	class:paddle::PoolProjection
confPadding_	gserver/layers/PoolLayer.h	/^  int confPadding_;$/;"	m	class:paddle::PoolLayer
confPadding_	gserver/layers/PoolProjection.h	/^  int confPaddingY_, confPadding_;$/;"	m	class:paddle::PoolProjection
config	api/ConfigParser.cpp	/^  paddle::ParameterConfig config;$/;"	m	struct:ParameterConfigPrivate	file:
config	api/PaddleAPIPrivate.h	/^  paddle::OptimizationConfig config;$/;"	m	struct:OptimizationConfigPrivate
config	gserver/gradientmachines/RecurrentGradientMachine.h	/^    GeneratorConfig config;$/;"	m	struct:paddle::RecurrentGradientMachine::Generator
config	gserver/tests/test_SelectiveFCLayer.cpp	/^DECLARE_string(config);$/;"	v
config	pserver/ParameterServer2.h	/^    const ParameterConfig* config;$/;"	m	struct:paddle::ParameterServer2::BlockInfo
config	trainer/TesterConfig.h	/^  std::string config;$/;"	m	struct:paddle::TesterConfig
config	trainer/TrainerConfigHelper.cpp	/^DECLARE_string(config);$/;"	v
config	trainer/TrainerMain.cpp	/^DECLARE_string(config);$/;"	v
config	trainer/tests/test_Compare.cpp	/^DECLARE_string(config);$/;"	v
config	trainer/tests/test_CompareSparse.cpp	/^DECLARE_string(config);$/;"	v
config	trainer/tests/test_CompareTwoNets.cpp	/^DECLARE_string(config);$/;"	v
config	trainer/tests/test_CompareTwoOpts.cpp	/^DECLARE_string(config);$/;"	v
config	trainer/tests/test_Trainer.cpp	/^DECLARE_string(config);$/;"	v
config	trainer/tests/test_TrainerOnePass.cpp	/^DECLARE_string(config);$/;"	v
configFile	trainer/tests/test_Compare.cpp	/^static const string& configFile = "trainer\/tests\/sample_trainer_config.conf";$/;"	v	file:
configFile1	trainer/tests/test_CompareSparse.cpp	/^static const string& configFile1 =$/;"	v	file:
configFile1	trainer/tests/test_Trainer.cpp	/^static const string& configFile1 = "trainer\/tests\/sample_trainer_config.conf";$/;"	v	file:
configFile1	trainer/tests/test_TrainerOnePass.cpp	/^static const string& configFile1 = "trainer\/tests\/sample_trainer_config.conf";$/;"	v	file:
configFile2	trainer/tests/test_Trainer.cpp	/^static const string& configFile2 =$/;"	v	file:
configFile2	trainer/tests/test_TrainerOnePass.cpp	/^static const string& configFile2 =$/;"	v	file:
configFile3	trainer/tests/test_Trainer.cpp	/^static const string& configFile3 = "trainer\/tests\/chunking.conf";$/;"	v	file:
configFile4	trainer/tests/test_Trainer.cpp	/^static const string& configFile4 =$/;"	v	file:
configFileSimpleSparse	trainer/tests/test_TrainerOnePass.cpp	/^static const string& configFileSimpleSparse =$/;"	v	file:
configImgH_	gserver/layers/ConvProjection.h	/^  int configImgH_, configImgW_;$/;"	m	class:paddle::ConvProjection
configImgW_	gserver/layers/ConvProjection.h	/^  int configImgH_, configImgW_;$/;"	m	class:paddle::ConvProjection
configMap_	pserver/ParameterServer2.h	/^  std::unordered_map<size_t, ParameterConfig> configMap_;$/;"	m	class:paddle::ParameterServer2
config_	gserver/dataproviders/DataProvider.h	/^  DataConfig config_;$/;"	m	class:paddle::DataProvider
config_	gserver/evaluators/Evaluator.h	/^  EvaluatorConfig config_;$/;"	m	class:paddle::Evaluator
config_	gserver/gradientmachines/MultiGradientMachine.h	/^  ModelConfig config_;$/;"	m	class:paddle::TrainerThread
config_	gserver/gradientmachines/NeuralNetwork.h	/^  ModelConfig config_;$/;"	m	class:paddle::NeuralNetwork
config_	gserver/layers/Layer.h	/^  LayerConfig config_;$/;"	m	class:paddle::Layer
config_	gserver/layers/Operator.h	/^  OperatorConfig config_;$/;"	m	class:paddle::Operator
config_	gserver/layers/Projection.h	/^  ProjectionConfig config_;$/;"	m	class:paddle::Projection
config_	gserver/tests/test_RecurrentLayer.cpp	/^  LayerConfig config_;$/;"	m	class:TestRecurrentLayer	file:
config_	parameter/Parameter.h	/^  ParameterConfig config_;$/;"	m	class:paddle::Parameter
config_	pserver/ParameterServer2.h	/^  OptimizationConfig config_;$/;"	m	class:paddle::ParameterServer2
config_	trainer/ParamUtil.h	/^  std::shared_ptr<TrainerConfigHelper> config_;$/;"	m	class:paddle::ParameterUtil
config_	trainer/ParamUtil.h	/^  std::string config_;$/;"	m	struct:paddle::ParameterUtilConfig
config_	trainer/RemoteParameterUpdater.h	/^  OptimizationConfig config_;$/;"	m	class:paddle::RemoteParameterUpdater
config_	trainer/RemoteParameterUpdater.h	/^  OptimizationConfig config_;$/;"	m	class:paddle::SparseRemoteParameterUpdater
config_	trainer/Tester.h	/^  std::shared_ptr<TrainerConfigHelper> config_;$/;"	m	class:paddle::Tester
config_	trainer/ThreadParameterUpdater.h	/^  OptimizationConfig config_;$/;"	m	class:paddle::SgdThreadUpdater
config_	trainer/Trainer.h	/^  std::shared_ptr<TrainerConfigHelper> config_;$/;"	m	class:paddle::Trainer
config_	trainer/TrainerInternal.h	/^  std::shared_ptr<TrainerConfigHelper> config_;$/;"	m	class:paddle::TrainerInternal
config_args	gserver/tests/test_SelectiveFCLayer.cpp	/^DECLARE_string(config_args);$/;"	v
config_args	trainer/TrainerConfigHelper.cpp	/^DECLARE_string(config_args);$/;"	v
config_args	trainer/tests/test_Compare.cpp	/^DECLARE_string(config_args);$/;"	v
config_args	trainer/tests/test_CompareSparse.cpp	/^DECLARE_string(config_args);$/;"	v
config_args	trainer/tests/test_recurrent_machine_generation.cpp	/^DECLARE_string(config_args);$/;"	v
connect	gserver/gradientmachines/NeuralNetwork.cpp	/^void NeuralNetwork::connect(LayerPtr agentLayer,$/;"	f	class:paddle::NeuralNetwork
connect	gserver/gradientmachines/NeuralNetwork.cpp	/^void NeuralNetwork::connect(std::string agentLayerName,$/;"	f	class:paddle::NeuralNetwork
connect	pserver/RDMANetwork.h	/^inline sxi_sock* connect(sxi_socket* socket, const char* url) {$/;"	f	namespace:paddle::rdma
connectPrevFrame	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::connectPrevFrame(int stepId,$/;"	f	class:paddle::RecurrentGradientMachine
const_pointer	utils/Util.h	/^  typedef const T* const_pointer;$/;"	t	class:paddle::AlignedAllocator
const_reference	utils/Util.h	/^  typedef const T& const_reference;$/;"	t	class:paddle::AlignedAllocator
constant	cuda/include/hl_tensor_ops.h	/^  INLINE constant(const T s) : p(s) {}$/;"	f	class:hppl::unary::constant
constant	cuda/include/hl_tensor_ops.h	/^class constant {$/;"	c	namespace:hppl::unary
constant	math/TensorExpression.h	/^  const TensorConstant<hppl::unary::constant<T>, const Derived, T> constant($/;"	f	class:paddle::TensorExpression
constantSlots_	gserver/dataproviders/DataProvider.h	/^  ThreadLocal<std::vector<MatrixPtr>> constantSlots_;$/;"	m	class:paddle::DataProvider
construct	math/tests/TestUtils.h	/^CpuMatrix construct(int height, int width) {$/;"	f	namespace:autotest
construct	math/tests/TestUtils.h	/^GpuMatrix construct(int height, int width) {$/;"	f	namespace:autotest
construct	math/tests/TestUtils.h	/^double construct(int height, int width) {$/;"	f	namespace:autotest
construct	math/tests/TestUtils.h	/^float construct(int height, int width) {$/;"	f	namespace:autotest
construct	math/tests/TestUtils.h	/^size_t construct(int height, int width) {$/;"	f	namespace:autotest
construct	utils/Util.h	/^  void construct(const T* p, const T& t) const {$/;"	f	class:paddle::AlignedAllocator
constructors_	trainer/RemoteParameterUpdater.cpp	/^    ParameterUpdaterCreators::constructors_;$/;"	m	class:paddle::ParameterUpdaterCreators	file:
constructors_	trainer/RemoteParameterUpdater.h	/^      constructors_;$/;"	m	class:paddle::ParameterUpdaterCreators
contains	trainer/tests/picojson.h	/^inline bool value::contains(const std::string& key) const {$/;"	f	class:picojson::value
contains	trainer/tests/picojson.h	/^inline bool value::contains(size_t idx) const {$/;"	f	class:picojson::value
contains	utils/Util.h	/^static bool contains(const Container& container, const T& val) {$/;"	f	namespace:paddle
context	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^context = mixed_layer($/;"	v
context	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^context = mixed_layer($/;"	v
context_length_	function/ContextProjectionOp.cpp	/^  size_t context_length_;$/;"	m	class:paddle::ContextProjectionBackwardDataFunc	file:
context_length_	function/ContextProjectionOp.cpp	/^  size_t context_length_;$/;"	m	class:paddle::ContextProjectionBackwardFunc	file:
context_length_	function/ContextProjectionOp.cpp	/^  size_t context_length_;$/;"	m	class:paddle::ContextProjectionBackwardWeightFunc	file:
context_length_	function/ContextProjectionOp.cpp	/^  size_t context_length_;$/;"	m	class:paddle::ContextProjectionForwardFunc	file:
context_start_	function/ContextProjectionOp.cpp	/^  int context_start_;$/;"	m	class:paddle::ContextProjectionBackwardDataFunc	file:
context_start_	function/ContextProjectionOp.cpp	/^  int context_start_;$/;"	m	class:paddle::ContextProjectionBackwardFunc	file:
context_start_	function/ContextProjectionOp.cpp	/^  int context_start_;$/;"	m	class:paddle::ContextProjectionBackwardWeightFunc	file:
context_start_	function/ContextProjectionOp.cpp	/^  int context_start_;$/;"	m	class:paddle::ContextProjectionForwardFunc	file:
controlParam_	parameter/ParallelParameter.h	/^  ParallelParameterPtr controlParam_;$/;"	m	class:paddle::SyncParameter
controlUpdate	parameter/ParallelParameter.cpp	/^void SyncParameter::controlUpdate(const UpdateCallback &callBack) {$/;"	f	class:paddle::SyncParameter
controlUpdate	parameter/ParallelParameter.h	/^  virtual void controlUpdate(const UpdateCallback& callback) { (void)callback; }$/;"	f	class:paddle::ParallelParameter
controller	trainer/RemoteParameterUpdater.cpp	/^void RemoteParameterUpdater::controller() {$/;"	f	class:paddle::RemoteParameterUpdater
controller	trainer/RemoteParameterUpdater.cpp	/^void SparseRemoteParameterUpdater::controller() {$/;"	f	class:paddle::SparseRemoteParameterUpdater
controllerThread_	trainer/RemoteParameterUpdater.h	/^  std::unique_ptr<std::thread> controllerThread_;$/;"	m	class:paddle::RemoteParameterUpdater
controllerThread_	trainer/RemoteParameterUpdater.h	/^  std::unique_ptr<std::thread> controllerThread_;$/;"	m	class:paddle::SparseRemoteParameterUpdater
convDesc_	gserver/layers/ConvOperator.cpp	/^  hl_convolution_descriptor convDesc_;$/;"	m	class:paddle::ConvOperator	file:
convDesc_	gserver/layers/ConvProjection.h	/^  hl_convolution_descriptor convDesc_;$/;"	m	class:paddle::ConvProjection
convExpand	math/Matrix.cpp	/^void CpuMatrix::convExpand(Matrix& feature,$/;"	f	class:paddle::CpuMatrix
convExpand	math/Matrix.cpp	/^void GpuMatrix::convExpand(Matrix& feature,$/;"	f	class:paddle::GpuMatrix
convExpand	math/Matrix.h	/^  virtual void convExpand(Matrix& feature,$/;"	f	class:paddle::Matrix
convMem_	gserver/layers/ConvProjection.cpp	/^ThreadLocalD<std::vector<MemoryHandle *>> ConvProjection::convMem_;$/;"	m	class:paddle::ConvProjection	file:
convMem_	gserver/layers/ConvProjection.h	/^  static ThreadLocalD<std::vector<MemoryHandle*>> convMem_;$/;"	m	class:paddle::ConvProjection
convShrink	math/Matrix.cpp	/^void CpuMatrix::convShrink(Matrix& expandFeat,$/;"	f	class:paddle::CpuMatrix
convShrink	math/Matrix.cpp	/^void GpuMatrix::convShrink(Matrix& expandFeat,$/;"	f	class:paddle::GpuMatrix
convShrink	math/Matrix.h	/^  virtual void convShrink(Matrix& expandColMat,$/;"	f	class:paddle::Matrix
convert	py_paddle/dataprovider_converter.py	/^    def convert(self, dat, argument=None):$/;"	m	class:DataProviderConverter
convert	py_paddle/util.py	/^    def convert(self, wrapper_data, argument=None):$/;"	m	class:DataProviderWrapperConverter
copiedArg	math/ExecViaCpu.h	/^  Arg& copiedArg() const { return arg_; }$/;"	f	class:paddle::CopyToCpu
copiedArg	math/ExecViaCpu.h	/^  IVector& copiedArg() const { return copied_ ? *copied_ : arg_; }$/;"	f	class:paddle::CopyToCpu
copiedArg	math/ExecViaCpu.h	/^  Matrix& copiedArg() const { return copied_ ? *copied_ : arg_; }$/;"	f	class:paddle::CopyToCpu
copiedArg	math/ExecViaCpu.h	/^  const IVector& copiedArg() const { return copied_ ? *copied_ : arg_; }$/;"	f	class:paddle::CopyToCpu
copiedArg	math/ExecViaCpu.h	/^  const Matrix& copiedArg() const { return copied_ ? *copied_ : arg_; }$/;"	f	class:paddle::CopyToCpu
copiedArg	math/tests/TensorCheck.h	/^  CpuMatrix& copiedArg() { return arg_; }$/;"	f	class:autotest::CopyToCpu
copiedArg	math/tests/TensorCheck.h	/^  CpuVectorT<T>& copiedArg() { return arg_; }$/;"	f	class:autotest::CopyToCpu
copiedArg	math/tests/TensorCheck.h	/^  const CpuMatrix& copiedArg() const { return arg_; }$/;"	f	class:autotest::CopyToCpu
copiedArg	math/tests/TensorCheck.h	/^  const CpuVectorT<T>& copiedArg() const { return arg_; }$/;"	f	class:autotest::CopyToCpu
copied_	math/ExecViaCpu.h	/^  IVectorPtr copied_;$/;"	m	class:paddle::CopyToCpu
copied_	math/ExecViaCpu.h	/^  MatrixPtr copied_;$/;"	m	class:paddle::CopyToCpu
copy	gserver/layers/SequenceToBatch.cpp	/^void SequenceToBatch::copy(Matrix &seqValue,$/;"	f	class:paddle::SequenceToBatch
copy	trainer/tests/picojson.h	/^void copy(const std::string& s, Iter oi) {$/;"	f	namespace:picojson
copyBackSeq	gserver/layers/SequenceToBatch.cpp	/^void SequenceToBatch::copyBackSeq(Matrix &seqValue) {$/;"	f	class:paddle::SequenceToBatch
copyByRowIndex	math/Matrix.cpp	/^void CpuMatrix::copyByRowIndex(Matrix& b, const IVector& rowIndex) {$/;"	f	class:paddle::CpuMatrix
copyByRowIndex	math/Matrix.cpp	/^void GpuMatrix::copyByRowIndex(Matrix& b, const IVector& rowIndex) {$/;"	f	class:paddle::GpuMatrix
copyByRowIndex	math/Matrix.h	/^  virtual void copyByRowIndex(Matrix& b, const IVector& rowIndex) {$/;"	f	class:paddle::Matrix
copyDataOutlinkFrame	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::copyDataOutlinkFrame(size_t machineCur) {$/;"	f	class:paddle::RecurrentGradientMachine
copyDataToOutput	gserver/layers/DataLayer.cpp	/^void DataLayer::copyDataToOutput(Argument& output) {$/;"	f	class:paddle::DataLayer
copyEvents_	trainer/ParameterUpdater.h	/^  std::vector<hl_event_t> copyEvents_;$/;"	m	class:paddle::SgdUpdaterWithCpuAverager
copyFileToPath	utils/Util.cpp	/^void copyFileToPath(const std::string& file, const std::string& dir) {$/;"	f	namespace:paddle
copyFrom	api/Vector.cpp	/^void Vector::copyFrom(Vector* src) throw(RangeError) {$/;"	f	class:Vector
copyFrom	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::copyFrom(const CpuMatrix& src) {$/;"	f	class:paddle::CpuSparseMatrix
copyFrom	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::copyFrom(const CpuSparseMatrix& src) {$/;"	f	class:paddle::CpuSparseMatrix
copyFrom	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::copyFrom(const GpuSparseMatrix& src, hl_stream_t stream) {$/;"	f	class:paddle::CpuSparseMatrix
copyFrom	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::copyFrom(const Matrix& src) {$/;"	f	class:paddle::CpuSparseMatrix
copyFrom	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::copyFrom(const Matrix& src, hl_stream_t stream) {$/;"	f	class:paddle::CpuSparseMatrix
copyFrom	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::copyFrom(int64_t* ids, int64_t* indices, T* data) {$/;"	f	class:paddle::CpuSparseMatrix
copyFrom	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::copyFrom(int64_t* indices, T* data) {$/;"	f	class:paddle::CpuSparseMatrix
copyFrom	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::copyFrom(std::vector<int>& rows,$/;"	f	class:paddle::CpuSparseMatrix
copyFrom	math/CpuSparseMatrix.h	/^  void copyFrom(const real* data, size_t len) {$/;"	f	class:paddle::CpuSparseMatrix
copyFrom	math/Matrix.cpp	/^void CpuMatrix::copyFrom(CpuSparseMatrix& src) {$/;"	f	class:paddle::CpuMatrix
copyFrom	math/Matrix.cpp	/^void CpuMatrix::copyFrom(const IVector& src) {$/;"	f	class:paddle::CpuMatrix
copyFrom	math/Matrix.cpp	/^void CpuMatrix::copyFrom(const Matrix& src) {$/;"	f	class:paddle::CpuMatrix
copyFrom	math/Matrix.cpp	/^void CpuMatrix::copyFrom(const Matrix& src, hl_stream_t stream) {$/;"	f	class:paddle::CpuMatrix
copyFrom	math/Matrix.cpp	/^void CpuMatrix::copyFrom(const real* cpuSrc, const int64_t* seq) {$/;"	f	class:paddle::CpuMatrix
copyFrom	math/Matrix.cpp	/^void CpuMatrix::copyFrom(const real* cpuSrc, size_t size) {$/;"	f	class:paddle::CpuMatrix
copyFrom	math/Matrix.cpp	/^void GpuMatrix::copyFrom(const IVector& src) {$/;"	f	class:paddle::GpuMatrix
copyFrom	math/Matrix.cpp	/^void GpuMatrix::copyFrom(const Matrix& src) {$/;"	f	class:paddle::GpuMatrix
copyFrom	math/Matrix.cpp	/^void GpuMatrix::copyFrom(const Matrix& src, hl_stream_t stream) {$/;"	f	class:paddle::GpuMatrix
copyFrom	math/Matrix.cpp	/^void GpuMatrix::copyFrom(const real* hostSrc, const int64_t* seq) {$/;"	f	class:paddle::GpuMatrix
copyFrom	math/Matrix.cpp	/^void GpuMatrix::copyFrom(const real* hostSrc, size_t size) {$/;"	f	class:paddle::GpuMatrix
copyFrom	math/Matrix.h	/^  virtual void copyFrom(const IVector& src) {$/;"	f	class:paddle::Matrix
copyFrom	math/Matrix.h	/^  virtual void copyFrom(const Matrix& src) { LOG(FATAL) << "Not implemented"; }$/;"	f	class:paddle::Matrix
copyFrom	math/Matrix.h	/^  virtual void copyFrom(const Matrix& src, hl_stream_t stream) {$/;"	f	class:paddle::Matrix
copyFrom	math/Matrix.h	/^  virtual void copyFrom(const real* src, const int64_t* seq) {$/;"	f	class:paddle::Matrix
copyFrom	math/Matrix.h	/^  virtual void copyFrom(const real* src, size_t size) {$/;"	f	class:paddle::Matrix
copyFrom	math/SparseMatrix.cpp	/^void GpuSparseMatrix::copyFrom(CpuSparseMatrix& src, hl_stream_t stream) {$/;"	f	class:paddle::GpuSparseMatrix
copyFrom	math/SparseMatrix.cpp	/^void GpuSparseMatrix::copyFrom(GpuSparseMatrix& src, hl_stream_t stream) {$/;"	f	class:paddle::GpuSparseMatrix
copyFrom	math/SparseMatrix.cpp	/^void GpuSparseMatrix::copyFrom(const Matrix& src) {$/;"	f	class:paddle::GpuSparseMatrix
copyFrom	math/SparseMatrix.cpp	/^void GpuSparseMatrix::copyFrom(const Matrix& src, hl_stream_t stream) {$/;"	f	class:paddle::GpuSparseMatrix
copyFrom	math/SparseMatrix.cpp	/^void GpuSparseMatrix::copyFrom(int64_t* ids,$/;"	f	class:paddle::GpuSparseMatrix
copyFrom	math/SparseMatrix.h	/^  void copyFrom(const IVector& src) { LOG(FATAL) << "not implemented"; }$/;"	f	class:paddle::GpuSparseMatrix
copyFrom	math/SparseMatrix.h	/^  void copyFrom(const IVector& src, hl_stream_t stream) {$/;"	f	class:paddle::GpuSparseMatrix
copyFrom	math/SparseRowMatrix.cpp	/^void SparseRowCpuMatrix::copyFrom(const real* src, size_t size) {$/;"	f	class:paddle::SparseRowCpuMatrix
copyFrom	math/Vector.cpp	/^void CpuGpuVectorT<T>::copyFrom(CpuGpuVectorT<T>& src, hl_stream_t stream) {$/;"	f	class:paddle::CpuGpuVectorT
copyFrom	math/Vector.cpp	/^void CpuGpuVectorT<T>::copyFrom(CpuGpuVectorT<T>& src,$/;"	f	class:paddle::CpuGpuVectorT
copyFrom	math/Vector.cpp	/^void CpuGpuVectorT<T>::copyFrom(const T* data, size_t size, bool useGpu) {$/;"	f	class:paddle::CpuGpuVectorT
copyFrom	math/Vector.cpp	/^void CpuGpuVectorT<T>::copyFrom(const T* data,$/;"	f	class:paddle::CpuGpuVectorT
copyFrom	math/Vector.cpp	/^void CpuGpuVectorT<T>::copyFrom(const VectorT<T>& src, hl_stream_t stream) {$/;"	f	class:paddle::CpuGpuVectorT
copyFrom	math/Vector.cpp	/^void CpuVectorT<T>::copyFrom(const T* hostSrc, size_t size) {$/;"	f	class:paddle::CpuVectorT
copyFrom	math/Vector.cpp	/^void CpuVectorT<T>::copyFrom(const T* hostSrc,$/;"	f	class:paddle::CpuVectorT
copyFrom	math/Vector.cpp	/^void CpuVectorT<T>::copyFrom(const VectorT<T>& src) {$/;"	f	class:paddle::CpuVectorT
copyFrom	math/Vector.cpp	/^void CpuVectorT<T>::copyFrom(const VectorT<T>& src, hl_stream_t stream) {$/;"	f	class:paddle::CpuVectorT
copyFrom	math/Vector.cpp	/^void GpuVectorT<T>::copyFrom(const T* gpuSrc, size_t size) {$/;"	f	class:paddle::GpuVectorT
copyFrom	math/Vector.cpp	/^void GpuVectorT<T>::copyFrom(const T* gpuSrc, size_t size, hl_stream_t stream) {$/;"	f	class:paddle::GpuVectorT
copyFrom	math/Vector.cpp	/^void GpuVectorT<T>::copyFrom(const VectorT<T>& src) {$/;"	f	class:paddle::GpuVectorT
copyFrom	math/Vector.cpp	/^void GpuVectorT<T>::copyFrom(const VectorT<T>& src, hl_stream_t stream) {$/;"	f	class:paddle::GpuVectorT
copyFromCSC	math/SparseMatrix.cpp	/^void GpuSparseMatrix::copyFromCSC(CpuSparseMatrix& src, hl_stream_t stream) {$/;"	f	class:paddle::GpuSparseMatrix
copyFromCSR	math/SparseMatrix.cpp	/^void GpuSparseMatrix::copyFromCSR(CpuSparseMatrix& src, hl_stream_t stream) {$/;"	f	class:paddle::GpuSparseMatrix
copyFromNumpyArray	api/Vector.cpp	/^void IVector::copyFromNumpyArray(int* data, int dim) {$/;"	f	class:IVector
copyFromNumpyArray	api/Vector.cpp	/^void Vector::copyFromNumpyArray(float* data, int dim) {$/;"	f	class:Vector
copyFromNumpyMat	api/Matrix.cpp	/^void Matrix::copyFromNumpyMat(float* data,$/;"	f	class:Matrix
copyFromSeq	gserver/layers/SequenceToBatch.cpp	/^void SequenceToBatch::copyFromSeq(Matrix &seqValue) {$/;"	f	class:paddle::SequenceToBatch
copyGradToBufferThread	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::copyGradToBufferThread() {$/;"	f	class:paddle::TrainerThread
copyIdAndSequenceInfo	gserver/layers/AgentLayer.cpp	/^void GatherAgentLayer::copyIdAndSequenceInfo(const Argument& input,$/;"	f	class:paddle::GatherAgentLayer
copyIdx	gserver/layers/MultiplexLayer.cpp	/^    int copyIdx;$/;"	m	struct:paddle::MultiplexLayer::CopyInfo	file:
copyInArgs	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::copyInArgs() {$/;"	f	class:paddle::TrainerThread
copyOutputGrad	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::copyOutputGrad() {$/;"	f	class:paddle::TrainerThread
copyOutputToOtherDevice	gserver/layers/Layer.cpp	/^void Layer::copyOutputToOtherDevice() {$/;"	f	class:paddle::Layer
copyParametersFromDevice	trainer/RemoteParameterUpdater.cpp	/^void RemoteParameterUpdater::copyParametersFromDevice($/;"	f	class:paddle::RemoteParameterUpdater
copyParametersToDevice	trainer/RemoteParameterUpdater.cpp	/^void RemoteParameterUpdater::copyParametersToDevice($/;"	f	class:paddle::RemoteParameterUpdater
copyRow	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::copyRow(int offsets,$/;"	f	class:paddle::CpuSparseMatrix
copyRow	math/SparseMatrix.cpp	/^void GpuSparseMatrix::copyRow(int offsets,$/;"	f	class:paddle::GpuSparseMatrix
copyScattedId	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::copyScattedId(std::vector<int>& srcIds,$/;"	f	class:paddle::RecurrentGradientMachine
copySchedule_	gserver/layers/MultiplexLayer.cpp	/^  std::vector<CopyInfo> copySchedule_;$/;"	m	class:paddle::MultiplexLayer	file:
copySingleParaFromDevice	trainer/RemoteParameterUpdater.cpp	/^void ConcurrentRemoteParameterUpdater::copySingleParaFromDevice($/;"	f	class:paddle::ConcurrentRemoteParameterUpdater
copySingleParaToDevice	trainer/RemoteParameterUpdater.cpp	/^void ConcurrentRemoteParameterUpdater::copySingleParaToDevice($/;"	f	class:paddle::ConcurrentRemoteParameterUpdater
copyThread_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::unique_ptr<std::thread> copyThread_;$/;"	m	class:paddle::TrainerThread
copyTo	math/Vector.cpp	/^void CpuVectorT<T>::copyTo(CpuVectorT<T>* dest) const {$/;"	f	class:paddle::CpuVectorT
copyTo	math/Vector.cpp	/^void CpuVectorT<T>::copyTo(GpuVectorT<T>* dest) const {$/;"	f	class:paddle::CpuVectorT
copyTo	math/Vector.cpp	/^void GpuVectorT<T>::copyTo(CpuVectorT<T>* dest) const {$/;"	f	class:paddle::GpuVectorT
copyTo	math/Vector.cpp	/^void GpuVectorT<T>::copyTo(GpuVectorT<T>* dest) const {$/;"	f	class:paddle::GpuVectorT
copyToCpu	math/Vector.cpp	/^void CpuGpuVectorT<T>::copyToCpu() {$/;"	f	class:paddle::CpuGpuVectorT
copyToCpu	math/Vector.h	/^  inline void copyToCpu(const T* data, size_t size) {$/;"	f	class:paddle::CpuGpuVectorT
copyToCpu	math/Vector.h	/^  inline void copyToCpu(const T* data, size_t size, hl_stream_t stream) {$/;"	f	class:paddle::CpuGpuVectorT
copyToGpu	math/Vector.cpp	/^void CpuGpuVectorT<T>::copyToGpu() {$/;"	f	class:paddle::CpuGpuVectorT
copyToGpu	math/Vector.h	/^  inline void copyToGpu(const T* data, size_t size) {$/;"	f	class:paddle::CpuGpuVectorT
copyToGpu	math/Vector.h	/^  inline void copyToGpu(const T* data, size_t size, hl_stream_t stream) {$/;"	f	class:paddle::CpuGpuVectorT
copyToNumpyArray	api/Vector.cpp	/^void IVector::copyToNumpyArray(int** view_m_data, int* dim1) {$/;"	f	class:IVector
copyToNumpyArray	api/Vector.cpp	/^void Vector::copyToNumpyArray(float** view_m_data, int* dim1) {$/;"	f	class:Vector
copyToNumpyMat	api/Matrix.cpp	/^void Matrix::copyToNumpyMat(float** view_m_data,$/;"	f	class:Matrix
copyToRepeatedField	pserver/ParameterClient2.cpp	/^void copyToRepeatedField(google::protobuf::RepeatedField<T1>* dest,$/;"	f	namespace:paddle
cos	cuda/src/hl_math.cc	/^__m256 cos(__m256 a) { return cos256_ps(a); }$/;"	f	namespace:hppl
cos256_ps	cuda/src/avx_mathfun.h	/^v8sf cos256_ps(v8sf x) {  \/\/ any x$/;"	f
cost	trainer/Tester.h	/^    real cost;$/;"	m	struct:paddle::Tester::__anon13
cost_	pserver/ParameterServer2.h	/^  double cost_;$/;"	m	class:paddle::ParameterServer2
countIncrement	parameter/Argument.h	/^  void countIncrement() { allCount++; }$/;"	f	struct:paddle::Argument
count_	utils/Stat.h	/^  uint64_t count_;$/;"	m	class:paddle::StatInfo
count_	utils/arch/osx/Locks.cpp	/^  int count_;$/;"	m	class:paddle::ThreadBarrierPrivate	file:
cpuAllocator_	math/Storage.h	/^  PoolAllocator* cpuAllocator_;$/;"	m	class:paddle::StorageEngine
cpuBatch_	gserver/dataproviders/ProtoDataProvider.h	/^  ThreadLocalD<DataBatch> cpuBatch_;$/;"	m	class:paddle::ProtoDataProvider
cpuBatch_	gserver/dataproviders/PyDataProvider.h	/^  ThreadLocalD<DataBatch> cpuBatch_;$/;"	m	class:paddle::PyDataProvider
cpuCosts_	gserver/layers/WarpCTCLayer.h	/^  MatrixPtr cpuCosts_;$/;"	m	class:paddle::WarpCTCLayer
cpuEos_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  IVectorPtr cpuEos_;$/;"	m	class:paddle::RecurrentGradientMachine
cpuFunc_	function/FunctionTest.h	/^  std::shared_ptr<FunctionBase> cpuFunc_;$/;"	m	class:paddle::FunctionCompare
cpuId_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  IVectorPtr cpuId_;$/;"	m	class:paddle::RecurrentGradientMachine
cpuIds_	gserver/evaluators/Evaluator.cpp	/^  std::vector<IVectorPtr> cpuIds_;$/;"	m	class:paddle::SequenceTextPrinter	file:
cpuIds_	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^  IVectorPtr cpuIds_;$/;"	m	class:paddle::BootBiasLayer	file:
cpuIds_	gserver/layers/AgentLayer.h	/^  IVectorPtr cpuIds_;$/;"	m	class:paddle::ScatterAgentLayer
cpuIn_	gserver/evaluators/Evaluator.cpp	/^  std::vector<MatrixPtr> cpuIn_;$/;"	m	class:paddle::SequenceTextPrinter	file:
cpuInfo_	gserver/evaluators/Evaluator.h	/^  IVectorPtr cpuInfo_;$/;"	m	class:paddle::PnpairEvaluator
cpuInputs_	function/FunctionTest.h	/^  std::vector<BufferArgPtr> cpuInputs_;$/;"	m	class:paddle::FunctionCompare
cpuLabel_	gserver/evaluators/Evaluator.cpp	/^  IVectorPtr cpuLabel_;$/;"	m	class:paddle::SumEvaluator	file:
cpuLabel_	gserver/evaluators/Evaluator.h	/^  IVectorPtr cpuLabel_;$/;"	m	class:paddle::AucEvaluator
cpuLabel_	gserver/evaluators/Evaluator.h	/^  IVectorPtr cpuLabel_;$/;"	m	class:paddle::PnpairEvaluator
cpuLabel_	gserver/evaluators/Evaluator.h	/^  IVectorPtr cpuLabel_;$/;"	m	class:paddle::PrecisionRecallEvaluator
cpuLabel_	gserver/layers/ValidationLayer.h	/^  IVectorPtr cpuLabel_;$/;"	m	class:paddle::AucValidation
cpuLabels_	gserver/layers/WarpCTCLayer.h	/^  IVectorPtr cpuLabels_;$/;"	m	class:paddle::WarpCTCLayer
cpuLocalMats_	math/CpuSparseMatrix.cpp	/^ThreadLocal<std::vector<CpuSparseMatrixPtr>> CpuSparseMatrix::cpuLocalMats_;$/;"	m	class:paddle::CpuSparseMatrix	file:
cpuLocalMats_	math/CpuSparseMatrix.h	/^  static ThreadLocal<std::vector<CpuSparseMatrixPtr>> cpuLocalMats_;$/;"	m	class:paddle::CpuSparseMatrix
cpuMat_	trainer/Tester.h	/^  std::vector<MatrixPtr> cpuMat_;$/;"	m	class:paddle::Tester
cpuMemory_	function/FunctionTest.h	/^  std::vector<CpuMemHandlePtr> cpuMemory_;$/;"	m	class:paddle::FunctionCompare
cpuOutput_	gserver/evaluators/Evaluator.h	/^  MatrixPtr cpuOutput_;$/;"	m	class:paddle::AucEvaluator
cpuOutput_	gserver/evaluators/Evaluator.h	/^  MatrixPtr cpuOutput_;$/;"	m	class:paddle::PnpairEvaluator
cpuOutput_	gserver/evaluators/Evaluator.h	/^  MatrixPtr cpuOutput_;$/;"	m	class:paddle::PrecisionRecallEvaluator
cpuOutput_	gserver/layers/ValidationLayer.h	/^  MatrixPtr cpuOutput_;$/;"	m	class:paddle::AucValidation
cpuOutputs_	function/FunctionTest.h	/^  std::vector<BufferArgPtr> cpuOutputs_;$/;"	m	class:paddle::FunctionCompare
cpuParameters_	trainer/ParameterUpdater.h	/^  std::vector<ParameterPtr> cpuParameters_;$/;"	m	class:paddle::SgdUpdaterWithCpuAverager
cpuParameters_	trainer/RemoteParameterUpdater.h	/^  std::vector<ParameterPtr> cpuParameters_;$/;"	m	class:paddle::RemoteParameterUpdater
cpuProb_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  MatrixPtr cpuProb_;$/;"	m	class:paddle::RecurrentGradientMachine
cpuSelCols_	gserver/layers/SelectiveFullyConnectedLayer.h	/^  MatrixPtr cpuSelCols_;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
cpuSeq2BatchIdx_	gserver/layers/SequenceToBatch.h	/^  IVectorPtr cpuSeq2BatchIdx_;$/;"	m	class:paddle::SequenceToBatch
cpuSeqEndIdxInBatch_	gserver/layers/SequenceToBatch.h	/^  IVectorPtr cpuSeqEndIdxInBatch_;$/;"	m	class:paddle::SequenceToBatch
cpuSeqIdx_	gserver/layers/SequenceToBatch.h	/^  IVectorPtr cpuSeqIdx_;$/;"	m	class:paddle::SequenceToBatch
cpuSeq_	function/FunctionTest.h	/^  std::shared_ptr<SequenceIdArg> cpuSeq_;$/;"	m	class:paddle::FunctionCompare
cpuSequenceDims	parameter/Argument.h	/^  IVectorPtr cpuSequenceDims;$/;"	m	struct:paddle::Argument
cpuSparse_	function/FunctionTest.h	/^  std::shared_ptr<CpuSparseMatrix> cpuSparse_;$/;"	m	class:paddle::FunctionCompare
cpuVec_	trainer/Tester.h	/^  std::vector<IVectorPtr> cpuVec_;$/;"	m	class:paddle::Tester
cpuVectorT_	math/Vector.h	/^  std::shared_ptr<VectorT<T>> cpuVectorT_;$/;"	m	class:paddle::CpuGpuVectorT
cpuWeight_	gserver/evaluators/Evaluator.cpp	/^  MatrixPtr cpuWeight_;$/;"	m	class:paddle::SumEvaluator	file:
cpuWeight_	gserver/evaluators/Evaluator.h	/^  MatrixPtr cpuWeight_;$/;"	m	class:paddle::AucEvaluator
cpuWeight_	gserver/evaluators/Evaluator.h	/^  MatrixPtr cpuWeight_;$/;"	m	class:paddle::PnpairEvaluator
cpuWeight_	gserver/evaluators/Evaluator.h	/^  MatrixPtr cpuWeight_;$/;"	m	class:paddle::PrecisionRecallEvaluator
cpuWeight_	gserver/layers/ValidationLayer.h	/^  MatrixPtr cpuWeight_;$/;"	m	class:paddle::AucValidation
creatDataLayer	gserver/tests/test_RecurrentLayer.cpp	/^LayerPtr creatDataLayer(string name,$/;"	f
creatDataLayer	gserver/tests/test_SelectiveFCLayer.cpp	/^LayerPtr creatDataLayer(string name,$/;"	f
creatParameter	gserver/tests/test_RecurrentLayer.cpp	/^ParameterPtr creatParameter(string name,$/;"	f
creatParameter	gserver/tests/test_SelectiveFCLayer.cpp	/^ParameterPtr creatParameter($/;"	f
creatParameterBias	gserver/tests/test_RecurrentLayer.cpp	/^ParameterPtr creatParameterBias(string name,$/;"	f
create	api/ParameterOptimizer.cpp	/^ParameterOptimizer* ParameterOptimizer::create(OptimizationConfig* config) {$/;"	f	class:ParameterOptimizer
create	api/Trainer.cpp	/^Trainer* Trainer::create(TrainerConfig* config,$/;"	f	class:Trainer
create	api/Vector.cpp	/^IVector* IVector::create(const std::vector<int>& data, bool useGpu) {$/;"	f	class:IVector
create	api/Vector.cpp	/^Vector* Vector::create(const std::vector<float>& data, bool useGpu) {$/;"	f	class:Vector
create	gserver/activations/ActivationFunction.cpp	/^ActivationFunction* ActivationFunction::create(const std::string& type) {$/;"	f	class:paddle::ActivationFunction
create	gserver/dataproviders/DataProvider.cpp	/^DataProvider* DataProvider::create(const DataConfig& config,$/;"	f	class:paddle::DataProvider
create	gserver/dataproviders/DataProvider.h	/^  inline static DataProvider* create(const DataConfig& config,$/;"	f	class:paddle::DataProvider
create	gserver/dataproviders/PyDataProvider2.cpp	/^IFieldScanner* IFieldScanner::create(SlotHeader* header) {$/;"	f	class:paddle::IFieldScanner
create	gserver/dataproviders/PyDataProvider2.cpp	/^IPyDataProviderCache* IPyDataProviderCache::create(CacheType ct) {$/;"	f	class:paddle::IPyDataProviderCache
create	gserver/evaluators/Evaluator.cpp	/^Evaluator* Evaluator::create(const EvaluatorConfig& config) {$/;"	f	class:paddle::Evaluator
create	gserver/gradientmachines/GradientMachine.cpp	/^GradientMachine* GradientMachine::create($/;"	f	class:paddle::GradientMachine
create	gserver/gradientmachines/NeuralNetwork.cpp	/^NeuralNetwork* NeuralNetwork::create(const ModelConfig& config) {$/;"	f	class:paddle::NeuralNetwork
create	gserver/layers/Layer.cpp	/^LayerPtr Layer::create(const LayerConfig& config) {$/;"	f	class:paddle::Layer
create	gserver/layers/MultinomialSampler.h	/^  static MultinomialSampler* create(const double* prob, int size) {$/;"	f	class:paddle::MultinomialSampler
create	gserver/layers/NormLayer.cpp	/^Layer* NormLayer::create(const LayerConfig& config) {$/;"	f	class:paddle::NormLayer
create	gserver/layers/Operator.cpp	/^Operator* Operator::create(const OperatorConfig& config, bool useGpu) {$/;"	f	class:paddle::Operator
create	gserver/layers/PoolLayer.cpp	/^Layer* PoolLayer::create(const LayerConfig& config) {$/;"	f	class:paddle::PoolLayer
create	gserver/layers/PoolProjection.cpp	/^PoolProjection* PoolProjection::create(const ProjectionConfig& config,$/;"	f	class:paddle::PoolProjection
create	gserver/layers/Projection.cpp	/^Projection* Projection::create(const ProjectionConfig& config,$/;"	f	class:paddle::Projection
create	math/Matrix.cpp	/^MatrixPtr Matrix::create($/;"	f	class:paddle::Matrix
create	math/Matrix.cpp	/^MatrixPtr Matrix::create(MemoryHandlePtr memHandle,$/;"	f	class:paddle::Matrix
create	math/Matrix.cpp	/^MatrixPtr Matrix::create(real* data,$/;"	f	class:paddle::Matrix
create	math/Matrix.cpp	/^MatrixPtr Matrix::create(size_t height, size_t width, bool trans, bool useGpu) {$/;"	f	class:paddle::Matrix
create	math/Vector.cpp	/^std::shared_ptr<CpuGpuVectorT<T>> CpuGpuVectorT<T>::create(size_t size,$/;"	f	class:paddle::CpuGpuVectorT
create	math/Vector.cpp	/^std::shared_ptr<VectorT<T>> VectorT<T>::create(T* data,$/;"	f	class:paddle::VectorT
create	math/Vector.cpp	/^std::shared_ptr<VectorT<T>> VectorT<T>::create(size_t size, bool useGpu) {$/;"	f	class:paddle::VectorT
create	math/Vector.cpp	/^std::shared_ptr<VectorT<T>> VectorT<T>::create(size_t size,$/;"	f	class:paddle::VectorT
create	parameter/AverageOptimizer.cpp	/^ParameterOptimizer* AverageOptimizer::create($/;"	f	class:paddle::AverageOptimizer
create	parameter/LearningRateScheduler.cpp	/^LearningRateScheduler* LearningRateScheduler::create($/;"	f	class:paddle::LearningRateScheduler
create	parameter/OptimizerWithRegularizer.cpp	/^ParameterOptimizer* OptimizerWithRegularizer::create($/;"	f	class:paddle::OptimizerWithRegularizer
create	parameter/ParallelParameter.cpp	/^ParallelParameterPtr ParallelParameter::create(TrainerRole role,$/;"	f	class:paddle::ParallelParameter
create	parameter/ParameterOptimizer.cpp	/^ParameterOptimizer* ParameterOptimizer::create($/;"	f	class:paddle::ParameterOptimizer
create	parameter/ParameterUpdaterHook.cpp	/^std::shared_ptr<IParameterUpdaterHook> IParameterUpdaterHook::create($/;"	f	class:paddle::IParameterUpdaterHook
create	pserver/ParameterServerController.cpp	/^ParameterServerController* ParameterServerController::create($/;"	f	class:paddle::ParameterServerController
createArguments	api/Arguments.cpp	/^Arguments* Arguments::createArguments(size_t slotNum) {$/;"	f	class:Arguments
createByCommandLine	api/Trainer.cpp	/^Trainer* Trainer::createByCommandLine() throw(IOError) {$/;"	f	class:Trainer
createByConfigProtoStr	api/GradientMachine.cpp	/^GradientMachine* GradientMachine::createByConfigProtoStr($/;"	f	class:GradientMachine
createByGradientMachineSharedPtr	api/SequenceGenerator.cpp	/^SequenceGenerator* SequenceGenerator::createByGradientMachineSharedPtr($/;"	f	class:SequenceGenerator
createByModelConfig	api/GradientMachine.cpp	/^GradientMachine* GradientMachine::createByModelConfig($/;"	f	class:GradientMachine
createByPaddleArgumentVector	api/Arguments.cpp	/^Arguments* Arguments::createByPaddleArgumentVector(void* ptr) {$/;"	f	class:Arguments
createByPaddleMatrixPtr	api/Matrix.cpp	/^Matrix* Matrix::createByPaddleMatrixPtr(void* sharedPtr) {$/;"	f	class:Matrix
createByPaddleVectorPtr	api/Vector.cpp	/^IVector* IVector::createByPaddleVectorPtr(void* ptr) {$/;"	f	class:IVector
createByPaddleVectorPtr	api/Vector.cpp	/^Vector* Vector::createByPaddleVectorPtr(void* ptr) {$/;"	f	class:Vector
createByType	utils/ClassRegistrar.h	/^  BaseClass* createByType(const std::string& type, CreateArgs... args) {$/;"	f	class:paddle::ClassRegistrar
createCTCLayer	gserver/tests/test_WarpCTCLayer.cpp	/^LayerPtr createCTCLayer(string name,$/;"	f
createChannel	pserver/LightNetwork.h	/^  std::unique_ptr<SocketChannel> createChannel(int sock,$/;"	f	class:paddle::SocketServer
createChannel	pserver/LightNetwork.h	/^  std::unique_ptr<SocketChannel> createChannel(struct sxi_sock* sock,$/;"	f	class:paddle::SocketServer
createCpuDenseFromNumpy	api/Matrix.cpp	/^Matrix* Matrix::createCpuDenseFromNumpy(float* data,$/;"	f	class:Matrix
createCpuVectorFromNumpy	api/Vector.cpp	/^IVector* IVector::createCpuVectorFromNumpy(int* data, int dim, bool copy) {$/;"	f	class:IVector
createCpuVectorFromNumpy	api/Vector.cpp	/^Vector* Vector::createCpuVectorFromNumpy(float* data, int dim, bool copy) {$/;"	f	class:Vector
createCuEvent	gserver/dataproviders/DataProvider.h	/^  void createCuEvent() {$/;"	f	class:paddle::BufferBatch
createDataLayer	gserver/tests/test_WarpCTCLayer.cpp	/^LayerPtr createDataLayer($/;"	f
createDataOutlink	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::createDataOutlink($/;"	f	class:paddle::RecurrentGradientMachine
createDense	api/Matrix.cpp	/^Matrix* Matrix::createDense(const std::vector<float>& data,$/;"	f	class:Matrix
createDenseFromNumpy	api/Matrix.cpp	/^Matrix* Matrix::createDenseFromNumpy(float* data,$/;"	f	class:Matrix
createFromConfigProto	py_paddle/util.py	/^    def createFromConfigProto(protoObj,$/;"	f	function:__monkeypatch_gradient_machine__
createFromFlagConfig	trainer/TrainerConfigHelper.cpp	/^TrainerConfigHelper::createFromFlagConfig() {$/;"	f	class:paddle::TrainerConfigHelper
createFromFlags	trainer/TrainerConfigHelper.cpp	/^std::shared_ptr<TrainerConfigHelper> TrainerConfigHelper::createFromFlags() {$/;"	f	class:paddle::TrainerConfigHelper
createFromGflags	pserver/ParameterServerController.cpp	/^ParameterServerController* ParameterServerController::createFromGflags() {$/;"	f	class:paddle::ParameterServerController
createFromMode	trainer/TrainerInternalConfig.cpp	/^std::unique_ptr<TrainerInternalConfig> TrainerInternalConfig::createFromMode($/;"	f	class:paddle::TrainerInternalConfig
createFromPaddleModelPtr	api/GradientMachine.cpp	/^GradientMachine* GradientMachine::createFromPaddleModelPtr($/;"	f	class:GradientMachine
createFromProtoString	api/ConfigParser.cpp	/^OptimizationConfig* OptimizationConfig::createFromProtoString($/;"	f	class:OptimizationConfig
createFromProtoString	api/ConfigParser.cpp	/^TrainerConfig* TrainerConfig::createFromProtoString(const std::string& str) {$/;"	f	class:TrainerConfig
createFromRawPtr	api/Parameter.cpp	/^Parameter* Parameter::createFromRawPtr(void* ptr) {$/;"	f	class:Parameter
createFromSharedPtr	api/Parameter.cpp	/^Parameter* Parameter::createFromSharedPtr(void* ptr) {$/;"	f	class:Parameter
createFromTrainerConfigFile	api/ConfigParser.cpp	/^TrainerConfig* TrainerConfig::createFromTrainerConfigFile($/;"	f	class:TrainerConfig
createFunction	gserver/layers/Layer.h	/^  void createFunction(std::vector<std::shared_ptr<FunctionBase>>& function,$/;"	f	class:paddle::Layer
createFunction	gserver/layers/Projection.h	/^  void createFunction(std::vector<std::shared_ptr<FunctionBase>>& function,$/;"	f	class:paddle::Projection
createGpuDenseFromNumpy	api/Matrix.cpp	/^Matrix* Matrix::createGpuDenseFromNumpy(float* data, int dim1, int dim2) {$/;"	f	class:Matrix
createGpuVectorFromNumpy	api/Vector.cpp	/^IVector* IVector::createGpuVectorFromNumpy(int* data, int dim) {$/;"	f	class:IVector
createGpuVectorFromNumpy	api/Vector.cpp	/^Vector* Vector::createGpuVectorFromNumpy(float* data, int dim) {$/;"	f	class:Vector
createImpl	parameter/ParameterUpdaterHook.cpp	/^static IParameterUpdaterHook* createImpl($/;"	f	namespace:paddle
createInFrameInfo	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::createInFrameInfo(int inlinkId,$/;"	f	class:paddle::RecurrentGradientMachine
createLabelLayer	gserver/tests/test_WarpCTCLayer.cpp	/^LayerPtr createLabelLayer(string name,$/;"	f
createLocalUpdater	api/ParameterUpdater.cpp	/^ParameterUpdater *ParameterUpdater::createLocalUpdater($/;"	f	class:ParameterUpdater
createMatrix	pserver/ParameterClient2.cpp	/^PServerMatrix ParameterClient2::createMatrix(int32_t numCols) {$/;"	f	class:paddle::ParameterClient2
createMatrix	pserver/ParameterServer2.cpp	/^void ParameterServer2::createMatrix(const CreateMatrixRequest& request,$/;"	f	class:paddle::ParameterServer2
createMemoryFrameInfo	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::createMemoryFrameInfo($/;"	f	class:paddle::RecurrentGradientMachine
createParallelVector	math/Vector.cpp	/^std::shared_ptr<VectorT<T>> VectorT<T>::createParallelVector($/;"	f	class:paddle::VectorT
createParameterConfigFromParameterPtr	api/ConfigParser.cpp	/^ParameterConfig* ParameterConfig::createParameterConfigFromParameterPtr($/;"	f	class:ParameterConfig
createParameterConfigFromParameterSharedPtr	api/ConfigParser.cpp	/^ParameterConfig* ParameterConfig::createParameterConfigFromParameterSharedPtr($/;"	f	class:ParameterConfig
createParameterUpdater	trainer/TrainerInternal.cpp	/^void TrainerInternal::createParameterUpdater(bool testing) {$/;"	f	class:paddle::TrainerInternal
createPyDataObj	gserver/dataproviders/PyDataProvider2.cpp	/^  void createPyDataObj(const std::string& model,$/;"	f	class:paddle::PyDataProvider2	file:
createRemoteUpdater	api/ParameterUpdater.cpp	/^ParameterUpdater *ParameterUpdater::createRemoteUpdater($/;"	f	class:ParameterUpdater
createSeqPos	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::createSeqPos($/;"	f	class:paddle::RecurrentGradientMachine
createSparse	api/Matrix.cpp	/^Matrix* Matrix::createSparse(size_t height,$/;"	f	class:Matrix
createSparseMatrix	math/Matrix.cpp	/^MatrixPtr Matrix::createSparseMatrix(real* data,$/;"	f	class:paddle::Matrix
createSparseMatrix	math/Matrix.cpp	/^MatrixPtr Matrix::createSparseMatrix(size_t height,$/;"	f	class:paddle::Matrix
createTester	trainer/Trainer.cpp	/^void Trainer::createTester() {$/;"	f	class:paddle::Trainer
createTesterConfig	trainer/Trainer.cpp	/^std::unique_ptr<TesterConfig> Trainer::createTesterConfig() {$/;"	f	class:paddle::Trainer
createVector	pserver/ParameterClient2.cpp	/^PServerVector ParameterClient2::createVector() {$/;"	f	class:paddle::ParameterClient2
createVector	pserver/ParameterServer2.cpp	/^void ParameterServer2::createVector(const CreateVectorRequest& request,$/;"	f	class:paddle::ParameterServer2
createVectorFromNumpy	api/Vector.cpp	/^IVector* IVector::createVectorFromNumpy(int* data,$/;"	f	class:IVector
createVectorFromNumpy	api/Vector.cpp	/^Vector* Vector::createVectorFromNumpy(float* data,$/;"	f	class:Vector
createWarpCTCLayer	gserver/tests/test_WarpCTCLayer.cpp	/^LayerPtr createWarpCTCLayer(string name,$/;"	f
createZero	api/Matrix.cpp	/^Matrix* Matrix::createZero(size_t height, size_t width, bool useGpu) {$/;"	f	class:Matrix
createZero	api/Vector.cpp	/^IVector* IVector::createZero(size_t sz, bool useGpu) {$/;"	f	class:IVector
createZero	api/Vector.cpp	/^Vector* Vector::createZero(size_t sz, bool useGpu) {$/;"	f	class:Vector
create_dictionaries	trainer/tests/gen_proto_data.py	/^def create_dictionaries(filename, cutoff, oov_policy):$/;"	f
create_scanner	py_paddle/dataprovider_converter.py	/^    def create_scanner(i, each):$/;"	m	class:DataProviderConverter
creatorMap_	utils/ClassRegistrar.h	/^  std::map<std::string, ClassCreator> creatorMap_;$/;"	m	class:paddle::ClassRegistrar
crf_	gserver/layers/CRFDecodingLayer.h	/^  std::unique_ptr<LinearChainCRF> crf_;$/;"	m	class:paddle::CRFDecodingLayer
crfs_	gserver/layers/CRFLayer.h	/^  std::vector<LinearChainCRF> crfs_;$/;"	m	class:paddle::CRFLayer
csocket	pserver/RDMANetwork.h	/^inline sxi_socket* csocket(int cpuId) {$/;"	f	namespace:paddle::rdma
ctcs_	gserver/layers/CTCLayer.h	/^  std::vector<LinearChainCTC> ctcs_;$/;"	m	class:paddle::CTCLayer
cublas_dso_flag	cuda/src/hl_cuda_cublas.cc	/^std::once_flag cublas_dso_flag;$/;"	m	namespace:dynload	file:
cublas_dso_handle	cuda/src/hl_cuda_cublas.cc	/^void *cublas_dso_handle = nullptr;$/;"	m	namespace:dynload	file:
cudnn_dso_flag	cuda/src/hl_cuda_cudnn.cc	/^std::once_flag cudnn_dso_flag;$/;"	m	namespace:dynload	file:
cudnn_dso_handle	cuda/src/hl_cuda_cudnn.cc	/^void* cudnn_dso_handle = nullptr;$/;"	m	namespace:dynload	file:
cur	trainer/tests/picojson.h	/^  Iter cur() const { return cur_; }$/;"	f	class:picojson::input
curCpu_	pserver/LightNetwork.h	/^  std::atomic<int> curCpu_;$/;"	m	class:paddle::RdmaClientDaemons
curOffset_	pserver/ParameterServer2.h	/^    size_t curOffset_;$/;"	m	class:paddle::ParameterServer2::ReadWriteBuffer
curPos	gserver/layers/MDLstmLayer.cpp	/^  std::vector<int>& curPos() { return curPos_; }$/;"	f	class:paddle::CoordIterator
curPos_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<int> curPos_;$/;"	m	class:paddle::CoordIterator	file:
cur_	trainer/tests/picojson.h	/^  Iter cur_, end_;$/;"	m	class:picojson::input
curand_dso_flag	cuda/src/hl_cuda_device.cc	/^std::once_flag curand_dso_flag;$/;"	m	namespace:dynload	file:
curand_dso_handle	cuda/src/hl_cuda_device.cc	/^void *curand_dso_handle = nullptr;$/;"	m	namespace:dynload	file:
currentBlockIndex_	pserver/SocketChannel.h	/^  size_t currentBlockIndex_;$/;"	m	class:paddle::MsgReader
currentCost_	trainer/TrainerInternalConfig.h	/^  real currentCost_;$/;"	m	class:paddle::TrainerStats
currentEvaluator_	trainer/Trainer.h	/^  std::unique_ptr<Evaluator> currentEvaluator_;$/;"	m	class:paddle::Trainer
currentEvaluator_	trainer/TrainerInternal.h	/^  Evaluator* currentEvaluator_;$/;"	m	class:paddle::TrainerInternal
currentSampleIndex_	gserver/dataproviders/DataProvider.h	/^  size_t currentSampleIndex_;$/;"	m	class:paddle::SimpleDataProvider
currentSamples_	trainer/TrainerInternalConfig.h	/^  int64_t currentSamples_;$/;"	m	class:paddle::TrainerStats
currentSegment_	parameter/LearningRateScheduler.cpp	/^  size_t currentSegment_;$/;"	m	class:paddle::ManualLRS	file:
currentSequenceIndex_	gserver/dataproviders/ProtoDataProvider.h	/^  int64_t currentSequenceIndex_;$/;"	m	class:paddle::ProtoDataProvider
dCol_	math/BaseMatrix.h	/^  size_t dCol_;$/;"	m	class:paddle::MatrixOffset
dRow_	math/BaseMatrix.h	/^  size_t dRow_;$/;"	m	class:paddle::MatrixOffset
da_	gserver/layers/LinearChainCRF.h	/^  MatrixPtr da_;$/;"	m	class:paddle::LinearChainCRF
daemons_	pserver/LightNetwork.cpp	/^std::unique_ptr<RdmaClientDaemons> RdmaClientDaemons::daemons_ = nullptr;$/;"	m	class:paddle::RdmaClientDaemons	file:
daemons_	pserver/LightNetwork.h	/^  static std::unique_ptr<RdmaClientDaemons> daemons_;$/;"	m	class:paddle::RdmaClientDaemons
data	function/BufferArg.h	/^  T* data() const {$/;"	f	class:paddle::BufferArg
data	function/BufferArg.h	/^  void* data() const { return buf_; }$/;"	f	class:paddle::BufferArg
data	gserver/dataproviders/ProtoDataProvider.h	/^    std::vector<real> data;$/;"	m	struct:paddle::ProtoDataProvider::ProtoVarSlot
data	gserver/tests/rnn_data_provider.py	/^data = [$/;"	v
data	math/RowBuffer.h	/^  inline real* data() {$/;"	f	class:paddle::RowBuffer
data2	gserver/tests/rnn_data_provider.py	/^data2 = [$/;"	v
dataArgsFrame_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<std::vector<Argument>> dataArgsFrame_;$/;"	m	class:paddle::RecurrentGradientMachine
dataArgsSize_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  size_t dataArgsSize_;  \/\/ size of dataArgs_ = size of dataArgsFrame_$/;"	m	class:paddle::RecurrentGradientMachine
dataArgs_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<Argument> dataArgs_;$/;"	m	class:paddle::RecurrentGradientMachine
dataBatch_	gserver/dataproviders/DataProvider.h	/^  ThreadLocal<MatrixPtr> dataBatch_;$/;"	m	class:paddle::SimpleDataProviderBase
dataCompression_	gserver/dataproviders/ProtoReader.h	/^  bool dataCompression_;$/;"	m	class:paddle::ProtoReader
dataDestructor	utils/ThreadLocal.h	/^  static void dataDestructor(void* p) { delete (T*)p; }$/;"	f	class:paddle::ThreadLocal
dataDestructor	utils/ThreadLocal.h	/^  static void dataDestructor(void* p) { delete (T*)p; }$/;"	f	class:paddle::ThreadLocalD
dataFormat	function/BufferArg.h	/^  SparseDataFormat dataFormat() const { return format_; }$/;"	f	class:paddle::SparseMatrixArg
dataId	parameter/Argument.h	/^  int dataId;  \/\/ dataProvider id$/;"	m	struct:paddle::Argument
dataLayer_	gserver/tests/test_RecurrentLayer.cpp	/^  LayerPtr dataLayer_;$/;"	m	class:TestRecurrentLayer	file:
dataLayers_	gserver/gradientmachines/NeuralNetwork.h	/^  std::vector<DataLayerPtr> dataLayers_;$/;"	m	class:paddle::NeuralNetwork
dataLength	pserver/test/SocketTest.cpp	/^  int64_t dataLength;$/;"	m	struct:MessageHeader	file:
dataMems_	pserver/ParameterServer2.h	/^  std::vector<CpuMemHandlePtr> dataMems_;$/;"	m	class:paddle::ParameterServer2
dataMtx_	gserver/layers/AverageLayer.h	/^  MatrixPtr dataMtx_;$/;"	m	class:paddle::AverageLayer
dataMustInCpu	gserver/gradientmachines/GradientMachineMode.h	/^  static bool dataMustInCpu(int32_t mode, size_t trainerCount) {$/;"	f	class:paddle::IGradientMachineMode
dataPool_	gserver/dataproviders/DataProvider.h	/^  DataProvider* dataPool_;$/;"	m	class:paddle::DoubleBuffer
dataPool_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::deque<PyObjectPtr> dataPool_;$/;"	m	class:paddle::PyDataProvider2	file:
dataProvider_	trainer/Trainer.h	/^  DataProviderPtr dataProvider_;$/;"	m	class:paddle::Trainer
dataQueue_	gserver/dataproviders/DataProvider.h	/^  BufferBatchQueue* dataQueue_;$/;"	m	class:paddle::DoubleBuffer
dataSize_	pserver/ParameterServer2.h	/^  int dataSize_;$/;"	m	class:paddle::ParameterServer2
dataType	function/BufferArg.h	/^  SparseDataType dataType() const { return type_; }$/;"	f	class:paddle::SparseMatrixArg
data_	gserver/dataproviders/DataProvider.h	/^  std::vector<Argument> data_;$/;"	m	class:paddle::DataBatch
data_	gserver/dataproviders/DataProvider.h	/^  std::vector<real> data_;$/;"	m	class:paddle::SimpleDataProvider
data_	gserver/layers/DataLayer.h	/^  Argument data_;$/;"	m	class:paddle::DataLayer
data_	math/BaseMatrix.h	/^  T* data_;$/;"	m	class:paddle::BaseMatrixT
data_	math/TensorApply.h	/^  T* data_;$/;"	m	class:paddle::TensorApply
data_	math/TensorApply.h	/^  const T* data_;$/;"	m	class:paddle::TensorApply
data_	pserver/SparseParameterDistribution.h	/^  std::vector<size_t> data_;$/;"	m	class:paddle::SparseParameterDistribution
data_provider	gserver/tests/pyDataProvider.py	/^    data_provider = SimpleDataProvider('.\/test_batch')$/;"	v	class:SimpleNestDataProvider
data_provider	gserver/tests/pyDataProvider.py	/^    data_provider = SimpleNestDataProvider('.\/test_batch')$/;"	v	class:SimpleNestDataProvider
data_server_port	utils/Flags.h	/^DECLARE_int32(data_server_port);$/;"	v
db_	gserver/layers/LinearChainCRF.h	/^  MatrixPtr db_;$/;"	m	class:paddle::LinearChainCRF
deallocate	utils/Util.h	/^  void deallocate(const T* p, const size_type n) const {$/;"	f	class:paddle::AlignedAllocator
decayL1	math/SIMDFunctions.h	/^inline void decayL1($/;"	f	namespace:paddle::simd
decayL1	math/SIMDFunctions.h	/^inline void decayL1(Type* dst, Type* src, Type lambda, size_t len) {$/;"	f	namespace:paddle::simd
decayL1	math/SIMDFunctions.h	/^inline void decayL1(Type* dst, Type* src, Type lambda, size_t len) {$/;"	f	namespace:paddle::simd::naive
decayL1	math/SIMDFunctions.h	/^inline void decayL1(Type* dst, Type* src, Type* lr, Type lambda, size_t len) {$/;"	f	namespace:paddle::simd
decayL1	math/SIMDFunctions.h	/^inline void decayL1(Type* dst, Type* src, Type* lr, Type lambda, size_t len) {$/;"	f	namespace:paddle::simd::naive
decayL1	math/SIMDFunctions.h	/^inline void decayL1(float* dst, float* src, float lambda, size_t len) {$/;"	f	namespace:paddle::simd
decayL1AvxImpl	math/SIMDFunctions.cpp	/^void decayL1AvxImpl($/;"	f	namespace:paddle::simd::internal
decayL1AvxImpl	math/SIMDFunctions.cpp	/^void decayL1AvxImpl(float* dst, float* src, float lambda, size_t len) {$/;"	f	namespace:paddle::simd::internal
decayL1_avx	math/SIMDFunctions.cpp	/^static void decayL1_avx($/;"	f	file:
decayL1_avx	math/SIMDFunctions.cpp	/^static void decayL1_avx(float* dst, float* src, float lambda, size_t sz) {$/;"	f	file:
decayRate_	parameter/FirstOrderOptimizer.h	/^  real decayRate_;$/;"	m	class:paddle::SparseMomentumParameterOptimizer
decimalReciprocal_	gserver/layers/DataNormLayer.h	/^  MatrixPtr decimalReciprocal_;  \/\/ 1\/10^j$/;"	m	class:paddle::DataNormLayer
decode	gserver/layers/LinearChainCRF.cpp	/^void LinearChainCRF::decode(real* x, int* s, int length) {$/;"	f	class:paddle::LinearChainCRF
defaultParamTypes	api/GradientMachine.cpp	/^std::vector<int> GradientMachine::defaultParamTypes = {$/;"	m	class:GradientMachine	file:
defaultParamTypes	api/PaddleAPI.h	/^  static std::vector<int> defaultParamTypes;$/;"	m	class:GradientMachine
defaultSeed_	utils/ThreadLocal.cpp	/^unsigned int ThreadLocalRand::defaultSeed_ = 1;$/;"	m	class:paddle::ThreadLocalRand	file:
defaultSeed_	utils/ThreadLocal.h	/^  static unsigned int defaultSeed_;$/;"	m	class:paddle::ThreadLocalRand
default_parse_context	trainer/tests/picojson.h	/^  default_parse_context(value* out) : out_(out) {}$/;"	f	class:picojson::default_parse_context
default_parse_context	trainer/tests/picojson.h	/^class default_parse_context {$/;"	c	namespace:picojson
default_stream	cuda/src/hl_cuda_device.cc	/^__thread cudaStream_t default_stream = 0;$/;"	v
degradeSequence	parameter/Argument.cpp	/^void Argument::degradeSequence(const Argument& input, bool useGpu) {$/;"	f	class:paddle::Argument
delays_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<int> delays_;$/;"	m	class:paddle::MDLstmLayer	file:
deleteParameters	trainer/ParamUtil.cpp	/^void ParameterUtil::deleteParameters(int passId, int passInnerId) {$/;"	f	class:paddle::ParameterUtil
deleteStat	utils/Stat.cpp	/^void StatSet::deleteStat(const std::string& name) {$/;"	f	class:paddle::StatSet
deletions_	gserver/evaluators/CTCErrorEvaluator.cpp	/^  real deletions_, insertions_, substitutions_;$/;"	m	class:paddle::CTCErrorEvaluator	file:
delimited_	gserver/evaluators/Evaluator.cpp	/^  bool delimited_;$/;"	m	class:paddle::SequenceTextPrinter	file:
denoms_	gserver/layers/NormLayer.h	/^  MatrixPtr denoms_;$/;"	m	class:paddle::ResponseNormLayer
dense	trainer/tests/testPyDataWrapper.py	/^dense = map(dense_creator, range(seq_count_randomer()))$/;"	v
denseData	gserver/dataproviders/ProtoDataProvider.h	/^    std::vector<real> denseData;$/;"	m	struct:paddle::ProtoDataProvider::ProtoSlot
denseData	gserver/dataproviders/PyDataProvider.h	/^    std::vector<real> denseData;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
dense_creator	trainer/tests/testPyDataWrapper.py	/^def dense_creator(_):$/;"	f
dense_value_creator	gserver/tests/pyDataProvider.py	/^def dense_value_creator(sample_num):$/;"	f
deny_parse_context	trainer/tests/picojson.h	/^class deny_parse_context {$/;"	c	namespace:picojson
dequeue	utils/Queue.h	/^  T dequeue() {$/;"	f	class:paddle::BlockingQueue
dequeue	utils/Queue.h	/^  T dequeue() {$/;"	f	class:paddle::Queue
derived	math/TensorExpression.h	/^  const Derived& derived() const { return *static_cast<const Derived*>(this); }$/;"	f	class:paddle::TensorExpression
destroy	pserver/ParameterClient2.cpp	/^void ParameterClient2::destroy() {$/;"	f	class:paddle::ParameterClient2
destroy	utils/Util.h	/^  void destroy(const T* p) const { p->~T(); }$/;"	f	class:paddle::AlignedAllocator
destructStat_	utils/Stat.h	/^  StatInfo destructStat_;$/;"	m	class:paddle::Stat
detach	pserver/LightNetwork.h	/^  void detach() {}  \/\/ detach accept thread is forbidden$/;"	f	class:paddle::SocketServer
detach	utils/Thread.h	/^  void detach() { thread_->detach(); }$/;"	f	class:paddle::Thread
detail	function/TensorType.h	/^namespace detail {$/;"	n	namespace:paddle
detail	math/ExecViaCpu.h	/^namespace detail {$/;"	n	namespace:paddle
devId_	utils/Util.h	/^  int devId_;$/;"	m	class:paddle::SetDevice
deviceId	parameter/Argument.h	/^  int deviceId;            \/\/ the GPU device id which the argument in$/;"	m	struct:paddle::Argument
deviceId_	gserver/gradientmachines/MultiGradientMachine.h	/^  int deviceId_;$/;"	m	class:paddle::TrainerThread
deviceId_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  int deviceId_;$/;"	m	class:paddle::ParallelThread
deviceId_	gserver/layers/Layer.h	/^  int deviceId_;$/;"	m	class:paddle::Layer
deviceId_	math/MemoryHandle.h	/^  int deviceId_;      \/\/ the device id of memory if gpu memory$/;"	m	class:paddle::MemoryHandle
deviceId_	parameter/Parameter.h	/^  int deviceId_;$/;"	m	class:paddle::Parameter
device_num	cuda/src/hl_cuda_device.cc	/^int device_num = 0;                         \/* use    device number *\/$/;"	v
dict	api/SequenceGenerator.cpp	/^  std::shared_ptr<std::vector<std::string>> dict;$/;"	m	struct:SequenceGeneratorPrivate	file:
dict2	trainer/tests/gen_proto_data.py	/^dict2 = {$/;"	v
dict_	api/SequenceGenerator.cpp	/^  std::shared_ptr<std::vector<std::string>> dict_;$/;"	m	class:PathSequenceResults	file:
dict_	gserver/evaluators/Evaluator.cpp	/^  std::vector<std::string> dict_;$/;"	m	class:paddle::SequenceTextPrinter	file:
dict_	utils/PythonUtil.h	/^  PyObject* dict_;$/;"	m	class:paddle::py::DictHelper
dict_dim	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^dict_dim = 10$/;"	v
dict_dim	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^dict_dim = 10$/;"	v
difference_type	utils/Util.h	/^  typedef ptrdiff_t difference_type;$/;"	t	class:paddle::AlignedAllocator
dim	gserver/dataproviders/ProtoDataProvider.h	/^    int dim;$/;"	m	struct:paddle::ProtoDataProvider::ProtoSlot
dim	gserver/dataproviders/PyDataProvider.h	/^    int dim;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
dim	gserver/dataproviders/PyDataProvider2.cpp	/^  size_t dim;$/;"	m	struct:paddle::SlotHeader	file:
dim	gserver/tests/LayerGradUtil.h	/^  size_t dim;$/;"	m	struct:paddle::InputDef
dim	gserver/tests/test_Evaluator.cpp	/^  size_t dim;$/;"	m	struct:InputDef	file:
dims	gserver/dataproviders/ProtoDataProvider.h	/^    std::vector<int> dims;$/;"	m	struct:paddle::ProtoDataProvider::ProtoVarSlot
dimsV_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<std::vector<int>> dimsV_;$/;"	m	class:paddle::MDLstmLayer	file:
dims_	function/TensorShape.h	/^  std::vector<size_t> dims_;$/;"	m	class:paddle::TensorShape
dims_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<int> dims_;$/;"	m	class:paddle::CoordIterator	file:
din	api/test/testTrainConfig.py	/^din = data_layer(name='input', size=784)$/;"	v
directions_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<bool> directions_;$/;"	m	class:paddle::CoordIterator	file:
directions_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<bool> directions_;$/;"	m	class:paddle::MDLstmLayer	file:
dirname	utils/Util.cpp	/^std::string dirname(const std::string& path) {$/;"	f	namespace:paddle::path
disableRemoteSparseUpdater	trainer/TrainerConfigHelper.cpp	/^void TrainerConfigHelper::disableRemoteSparseUpdater() {$/;"	f	class:paddle::TrainerConfigHelper
disableRemoteSparseUpdaterForEachParams	trainer/TrainerConfigHelper.cpp	/^void TrainerConfigHelper::disableRemoteSparseUpdaterForEachParams() {$/;"	f	class:paddle::TrainerConfigHelper
dispatchByDeviceId	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^void ParallelNeuralNetwork::dispatchByDeviceId(int deviceId,$/;"	f	class:paddle::ParallelNeuralNetwork
dist_	gserver/dataproviders/PyDataProvider2.cpp	/^    std::unique_ptr<std::uniform_int_distribution<size_t>> dist_;$/;"	m	class:paddle::PyDataProvider2::PositionRandom	file:
distributeEval	gserver/evaluators/CTCErrorEvaluator.cpp	/^  virtual void distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::CTCErrorEvaluator
distributeEval	gserver/evaluators/ChunkEvaluator.cpp	/^  virtual void distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::ChunkEvaluator
distributeEval	gserver/evaluators/Evaluator.cpp	/^  virtual void distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::ClassificationErrorEvaluator
distributeEval	gserver/evaluators/Evaluator.cpp	/^  virtual void distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::SequenceClassificationErrorEvaluator
distributeEval	gserver/evaluators/Evaluator.cpp	/^  virtual void distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::SumEvaluator
distributeEval	gserver/evaluators/Evaluator.cpp	/^  void distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::ColumnSumEvaluator
distributeEval	gserver/evaluators/Evaluator.cpp	/^void AucEvaluator::distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::AucEvaluator
distributeEval	gserver/evaluators/Evaluator.cpp	/^void PrecisionRecallEvaluator::distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::PrecisionRecallEvaluator
distributeEval	gserver/evaluators/Evaluator.h	/^  virtual void distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::Evaluator
distributeEval	gserver/evaluators/Evaluator.h	/^  virtual void distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::PnpairEvaluator
distributeEval	gserver/evaluators/Evaluator.h	/^  virtual void distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::RankAucEvaluator
distributeEval	gserver/gradientmachines/MultiNetwork.cpp	/^  virtual void distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::MultiCombinedEvaluator
distributeEval	gserver/gradientmachines/NeuralNetwork.cpp	/^  virtual void distributeEval(ParameterClient2* client) {$/;"	f	class:paddle::CombinedEvaluator
distributeTest	trainer/TesterConfig.h	/^  bool distributeTest;$/;"	m	struct:paddle::TesterConfig
div	cuda/include/hl_tensor_ops.h	/^class div {$/;"	c	namespace:hppl::binary
div_scale	cuda/include/hl_tensor_ops.h	/^  INLINE div_scale(const T s) : p(s) {}$/;"	f	class:hppl::unary::div_scale
div_scale	cuda/include/hl_tensor_ops.h	/^class div_scale {$/;"	c	namespace:hppl::unary
divup	pserver/BaseClient.h	/^  static int divup(int a, int b) { return (a + b - 1) \/ b; }$/;"	f	class:paddle::BaseClient
dllInitMap	gserver/gradientmachines/NeuralNetwork.cpp	/^std::map<std::string, bool> NeuralNetwork::dllInitMap;$/;"	m	class:paddle::NeuralNetwork	file:
dllInitMap	gserver/gradientmachines/NeuralNetwork.h	/^  static std::map<std::string, bool> dllInitMap;$/;"	m	class:paddle::NeuralNetwork
doCallback	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::doCallback(int pid) {$/;"	f	class:paddle::TrainerThread
doCopyFromSafely	api/Arguments.cpp	/^static inline void doCopyFromSafely(std::shared_ptr<T1>& dest,$/;"	f	file:
doOneConvTest	gserver/tests/test_ConvUnify.cpp	/^MatrixPtr doOneConvTest(size_t imgSize,$/;"	f
doOneConvtTest	gserver/tests/test_ConvTrans.cpp	/^void doOneConvtTest(size_t imgSize,$/;"	f
doOnePriorBoxTest	gserver/tests/test_PriorBox.cpp	/^void doOnePriorBoxTest(size_t feature_map_width,$/;"	f
doOperation	pserver/ParameterClient2.cpp	/^void ParameterClient2::doOperation(PreparedOperations& ops,$/;"	f	class:paddle::ParameterClient2
doOperation	pserver/ParameterServer2.cpp	/^void ParameterServer2::doOperation(const DoOperationRequest& request,$/;"	f	class:paddle::ParameterServer2
doTraversal	parameter/OptimizerWithRegularizer.cpp	/^void OptimizerWithRegularizerEveryNumBatches::doTraversal($/;"	f	class:paddle::OptimizerWithRegularizerEveryNumBatches
dotProduct	math/MathFunctions.cpp	/^double dotProduct<double>(const int n, const double* x, const double* y) {$/;"	f	namespace:paddle
dotProduct	math/MathFunctions.cpp	/^float dotProduct<float>(const int n, const float* x, const float* y) {$/;"	f	namespace:paddle
dotSum_	gserver/layers/SumToOneNormLayer.cpp	/^  MatrixPtr dotSum_;$/;"	m	class:paddle::SumToOneNormLayer	file:
dot_period	trainer/TrainerInternalConfig.h	/^  int dot_period;$/;"	m	struct:paddle::TrainerInternalConfig
doubleBuffer_	gserver/dataproviders/DataProvider.h	/^  std::unique_ptr<DoubleBuffer> doubleBuffer_;$/;"	m	class:paddle::DataProvider
doubleEqual	api/test/util.py	/^def doubleEqual(a, b):$/;"	f
drop	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void drop(std::deque<PyObjectPtr>* data) { data->clear(); }$/;"	f	class:paddle::NoCacheStrategy
drop	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void drop(std::deque<PyObjectPtr>* data) {$/;"	f	class:paddle::CacheOnePassInMemory
dropOutMask_	gserver/layers/Layer.h	/^  MatrixPtr dropOutMask_;$/;"	m	class:paddle::Layer
droppedPool_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::unique_ptr<std::deque<PyObjectPtr>> droppedPool_;$/;"	m	class:paddle::CacheOnePassInMemory	file:
dummy_str	trainer/tests/picojson.h	/^  struct dummy_str {$/;"	s	class:picojson::null_parse_context
dump	utils/CustomStackTrace.h	/^  void dump(const DumpCallback& callback, bool onlyCurrentThread = false) {$/;"	f	class:paddle::CustomStackTrace
dw_	gserver/layers/LinearChainCRF.h	/^  MatrixPtr dw_;$/;"	m	class:paddle::LinearChainCRF
dynload	cuda/src/hl_cuda_cublas.cc	/^namespace dynload {$/;"	n	file:
dynload	cuda/src/hl_cuda_cudnn.cc	/^namespace dynload {$/;"	n	file:
dynload	cuda/src/hl_cuda_device.cc	/^namespace dynload {$/;"	n	file:
dynload	cuda/src/hl_warpctc_wrap.cc	/^namespace dynload {$/;"	n	file:
editDistance	gserver/evaluators/CTCErrorEvaluator.cpp	/^  real editDistance($/;"	f	class:paddle::CTCErrorEvaluator	file:
elementCnt_	math/Matrix.h	/^  size_t elementCnt_;  \/\/ maximal number of elements which can be held in data_$/;"	m	class:paddle::Matrix
elements_	utils/Queue.h	/^  std::deque<T> elements_;$/;"	m	class:paddle::Queue
emb1	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^emb1 = embedding_layer(input=speaker1, size=word_dim)$/;"	v
emb1	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^emb1 = embedding_layer(input=speaker1, size=word_dim)$/;"	v
emb2	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^emb2 = embedding_layer(input=speaker2, size=word_dim)$/;"	v
emb2	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^emb2 = embedding_layer(input=speaker2, size=word_dim)$/;"	v
embedding	trainer/tests/simple_sparse_neural_network.py	/^embedding = embedding_layer($/;"	v
empty	utils/BarrierStat.h	/^  bool empty() { return index_ == 0; }$/;"	f	class:paddle::TimeVectorDelta
empty	utils/BarrierStat.h	/^  bool empty() { return index_ == 0; }$/;"	f	class:paddle::TimeVectorEnd
empty	utils/CustomStackTrace.h	/^  bool empty() const {$/;"	f	class:paddle::CustomStackTrace
empty	utils/Queue.h	/^  inline bool empty() const { return numElements_ == 0; }$/;"	f	class:paddle::Queue
empty	utils/Queue.h	/^  size_t empty() {$/;"	f	class:paddle::BlockingQueue
empty_	utils/Thread.h	/^  bool empty_;$/;"	m	class:paddle::ThreadWorker
enableBufType	parameter/Parameter.h	/^  void enableBufType(ParameterType type) {$/;"	f	class:paddle::Parameter
enableIntType	parameter/Parameter.h	/^  void enableIntType(ParameterType type, size_t intStoreSize = 0) {$/;"	f	class:paddle::Parameter
enablePeerAccess	utils/Util.h	/^inline void enablePeerAccess(int d1, int d2) {$/;"	f	namespace:paddle
enableSharedType	parameter/Parameter.h	/^  void enableSharedType(ParameterType type, VectorPtr vec, MatType matType) {$/;"	f	class:paddle::Parameter
enableSharedType	parameter/Parameter.h	/^  void enableSharedType(ParameterType type,$/;"	f	class:paddle::Parameter
enableSparseParameter	parameter/Parameter.h	/^  void enableSparseParameter() {$/;"	f	class:paddle::Parameter
enableType	parameter/Parameter.h	/^  void enableType(ParameterType type, MatType matType = MAT_NORMAL) {$/;"	f	class:paddle::Parameter
enable_parallel_vector	utils/Flags.h	/^DECLARE_int32(enable_parallel_vector);$/;"	v
enable_virtualenv_py	utils/enable_virtualenv.c	/^const unsigned char enable_virtualenv_py[] = {0x69,0x6d,0x70,0x6f,0x72,0x74,0x20,0x6f,0x73,0x0a,0x0a,0x0a,0x64,0x65,0x66,0x20,0x5f,0x5f,0x61,0x63,0x74,0x69,0x76,0x61,0x74,0x65,0x5f,0x76,0x69,0x72,0x74,0x75,0x61,0x6c,0x5f,0x65,0x6e,0x76,0x5f,0x5f,0x28,0x29,0x3a,0x0a,0x20,0x20,0x20,0x20,0x5f,0x5f,0x70,0x61,0x74,0x68,0x5f,0x5f,0x20,0x3d,0x20,0x6f,0x73,0x2e,0x67,0x65,0x74,0x65,0x6e,0x76,0x28,0x27,0x56,0x49,0x52,0x54,0x55,0x41,0x4c,0x5f,0x45,0x4e,0x56,0x27,0x29,0x0a,0x20,0x20,0x20,0x20,0x69,0x66,0x20,0x5f,0x5f,0x70,0x61,0x74,0x68,0x5f,0x5f,0x20,0x69,0x73,0x20,0x4e,0x6f,0x6e,0x65,0x3a,0x0a,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x72,0x65,0x74,0x75,0x72,0x6e,0x0a,0x20,0x20,0x20,0x20,0x5f,0x5f,0x73,0x63,0x72,0x69,0x70,0x74,0x5f,0x5f,0x20,0x3d,0x20,0x6f,0x73,0x2e,0x70,0x61,0x74,0x68,0x2e,0x6a,0x6f,0x69,0x6e,0x28,0x5f,0x5f,0x70,0x61,0x74,0x68,0x5f,0x5f,0x2c,0x20,0x27,0x62,0x69,0x6e,0x27,0x2c,0x20,0x27,0x61,0x63,0x74,0x69,0x76,0x61,0x74,0x65,0x5f,0x74,0x68,0x69,0x73,0x2e,0x70,0x79,0x27,0x29,0x0a,0x20,0x20,0x20,0x20,0x65,0x78,0x65,0x63,0x66,0x69,0x6c,0x65,0x28,0x5f,0x5f,0x73,0x63,0x72,0x69,0x70,0x74,0x5f,0x5f,0x2c,0x20,0x7b,0x27,0x5f,0x5f,0x66,0x69,0x6c,0x65,0x5f,0x5f,0x27,0x3a,0x20,0x5f,0x5f,0x73,0x63,0x72,0x69,0x70,0x74,0x5f,0x5f,0x7d,0x29,0x0a,0x0a,0x0a,0x5f,0x5f,0x61,0x63,0x74,0x69,0x76,0x61,0x74,0x65,0x5f,0x76,0x69,0x72,0x74,0x75,0x61,0x6c,0x5f,0x65,0x6e,0x76,0x5f,0x5f,0x28,0x29,0x0a,0};$/;"	v
enable_virtualenv_py_size	utils/enable_virtualenv.c	/^const unsigned enable_virtualenv_py_size = sizeof(enable_virtualenv_py);$/;"	v
encode_varint	trainer/tests/gen_proto_data.py	/^def encode_varint(v):$/;"	f
encoder1_expandlast	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^encoder1_expandlast = expand_layer(input=encoder1_last, expand_as=encoder2_rep)$/;"	v
encoder1_expandlast	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^encoder1_expandlast = expand_layer(input=encoder1_last, expand_as=encoder2_rep)$/;"	v
encoder1_last	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^encoder1_last = last_seq(input=encoder1_rep)$/;"	v
encoder1_last	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^encoder1_last = last_seq(input=encoder1_rep)$/;"	v
end	gserver/evaluators/ChunkEvaluator.cpp	/^    int end;$/;"	m	struct:paddle::ChunkEvaluator::Segment	file:
end	gserver/layers/MDLstmLayer.cpp	/^  bool end() { return end_; }$/;"	f	class:paddle::CoordIterator
endDim	parameter/Parameter.h	/^  int64_t endDim;$/;"	m	struct:paddle::Segment
endPad_	gserver/layers/ContextProjection.h	/^  size_t endPad_;$/;"	m	class:paddle::ContextProjection
endPos	api/SequenceGenerator.cpp	/^  size_t endPos;$/;"	m	struct:SequenceGeneratorPrivate	file:
end_	gserver/layers/MDLstmLayer.cpp	/^  bool end_;$/;"	m	class:paddle::CoordIterator	file:
end_	math/SparseMatrix.h	/^  const char* end_; \/* point to the end of sMemoryHandle_ *\/$/;"	m	class:paddle::GpuSparseMatrix
end_	trainer/tests/picojson.h	/^  Iter cur_, end_;$/;"	m	class:picojson::input
endsWith	utils/StringUtil.cpp	/^bool endsWith(const std::string& str, const std::string& ext) {$/;"	f	namespace:paddle::str
eng_	gserver/dataproviders/PyDataProvider2.cpp	/^    std::default_random_engine& eng_;$/;"	m	class:paddle::PyDataProvider2::PositionRandom	file:
engine_	utils/ThreadLocal.cpp	/^ThreadLocal<std::default_random_engine> ThreadLocalRandomEngine::engine_;$/;"	m	class:paddle::ThreadLocalRandomEngine	file:
engine_	utils/ThreadLocal.h	/^  static ThreadLocal<std::default_random_engine> engine_;$/;"	m	class:paddle::ThreadLocalRandomEngine
enqueue	utils/Queue.h	/^  void enqueue(T&& el) {$/;"	f	class:paddle::Queue
enqueue	utils/Queue.h	/^  void enqueue(const T& el) {$/;"	f	class:paddle::Queue
enqueue	utils/Queue.h	/^  void enqueue(const T& x) {$/;"	f	class:paddle::BlockingQueue
enumeration_wrapper	utils/GlobalConstants.h	/^namespace enumeration_wrapper {$/;"	n	namespace:paddle
eosFrameLine_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::unique_ptr<EosFrameLine> eosFrameLine_;$/;"	m	class:paddle::RecurrentGradientMachine
epsilon	gserver/tests/test_PyDataProvider2.cpp	/^const paddle::real epsilon = 1e-5;$/;"	v
epsilon_	parameter/FirstOrderOptimizer.h	/^  real epsilon_;$/;"	m	class:paddle::AdaDeltaParameterOptimizer
epsilon_	parameter/FirstOrderOptimizer.h	/^  real epsilon_;$/;"	m	class:paddle::AdamParameterOptimizer
epsilon_	parameter/FirstOrderOptimizer.h	/^  real epsilon_;$/;"	m	class:paddle::DecayedAdagradParameterOptimizer
epsilon_	parameter/FirstOrderOptimizer.h	/^  real epsilon_;$/;"	m	class:paddle::RMSPropParameterOptimizer
equalNnzPerSample	gserver/tests/LayerGradUtil.h	/^  bool equalNnzPerSample;$/;"	m	struct:paddle::ParaSparse
err_	math/tests/TensorCheck.h	/^  real err_;$/;"	m	class:autotest::AssertEqual
eval	api/GradientMachine.cpp	/^void GradientMachine::eval(Evaluator* evaluator) {$/;"	f	class:GradientMachine
eval	gserver/evaluators/CTCErrorEvaluator.cpp	/^  virtual void eval(const NeuralNetwork& nn) {$/;"	f	class:paddle::CTCErrorEvaluator
eval	gserver/evaluators/Evaluator.cpp	/^  virtual void eval(const NeuralNetwork& nn) {$/;"	f	class:paddle::GradientPrinter
eval	gserver/evaluators/Evaluator.cpp	/^  virtual void eval(const NeuralNetwork& nn) {$/;"	f	class:paddle::MaxFramePrinter
eval	gserver/evaluators/Evaluator.cpp	/^  virtual void eval(const NeuralNetwork& nn) {$/;"	f	class:paddle::MaxIdPrinter
eval	gserver/evaluators/Evaluator.cpp	/^  virtual void eval(const NeuralNetwork& nn) {$/;"	f	class:paddle::ValuePrinter
eval	gserver/evaluators/Evaluator.cpp	/^void Evaluator::eval(const NeuralNetwork& nn) {$/;"	f	class:paddle::Evaluator
eval	gserver/evaluators/Evaluator.h	/^  virtual void eval(const NeuralNetwork&) {}$/;"	f	class:paddle::DummyEvaluator
eval	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::eval(Evaluator* evaluator) const {$/;"	f	class:paddle::MultiGradientMachine
eval	gserver/gradientmachines/MultiNetwork.cpp	/^  virtual void eval(const NeuralNetwork& nn) {$/;"	f	class:paddle::MultiCombinedEvaluator
eval	gserver/gradientmachines/MultiNetwork.cpp	/^void MultiNetwork::eval(Evaluator* evaluator) const { evaluator->eval(*this); }$/;"	f	class:paddle::MultiNetwork
eval	gserver/gradientmachines/NeuralNetwork.cpp	/^  virtual void eval(const NeuralNetwork& nn) {$/;"	f	class:paddle::CombinedEvaluator
eval	gserver/gradientmachines/NeuralNetwork.cpp	/^void NeuralNetwork::eval(Evaluator* evaluator) const { evaluator->eval(*this); }$/;"	f	class:paddle::NeuralNetwork
eval	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::eval(Evaluator* evaluator) const {$/;"	f	class:paddle::RecurrentGradientMachine
eval1	gserver/evaluators/ChunkEvaluator.cpp	/^  void eval1(int* output, int* label, int length) {$/;"	f	class:paddle::ChunkEvaluator
evalImp	gserver/evaluators/CTCErrorEvaluator.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::CTCErrorEvaluator
evalImp	gserver/evaluators/ChunkEvaluator.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::ChunkEvaluator
evalImp	gserver/evaluators/Evaluator.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) { return 0; }$/;"	f	class:paddle::GradientPrinter
evalImp	gserver/evaluators/Evaluator.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) { return 0; }$/;"	f	class:paddle::MaxFramePrinter
evalImp	gserver/evaluators/Evaluator.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) { return 0; }$/;"	f	class:paddle::MaxIdPrinter
evalImp	gserver/evaluators/Evaluator.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) { return 0; }$/;"	f	class:paddle::ValuePrinter
evalImp	gserver/evaluators/Evaluator.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::ClassificationErrorEvaluator
evalImp	gserver/evaluators/Evaluator.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::ClassificationErrorPrinter
evalImp	gserver/evaluators/Evaluator.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::ColumnSumEvaluator
evalImp	gserver/evaluators/Evaluator.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::SequenceClassificationErrorEvaluator
evalImp	gserver/evaluators/Evaluator.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::SequenceTextPrinter
evalImp	gserver/evaluators/Evaluator.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::SumEvaluator
evalImp	gserver/evaluators/Evaluator.cpp	/^real AucEvaluator::evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::AucEvaluator
evalImp	gserver/evaluators/Evaluator.cpp	/^real PnpairEvaluator::evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::PnpairEvaluator
evalImp	gserver/evaluators/Evaluator.cpp	/^real PrecisionRecallEvaluator::evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::PrecisionRecallEvaluator
evalImp	gserver/evaluators/Evaluator.cpp	/^real RankAucEvaluator::evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::RankAucEvaluator
evalImp	gserver/evaluators/Evaluator.h	/^  virtual real evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::DummyEvaluator
evalImp	gserver/gradientmachines/MultiNetwork.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::MultiCombinedEvaluator
evalImp	gserver/gradientmachines/NeuralNetwork.cpp	/^  virtual real evalImp(std::vector<Argument>& arguments) {$/;"	f	class:paddle::CombinedEvaluator
evaluate_as_boolean	trainer/tests/picojson.h	/^inline bool value::evaluate_as_boolean() const {$/;"	f	class:picojson::value
evaluatorConfig	gserver/tests/test_Evaluator.cpp	/^  EvaluatorConfig evaluatorConfig;$/;"	m	struct:TestConfig	file:
evaluator_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::unique_ptr<Evaluator> evaluator_;  \/\/ frame printers in this layer group$/;"	m	class:paddle::RecurrentGradientMachine
evaluator_	gserver/layers/ValidationLayer.h	/^  std::unique_ptr<Evaluator> evaluator_;$/;"	m	class:paddle::AucValidation
evaluator_	gserver/layers/ValidationLayer.h	/^  std::unique_ptr<Evaluator> evaluator_;$/;"	m	class:paddle::PnpairValidation
evaluator_	trainer/Trainer.h	/^  std::unique_ptr<Evaluator> evaluator_;$/;"	m	class:paddle::Trainer
evaluator_	trainer/TrainerInternal.h	/^  Evaluator* evaluator_;$/;"	m	class:paddle::TrainerInternal
evaluators_	gserver/gradientmachines/MultiNetwork.cpp	/^  std::vector<std::unique_ptr<Evaluator>> evaluators_;$/;"	m	class:paddle::MultiCombinedEvaluator	file:
evaluators_	gserver/gradientmachines/NeuralNetwork.cpp	/^  std::vector<std::unique_ptr<Evaluator>> evaluators_;$/;"	m	class:paddle::CombinedEvaluator	file:
excludedChunkTypes_	gserver/evaluators/ChunkEvaluator.cpp	/^  std::set<int> excludedChunkTypes_;$/;"	m	class:paddle::ChunkEvaluator	file:
exec	math/Vector.cpp	/^void ParallelCpuVectorT<T>::exec(SyncThreadPool::JobFunc func) {$/;"	f	class:paddle::ParallelCpuVectorT
exec	math/Vector.cpp	/^void ParallelCpuVectorT<real>::exec(SyncThreadPool::JobFunc func) {$/;"	f	class:paddle::ParallelCpuVectorT
exec	math/Vector.h	/^  virtual void exec(SyncThreadPool::JobFunc func) { func(0, 1); }$/;"	f	class:paddle::VectorT
exec	parameter/Parameter.cpp	/^void Parameter::exec(ExecFunc func) {$/;"	f	class:paddle::Parameter
exec	utils/Thread.h	/^  void exec(JobFunc jobFunc, JobFunc ownerFunc = nullptr) {$/;"	f	class:paddle::SyncThreadPool
execHelper	utils/Thread.h	/^  static void execHelper(SyncThreadPool* pool, JobFunc jobFunc) {$/;"	f	class:paddle::SyncThreadPool
execPlusOwner	utils/Thread.h	/^  void execPlusOwner(JobFunc jobFunc) { exec(jobFunc, jobFunc); }$/;"	f	class:paddle::SyncThreadPool
execViaCpu	math/ExecViaCpu.h	/^typename detail::GpuFuncWrapper<F>::ResultType execViaCpu(F&& f,$/;"	f	namespace:paddle
executeCMD	utils/PythonUtil.cpp	/^int executeCMD(const char* cmd, char* result) {$/;"	f	namespace:paddle
exit_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::atomic<bool> exit_;$/;"	m	class:paddle::PyDataProvider2	file:
exit_	utils/Util.h	/^  std::function<void()> exit_;$/;"	m	class:paddle::ScopedCallbacks
exit_diy_prob	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^static void exit_diy_prob() { dlclose(gDiyProbHandle); }$/;"	f	namespace:paddle
exp	cuda/src/hl_math.cc	/^__m256 exp(__m256 a) { return exp256_ps(a); }$/;"	f	namespace:hppl
exp	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::exp_op<T>, const Derived, T> exp() const {$/;"	f	class:paddle::TensorExpression
exp256_ps	cuda/src/avx_mathfun.h	/^v8sf exp256_ps(v8sf x) {$/;"	f
expW_	gserver/layers/LinearChainCRF.h	/^  MatrixPtr expW_;$/;"	m	class:paddle::LinearChainCRF
expX_	gserver/layers/LinearChainCRF.h	/^  MatrixPtr expX_;$/;"	m	class:paddle::LinearChainCRF
exp_op	cuda/include/hl_tensor_ops.h	/^class exp_op {$/;"	c	namespace:hppl::unary
expandFwdOnce	gserver/layers/ExpandConvBaseLayer.cpp	/^void ExpandConvBaseLayer::expandFwdOnce(MatrixPtr image,$/;"	f	class:paddle::ExpandConvBaseLayer
expandInput_	gserver/layers/ExpandConvBaseLayer.h	/^  MatrixPtr expandInput_;$/;"	m	class:paddle::ExpandConvBaseLayer
expandMat	gserver/layers/BatchNormalizationLayer.cpp	/^void BatchNormalizationLayer::expandMat(const MatrixPtr& in, MatrixPtr& out) {$/;"	f	class:paddle::BatchNormalizationLayer
expandOneFrame	gserver/layers/ExpandConvBaseLayer.cpp	/^void ExpandConvBaseLayer::expandOneFrame(MatrixPtr image,$/;"	f	class:paddle::ExpandConvBaseLayer
expandStartsPos_	gserver/layers/ExpandLayer.h	/^  ICpuGpuVectorPtr expandStartsPos_;$/;"	m	class:paddle::ExpandLayer
expandedInGrad_	gserver/layers/BatchNormalizationLayer.h	/^  MatrixPtr expandedInGrad_, expandedOutGrad_, inGrad_;$/;"	m	class:paddle::BatchNormalizationLayer
expandedIn_	gserver/layers/BatchNormalizationLayer.h	/^  MatrixPtr expandedIn_, expandedOut_;$/;"	m	class:paddle::BatchNormalizationLayer
expandedOutGrad_	gserver/layers/BatchNormalizationLayer.h	/^  MatrixPtr expandedInGrad_, expandedOutGrad_, inGrad_;$/;"	m	class:paddle::BatchNormalizationLayer
expandedOut_	gserver/layers/BatchNormalizationLayer.h	/^  MatrixPtr expandedIn_, expandedOut_;$/;"	m	class:paddle::BatchNormalizationLayer
expect	trainer/tests/picojson.h	/^  bool expect(int expect) {$/;"	f	class:picojson::input
expectFile	trainer/tests/test_recurrent_machine_generation.cpp	/^static string expectFile =                                           \/\/ NOLINT$/;"	v	file:
expectedPassCount_	trainer/RemoteParameterUpdater.h	/^  int64_t expectedPassCount_;$/;"	m	class:paddle::RemoteParameterUpdater
expectedPassCount_	trainer/RemoteParameterUpdater.h	/^  int64_t expectedPassCount_;$/;"	m	class:paddle::SparseRemoteParameterUpdater
expr1_	math/TensorApply.h	/^  TensorApply<ArgType1, T> expr1_;$/;"	m	class:paddle::TensorApply
expr1_	math/TensorExpression.h	/^  const ExprType1 expr1_;$/;"	m	class:paddle::TensorTernaryOp
expr2_	math/TensorApply.h	/^  TensorApply<ArgType2, T> expr2_;$/;"	m	class:paddle::TensorApply
expr2_	math/TensorExpression.h	/^  const ExprType2 expr2_;$/;"	m	class:paddle::TensorTernaryOp
expr3_	math/TensorApply.h	/^  TensorApply<ArgType3, T> expr3_;$/;"	m	class:paddle::TensorApply
expr3_	math/TensorExpression.h	/^  const ExprType3 expr3_;$/;"	m	class:paddle::TensorTernaryOp
expr_	math/TensorApply.h	/^  TensorApply<ArgType, T> expr_;$/;"	m	class:paddle::TensorApply
expr_	math/TensorApply.h	/^  TensorApply<const Derived, T> expr_;$/;"	m	class:paddle::TensorApply
expr_	math/TensorExpression.h	/^  const ExprType expr_;$/;"	m	class:paddle::TensorConstant
expr_	math/TensorExpression.h	/^  const ExprType expr_;$/;"	m	class:paddle::TensorUnaryOp
ext_modules	setup.py	/^  ext_modules=[$/;"	v
extend_cols	py_paddle/dataprovider_converter.py	/^    def extend_cols(self, dat):$/;"	m	class:SparseBinaryScanner
extend_cols	py_paddle/dataprovider_converter.py	/^    def extend_cols(self, dat):$/;"	m	class:SparseFloatScanner
external	gserver/gradientmachines/MultiGradientMachine.cpp	/^DECLARE_bool(external);$/;"	v
extra_compile_args	setup.py	/^       extra_compile_args = extra_comps$/;"	v
extra_comps	setup.py	/^extra_comps = []$/;"	v
extra_comps	setup.py	/^extra_comps = obj.c_flag()$/;"	v
extra_link_args	setup.py	/^       extra_link_args = extra_links,$/;"	v
extra_links	setup.py	/^    extra_links = ["-Wl,-all_load"] + extra_links$/;"	v
extra_links	setup.py	/^    extra_links = ["-Xlinker", '-start-group'] + extra_links + ["-Xlinker", "-end-group"]$/;"	v
extra_links	setup.py	/^extra_links = []$/;"	v
f	math/tests/test_ExecViaCpu.cpp	/^real f(Matrix& mat1,$/;"	f
false_type	math/BaseMatrix.h	/^typedef bool_constant<bool, false> false_type;$/;"	t	namespace:paddle
fc1	api/test/testTrainConfig.py	/^fc1 = fc_layer(name='hidden1', input=din, size=100)$/;"	v
fc2	api/test/testTrainConfig.py	/^fc2 = fc_layer(name='hidden2', input=fc1, size=100)$/;"	v
fcLayerWidth	gserver/tests/test_SelectiveFCLayer.cpp	/^size_t fcLayerWidth = 1024;$/;"	v
featFile	trainer/TesterConfig.h	/^  std::string featFile;$/;"	m	struct:paddle::TesterConfig
featLen_	gserver/layers/MaxOutLayer.h	/^  size_t featLen_;$/;"	m	class:paddle::MaxOutLayer
fedisableexcept	utils/arch/osx/Excepts.cpp	/^int fedisableexcept(unsigned int excepts) {$/;"	f
feedback	api/SequenceGenerator.cpp	/^  paddle::Argument feedback;$/;"	m	struct:SequenceGeneratorPrivate	file:
feenableexcept	utils/arch/osx/Excepts.cpp	/^int feenableexcept(unsigned int excepts) {$/;"	f
fegetexcept	utils/arch/osx/Excepts.cpp	/^int fegetexcept(void) {$/;"	f
fileExist	utils/Util.cpp	/^bool fileExist(const char* filename) { return (access(filename, 0) == 0); }$/;"	f	namespace:paddle
fileList_	gserver/dataproviders/DataProviderGroup.h	/^  std::vector<std::string> fileList_;$/;"	m	class:paddle::DataProviderGroup
fileLists_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::vector<std::string> fileLists_;$/;"	m	class:paddle::PyDataProvider2	file:
file_list	trainer/tests/simple_sparse_neural_network.py	/^file_list = 'trainer\/tests\/fake_file_list.list'$/;"	v
fill	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void fill(Argument& argument, PyObject* obj) {$/;"	f	class:paddle::DenseScanner
fill	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void fill(Argument& argument, PyObject* obj) {$/;"	f	class:paddle::IndexScanner
fill	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void fill(Argument& argument, PyObject* obj) {$/;"	f	class:paddle::SequenceScanner
fill	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void fill(Argument& argument, PyObject* obj) {$/;"	f	class:paddle::SparseNonValueScanner
fill	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void fill(Argument& argument, PyObject* obj) {}$/;"	f	class:paddle::IFieldScanner
fillBuffer	gserver/dataproviders/DataProvider.cpp	/^int64_t SimpleDataProviderBase::fillBuffer() {$/;"	f	class:paddle::SimpleDataProviderBase
fillBufferImp	gserver/dataproviders/DataProvider.cpp	/^int64_t SimpleDataProvider::fillBufferImp(real* data,$/;"	f	class:paddle::SimpleDataProvider
fillDenseSlot	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::fillDenseSlot(ProtoSlot& slot,$/;"	f	class:paddle::PyDataProvider
fillFullySelectiveData	gserver/layers/SelectiveFullyConnectedLayer.h	/^  void fillFullySelectiveData() { fullOutput_ = true; }$/;"	f	class:paddle::SelectiveFullyConnectedLayer
fillGenOutputs	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::fillGenOutputs() {$/;"	f	class:paddle::RecurrentGradientMachine
fillIndexSlot	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::fillIndexSlot(ProtoSlot& slot,$/;"	f	class:paddle::PyDataProvider
fillMergeTypes	gserver/gradientmachines/MultiGradientMachine.cpp	/^static void fillMergeTypes(PassType passType,$/;"	f	namespace:paddle
fillRowIndices	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::fillRowIndices(IVectorPtr& outVec) const {$/;"	f	class:paddle::CpuSparseMatrix
fillSelectiveData	gserver/layers/SelectiveFullyConnectedLayer.cpp	/^void paddle::SelectiveFullyConnectedLayer::fillSelectiveData($/;"	f	class:paddle::paddle::SelectiveFullyConnectedLayer
fillSequence	math/Vector.cpp	/^void CpuGpuVectorT<T>::fillSequence(bool useGpu) {$/;"	f	class:paddle::CpuGpuVectorT
fillSequence	math/Vector.cpp	/^void CpuVectorT<T>::fillSequence() {$/;"	f	class:paddle::CpuVectorT
fillSequence	math/Vector.cpp	/^void GpuVectorT<T>::fillSequence() {$/;"	f	class:paddle::GpuVectorT
fillSlots	gserver/dataproviders/ProtoDataProvider.cpp	/^void ProtoDataProvider::fillSlots(const DataSample& sample) {$/;"	f	class:paddle::ProtoDataProvider
fillSlotsByStr	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::fillSlotsByStr(const std::string& samples) {$/;"	f	class:paddle::PyDataProvider
fillSparseNonValueSlot	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::fillSparseNonValueSlot(ProtoSlot& slot,$/;"	f	class:paddle::PyDataProvider
fillSparseValueSlot	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::fillSparseValueSlot(ProtoSlot& slot,$/;"	f	class:paddle::PyDataProvider
fillStringSlot	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::fillStringSlot(ProtoSlot& slot,$/;"	f	class:paddle::PyDataProvider
filterChannels_	gserver/layers/ConvBaseLayer.h	/^  IntV filterChannels_;$/;"	m	class:paddle::ConvBaseLayer
filterChannels_	gserver/layers/ConvOperator.cpp	/^  int imgPixels_, filterPixels_, filterChannels_, outputX_, outputY_, outputs_;$/;"	m	class:paddle::ConvOperator	file:
filterDesc_	gserver/layers/ConvOperator.cpp	/^  hl_filter_descriptor filterDesc_;$/;"	m	class:paddle::ConvOperator	file:
filterDesc_	gserver/layers/ConvProjection.h	/^  hl_filter_descriptor filterDesc_;$/;"	m	class:paddle::ConvProjection
filterH_	gserver/layers/ConvProjection.h	/^  int filterH_, filterW_;$/;"	m	class:paddle::ConvProjection
filterPixels_	gserver/layers/ConvBaseLayer.h	/^  IntV filterPixels_;$/;"	m	class:paddle::ConvBaseLayer
filterPixels_	gserver/layers/ConvOperator.cpp	/^  int imgPixels_, filterPixels_, filterChannels_, outputX_, outputY_, outputs_;$/;"	m	class:paddle::ConvOperator	file:
filterSizeY_	gserver/layers/ConvBaseLayer.h	/^  IntV filterSizeY_;$/;"	m	class:paddle::ConvBaseLayer
filterSizeY_	gserver/layers/ConvOperator.cpp	/^  int paddingY_, strideY_, filterSizeY_;$/;"	m	class:paddle::ConvOperator	file:
filterSize_	gserver/layers/ConvBaseLayer.h	/^  IntV filterSize_;$/;"	m	class:paddle::ConvBaseLayer
filterSize_	gserver/layers/ConvOperator.cpp	/^  int padding_, stride_, filterSize_, channels_, imgSize_, imgSizeY_;$/;"	m	class:paddle::ConvOperator	file:
filterW_	gserver/layers/ConvProjection.h	/^  int filterH_, filterW_;$/;"	m	class:paddle::ConvProjection
final	pserver/ParameterServerController.h	/^class ParameterServerController final {$/;"	c	namespace:paddle
final	utils/CpuId.h	/^class SIMDFlags final {$/;"	c	namespace:paddle
final	utils/Stat.h	/^class GpuProfiler final {$/;"	c	namespace:paddle
finalPaths_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<std::vector<Path>> finalPaths_;$/;"	m	class:paddle::RecurrentGradientMachine
findLastSet	utils/Util.h	/^inline constexpr size_t findLastSet(size_t x) {$/;"	f	namespace:paddle
findNBest	api/SequenceGenerator.cpp	/^  inline void findNBest(std::vector<paddle::Argument>& inArgs,$/;"	f	struct:SequenceGeneratorPrivate
findNBest	api/SequenceGenerator.cpp	/^static void findNBest(paddle::GradientMachine* gradMachine,$/;"	f	file:
finish	api/Evaluator.cpp	/^void Evaluator::finish() { m->rawPtr->finish(); }$/;"	f	class:Evaluator
finish	api/GradientMachine.cpp	/^void GradientMachine::finish() { m->machine->finish(); }$/;"	f	class:GradientMachine
finish	gserver/evaluators/Evaluator.h	/^  virtual void finish() { calc(predictArray_); }$/;"	f	class:paddle::PnpairEvaluator
finish	gserver/evaluators/Evaluator.h	/^  virtual void finish() {}$/;"	f	class:paddle::DummyEvaluator
finish	gserver/evaluators/Evaluator.h	/^  virtual void finish() {}$/;"	f	class:paddle::Evaluator
finish	gserver/gradientmachines/GradientMachine.h	/^  virtual void finish() {}$/;"	f	class:paddle::GradientMachine
finish	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::finish() {$/;"	f	class:paddle::MultiGradientMachine
finish	gserver/gradientmachines/MultiNetwork.cpp	/^  virtual void finish() {$/;"	f	class:paddle::MultiCombinedEvaluator
finish	gserver/gradientmachines/MultiNetwork.cpp	/^void MultiNetwork::finish() {$/;"	f	class:paddle::MultiNetwork
finish	gserver/gradientmachines/NeuralNetwork.cpp	/^  virtual void finish() {$/;"	f	class:paddle::CombinedEvaluator
finishAsyncLoad	gserver/dataproviders/DataProvider.h	/^  void finishAsyncLoad() {$/;"	f	class:paddle::DoubleBuffer
finishBatch	api/ParameterOptimizer.cpp	/^void ParameterOptimizer::finishBatch() { m->optimizer->finishBatch(); }$/;"	f	class:ParameterOptimizer
finishBatch	api/ParameterUpdater.cpp	/^void ParameterUpdater::finishBatch(float cost) {$/;"	f	class:ParameterUpdater
finishBatch	parameter/AverageOptimizer.cpp	/^void AverageOptimizer::finishBatch() {$/;"	f	class:paddle::AverageOptimizer
finishBatch	parameter/AverageOptimizer.h	/^  virtual void finishBatch() {$/;"	f	class:paddle::AverageSparseOptimizer
finishBatch	parameter/FirstOrderOptimizer.cpp	/^void SparseMomentumParameterOptimizer::finishBatch() {$/;"	f	class:paddle::SparseMomentumParameterOptimizer
finishBatch	parameter/FirstOrderOptimizer.h	/^  virtual void finishBatch() { ++step_; }$/;"	f	class:paddle::AdamParameterOptimizer
finishBatch	parameter/FirstOrderOptimizer.h	/^  virtual void finishBatch() { ++step_; }$/;"	f	class:paddle::AdamaxParameterOptimizer
finishBatch	parameter/FirstOrderOptimizer.h	/^  virtual void finishBatch() { firstTime_ = false; }$/;"	f	class:paddle::SgdOptimizer
finishBatch	parameter/FirstOrderOptimizer.h	/^  virtual void finishBatch() { optimizer_->finishBatch(); }$/;"	f	class:paddle::OptimizerWithGradientClipping
finishBatch	parameter/FirstOrderOptimizer.h	/^  virtual void finishBatch() { timer_++; }$/;"	f	class:paddle::DecayedAdagradParameterOptimizer
finishBatch	parameter/FirstOrderOptimizer.h	/^  virtual void finishBatch() { timer_++; }$/;"	f	class:paddle::RMSPropParameterOptimizer
finishBatch	parameter/OptimizerWithRegularizer.h	/^  virtual void finishBatch() {$/;"	f	class:paddle::OptimizerWithRegularizer
finishBatch	parameter/ParameterOptimizer.h	/^  virtual void finishBatch() {}$/;"	f	class:paddle::ParameterOptimizer
finishBatch	parameter/ParameterUpdaterBase.h	/^  virtual void finishBatch(real cost) { (void)cost; }$/;"	f	class:paddle::ParameterUpdater
finishBatch	parameter/ParameterUpdaterBase.h	/^  virtual void finishBatch(real cost) {$/;"	f	class:paddle::ParameterUpdaterComposite
finishBatch	trainer/ParameterUpdater.cpp	/^void SgdUpdaterWithCpuAverager::finishBatch(real cost) {$/;"	f	class:paddle::SgdUpdaterWithCpuAverager
finishBatch	trainer/ParameterUpdater.h	/^  virtual void finishBatch(real cost) { optimizer_->finishBatch(); }$/;"	f	class:paddle::SgdLocalUpdater
finishBatch	trainer/ParameterUpdater.h	/^  virtual void finishBatch(real cost) {$/;"	f	class:paddle::SgdCpuUpdater
finishBatch	trainer/RemoteParameterUpdater.cpp	/^void ConcurrentRemoteParameterUpdater::finishBatch(real cost) {$/;"	f	class:paddle::ConcurrentRemoteParameterUpdater
finishBatch	trainer/RemoteParameterUpdater.cpp	/^void RemoteParameterUpdater::finishBatch(real cost) {$/;"	f	class:paddle::RemoteParameterUpdater
finishBatch	trainer/RemoteParameterUpdater.cpp	/^void SparseRemoteParameterUpdater::finishBatch(real cost) {$/;"	f	class:paddle::SparseRemoteParameterUpdater
finishBatch	trainer/ThreadParameterUpdater.cpp	/^void SgdThreadUpdater::finishBatch(real cost) {$/;"	f	class:paddle::SgdThreadUpdater
finishBatchCond_	trainer/RemoteParameterUpdater.h	/^  LockedCondition finishBatchCond_;$/;"	m	class:paddle::ConcurrentRemoteParameterUpdater
finishCV_	utils/Thread.h	/^  LockedCondition finishCV_;$/;"	m	class:paddle::ThreadWorker
finishCatchUpWith	parameter/AverageOptimizer.h	/^  virtual void finishCatchUpWith() { return optimizer_->finishCatchUpWith(); }$/;"	f	class:paddle::AverageOptimizer
finishCatchUpWith	parameter/AverageOptimizer.h	/^  virtual void finishCatchUpWith() {$/;"	f	class:paddle::AverageSparseOptimizer
finishCatchUpWith	parameter/OptimizerWithRegularizer.h	/^  virtual void finishCatchUpWith() { baseTimer_ = timer_; }$/;"	f	class:paddle::OptimizerWithRegularizerEveryNumBatches
finishCatchUpWith	parameter/OptimizerWithRegularizer.h	/^  virtual void finishCatchUpWith() {$/;"	f	class:paddle::OptimizerWithRegularizerSparse
finishCatchUpWith	parameter/ParameterOptimizer.h	/^  virtual void finishCatchUpWith() {}$/;"	f	class:paddle::ParameterOptimizer
finishFill	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void finishFill(Argument& argument) { inner_->finishFill(argument); }$/;"	f	class:paddle::SequenceScanner
finishFill	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void finishFill(Argument& argument) {}$/;"	f	class:paddle::IFieldScanner
finishPass	api/ParameterOptimizer.cpp	/^void ParameterOptimizer::finishPass() { m->optimizer->finishPass(); }$/;"	f	class:ParameterOptimizer
finishPass	api/ParameterUpdater.cpp	/^void ParameterUpdater::finishPass() { m->updater->finishPass(); }$/;"	f	class:ParameterUpdater
finishPass	parameter/AverageOptimizer.h	/^  virtual void finishPass() {$/;"	f	class:paddle::AverageOptimizer
finishPass	parameter/FirstOrderOptimizer.h	/^  virtual void finishPass() { optimizer_->finishPass(); }$/;"	f	class:paddle::OptimizerWithGradientClipping
finishPass	parameter/OptimizerWithRegularizer.h	/^  virtual void finishPass() { optimizer_->finishPass(); }$/;"	f	class:paddle::OptimizerWithRegularizer
finishPass	parameter/ParameterOptimizer.h	/^  virtual void finishPass() { ++pass_; }$/;"	f	class:paddle::ParameterOptimizer
finishPass	parameter/ParameterUpdaterBase.h	/^  virtual bool finishPass() { return true; }$/;"	f	class:paddle::ParameterUpdater
finishPass	parameter/ParameterUpdaterBase.h	/^  virtual bool finishPass() {$/;"	f	class:paddle::ParameterUpdaterComposite
finishPass	trainer/ParameterUpdater.h	/^  virtual bool finishPass() {$/;"	f	class:paddle::SgdLocalUpdater
finishPass	trainer/ParameterUpdater.h	/^  virtual bool finishPass() {$/;"	f	class:paddle::SgdUpdaterWithCpuAverager
finishPass	trainer/RemoteParameterUpdater.cpp	/^bool RemoteParameterUpdater::finishPass() {$/;"	f	class:paddle::RemoteParameterUpdater
finishPass	trainer/RemoteParameterUpdater.cpp	/^bool SparseRemoteParameterUpdater::finishPass() {$/;"	f	class:paddle::SparseRemoteParameterUpdater
finishPass	trainer/ThreadParameterUpdater.cpp	/^bool SgdThreadUpdater::finishPass() {$/;"	f	class:paddle::SgdThreadUpdater
finishPrepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void finishPrepare(Argument& argument) {$/;"	f	class:paddle::DenseScanner
finishPrepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void finishPrepare(Argument& argument) {$/;"	f	class:paddle::IndexScanner
finishPrepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void finishPrepare(Argument& argument) {$/;"	f	class:paddle::SequenceScanner
finishPrepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void finishPrepare(Argument& argument) {$/;"	f	class:paddle::SparseNonValueScanner
finishPrepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void finishPrepare(Argument& argument) {$/;"	f	class:paddle::SparseValueScanner
finishPrepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void finishPrepare(Argument& argument) {}$/;"	f	class:paddle::IFieldScanner
finishTestPeriod	api/Trainer.cpp	/^void Trainer::finishTestPeriod() { m->finishTestPeriod(); }$/;"	f	class:Trainer
finishTestPeriod	api/Trainer.cpp	/^void TrainerPrivate::finishTestPeriod() { tester_->finishTestPeriod(); }$/;"	f	class:TrainerPrivate
finishTestPeriod	trainer/Tester.cpp	/^void Tester::finishTestPeriod() {$/;"	f	class:paddle::Tester
finishThreads	pserver/BaseClient.cpp	/^void BaseClient::finishThreads() {$/;"	f	class:paddle::BaseClient
finishTrain	api/Trainer.cpp	/^void Trainer::finishTrain() { m->finishTrain(); }$/;"	f	class:Trainer
finishTrain	gserver/tests/test_RecurrentGradientMachine.cpp	/^  void finishTrain() {$/;"	f	class:TrainerForTest
finishTrain	trainer/Trainer.cpp	/^void Trainer::finishTrain() { trainerInternal_.getGradientMachine()->finish(); }$/;"	f	class:paddle::Trainer
finishTrainPass	api/Trainer.cpp	/^void Trainer::finishTrainPass() { m->finishTrainPass(); }$/;"	f	class:Trainer
finishTrainPass	trainer/Trainer.cpp	/^void Trainer::finishTrainPass() {$/;"	f	class:paddle::Trainer
finishTrainPass	trainer/TrainerInternal.cpp	/^void TrainerInternal::finishTrainPass(int passId, int batchId) {$/;"	f	class:paddle::TrainerInternal
finish_scan	py_paddle/dataprovider_converter.py	/^    def finish_scan(self, argument):$/;"	m	class:DenseScanner
finish_scan	py_paddle/dataprovider_converter.py	/^    def finish_scan(self, argument):$/;"	m	class:IScanner
finish_scan	py_paddle/dataprovider_converter.py	/^    def finish_scan(self, argument):$/;"	m	class:IndexScanner
finish_scan	py_paddle/dataprovider_converter.py	/^    def finish_scan(self, argument):$/;"	m	class:SequenceScanner
finish_scan	py_paddle/dataprovider_converter.py	/^    def finish_scan(self, argument):$/;"	m	class:SparseBinaryScanner
firstTest_	gserver/layers/BatchNormalizationLayer.h	/^  bool firstTest_;$/;"	m	class:paddle::BatchNormalizationLayer
firstTime_	parameter/ParameterOptimizer.h	/^        firstTime_(true) {}$/;"	f	class:paddle::ParameterOptimizer
firstTime_	parameter/ParameterOptimizer.h	/^  bool firstTime_;$/;"	m	class:paddle::ParameterOptimizer
fixed_seq_length	gserver/tests/test_RecurrentLayer.cpp	/^DECLARE_int32(fixed_seq_length);$/;"	v
forEachLayer	gserver/gradientmachines/NeuralNetwork.h	/^  void forEachLayer(T callback) {$/;"	f	class:paddle::NeuralNetwork
forEachType	utils/ClassRegistrar.h	/^  inline void forEachType(T callback) {$/;"	f	class:paddle::ClassRegistrar
forceStop	utils/Thread.h	/^  void forceStop() {$/;"	f	class:paddle::MultiThreadWorker
forceStopLoader	gserver/dataproviders/DataProviderGroup.h	/^void DataProviderGroup<T>::forceStopLoader() {$/;"	f	class:paddle::DataProviderGroup
format	cuda/include/hl_base.h	/^  hl_matrix_format_t format;$/;"	m	struct:__anon10
format	gserver/tests/LayerGradUtil.h	/^  string format;$/;"	m	struct:paddle::ParaSparse
format	math/tests/test_SparseMatrix.cpp	/^  SparseFormat format;$/;"	m	struct:MatrixPara	file:
format	trainer/tests/gen_proto_data.py	/^    format='[%(levelname)s %(asctime)s %(filename)s:%(lineno)s] %(message)s', )$/;"	v
format_	function/BufferArg.h	/^  SparseDataFormat format_;$/;"	m	class:paddle::SparseMatrixArg
format_	math/CpuSparseMatrix.h	/^  SparseFormat format_;       \/* matrix format *\/$/;"	m	class:paddle::CpuSparseMatrix
format_	math/SparseMatrix.h	/^  SparseFormat format_;$/;"	m	class:paddle::GpuSparseMatrix
format_	parameter/Parameter.h	/^  SparseFormat format_;$/;"	m	class:paddle::Parameter
forward	api/GradientMachine.cpp	/^void GradientMachine::forward(const Arguments& inArgs,$/;"	f	class:GradientMachine
forward	cuda/include/hl_activation_functions.h	/^  typedef T (*forward)(T);$/;"	t	class:hppl::Active
forward	cuda/include/hl_activation_functions.h	/^static __device__ Active<real>::forward forward[] = HPPL_ACTIVE_FUNCTION;$/;"	m	namespace:hppl::gpu
forward	gserver/activations/ActivationFunction.cpp	/^  Error __must_check forward(Argument& act) {$/;"	f	class:paddle::IdentityActivation
forward	gserver/activations/ActivationFunction.cpp	/^Error __must_check forward(Argument& act) {$/;"	f	namespace:paddle
forward	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::forward(const std::vector<Argument>& inArgs,$/;"	f	class:paddle::MultiGradientMachine
forward	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::forward() {$/;"	f	class:paddle::TrainerThread
forward	gserver/gradientmachines/MultiNetwork.cpp	/^void MultiNetwork::forward(const std::vector<Argument>& inArgs,$/;"	f	class:paddle::MultiNetwork
forward	gserver/gradientmachines/NeuralNetwork.cpp	/^void NeuralNetwork::forward(const std::vector<Argument>& inArgs,$/;"	f	class:paddle::NeuralNetwork
forward	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^void ParallelNeuralNetwork::forward(const std::vector<Argument>& inArgs,$/;"	f	class:paddle::ParallelNeuralNetwork
forward	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::forward(const std::vector<Argument>& inArgs,$/;"	f	class:paddle::RecurrentGradientMachine
forward	gserver/layers/AddtoLayer.cpp	/^void AddtoLayer::forward(PassType passType) {$/;"	f	class:paddle::AddtoLayer
forward	gserver/layers/AgentLayer.cpp	/^void AgentLayer::forward(PassType passType) {$/;"	f	class:paddle::AgentLayer
forward	gserver/layers/AgentLayer.cpp	/^void GatherAgentLayer::forward(PassType passType) {$/;"	f	class:paddle::GatherAgentLayer
forward	gserver/layers/AgentLayer.cpp	/^void ScatterAgentLayer::forward(PassType passType) {$/;"	f	class:paddle::ScatterAgentLayer
forward	gserver/layers/AgentLayer.cpp	/^void SequenceAgentLayer::forward(PassType passType) {$/;"	f	class:paddle::SequenceAgentLayer
forward	gserver/layers/AgentLayer.cpp	/^void SequenceGatherAgentLayer::forward(PassType passType) {$/;"	f	class:paddle::SequenceGatherAgentLayer
forward	gserver/layers/AgentLayer.cpp	/^void SequenceScatterAgentLayer::forward(PassType passType) {$/;"	f	class:paddle::SequenceScatterAgentLayer
forward	gserver/layers/AverageLayer.cpp	/^void AverageLayer::forward(PassType passType) {$/;"	f	class:paddle::AverageLayer
forward	gserver/layers/BatchNormalizationLayer.cpp	/^void BatchNormalizationLayer::forward(PassType passType) {$/;"	f	class:paddle::BatchNormalizationLayer
forward	gserver/layers/BilinearInterpLayer.cpp	/^void BilinearInterpLayer::forward(PassType passType) {$/;"	f	class:paddle::BilinearInterpLayer
forward	gserver/layers/BlockExpandLayer.cpp	/^void BlockExpandLayer::forward(PassType passType) {$/;"	f	class:paddle::BlockExpandLayer
forward	gserver/layers/CRFDecodingLayer.cpp	/^void CRFDecodingLayer::forward(PassType passType) {$/;"	f	class:paddle::CRFDecodingLayer
forward	gserver/layers/CRFLayer.cpp	/^void CRFLayer::forward(PassType passType) {$/;"	f	class:paddle::CRFLayer
forward	gserver/layers/CTCLayer.cpp	/^void CTCLayer::forward(PassType passType) {$/;"	f	class:paddle::CTCLayer
forward	gserver/layers/ConcatenateLayer.cpp	/^void ConcatenateLayer2::forward(PassType passType) {$/;"	f	class:paddle::ConcatenateLayer2
forward	gserver/layers/ConcatenateLayer.cpp	/^void ConcatenateLayer::forward(PassType passType) {$/;"	f	class:paddle::ConcatenateLayer
forward	gserver/layers/ContextProjection.cpp	/^void ContextProjection::forward() {$/;"	f	class:paddle::ContextProjection
forward	gserver/layers/ConvOperator.cpp	/^void ConvOperator::forward() {$/;"	f	class:paddle::ConvOperator
forward	gserver/layers/ConvProjection.cpp	/^void ConvProjection::forward() {$/;"	f	class:paddle::ConvProjection
forward	gserver/layers/ConvShiftLayer.cpp	/^void ConvShiftLayer::forward(PassType passType) {$/;"	f	class:paddle::ConvShiftLayer
forward	gserver/layers/ConvexCombinationLayer.cpp	/^void ConvexCombinationLayer::forward(PassType passType) {$/;"	f	class:paddle::ConvexCombinationLayer
forward	gserver/layers/CosSimLayer.cpp	/^void CosSimLayer::forward(PassType passType) {$/;"	f	class:paddle::CosSimLayer
forward	gserver/layers/CosSimVecMatLayer.cpp	/^void CosSimVecMatLayer::forward(PassType passType) {$/;"	f	class:paddle::CosSimVecMatLayer
forward	gserver/layers/CostLayer.cpp	/^void CostLayer::forward(PassType passType) {$/;"	f	class:paddle::CostLayer
forward	gserver/layers/CostLayer.cpp	/^void LambdaCost::forward(PassType passType) {$/;"	f	class:paddle::LambdaCost
forward	gserver/layers/CostLayer.cpp	/^void RankingCost::forward(PassType passType) {$/;"	f	class:paddle::RankingCost
forward	gserver/layers/CudnnBatchNormLayer.cpp	/^void CudnnBatchNormLayer::forward(PassType passType) {$/;"	f	class:paddle::CudnnBatchNormLayer
forward	gserver/layers/CudnnConvLayer.cpp	/^void CudnnConvLayer::forward(PassType passType) {$/;"	f	class:paddle::CudnnConvLayer
forward	gserver/layers/CudnnPoolLayer.cpp	/^void CudnnPoolLayer::forward(PassType passType) {$/;"	f	class:paddle::CudnnPoolLayer
forward	gserver/layers/DataNormLayer.cpp	/^void DataNormLayer::forward(PassType passType) {$/;"	f	class:paddle::DataNormLayer
forward	gserver/layers/DotMulOperator.cpp	/^void DotMulOperator::forward() {$/;"	f	class:paddle::DotMulOperator
forward	gserver/layers/DotMulProjection.cpp	/^void DotMulProjection::forward() {$/;"	f	class:paddle::DotMulProjection
forward	gserver/layers/ExpandConvLayer.cpp	/^void ExpandConvLayer::forward(PassType passType) {$/;"	f	class:paddle::ExpandConvLayer
forward	gserver/layers/ExpandConvTransLayer.cpp	/^void ExpandConvTransLayer::forward(PassType passType) {$/;"	f	class:paddle::ExpandConvTransLayer
forward	gserver/layers/ExpandLayer.cpp	/^void ExpandLayer::forward(PassType passType) {$/;"	f	class:paddle::ExpandLayer
forward	gserver/layers/FeatureMapExpandLayer.cpp	/^void FeatureMapExpandLayer::forward(PassType passType) {$/;"	f	class:paddle::FeatureMapExpandLayer
forward	gserver/layers/FullMatrixProjection.cpp	/^void FullMatrixProjection::forward() {$/;"	f	class:paddle::FullMatrixProjection
forward	gserver/layers/FullyConnectedLayer.cpp	/^void FullyConnectedLayer::forward(PassType passType) {$/;"	f	class:paddle::FullyConnectedLayer
forward	gserver/layers/GatedRecurrentLayer.cpp	/^void GatedRecurrentLayer::forward(PassType passType) {$/;"	f	class:paddle::GatedRecurrentLayer
forward	gserver/layers/GruCompute.cpp	/^void GruCompute::forward<0>(hl_gru_value value, int frameSize, int batchSize) {$/;"	f	class:paddle::GruCompute
forward	gserver/layers/GruStepLayer.cpp	/^void GruStepLayer::forward(PassType passType) {$/;"	f	class:paddle::GruStepLayer
forward	gserver/layers/HierarchicalSigmoidLayer.cpp	/^void HierarchicalSigmoidLayer::forward(PassType passType) {$/;"	f	class:paddle::HierarchicalSigmoidLayer
forward	gserver/layers/IdentityProjection.cpp	/^void IdentityOffsetProjection::forward() {$/;"	f	class:paddle::IdentityOffsetProjection
forward	gserver/layers/IdentityProjection.cpp	/^void IdentityProjection::forward() { out_->value->add(*in_->value); }$/;"	f	class:paddle::IdentityProjection
forward	gserver/layers/InterpolationLayer.cpp	/^void InterpolationLayer::forward(PassType passType) {$/;"	f	class:paddle::InterpolationLayer
forward	gserver/layers/Layer.h	/^  virtual void forward(PassType passType) {$/;"	f	class:paddle::Layer
forward	gserver/layers/LinearChainCRF.cpp	/^real LinearChainCRF::forward(real* x, int* s, int length) {$/;"	f	class:paddle::LinearChainCRF
forward	gserver/layers/LinearChainCTC.cpp	/^real LinearChainCTC::forward(real* softmaxSeq,$/;"	f	class:paddle::LinearChainCTC
forward	gserver/layers/LstmLayer.cpp	/^void LstmLayer::forward(PassType passType) {$/;"	f	class:paddle::LstmLayer
forward	gserver/layers/LstmStepLayer.cpp	/^void LstmStepLayer::forward(PassType passType) {$/;"	f	class:paddle::LstmStepLayer
forward	gserver/layers/MDLstmLayer.cpp	/^void MDLstmLayer::forward(PassType passType) {$/;"	f	class:paddle::MDLstmLayer
forward	gserver/layers/MaxLayer.cpp	/^void MaxLayer::forward(PassType passType) {$/;"	f	class:paddle::MaxLayer
forward	gserver/layers/MaxOutLayer.cpp	/^void MaxOutLayer::forward(PassType passType) {$/;"	f	class:paddle::MaxOutLayer
forward	gserver/layers/MixedLayer.cpp	/^void MixedLayer::forward(PassType passType) {$/;"	f	class:paddle::MixedLayer
forward	gserver/layers/MultiplexLayer.cpp	/^void MultiplexLayer::forward(PassType passType) {$/;"	f	class:paddle::MultiplexLayer
forward	gserver/layers/NormProjectionLayer.cpp	/^void CMRProjectionNormLayer::forward(PassType passType) {$/;"	f	class:paddle::CMRProjectionNormLayer
forward	gserver/layers/Operator.h	/^  void forward(std::vector<const Argument*> ins,$/;"	f	class:paddle::Operator
forward	gserver/layers/OuterProdLayer.cpp	/^void OuterProdLayer::forward(PassType passType) {$/;"	f	class:paddle::OuterProdLayer
forward	gserver/layers/PadLayer.cpp	/^void PadLayer::forward(PassType passType) {$/;"	f	class:paddle::PadLayer
forward	gserver/layers/ParameterReluLayer.cpp	/^void ParameterReluLayer::forward(PassType passType) {$/;"	f	class:paddle::ParameterReluLayer
forward	gserver/layers/PoolProjection.cpp	/^void AvgPoolProjection::forward() {$/;"	f	class:paddle::AvgPoolProjection
forward	gserver/layers/PoolProjection.cpp	/^void MaxPoolProjection::forward() {$/;"	f	class:paddle::MaxPoolProjection
forward	gserver/layers/PoolProjectionLayer.cpp	/^void PoolProjectionLayer::forward(PassType passType) {$/;"	f	class:paddle::PoolProjectionLayer
forward	gserver/layers/PowerLayer.cpp	/^void PowerLayer::forward(PassType passType) {$/;"	f	class:paddle::PowerLayer
forward	gserver/layers/PrintLayer.cpp	/^void PrintLayer::forward(PassType passType) {$/;"	f	class:paddle::PrintLayer
forward	gserver/layers/PriorBox.cpp	/^void PriorBoxLayer::forward(PassType passType) {$/;"	f	class:paddle::PriorBoxLayer
forward	gserver/layers/Projection.h	/^  void forward(const Argument* in, const Argument* out, PassType passType) {$/;"	f	class:paddle::Projection
forward	gserver/layers/RecurrentLayer.cpp	/^void RecurrentLayer::forward(PassType passType) {$/;"	f	class:paddle::RecurrentLayer
forward	gserver/layers/ResizeLayer.cpp	/^void ResizeLayer::forward(PassType passType) {$/;"	f	class:paddle::ResizeLayer
forward	gserver/layers/RotateLayer.cpp	/^void RotateLayer::forward(PassType passType) {$/;"	f	class:paddle::RotateLayer
forward	gserver/layers/ScalingLayer.cpp	/^void ScalingLayer::forward(PassType passType) {$/;"	f	class:paddle::ScalingLayer
forward	gserver/layers/ScalingProjection.cpp	/^  void forward() {$/;"	f	class:paddle::ScalingProjection
forward	gserver/layers/SelectiveFullyConnectedLayer.cpp	/^void SelectiveFullyConnectedLayer::forward(PassType passType) {$/;"	f	class:paddle::SelectiveFullyConnectedLayer
forward	gserver/layers/SequenceConcatLayer.cpp	/^void SequenceConcatLayer::forward(PassType passType) {$/;"	f	class:paddle::SequenceConcatLayer
forward	gserver/layers/SequenceLastInstanceLayer.cpp	/^void SequenceLastInstanceLayer::forward(PassType passType) {$/;"	f	class:paddle::SequenceLastInstanceLayer
forward	gserver/layers/SequencePoolLayer.cpp	/^void SequencePoolLayer::forward(PassType passType) {$/;"	f	class:paddle::SequencePoolLayer
forward	gserver/layers/SequenceReshapeLayer.cpp	/^void SequenceReshapeLayer::forward(PassType passType) {$/;"	f	class:paddle::SequenceReshapeLayer
forward	gserver/layers/SlopeInterceptLayer.cpp	/^void SlopeInterceptLayer::forward(PassType passType) {$/;"	f	class:paddle::SlopeInterceptLayer
forward	gserver/layers/SpatialPyramidPoolLayer.cpp	/^void SpatialPyramidPoolLayer::forward(PassType passType) {$/;"	f	class:paddle::SpatialPyramidPoolLayer
forward	gserver/layers/SubSequenceLayer.cpp	/^void SubSequenceLayer::forward(PassType passType) {$/;"	f	class:paddle::SubSequenceLayer
forward	gserver/layers/SumToOneNormLayer.cpp	/^void SumToOneNormLayer::forward(PassType passType) {$/;"	f	class:paddle::SumToOneNormLayer
forward	gserver/layers/TableProjection.cpp	/^void TableProjection::forward() {$/;"	f	class:paddle::TableProjection
forward	gserver/layers/TensorLayer.cpp	/^void TensorLayer::forward(PassType passType) {$/;"	f	class:paddle::TensorLayer
forward	gserver/layers/TransLayer.cpp	/^void TransLayer::forward(PassType passType) {$/;"	f	class:paddle::TransLayer
forward	gserver/layers/TransposedFullMatrixProjection.cpp	/^void TransposedFullMatrixProjection::forward() {$/;"	f	class:paddle::TransposedFullMatrixProjection
forward	gserver/layers/ValidationLayer.cpp	/^void ValidationLayer::forward(PassType passType) {$/;"	f	class:paddle::ValidationLayer
forward	gserver/layers/WarpCTCLayer.cpp	/^void WarpCTCLayer::forward(PassType passType) {$/;"	f	class:paddle::WarpCTCLayer
forward	gserver/tests/test_RecurrentLayer.cpp	/^  void forward() {$/;"	f	class:TestRecurrentLayer
forwardActivation	gserver/layers/Layer.cpp	/^void Layer::forwardActivation() {$/;"	f	class:paddle::Layer
forwardBackward	api/GradientMachine.cpp	/^void GradientMachine::forwardBackward(const Arguments& inArgs,$/;"	f	class:GradientMachine
forwardBackward	gserver/gradientmachines/GradientMachine.h	/^  virtual void forwardBackward(const std::vector<Argument>& inArgs,$/;"	f	class:paddle::GradientMachine
forwardBackward	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::forwardBackward(const std::vector<Argument>& inArgs,$/;"	f	class:paddle::MultiGradientMachine
forwardBackward	gserver/gradientmachines/MultiNetwork.cpp	/^void MultiNetwork::forwardBackward(const std::vector<Argument>& inArgs,$/;"	f	class:paddle::MultiNetwork
forwardBackward	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^void ParallelNeuralNetwork::forwardBackward(const std::vector<Argument>& inArgs,$/;"	f	class:paddle::ParallelNeuralNetwork
forwardBackward	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::forwardBackward($/;"	f	class:paddle::RecurrentGradientMachine
forwardBackward	py_paddle/util.py	/^    def forwardBackward(self,$/;"	f	function:__monkeypatch_gradient_machine__
forwardBackwardBatch	trainer/TrainerInternal.cpp	/^void TrainerInternal::forwardBackwardBatch(const std::vector<Argument>& inArgs,$/;"	f	class:paddle::TrainerInternal
forwardBatch	gserver/layers/GatedRecurrentLayer.cpp	/^void GatedRecurrentLayer::forwardBatch(int batchSize,$/;"	f	class:paddle::GatedRecurrentLayer
forwardBatch	gserver/layers/LstmCompute.cpp	/^void LstmCompute::forwardBatch<0>(hl_lstm_value value,$/;"	f	class:paddle::LstmCompute
forwardBatch	gserver/layers/LstmLayer.cpp	/^void LstmLayer::forwardBatch(int batchSize,$/;"	f	class:paddle::LstmLayer
forwardBatch	gserver/layers/RecurrentLayer.cpp	/^void RecurrentLayer::forwardBatch(int batchSize,$/;"	f	class:paddle::RecurrentLayer
forwardBias	gserver/layers/NCELayer.cpp	/^  void forwardBias() {$/;"	f	class:paddle::NCELayer
forwardCost	gserver/layers/NCELayer.cpp	/^  void forwardCost() {$/;"	f	class:paddle::NCELayer
forwardDropOut	gserver/layers/Layer.cpp	/^void Layer::forwardDropOut() {$/;"	f	class:paddle::Layer
forwardFrame	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::forwardFrame(int machineCur) {$/;"	f	class:paddle::RecurrentGradientMachine
forwardGate2OutputSequence	gserver/layers/MDLstmLayer.cpp	/^void MDLstmLayer::forwardGate2OutputSequence(int start,$/;"	f	class:paddle::MDLstmLayer
forwardImp	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::forwardImp(const std::vector<Argument>& inArgs,$/;"	f	class:paddle::MultiGradientMachine
forwardImp	gserver/layers/CTCLayer.cpp	/^void CTCLayer::forwardImp(const Argument& softmaxSeqs,$/;"	f	class:paddle::CTCLayer
forwardImp	gserver/layers/CostLayer.cpp	/^void HuberTwoClass::forwardImp(Matrix& output, Argument& label, Matrix& cost) {$/;"	f	class:paddle::HuberTwoClass
forwardImp	gserver/layers/CostLayer.cpp	/^void MultiBinaryLabelCrossEntropy::forwardImp(Matrix& output,$/;"	f	class:paddle::MultiBinaryLabelCrossEntropy
forwardImp	gserver/layers/CostLayer.cpp	/^void MultiClassCrossEntropy::forwardImp(Matrix& output,$/;"	f	class:paddle::MultiClassCrossEntropy
forwardImp	gserver/layers/CostLayer.cpp	/^void MultiClassCrossEntropyWithSelfNorm::forwardImp(Matrix& output,$/;"	f	class:paddle::MultiClassCrossEntropyWithSelfNorm
forwardImp	gserver/layers/CostLayer.cpp	/^void SoftBinaryClassCrossEntropy::forwardImp(Matrix& output,$/;"	f	class:paddle::SoftBinaryClassCrossEntropy
forwardImp	gserver/layers/CostLayer.cpp	/^void SumOfSquaresCostLayer::forwardImp(Matrix& output,$/;"	f	class:paddle::SumOfSquaresCostLayer
forwardImp	gserver/layers/CostLayer.h	/^  void forwardImp(Matrix& output, Argument& label, Matrix& cost) {$/;"	f	class:paddle::RankingCost
forwardImp	gserver/layers/SamplingIdLayer.cpp	/^  void forwardImp(const Argument& input) {$/;"	f	class:paddle::SamplingIdLayer
forwardImpIn	gserver/layers/CostLayer.cpp	/^void HuberTwoClass::forwardImpIn(Matrix& output,$/;"	f	class:paddle::HuberTwoClass
forwardOneBatch	api/Trainer.cpp	/^bool TrainerPrivate::forwardOneBatch(size_t batchSize) {$/;"	f	class:TrainerPrivate
forwardOneBatch	api/Trainer.cpp	/^void Trainer::forwardOneBatch(size_t batchSize) {$/;"	f	class:Trainer
forwardOneBatch	trainer/Tester.cpp	/^real Tester::forwardOneBatch(const DataBatch& dataBatch,$/;"	f	class:paddle::Tester
forwardOneDataBatch	api/Trainer.cpp	/^void TrainerPrivate::forwardOneDataBatch($/;"	f	class:TrainerPrivate
forwardOneInput	gserver/layers/NCELayer.cpp	/^  void forwardOneInput(int layerId) {$/;"	f	class:paddle::NCELayer
forwardOneSequence	gserver/layers/LstmCompute.cpp	/^void LstmCompute::forwardOneSequence<0>(hl_lstm_value value, int frameSize) {$/;"	f	class:paddle::LstmCompute
forwardOneSequence	gserver/layers/MDLstmLayer.cpp	/^void MDLstmLayer::forwardOneSequence(int start, CoordIterator& coordIter) {$/;"	f	class:paddle::MDLstmLayer
forwardOneSequence	gserver/layers/RecurrentLayer.cpp	/^void RecurrentLayer::forwardOneSequence(int start, int length) {$/;"	f	class:paddle::RecurrentLayer
forwardOutput_	trainer/Trainer.h	/^  std::vector<paddle::Argument> forwardOutput_;$/;"	m	class:paddle::Trainer
forwardSeqParallel	gserver/layers/LstmLayer.cpp	/^void LstmLayer::forwardSeqParallel(int batchSize,$/;"	f	class:paddle::LstmLayer
forwardSequence	gserver/layers/GatedRecurrentLayer.cpp	/^void GatedRecurrentLayer::forwardSequence(int batchSize,$/;"	f	class:paddle::GatedRecurrentLayer
forwardSequence	gserver/layers/LstmLayer.cpp	/^void LstmLayer::forwardSequence(int batchSize,$/;"	f	class:paddle::LstmLayer
forwardSequence	gserver/layers/RecurrentLayer.cpp	/^void RecurrentLayer::forwardSequence(int batchSize,$/;"	f	class:paddle::RecurrentLayer
forwardTest	py_paddle/util.py	/^    def forwardTest(self, inArgs):$/;"	f	function:__monkeypatch_gradient_machine__
forwardVars_	gserver/layers/LinearChainCTC.h	/^  MatrixPtr logActs_, forwardVars_, backwardVars_, gradTerms_;$/;"	m	class:paddle::LinearChainCTC
forward_	gserver/layers/Layer.h	/^  std::vector<std::shared_ptr<FunctionBase>> forward_;$/;"	m	class:paddle::Layer
forward_	gserver/layers/Projection.h	/^  std::vector<std::shared_ptr<FunctionBase>> forward_;$/;"	m	class:paddle::Projection
forwardbackwordTime_	pserver/ParameterClient2.h	/^  uint64_t forwardbackwordTime_;$/;"	m	class:paddle::ParameterClient2
frameForgetGate_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<Argument> frameForgetGate_;$/;"	m	class:paddle::MDLstmLayer	file:
frameGate_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<Argument> frameGate_;$/;"	m	class:paddle::MDLstmLayer	file:
frameHeight	parameter/Argument.h	/^  size_t frameHeight;$/;"	m	struct:paddle::Argument
frameInputGate_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<Argument> frameInputGate_;$/;"	m	class:paddle::MDLstmLayer	file:
frameInputNode_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<Argument> frameInputNode_;$/;"	m	class:paddle::MDLstmLayer	file:
frameOutputGate_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<Argument> frameOutputGate_;$/;"	m	class:paddle::MDLstmLayer	file:
frameOutput_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<Argument> frameOutput_;$/;"	m	class:paddle::MDLstmLayer	file:
frameOutput_	gserver/layers/RecurrentLayer.cpp	/^  std::vector<Argument> frameOutput_;$/;"	m	class:paddle::RecurrentLayer	file:
framePreOutput_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<Argument> framePreOutput_;$/;"	m	class:paddle::MDLstmLayer	file:
frameState_	gserver/layers/MDLstmLayer.cpp	/^  std::vector<Argument> frameState_;$/;"	m	class:paddle::MDLstmLayer	file:
frameWidth	parameter/Argument.h	/^  size_t frameWidth;$/;"	m	struct:paddle::Argument
frames	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::vector<LayerPtr> frames;$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
frames	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::vector<LayerPtr> frames;$/;"	m	struct:paddle::RecurrentGradientMachine::OutFrameLine
frames_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<std::unique_ptr<NeuralNetwork>> frames_;$/;"	m	class:paddle::RecurrentGradientMachine
free	math/Allocator.h	/^  virtual void free(void* ptr) {$/;"	f	class:paddle::CpuAllocator
free	math/Allocator.h	/^  virtual void free(void* ptr) {$/;"	f	class:paddle::CudaHostAllocator
free	math/Allocator.h	/^  virtual void free(void* ptr) {$/;"	f	class:paddle::GpuAllocator
free	math/PoolAllocator.cpp	/^void PoolAllocator::free(void* ptr, size_t size) {$/;"	f	class:paddle::PoolAllocator
freeAll	math/PoolAllocator.cpp	/^void PoolAllocator::freeAll() {$/;"	f	class:paddle::PoolAllocator
freq	utils/BarrierStat.h	/^  uint64_t freq;$/;"	m	struct:paddle::Abstract
full	utils/BarrierStat.h	/^  bool full() { return index_ == size_; }$/;"	f	class:paddle::TimeVectorDelta
full	utils/BarrierStat.h	/^  bool full() { return index_ == size_; }$/;"	f	class:paddle::TimeVectorEnd
fullOutput_	gserver/layers/SelectiveFullyConnectedLayer.h	/^  bool fullOutput_;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
funcRegistrar_	function/Function.cpp	/^ClassRegistrar<FunctionBase> FunctionBase::funcRegistrar_;$/;"	m	class:paddle::FunctionBase	file:
funcRegistrar_	function/Function.h	/^  static ClassRegistrar<FunctionBase> funcRegistrar_;$/;"	m	class:paddle::FunctionBase
fwdAlgo_	gserver/layers/ConvOperator.cpp	/^  int fwdAlgo_, bwdFilterAlgo_, bwdDataAlgo_;$/;"	m	class:paddle::ConvOperator	file:
fwdAlgo_	gserver/layers/ConvProjection.h	/^  int fwdAlgo_;$/;"	m	class:paddle::ConvProjection
fwdLimitBytes_	gserver/layers/ConvOperator.cpp	/^  size_t fwdLimitBytes_, bwdDataLimitBytes_, bwdFilterLimitBytes_;$/;"	m	class:paddle::ConvOperator	file:
fwdLimitBytes_	gserver/layers/ConvProjection.h	/^  size_t fwdLimitBytes_;$/;"	m	class:paddle::ConvProjection
gActivationRegistrar	gserver/activations/ActivationFunction.cpp	/^static ClassRegistrar<ActivationFunction> gActivationRegistrar;$/;"	m	namespace:paddle	file:
gDiyProbHandle	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^static void* gDiyProbHandle = nullptr;$/;"	m	namespace:paddle	file:
gDiyProbMethod	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^static DiyCalcProbCallback gDiyProbMethod = nullptr;$/;"	m	namespace:paddle	file:
gDiyProbStart	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^static DiyStartCalcProbCallback gDiyProbStart = nullptr;$/;"	m	namespace:paddle	file:
gDiyProbStop	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^static DiyStopCalcProbCallback gDiyProbStop = nullptr;$/;"	m	namespace:paddle	file:
gLayerStackTrace	utils/CustomStackTrace.cpp	/^CustomStackTrace<std::string> gLayerStackTrace;$/;"	m	namespace:paddle	file:
gLayerStackTraceMtx	utils/CustomStackTrace.cpp	/^static std::mutex gLayerStackTraceMtx;$/;"	m	namespace:paddle	file:
gNumDevices	trainer/tests/test_CompareSparse.cpp	/^int gNumDevices = 0;$/;"	v
gNumDevices	trainer/tests/test_TrainerOnePass.cpp	/^int gNumDevices = 0;$/;"	v
g_cublasStat	cuda/src/hl_cuda_cublas.cc	/^cublasStatus_t g_cublasStat;$/;"	v
g_cuda_lib_version	cuda/src/hl_cuda_device.cc	/^int g_cuda_lib_version = 0;$/;"	v
g_cudnn_lib_version	cuda/src/hl_cuda_cudnn.cc	/^int g_cudnn_lib_version = 0;$/;"	v
g_device	cuda/src/hl_cuda_device.cc	/^hl_device_prop *g_device;                   \/* device info table *\/$/;"	v
g_hookCache_	parameter/ParameterUpdaterHook.cpp	/^    g_hookCache_;$/;"	m	namespace:paddle	file:
g_initFuncs	utils/Util.cpp	/^static InitFuncList* g_initFuncs = nullptr;$/;"	m	namespace:paddle	file:
g_initialized	utils/Util.cpp	/^static bool g_initialized = false;$/;"	m	namespace:paddle	file:
g_onceFlag	utils/Util.cpp	/^static std::once_flag g_onceFlag;$/;"	m	namespace:paddle	file:
g_profileCount	utils/Stat.cpp	/^static unsigned g_profileCount = 0;$/;"	m	namespace:paddle	file:
g_profileMutex	utils/Stat.cpp	/^static std::recursive_mutex g_profileMutex;$/;"	m	namespace:paddle	file:
g_server	pserver/test/test_ParameterServer2.cpp	/^std::unique_ptr<ParameterServer2Tester> g_server;$/;"	v
g_sync_flag	cuda/src/hl_cuda_device.cc	/^__thread bool g_sync_flag = true;$/;"	v
g_system_device_num	cuda/src/hl_cuda_device.cc	/^int g_system_device_num = 0;                \/* system device number *\/$/;"	v
g_warpctcVersion	cuda/src/hl_warpctc_wrap.cc	/^static int g_warpctcVersion = -1;$/;"	v	file:
gamma_	parameter/FirstOrderOptimizer.h	/^  real gamma_;$/;"	m	class:paddle::SparseMomentumParameterOptimizer
gateGrad	cuda/include/hl_base.h	/^  real *gateGrad;$/;"	m	struct:__anon5
gateGrad	cuda/include/hl_base.h	/^  real *gateGrad;$/;"	m	struct:__anon7
gateValue	cuda/include/hl_base.h	/^  real *gateValue;$/;"	m	struct:__anon4
gateValue	cuda/include/hl_base.h	/^  real *gateValue;$/;"	m	struct:__anon6
gateWeight	cuda/include/hl_base.h	/^  real *gateWeight;$/;"	m	struct:__anon6
gateWeightGrad	cuda/include/hl_base.h	/^  real *gateWeightGrad;$/;"	m	struct:__anon7
gateWeight_	gserver/layers/GatedRecurrentLayer.h	/^  std::unique_ptr<Weight> gateWeight_;$/;"	m	class:paddle::GatedRecurrentLayer
gate_	gserver/layers/GatedRecurrentLayer.h	/^  Argument gate_;$/;"	m	class:paddle::GatedRecurrentLayer
gate_	gserver/layers/GruStepLayer.cpp	/^  Argument gate_;$/;"	m	class:paddle::GruStepLayer	file:
gate_	gserver/layers/LstmLayer.h	/^  Argument gate_;$/;"	m	class:paddle::LstmLayer
gate_	gserver/layers/LstmStepLayer.cpp	/^  Argument gate_;$/;"	m	class:paddle::LstmStepLayer	file:
gemm	math/MathFunctions.cpp	/^void gemm<double>(const CBLAS_TRANSPOSE transA,$/;"	f	namespace:paddle
gemm	math/MathFunctions.cpp	/^void gemm<float>(const CBLAS_TRANSPOSE transA,$/;"	f	namespace:paddle
gen	gserver/layers/MultinomialSampler.h	/^  int gen(URNG& g) {$/;"	f	class:paddle::MultinomialSampler
gen1	gserver/layers/MultinomialSampler.h	/^  int gen1(Rand rand) {$/;"	f	class:paddle::MultinomialSampler
genPerturbation	gserver/tests/LayerGradUtil.cpp	/^double genPerturbation(const real* oldGrad, real* newGrad, size_t dim) {$/;"	f	namespace:paddle
genPerturbation	trainer/Trainer.cpp	/^static double genPerturbation(real* d, real* grad, size_t dim) {$/;"	f	namespace:paddle
gen_proto_file	trainer/tests/gen_proto_data.py	/^def gen_proto_file(input_file, dicts, oov_policy, output_file):$/;"	f
gen_sub_seq	gserver/tests/test_PyDataProvider2.py	/^    def gen_sub_seq(l):$/;"	f	function:test_index_sub_seq
generateMDimSequenceData	testing/TestUtil.cpp	/^void generateMDimSequenceData(const ICpuGpuVectorPtr& sequenceStartPositions,$/;"	f	namespace:paddle
generateMDimSequenceData	testing/TestUtil.cpp	/^void generateMDimSequenceData(const IVectorPtr& sequenceStartPositions,$/;"	f	namespace:paddle
generateRotationParams	math/tests/test_perturbation.cpp	/^  void generateRotationParams(real*& gpuAngle) {$/;"	f	class:PerturbationTest
generateScaleParams	math/tests/test_perturbation.cpp	/^  void generateScaleParams(real*& gpuScale) {$/;"	f	class:PerturbationTest
generateSequence	api/SequenceGenerator.cpp	/^ISequenceResults* SequenceGenerator::generateSequence($/;"	f	class:SequenceGenerator
generateSequence	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::generateSequence() {$/;"	f	class:paddle::RecurrentGradientMachine
generateSequenceStartPositions	testing/TestUtil.cpp	/^void generateSequenceStartPositions(size_t batchSize,$/;"	f	namespace:paddle
generateSubSequenceStartPositions	testing/TestUtil.cpp	/^void generateSubSequenceStartPositions($/;"	f	namespace:paddle
generateTestImages	math/tests/test_perturbation.cpp	/^  void generateTestImages(real*& gpuImages) {$/;"	f	class:PerturbationTest
generateTranslationParams	math/tests/test_perturbation.cpp	/^  void generateTranslationParams(int*& gpuCenterR,$/;"	f	class:PerturbationTest
generator_	gserver/dataproviders/PyDataProvider2.cpp	/^  PyObjectPtr generator_;$/;"	m	class:paddle::PyDataProvider2	file:
generator_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  Generator generator_;$/;"	m	class:paddle::RecurrentGradientMachine
get	api/Matrix.cpp	/^float Matrix::get(size_t x, size_t y) const throw(RangeError) {$/;"	f	class:Matrix
get	api/PaddleAPI.h	/^  inline int get(const size_t idx) const throw(RangeError, UnsupportError) {$/;"	f	class:IVector
get	api/Vector.cpp	/^float Vector::get(const size_t idx) const throw(RangeError, UnsupportError) {$/;"	f	class:Vector
get	function/Function.cpp	/^bool FuncConfig::get<bool>(const std::string& key) const {$/;"	f	class:paddle::FuncConfig
get	function/Function.cpp	/^int FuncConfig::get<int>(const std::string& key) const {$/;"	f	class:paddle::FuncConfig
get	function/Function.cpp	/^real FuncConfig::get<real>(const std::string& key) const {$/;"	f	class:paddle::FuncConfig
get	function/Function.cpp	/^size_t FuncConfig::get<size_t>(const std::string& key) const {$/;"	f	class:paddle::FuncConfig
get	math/RowBuffer.h	/^  inline real* get(int row) const {$/;"	f	class:paddle::RowBuffer
get	math/Vector.cpp	/^T CpuVectorT<T>::get(size_t pos) {$/;"	f	class:paddle::CpuVectorT
get	math/Vector.cpp	/^T GpuVectorT<T>::get(size_t pos) {$/;"	f	class:paddle::GpuVectorT
get	parameter/Regularizer.cpp	/^Regularizer* Regularizer::get(const std::vector<ParameterType>& types,$/;"	f	class:paddle::Regularizer
get	pserver/LightNetwork.h	/^  static RdmaClientDaemons* get() {$/;"	f	class:paddle::RdmaClientDaemons
get	trainer/tests/picojson.h	/^inline const value& value::get(const std::string& key) const {$/;"	f	class:picojson::value
get	trainer/tests/picojson.h	/^inline const value& value::get(size_t idx) const {$/;"	f	class:picojson::value
get	trainer/tests/picojson.h	/^inline value& value::get(const std::string& key) {$/;"	f	class:picojson::value
get	trainer/tests/picojson.h	/^inline value& value::get(size_t idx) {$/;"	f	class:picojson::value
get	utils/Stat.h	/^  uint64_t get() const { return total_; }$/;"	f	class:paddle::Timer
get	utils/ThreadLocal.cpp	/^std::default_random_engine& ThreadLocalRandomEngine::get() {$/;"	f	class:paddle::ThreadLocalRandomEngine
get	utils/ThreadLocal.h	/^  T* get() {$/;"	f	class:paddle::ThreadLocalD
get	utils/ThreadLocal.h	/^  T* get(bool createLocal = true) {$/;"	f	class:paddle::ThreadLocal
get	utils/Util.h	/^  std::shared_ptr<VType> get(const KType& key,$/;"	f	class:paddle::WeakKVCache
get1NDelta	utils/BarrierStat.h	/^  struct timeval get1NDelta() const {$/;"	f	class:paddle::TimeVectorEnd
get1NDelta	utils/BarrierStat.h	/^  uint64_t get1NDelta() const {$/;"	f	class:paddle::TimeVectorDelta
getAbsMax	math/Vector.cpp	/^T CpuVectorT<T>::getAbsMax() {$/;"	f	class:paddle::CpuVectorT
getAbsMax	math/Vector.cpp	/^int GpuVectorT<int>::getAbsMax() {$/;"	f	class:paddle::GpuVectorT
getAbsMax	math/Vector.cpp	/^real GpuVectorT<real>::getAbsMax() {$/;"	f	class:paddle::GpuVectorT
getAbsSum	math/Matrix.cpp	/^real CpuMatrix::getAbsSum() {$/;"	f	class:paddle::CpuMatrix
getAbsSum	math/Matrix.cpp	/^real GpuMatrix::getAbsSum() {$/;"	f	class:paddle::GpuMatrix
getAbsSum	math/Matrix.h	/^  virtual real getAbsSum() {$/;"	f	class:paddle::Matrix
getAbsSum	math/Vector.cpp	/^T CpuVectorT<T>::getAbsSum() {$/;"	f	class:paddle::CpuVectorT
getAbsSum	math/Vector.cpp	/^int GpuVectorT<int>::getAbsSum() {$/;"	f	class:paddle::GpuVectorT
getAbsSum	math/Vector.cpp	/^real CpuVectorT<real>::getAbsSum() {$/;"	f	class:paddle::CpuVectorT
getAbsSum	math/Vector.cpp	/^real GpuVectorT<real>::getAbsSum() {$/;"	f	class:paddle::GpuVectorT
getAccum	parameter/ParallelParameter.h	/^  VectorPtr getAccum() { return gradientAccum_; }$/;"	f	class:paddle::AsyncParameter
getAllCount	parameter/Argument.h	/^  int getAllCount() const { return allCount; }$/;"	f	struct:paddle::Argument
getAllData	pserver/BaseClient.h	/^  void getAllData(int clientId,$/;"	f	class:paddle::BaseClient
getAllRegisteredTypes	gserver/activations/ActivationFunction.cpp	/^std::vector<std::string> ActivationFunction::getAllRegisteredTypes() {$/;"	f	class:paddle::ActivationFunction
getAllThreads	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<TrainerThreadPtr>& getAllThreads() { return threads_; }$/;"	f	class:paddle::MultiGradientMachine
getAllocSize	math/MemoryHandle.h	/^  size_t getAllocSize() const { return allocSize_; }$/;"	f	class:paddle::MemoryHandle
getArg	api/PaddleAPIPrivate.h	/^  inline paddle::Argument& getArg(size_t idx) throw(RangeError) {$/;"	f	struct:ArgumentsPrivate
getArgType	function/BufferArg.h	/^  ArgType getArgType() const { return argType_; }$/;"	f	class:paddle::BufferArg
getArgs	utils/PythonUtil.h	/^  SequenceHelper getArgs() { return SequenceHelper(args); }$/;"	f	class:paddle::py::CallableHelper
getAttr	utils/PythonUtil.h	/^  inline PyObject* getAttr(const std::string& field) const {$/;"	f	class:paddle::py::ObjectHelper
getAvgCost	trainer/TrainerInternalConfig.h	/^  inline real getAvgCost() const {$/;"	f	class:paddle::TrainerStats
getBackwardCallback	gserver/gradientmachines/MultiGradientMachine.h	/^  const UpdateCallback& getBackwardCallback() const {$/;"	f	class:paddle::MultiGradientMachine
getBatchSize	api/Arguments.cpp	/^int64_t Arguments::getBatchSize(size_t idx) const throw(RangeError) {$/;"	f	class:Arguments
getBatchSize	gserver/dataproviders/DataProvider.h	/^  int64_t getBatchSize() { return batchSize_; }$/;"	f	class:paddle::DoubleBuffer
getBatchSize	parameter/Argument.h	/^  int64_t getBatchSize() const {$/;"	f	struct:paddle::Argument
getBatchSize	trainer/Trainer.cpp	/^int Trainer::getBatchSize() { return config_->getOptConfig().batch_size(); }$/;"	f	class:paddle::Trainer
getBatchValue	gserver/layers/SequenceToBatch.cpp	/^MatrixPtr SequenceToBatch::getBatchValue(Matrix &batchValue,$/;"	f	class:paddle::SequenceToBatch
getBatchValue	gserver/layers/SequenceToBatch.cpp	/^MatrixPtr SequenceToBatch::getBatchValue(int batchId, int numRows) {$/;"	f	class:paddle::SequenceToBatch
getBatchValue	gserver/layers/SequenceToBatch.h	/^  MatrixPtr getBatchValue() { return batchValue_; }$/;"	f	class:paddle::SequenceToBatch
getBeamSize	gserver/gradientmachines/RecurrentGradientMachine.h	/^  size_t getBeamSize() { return generator_.config.beam_size(); }$/;"	f	class:paddle::RecurrentGradientMachine
getBiasParameter	gserver/layers/Layer.h	/^  const ParameterPtr& getBiasParameter() { return biasParameter_; }$/;"	f	class:paddle::Layer
getBlockId	pserver/ParameterServer2.h	/^  int64_t getBlockId(const ParameterBlock& block) const {$/;"	f	class:paddle::ParameterServer2
getBlockLength	pserver/SocketChannel.h	/^  size_t getBlockLength(size_t i) const {$/;"	f	class:paddle::MsgReader
getBlockNum	gserver/layers/BlockExpandLayer.cpp	/^size_t BlockExpandLayer::getBlockNum() {$/;"	f	class:paddle::BlockExpandLayer
getBlockOffset	pserver/ParameterServer2.h	/^  int64_t getBlockOffset(const ParameterBlock& block) const {$/;"	f	class:paddle::ParameterServer2
getBoolAttr	utils/PythonUtil.h	/^  bool getBoolAttr(const std::string& field, bool* isBoolType = nullptr) const {$/;"	f	class:paddle::py::ObjectHelper
getBuf	api/Parameter.cpp	/^Vector* Parameter::getBuf(ParameterType type) {$/;"	f	class:Parameter
getBuf	math/MemoryHandle.h	/^  void* getBuf() const { return buf_; }$/;"	f	class:paddle::MemoryHandle
getBuf	parameter/Parameter.h	/^  const VectorPtr& getBuf(ParameterType pType) const {$/;"	f	class:paddle::Parameter
getBufs	parameter/Parameter.h	/^  const VectorPtr* getBufs() const { return bufs_; }$/;"	f	class:paddle::Parameter
getBufs	py_paddle/util.py	/^    def getBufs(self):$/;"	f	function:__monkey_patch_parameter__
getChannel	pserver/LightNetwork.h	/^  SocketChannel* getChannel() { return channel_.get(); }$/;"	f	class:paddle::SocketClient
getChannel	pserver/test/SocketTest.cpp	/^  SocketChannel* getChannel() const { return channel_.get(); }$/;"	f	class:SocketClient
getColBuf	function/BufferArg.h	/^  void* getColBuf() const { return col_.data(); }$/;"	f	class:paddle::SparseMatrixArg
getColNum	math/CpuSparseMatrix.h	/^  size_t getColNum(size_t i) const {$/;"	f	class:paddle::CpuSparseMatrix
getColNum	math/SparseMatrix.h	/^  size_t getColNum(size_t x) const { return rows_[x + 1] - rows_[x]; }$/;"	f	class:paddle::GpuSparseMatrix
getColRow	gserver/tests/test_ProtoDataProvider.cpp	/^void getColRow(const Argument& arg,$/;"	f
getColStartIdx	math/CpuSparseMatrix.h	/^  size_t getColStartIdx(size_t i) const {$/;"	f	class:paddle::CpuSparseMatrix
getCols	math/CpuSparseMatrix.h	/^  int* getCols() const { return cols_; }$/;"	f	class:paddle::CpuSparseMatrix
getCols	math/Matrix.h	/^  virtual int* getCols() const {$/;"	f	class:paddle::Matrix
getCols	math/SparseMatrix.h	/^  int* getCols() const {$/;"	f	class:paddle::GpuSparseMatrix
getColumn	math/CpuSparseMatrix.h	/^  real* getColumn(size_t i) const {$/;"	f	class:paddle::CpuSparseMatrix
getConfig	api/PaddleAPIPrivate.h	/^  const paddle::OptimizationConfig& getConfig() {$/;"	f	struct:OptimizationConfigPrivate
getConfig	api/Parameter.cpp	/^ParameterConfig* Parameter::getConfig() {$/;"	f	class:Parameter
getConfig	gserver/dataproviders/DataProvider.h	/^  const DataConfig& getConfig() const { return config_; }$/;"	f	class:paddle::DataProvider
getConfig	gserver/layers/Operator.h	/^  const OperatorConfig& getConfig() const { return config_; }$/;"	f	class:paddle::Operator
getConfig	gserver/layers/SpatialPyramidPoolLayer.cpp	/^ProjectionConfig SpatialPyramidPoolLayer::getConfig(size_t imgSizeW,$/;"	f	class:paddle::SpatialPyramidPoolLayer
getConfig	parameter/Parameter.h	/^  ParameterConfig& getConfig() { return config_; }$/;"	f	class:paddle::Parameter
getConfig	parameter/Parameter.h	/^  const ParameterConfig& getConfig() const { return config_; }$/;"	f	class:paddle::Parameter
getConfig	trainer/Trainer.h	/^  const TrainerConfig& getConfig() const { return config_->getConfig(); }$/;"	f	class:paddle::Trainer
getConfig	trainer/TrainerConfigHelper.cpp	/^const TrainerConfig &TrainerConfigHelper::getConfig() const { return m->conf; }$/;"	f	class:paddle::TrainerConfigHelper
getConfigName	trainer/TrainerConfigHelper.cpp	/^std::string TrainerConfigHelper::getConfigName(bool *ok) const {$/;"	f	class:paddle::TrainerConfigHelper
getConfigNameFromPassId	trainer/TrainerConfigHelper.cpp	/^std::string TrainerConfigHelper::getConfigNameFromPassId($/;"	f	class:paddle::TrainerConfigHelper
getConfigNameFromPath	trainer/TrainerConfigHelper.cpp	/^std::string TrainerConfigHelper::getConfigNameFromPath($/;"	f	class:paddle::TrainerConfigHelper
getConfigPtr	api/ConfigParser.cpp	/^  inline paddle::ParameterConfig* getConfigPtr() {$/;"	f	struct:ParameterConfigPrivate
getConvParams	gserver/layers/ConvOperator.cpp	/^void ConvOperator::getConvParams() {$/;"	f	class:paddle::ConvOperator
getConvParams	gserver/layers/ConvProjection.cpp	/^void ConvProjection::getConvParams() {$/;"	f	class:paddle::ConvProjection
getCostSum	gserver/tests/LayerGradUtil.cpp	/^real getCostSum(LayerPtr& testLayer, MatrixPtr weights) {$/;"	f	namespace:paddle
getCpuAllocator	math/Storage.cpp	/^PoolAllocator* StorageEngine::getCpuAllocator() {$/;"	f	class:paddle::StorageEngine
getCpuFunction	function/FunctionTest.h	/^  std::shared_ptr<FunctionBase> getCpuFunction() const { return cpuFunc_; }$/;"	f	class:paddle::FunctionCompare
getCpuStartPositions	parameter/Argument.h	/^  const int* getCpuStartPositions() const {$/;"	f	struct:paddle::Argument
getCuEvent	gserver/dataproviders/DataProvider.h	/^  hl_event_t getCuEvent() const { return hlEvent_; }$/;"	f	class:paddle::BufferBatch
getCuStream	gserver/dataproviders/DataProvider.h	/^  hl_stream_t getCuStream() const { return hlStream_; }$/;"	f	class:paddle::BufferBatch
getCurrentAvgCost	trainer/TrainerInternalConfig.h	/^  inline real getCurrentAvgCost() const {$/;"	f	class:paddle::TrainerStats
getCurrentTimeStick	cuda/src/hl_time.cc	/^int64_t getCurrentTimeStick() {$/;"	f
getData	api/Matrix.cpp	/^FloatArray Matrix::getData() const {$/;"	f	class:Matrix
getData	api/Vector.cpp	/^FloatArray Vector::getData() const {$/;"	f	class:Vector
getData	api/Vector.cpp	/^IntArray IVector::getData() const {$/;"	f	class:IVector
getData	gserver/tests/test_WarpCTCLayer.cpp	/^const real* getData(const Matrix& matrix) {$/;"	f
getData	math/CpuSparseMatrix.h	/^  const real* getData() const { return getValue(); }$/;"	f	class:paddle::CpuSparseMatrix
getData	math/CpuSparseMatrix.h	/^  real* getData() { return getValue(); }$/;"	f	class:paddle::CpuSparseMatrix
getData	math/Matrix.h	/^  virtual const real* getData() const { return data_; }$/;"	f	class:paddle::Matrix
getData	math/Matrix.h	/^  virtual real* getData() { return data_; }$/;"	f	class:paddle::Matrix
getData	math/SparseMatrix.h	/^  const real* getData() const { return getValue(); }$/;"	f	class:paddle::GpuSparseMatrix
getData	math/SparseMatrix.h	/^  real* getData() { return getValue(); }$/;"	f	class:paddle::GpuSparseMatrix
getData	math/Vector.cpp	/^const T* CpuGpuVectorT<T>::getData(bool useGpu) const {$/;"	f	class:paddle::CpuGpuVectorT
getData	math/Vector.h	/^  T* getData() { return this->data_; }$/;"	f	class:paddle::VectorT
getData	math/Vector.h	/^  const T* getData() const { return this->data_; }$/;"	f	class:paddle::VectorT
getDataBatch	gserver/dataproviders/DataProvider.h	/^  DataBatch* getDataBatch() { return batchData_; }$/;"	f	class:paddle::BufferBatch
getDataConfig	trainer/TrainerConfigHelper.h	/^  const DataConfig& getDataConfig() const {$/;"	f	class:paddle::TrainerConfigHelper
getDataConfigPtr	trainer/TrainerConfigHelper.cpp	/^const DataConfig *TrainerConfigHelper::getDataConfigPtr() const {$/;"	f	class:paddle::TrainerConfigHelper
getDataProvider	trainer/Trainer.h	/^  const DataProviderPtr& getDataProvider() { return dataProvider_; }$/;"	f	class:paddle::Trainer
getDefaultSeed	utils/ThreadLocal.h	/^  static int getDefaultSeed() { return defaultSeed_; }$/;"	f	class:paddle::ThreadLocalRand
getDelta	utils/BarrierStat.h	/^  struct timeval getDelta() const {$/;"	f	class:paddle::TimeVectorEnd
getDelta	utils/BarrierStat.h	/^  uint64_t getDelta() const {$/;"	f	class:paddle::TimeVectorDelta
getDenseParameters	trainer/tests/test_CompareSparse.cpp	/^std::vector<ParameterPtr>& getDenseParameters() {$/;"	f
getDeviceId	gserver/gradientmachines/MultiGradientMachine.h	/^  int getDeviceId() const { return deviceId_; }$/;"	f	class:paddle::TrainerThread
getDeviceId	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  int getDeviceId() const { return deviceId_; }$/;"	f	class:paddle::ParallelThread
getDeviceId	gserver/layers/Layer.h	/^  int getDeviceId() const { return deviceId_; }$/;"	f	class:paddle::Layer
getDeviceId	parameter/Parameter.h	/^  int getDeviceId() const { return deviceId_; }$/;"	f	class:paddle::Parameter
getDiffAndPrint	gserver/tests/LayerGradUtil.cpp	/^real getDiffAndPrint(real newCost1,$/;"	f	namespace:paddle
getDouble	utils/PythonUtil.h	/^  inline double getDouble(size_t i) const {$/;"	f	class:paddle::py::SequenceHelper
getElement	math/Matrix.cpp	/^real CpuMatrix::getElement(size_t x, size_t y) const {$/;"	f	class:paddle::CpuMatrix
getElement	math/Matrix.cpp	/^real GpuMatrix::getElement(size_t x, size_t y) const {$/;"	f	class:paddle::GpuMatrix
getElement	math/Matrix.h	/^  virtual real getElement(size_t x, size_t y) const {$/;"	f	class:paddle::Matrix
getElement	math/Vector.cpp	/^T CpuGpuVectorT<T>::getElement(size_t i) const {$/;"	f	class:paddle::CpuGpuVectorT
getElement	math/Vector.cpp	/^T GpuVectorT<T>::getElement(size_t i) const {$/;"	f	class:paddle::GpuVectorT
getElement	math/Vector.h	/^  virtual T getElement(size_t i) const { return this->getData()[i]; }$/;"	f	class:paddle::CpuVectorT
getElementCnt	math/Matrix.h	/^  size_t getElementCnt() const { return elementCnt_; }$/;"	f	class:paddle::Matrix
getElements	function/TensorShape.h	/^  size_t getElements() const { return nelements_; }$/;"	f	class:paddle::TensorShape
getFinalPaths	gserver/gradientmachines/RecurrentGradientMachine.h	/^  const std::vector<std::vector<Path>>& getFinalPaths() const {$/;"	f	class:paddle::RecurrentGradientMachine
getFormat	math/CpuSparseMatrix.h	/^  SparseFormat getFormat() const { return format_; }$/;"	f	class:paddle::CpuSparseMatrix
getFormat	math/Matrix.h	/^  virtual SparseFormat getFormat() const {$/;"	f	class:paddle::Matrix
getFormat	math/SparseMatrix.h	/^  SparseFormat getFormat() const { return format_; }$/;"	f	class:paddle::GpuSparseMatrix
getFormat	parameter/Parameter.h	/^  SparseFormat getFormat() { return format_; }$/;"	f	class:paddle::Parameter
getForwardOutput	api/Trainer.cpp	/^Arguments* Trainer::getForwardOutput() {$/;"	f	class:Trainer
getForwardOutput	api/Trainer.cpp	/^std::vector<paddle::Argument>& TrainerPrivate::getForwardOutput() {$/;"	f	class:TrainerPrivate
getForwardOutput	py_paddle/util.py	/^    def getForwardOutput(self):$/;"	f	function:__monkey_patch_trainer__
getFrameHeight	parameter/Argument.h	/^  size_t getFrameHeight() const { return frameHeight; }$/;"	f	struct:paddle::Argument
getFrameWidth	parameter/Argument.h	/^  size_t getFrameWidth() const { return frameWidth; }$/;"	f	struct:paddle::Argument
getGenBatchSize	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^size_t RecurrentGradientMachine::getGenBatchSize() {$/;"	f	class:paddle::RecurrentGradientMachine
getGlobalSyncThreadPool	utils/Util.cpp	/^SyncThreadPool* getGlobalSyncThreadPool() {$/;"	f	namespace:paddle
getGpuAllocator	math/Storage.cpp	/^PoolAllocator* StorageEngine::getGpuAllocator(int deviceId) {$/;"	f	class:paddle::StorageEngine
getGpuFunction	function/FunctionTest.h	/^  std::shared_ptr<FunctionBase> getGpuFunction() const { return gpuFunc_; }$/;"	f	class:paddle::FunctionCompare
getGradBuf	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<GradBuffer>& getGradBuf(int threadId) {$/;"	f	class:paddle::MultiGradientMachine
getGradientMachine	gserver/gradientmachines/MultiGradientMachine.h	/^  GradientMachine* getGradientMachine() { return gradientMachine_.get(); }$/;"	f	class:paddle::TrainerThread
getGradientMachine	trainer/Trainer.h	/^  const GradientMachinePtr& getGradientMachine() {$/;"	f	class:paddle::Trainer
getGradientMachine	trainer/TrainerInternal.h	/^  inline const GradientMachinePtr& getGradientMachine() const {$/;"	f	class:paddle::TrainerInternal
getGradientSegments	parameter/Parameter.h	/^  std::vector<Segment>& getGradientSegments() { return gradSegments_; }$/;"	f	class:paddle::Parameter
getHeader	gserver/tests/pyDataProvider.py	/^    def getHeader(self):$/;"	m	class:SimpleDataProvider
getHeader	gserver/tests/pyDataProvider.py	/^    def getHeader(self):$/;"	m	class:SimpleNestDataProvider
getHeight	api/Matrix.cpp	/^size_t Matrix::getHeight() const { return m->mat->getHeight(); }$/;"	f	class:Matrix
getHeight	math/Matrix.h	/^  size_t getHeight() const { return height_; }$/;"	f	class:paddle::Matrix
getHeight	math/TensorApply.h	/^  INLINE size_t getHeight() const { return expr1_.getHeight(); }$/;"	f	class:paddle::TensorApply
getHeight	math/TensorApply.h	/^  INLINE size_t getHeight() const { return expr_.getHeight(); }$/;"	f	class:paddle::TensorApply
getHeight	math/TensorApply.h	/^  INLINE size_t getHeight() const { return height_; }$/;"	f	class:paddle::TensorApply
getHeight	math/TensorApply.h	/^  INLINE size_t getHeight() const { return rhs_.getHeight(); }$/;"	f	class:paddle::TensorApply
getHeight	math/TensorAssign.h	/^  INLINE size_t getHeight() const { return rhs_.getHeight(); }$/;"	f	class:paddle::TensorAssignOp
getID	api/Parameter.cpp	/^size_t Parameter::getID() const { return m->getPtr()->getID(); }$/;"	f	class:Parameter
getID	parameter/Parameter.h	/^  size_t getID() const { return config_.para_id(); }$/;"	f	class:paddle::Parameter
getIdBuf	function/BufferArg.h	/^  void* getIdBuf() const { return startPositions_.data(); }$/;"	f	class:paddle::SequenceArg
getIds	math/SparseRowMatrix.h	/^  std::vector<uint32_t>& getIds(size_t threadId) { return idsArray_[threadId]; }$/;"	f	class:paddle::SparseRowIdsCpuMatrix
getInArgs	gserver/gradientmachines/MultiGradientMachine.h	/^  const std::vector<Argument>& getInArgs() { return inArgs_; }$/;"	f	class:paddle::MultiGradientMachine
getIndexDictHandle	math/SparseRowMatrix.h	/^  const IndexDictPtr& getIndexDictHandle() const { return indexDictHandle_; }$/;"	f	class:paddle::SparseRowCpuMatrix
getInfoLayer	gserver/layers/ValidationLayer.h	/^  LayerPtr getInfoLayer() {$/;"	f	class:paddle::ValidationLayer
getInitMean	parameter/Parameter.h	/^  float getInitMean() const { return config_.initial_mean(); }$/;"	f	class:paddle::Parameter
getInitStandardDeviation	parameter/Parameter.h	/^  float getInitStandardDeviation() const { return config_.initial_std(); }$/;"	f	class:paddle::Parameter
getInput	gserver/layers/Layer.h	/^  const Argument& getInput(const Layer& inputLayer) const {$/;"	f	class:paddle::Layer
getInput	gserver/layers/Layer.h	/^  const Argument& getInput(size_t inputIndex) const {$/;"	f	class:paddle::Layer
getInputGrad	gserver/layers/Layer.h	/^  const MatrixPtr& getInputGrad(const Layer& inputLayer) {$/;"	f	class:paddle::Layer
getInputGrad	gserver/layers/Layer.h	/^  const MatrixPtr& getInputGrad(int inputIndex) {$/;"	f	class:paddle::Layer
getInputLabel	gserver/layers/Layer.h	/^  const IVectorPtr& getInputLabel(const Layer& inputLayer) {$/;"	f	class:paddle::Layer
getInputValue	gserver/layers/Layer.h	/^  const MatrixPtr& getInputValue(const Layer& inputLayer) {$/;"	f	class:paddle::Layer
getInputValue	gserver/layers/Layer.h	/^  const MatrixPtr& getInputValue(int inputIndex) {$/;"	f	class:paddle::Layer
getInstance	pserver/LightNetwork.h	/^  static void getInstance() {$/;"	f	class:paddle::RdmaClientDaemons
getIntAttr	utils/PythonUtil.h	/^  T getIntAttr(const std::string& field, bool* ok = nullptr) const {$/;"	f	class:paddle::py::ObjectHelper
getIntAttrWithError	utils/PythonUtil.h	/^  T getIntAttrWithError(const std::string& field) const {$/;"	f	class:paddle::py::ObjectHelper
getIntBuf	parameter/Parameter.h	/^  const IVectorPtr& getIntBuf(ParameterType pType) { return intBufs_[pType]; }$/;"	f	class:paddle::Parameter
getInternalArgumentsPtr	api/Arguments.cpp	/^void* Arguments::getInternalArgumentsPtr() const { return &m->outputs; }$/;"	f	class:Arguments
getInverse	math/Matrix.cpp	/^MatrixPtr CpuMatrix::getInverse() {$/;"	f	class:paddle::CpuMatrix
getInverse	math/Matrix.cpp	/^MatrixPtr GpuMatrix::getInverse() {$/;"	f	class:paddle::GpuMatrix
getInverse	math/Matrix.h	/^  virtual MatrixPtr getInverse() {$/;"	f	class:paddle::Matrix
getIpAddr	pserver/LightNetwork.cpp	/^std::string getIpAddr(std::string &device) {$/;"	f	namespace:paddle
getLabelLayer	gserver/layers/CostLayer.h	/^  LayerPtr getLabelLayer() { return inputLayers_[1]; }$/;"	f	class:paddle::CostLayer
getLabelLayer	gserver/layers/CostLayer.h	/^  LayerPtr getLabelLayer() { return inputLayers_[2]; }$/;"	f	class:paddle::RankingCost
getLabelLayer	gserver/layers/HierarchicalSigmoidLayer.h	/^  LayerPtr getLabelLayer() { return inputLayers_.back(); }$/;"	f	class:paddle::HierarchicalSigmoidLayer
getLabelLayer	gserver/layers/ValidationLayer.h	/^  LayerPtr getLabelLayer() { return inputLayers_[1]; }$/;"	f	class:paddle::ValidationLayer
getLastTrainerId	utils/BarrierStat.h	/^  int32_t getLastTrainerId() const { return trainerIds_[index_ - 1]; }$/;"	f	class:paddle::TimeVectorEnd
getLayer	gserver/gradientmachines/NeuralNetwork.h	/^  const LayerPtr& getLayer(const std::string& layerName) const {$/;"	f	class:paddle::NeuralNetwork
getLayerOutput	api/GradientMachine.cpp	/^Matrix* GradientMachine::getLayerOutput(const std::string& layerName) const$/;"	f	class:GradientMachine
getLayerOutput	api/Trainer.cpp	/^Matrix* Trainer::getLayerOutput(const std::string& layerName) {$/;"	f	class:Trainer
getLayerOutput	gserver/gradientmachines/NeuralNetwork.cpp	/^MatrixPtr NeuralNetwork::getLayerOutput(const std::string& layerName) {$/;"	f	class:paddle::NeuralNetwork
getLayerOutputs	py_paddle/util.py	/^    def getLayerOutputs(self, layerNames):$/;"	f	function:__monkeypatch_gradient_machine__
getLearnRate	parameter/Parameter.h	/^  float getLearnRate() const { return config_.learning_rate(); }$/;"	f	class:paddle::Parameter
getLearningRate	parameter/ParameterOptimizer.h	/^  real getLearningRate() const { return learningRate_; }$/;"	f	class:paddle::ParameterOptimizer
getLength	math/MatrixBitCode.cpp	/^  inline int getLength() const { return findLastSet(c_) - 1; }$/;"	f	struct:paddle::__anon17::SimpleCode
getLocalIndices	math/SparseRowMatrix.h	/^  std::vector<unsigned int>& getLocalIndices() const {$/;"	f	class:paddle::SparseRowCpuMatrix
getLocalParameter	parameter/ParallelParameter.h	/^  ParameterPtr getLocalParameter() { return localParam_; }$/;"	f	class:paddle::ParallelParameter
getLocalRow	math/SparseRowMatrix.h	/^  real* getLocalRow(size_t row) { return buf_->getWithAutoGrowth(row); }$/;"	f	class:paddle::SparseRowCpuMatrix
getMajorPartners	parameter/ParallelParameter.h	/^  std::vector<ParallelParameterPtr>& getMajorPartners() {$/;"	f	class:paddle::SyncParameter
getMat	parameter/Parameter.h	/^  const MatrixPtr& getMat(ParameterType pType) const { return mats_[pType]; }$/;"	f	class:paddle::Parameter
getMax	math/CpuSparseMatrix.h	/^  virtual real getMax() {$/;"	f	class:paddle::CpuSparseMatrix
getMax	math/Matrix.cpp	/^real CpuMatrix::getMax() {$/;"	f	class:paddle::CpuMatrix
getMax	math/Matrix.cpp	/^real GpuMatrix::getMax() {$/;"	f	class:paddle::GpuMatrix
getMax	math/Matrix.h	/^  virtual real getMax() {$/;"	f	class:paddle::Matrix
getMax	math/Vector.cpp	/^T CpuVectorT<T>::getMax() {$/;"	f	class:paddle::CpuVectorT
getMax	math/Vector.cpp	/^int GpuVectorT<int>::getMax() {$/;"	f	class:paddle::GpuVectorT
getMax	math/Vector.cpp	/^real GpuVectorT<real>::getMax() {$/;"	f	class:paddle::GpuVectorT
getMaxCodeLength	math/MatrixBitCode.cpp	/^  int getMaxCodeLength() const { return findLastSet(numClasses_ - 1); }$/;"	f	struct:paddle::__anon17::SimpleCodeTable
getMaxTrainerId	utils/BarrierStat.h	/^  int32_t getMaxTrainerId() const { return maxTrainerId_; }$/;"	f	class:paddle::TimeVectorDelta
getMemoryHandle	math/Matrix.h	/^  MemoryHandlePtr getMemoryHandle() const { return memoryHandle_; }$/;"	f	class:paddle::Matrix
getMemoryHandle	math/Vector.h	/^  MemoryHandlePtr getMemoryHandle() const { return memoryHandle_; }$/;"	f	class:paddle::VectorT
getMemoryUsage	utils/Util.cpp	/^double getMemoryUsage() {$/;"	f	namespace:paddle
getMidNDelta	utils/BarrierStat.h	/^  struct timeval getMidNDelta() const {$/;"	f	class:paddle::TimeVectorEnd
getMidNDelta	utils/BarrierStat.h	/^  uint64_t getMidNDelta() const {$/;"	f	class:paddle::TimeVectorDelta
getMin	math/CpuSparseMatrix.h	/^  virtual real getMin() {$/;"	f	class:paddle::CpuSparseMatrix
getMin	math/Matrix.cpp	/^real CpuMatrix::getMin() {$/;"	f	class:paddle::CpuMatrix
getMin	math/Matrix.cpp	/^real GpuMatrix::getMin() {$/;"	f	class:paddle::GpuMatrix
getMin	math/Matrix.h	/^  virtual real getMin() {$/;"	f	class:paddle::Matrix
getMin	math/Vector.cpp	/^T CpuVectorT<T>::getMin() {$/;"	f	class:paddle::CpuVectorT
getMin	math/Vector.cpp	/^int GpuVectorT<int>::getMin() {$/;"	f	class:paddle::GpuVectorT
getMin	math/Vector.cpp	/^real GpuVectorT<real>::getMin() {$/;"	f	class:paddle::GpuVectorT
getMinorPartners	parameter/ParallelParameter.h	/^  std::vector<ParallelParameterPtr>& getMinorPartners() {$/;"	f	class:paddle::SyncParameter
getMinus1NDelta	utils/BarrierStat.h	/^  struct timeval getMinus1NDelta() const {$/;"	f	class:paddle::TimeVectorEnd
getMinus1NDelta	utils/BarrierStat.h	/^  uint64_t getMinus1NDelta() const {$/;"	f	class:paddle::TimeVectorDelta
getModelConfig	api/ConfigParser.cpp	/^ModelConfig* TrainerConfig::getModelConfig() const {$/;"	f	class:TrainerConfig
getModelConfig	trainer/TrainerConfigHelper.cpp	/^const ModelConfig &TrainerConfigHelper::getModelConfig() const {$/;"	f	class:paddle::TrainerConfigHelper
getMutableConfig	trainer/TrainerConfigHelper.cpp	/^TrainerConfig &TrainerConfigHelper::getMutableConfig() { return m->conf; }$/;"	f	class:paddle::TrainerConfigHelper
getMutableData	math/Vector.cpp	/^T* CpuGpuVectorT<T>::getMutableData(bool useGpu) {$/;"	f	class:paddle::CpuGpuVectorT
getMutableVector	math/Vector.cpp	/^std::shared_ptr<VectorT<T>>& CpuGpuVectorT<T>::getMutableVector(bool useGpu) {$/;"	f	class:paddle::CpuGpuVectorT
getName	api/Parameter.cpp	/^std::string Parameter::getName() const { return m->getPtr()->getName(); }$/;"	f	class:Parameter
getName	gserver/activations/ActivationFunction.cpp	/^  const std::string& getName() const { return name; }$/;"	f	class:paddle::IdentityActivation
getName	gserver/layers/Layer.h	/^  const std::string& getName() const { return config_.name(); }$/;"	f	class:paddle::Layer
getName	gserver/layers/Projection.h	/^  const std::string& getName() const { return config_.name(); }$/;"	f	class:paddle::Projection
getName	math/Allocator.h	/^  virtual std::string getName() { return "cpu_alloc"; }$/;"	f	class:paddle::CpuAllocator
getName	math/Allocator.h	/^  virtual std::string getName() { return "cuda_host_alloc"; }$/;"	f	class:paddle::CudaHostAllocator
getName	math/Allocator.h	/^  virtual std::string getName() { return "gpu_alloc"; }$/;"	f	class:paddle::GpuAllocator
getName	math/PoolAllocator.h	/^  std::string getName() { return name_; }$/;"	f	class:paddle::PoolAllocator
getName	parameter/Parameter.h	/^  const std::string& getName() const { return config_.name(); }$/;"	f	class:paddle::Parameter
getName	utils/BarrierStat.h	/^  const std::string &getName() { return name_; }$/;"	f	class:paddle::BarrierStatBase
getName	utils/Stat.h	/^  const std::string& getName() const { return name_; }$/;"	f	class:paddle::Stat
getNextBatch	gserver/dataproviders/DataProvider.cpp	/^int64_t DataProvider::getNextBatch(int64_t size, DataBatch* batch) {$/;"	f	class:paddle::DataProvider
getNextBatch	gserver/tests/pyDataProvider.py	/^    def getNextBatch(self, batch_size):$/;"	m	class:SimpleDataProvider
getNextBatch	gserver/tests/pyDataProvider.py	/^    def getNextBatch(self, batch_size):$/;"	m	class:SimpleNestDataProvider
getNextBatchFromBuffer	gserver/dataproviders/DataProvider.cpp	/^int64_t DataProvider::getNextBatchFromBuffer(int64_t size, DataBatch* batch) {$/;"	f	class:paddle::DataProvider
getNextBatchInternal	gserver/dataproviders/DataProvider.cpp	/^int64_t SimpleDataProviderBase::getNextBatchInternal(int64_t size,$/;"	f	class:paddle::SimpleDataProviderBase
getNextBatchInternal	gserver/dataproviders/DataProvider.h	/^  virtual int64_t getNextBatchInternal(int64_t size, DataBatch* batch) {$/;"	f	class:paddle::DummyDataProvider
getNextBatchInternal	gserver/dataproviders/DataProviderGroup.h	/^int64_t DataProviderGroup<T>::getNextBatchInternal(int64_t size,$/;"	f	class:paddle::DataProviderGroup
getNextBatchInternal	gserver/dataproviders/MultiDataProvider.cpp	/^int64_t MultiDataProvider::getNextBatchInternal(int64_t size,$/;"	f	class:paddle::MultiDataProvider
getNextBatchInternal	gserver/dataproviders/ProtoDataProvider.cpp	/^int64_t ProtoDataProvider::getNextBatchInternal(int64_t size,$/;"	f	class:paddle::ProtoDataProvider
getNextBatchInternal	gserver/dataproviders/ProtoDataProvider.cpp	/^int64_t ProtoSequenceDataProvider::getNextBatchInternal(int64_t size,$/;"	f	class:paddle::ProtoSequenceDataProvider
getNextBatchInternal	gserver/dataproviders/PyDataProvider.cpp	/^int64_t PyDataProvider::getNextBatchInternal(int64_t size, DataBatch* batch) {$/;"	f	class:paddle::PyDataProvider
getNextBatchInternal	gserver/dataproviders/PyDataProvider2.cpp	/^  int64_t getNextBatchInternal(int64_t size_, DataBatch* batch) {$/;"	f	class:paddle::PyDataProvider2
getNextBlockLength	pserver/SocketChannel.h	/^  size_t getNextBlockLength() const { return getBlockLength(0); }$/;"	f	class:paddle::MsgReader
getNextPos	gserver/layers/MDLstmLayer.cpp	/^  bool getNextPos(const std::vector<int>& delays,$/;"	f	class:paddle::CoordIterator
getNextSequence	gserver/tests/test_LinearChainCRF.cpp	/^static inline bool getNextSequence(vector<int>& seq, int numClasses) {$/;"	f	file:
getNonStaticParameters	gserver/gradientmachines/GradientMachine.h	/^  std::vector<ParameterPtr>& getNonStaticParameters() {$/;"	f	class:paddle::GradientMachine
getNumBatch	gserver/layers/SequenceToBatch.h	/^  size_t getNumBatch() const { return numBatch_; }$/;"	f	class:paddle::SequenceToBatch
getNumBlocks	pserver/SocketChannel.h	/^  size_t getNumBlocks() const {$/;"	f	class:paddle::MsgReader
getNumDevices	gserver/gradientmachines/MultiGradientMachine.h	/^  int getNumDevices() const { return numDevices_; }$/;"	f	class:paddle::MultiGradientMachine
getNumInputs	function/Function.h	/^  int getNumInputs() const { return numInputs_; }$/;"	f	class:paddle::FunctionBase
getNumLogicalDevices	gserver/gradientmachines/MultiGradientMachine.h	/^  int getNumLogicalDevices() const { return numLogicalDevices_; }$/;"	f	class:paddle::MultiGradientMachine
getNumOutputs	function/Function.h	/^  int getNumOutputs() const { return numOutputs_; }$/;"	f	class:paddle::FunctionBase
getNumProcessed	trainer/TrainerInternalConfig.h	/^  inline int64_t getNumProcessed() const { return this->numProcessed_; }$/;"	f	class:paddle::TrainerStats
getNumSequences	gserver/dataproviders/DataProvider.h	/^  int64_t getNumSequences() const {$/;"	f	class:paddle::DataBatch
getNumSequences	parameter/Argument.h	/^  int64_t getNumSequences() const {$/;"	f	struct:paddle::Argument
getNumStreams	gserver/dataproviders/DataProvider.h	/^  int64_t getNumStreams() const { return data_.size(); }$/;"	f	class:paddle::DataBatch
getNumSubSequences	parameter/Argument.h	/^  int64_t getNumSubSequences() const {$/;"	f	struct:paddle::Argument
getNumThreads	gserver/gradientmachines/MultiGradientMachine.h	/^  int getNumThreads() const { return numThreads_; }$/;"	f	class:paddle::MultiGradientMachine
getNumThreads	utils/Thread.h	/^  size_t getNumThreads() { return workers_.size(); }$/;"	f	class:paddle::SyncThreadPool
getOptConfig	trainer/TrainerConfigHelper.cpp	/^OptimizationConfig &TrainerConfigHelper::getOptConfig() {$/;"	f	class:paddle::TrainerConfigHelper
getOptConfig	trainer/TrainerConfigHelper.cpp	/^const OptimizationConfig &TrainerConfigHelper::getOptConfig() const {$/;"	f	class:paddle::TrainerConfigHelper
getOptimizationConfig	api/ConfigParser.cpp	/^OptimizationConfig* TrainerConfig::getOptimizationConfig() const {$/;"	f	class:TrainerConfig
getOutArgs	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::getOutArgs(std::vector<Argument>* outArgs,$/;"	f	class:paddle::MultiGradientMachine
getOutArgs	gserver/gradientmachines/MultiGradientMachine.h	/^  const std::vector<Argument>& getOutArgs() { return outArgs_; }$/;"	f	class:paddle::TrainerThread
getOutput	gserver/layers/Layer.h	/^  Argument& getOutput(const std::string& str = "") {$/;"	f	class:paddle::Layer
getOutput	gserver/layers/Layer.h	/^  const Argument& getOutput(int deviceId) const {$/;"	f	class:paddle::Layer
getOutputGrad	gserver/layers/Layer.h	/^  const MatrixPtr& getOutputGrad() { return output_.grad; }$/;"	f	class:paddle::Layer
getOutputLabel	gserver/layers/Layer.h	/^  const IVectorPtr& getOutputLabel() { return output_.ids; }$/;"	f	class:paddle::Layer
getOutputLayer	gserver/layers/CostLayer.h	/^  LayerPtr getOutputLayer() { return inputLayers_[0]; }$/;"	f	class:paddle::CostLayer
getOutputLayer	gserver/layers/CostLayer.h	/^  LayerPtr getOutputLayer() { return inputLayers_[0]; }$/;"	f	class:paddle::LambdaCost
getOutputLayer	gserver/layers/CostLayer.h	/^  LayerPtr getOutputLayer(size_t i) { return inputLayers_[i]; }$/;"	f	class:paddle::RankingCost
getOutputLayer	gserver/layers/ValidationLayer.h	/^  LayerPtr getOutputLayer() { return inputLayers_[0]; }$/;"	f	class:paddle::ValidationLayer
getOutputSize	gserver/layers/ExpandConvBaseLayer.cpp	/^size_t ExpandConvBaseLayer::getOutputSize() {$/;"	f	class:paddle::ExpandConvBaseLayer
getOutputSize	gserver/layers/Projection.h	/^  size_t getOutputSize() const { return config_.output_size(); }$/;"	f	class:paddle::Projection
getOutputValue	gserver/layers/Layer.h	/^  const MatrixPtr& getOutputValue() { return output_.value; }$/;"	f	class:paddle::Layer
getPServerParameterGradient	pserver/ParameterClient2.h	/^  PServerVector getPServerParameterGradient() {$/;"	f	class:paddle::ParameterClient2
getPServerParameterValue	pserver/ParameterClient2.h	/^  PServerVector getPServerParameterValue() {$/;"	f	class:paddle::ParameterClient2
getParameter	api/GradientMachine.cpp	/^Parameter* GradientMachine::getParameter(size_t i) throw(RangeError) {$/;"	f	class:GradientMachine
getParameter	pserver/ParameterClient2.h	/^  void getParameter(ParameterType recvParameterType = PARAMETER_VALUE,$/;"	f	class:paddle::ParameterClient2
getParameter	pserver/ParameterServer2.cpp	/^void ParameterServer2::getParameter(const SendParameterRequest& request,$/;"	f	class:paddle::ParameterServer2
getParameterConfig	pserver/ParameterServer2.h	/^  const ParameterConfig& getParameterConfig(const ParameterBlock& block) {$/;"	f	class:paddle::ParameterServer2
getParameterConfig	pserver/ParameterServer2.h	/^  const ParameterConfig& getParameterConfig(int64_t blockId) const {$/;"	f	class:paddle::ParameterServer2
getParameterIds	gserver/gradientmachines/RecurrentGradientMachine.h	/^  const std::vector<int>& getParameterIds() { return parameterIds_; }$/;"	f	class:paddle::RecurrentGradientMachine
getParameterMap	gserver/gradientmachines/NeuralNetwork.h	/^  ParameterMap* getParameterMap() { return &parameterMap_; }$/;"	f	class:paddle::NeuralNetwork
getParameterPtr	parameter/Weight.cpp	/^const ParameterPtr& Weight::getParameterPtr() { return parameter_; }$/;"	f	class:paddle::Weight
getParameterSize	api/GradientMachine.cpp	/^size_t GradientMachine::getParameterSize() const {$/;"	f	class:GradientMachine
getParameterSparse	pserver/ParameterClient2.h	/^  void getParameterSparse($/;"	f	class:paddle::ParameterClient2
getParameterSparse	pserver/ParameterServer2.cpp	/^void ParameterServer2::getParameterSparse(const SendParameterRequest& request,$/;"	f	class:paddle::ParameterServer2
getParameterTypes	api/ParameterOptimizer.cpp	/^std::vector<int> ParameterOptimizer::getParameterTypes() const {$/;"	f	class:ParameterOptimizer
getParameterTypes	parameter/ParameterOptimizer.h	/^  const std::vector<ParameterType>& getParameterTypes() const {$/;"	f	class:paddle::ParameterOptimizer
getParameterTypes	parameter/ParameterUpdaterBase.h	/^  const std::vector<ParameterType>& getParameterTypes() const {$/;"	f	class:paddle::ParameterUpdater
getParameterUpdater	trainer/TrainerInternal.h	/^  inline const std::shared_ptr<ParameterUpdater>& getParameterUpdater() {$/;"	f	class:paddle::TrainerInternal
getParameterUpdaterForTest	trainer/tests/test_TrainerOnePass.cpp	/^  inline const std::shared_ptr<ParameterUpdater>& getParameterUpdaterForTest() {$/;"	f	class:TrainerForTest
getParameterUtilPtr	trainer/Trainer.cpp	/^ParameterUtil* Trainer::getParameterUtilPtr() { return paramUtil_.get(); }$/;"	f	class:paddle::Trainer
getParameters	gserver/gradientmachines/GradientMachine.h	/^  std::vector<ParameterPtr>& getParameters() { return parameters_; }$/;"	f	class:paddle::GradientMachine
getParameters	gserver/gradientmachines/MultiGradientMachine.h	/^  const std::vector<ParameterPtr>& getParameters() { return parameters_; }$/;"	f	class:paddle::TrainerThread
getParameters	gserver/layers/Layer.h	/^  const std::vector<ParameterPtr>& getParameters() { return parameters_; }$/;"	f	class:paddle::Layer
getParameters	py_paddle/util.py	/^    def getParameters(self):$/;"	f	function:__monkeypatch_gradient_machine__
getParametersRemote	parameter/ParameterUpdaterBase.h	/^  virtual void getParametersRemote(bool fullSize = false, bool apply = false) {}$/;"	f	class:paddle::ParameterUpdater
getParametersRemote	parameter/ParameterUpdaterBase.h	/^  virtual void getParametersRemote(bool fullSize, bool apply) {$/;"	f	class:paddle::ParameterUpdaterComposite
getParametersRemote	trainer/RemoteParameterUpdater.cpp	/^void SparseRemoteParameterUpdater::getParametersRemote(bool fullSize,$/;"	f	class:paddle::SparseRemoteParameterUpdater
getPassType	gserver/gradientmachines/MultiGradientMachine.h	/^  PassType getPassType() const { return passType_; }$/;"	f	class:paddle::MultiGradientMachine
getPeerName	pserver/SocketChannel.h	/^  const std::string& getPeerName() const { return peerName_; }$/;"	f	class:paddle::SocketChannel
getPoint	math/Vector.cpp	/^T* GpuVectorT<T>::getPoint(const uint64_t beginPos) {$/;"	f	class:paddle::GpuVectorT
getPoint	math/Vector.h	/^  virtual T* getPoint(const uint64_t beginPos) {$/;"	f	class:paddle::CpuVectorT
getPoolType	gserver/layers/PoolProjection.h	/^  const std::string& getPoolType() const { return poolType_; }$/;"	f	class:paddle::PoolProjection
getPrePos	gserver/layers/MDLstmLayer.cpp	/^  bool getPrePos(const std::vector<int>& delays,$/;"	f	class:paddle::CoordIterator
getPrefetchMatrix	parameter/Parameter.cpp	/^SparsePrefetchRowCpuMatrix* Parameter::getPrefetchMatrix() {$/;"	f	class:paddle::Parameter
getPrev	gserver/layers/Layer.h	/^  const LayerPtr& getPrev(size_t i) { return inputLayers_[i]; }$/;"	f	class:paddle::Layer
getPrevBatchOutput	gserver/layers/LstmLayer.cpp	/^void LstmLayer::getPrevBatchOutput(size_t numSequences) {$/;"	f	class:paddle::LstmLayer
getPrevBatchState	gserver/layers/LstmLayer.cpp	/^void LstmLayer::getPrevBatchState(size_t numSequences) {$/;"	f	class:paddle::LstmLayer
getPtr	api/PaddleAPIPrivate.h	/^  paddle::Parameter* getPtr() {$/;"	f	struct:ParameterPrivate
getRawPtr	api/ConfigParser.cpp	/^void* ParameterConfig::getRawPtr() { return m->getConfigPtr(); }$/;"	f	class:ParameterConfig
getRow	math/Matrix.h	/^  real* getRow(size_t row) { return BaseMatrix::rowBuf(row); }$/;"	f	class:paddle::CpuMatrix
getRow	math/Matrix.h	/^  real* getRow(size_t row) { return BaseMatrix::rowBuf(row); }$/;"	f	class:paddle::GpuMatrix
getRow	math/SparseRowMatrix.h	/^  real* getRow(size_t row) {$/;"	f	class:paddle::CacheRowCpuMatrix
getRow	math/SparseRowMatrix.h	/^  real* getRow(size_t row) {$/;"	f	class:paddle::SparseAutoGrowRowCpuMatrix
getRow	math/SparseRowMatrix.h	/^  real* getRow(size_t row) {$/;"	f	class:paddle::SparseRowCpuMatrix
getRowBuf	function/BufferArg.h	/^  void* getRowBuf() const { return row_.data(); }$/;"	f	class:paddle::SparseMatrixArg
getRowBuf	math/Matrix.h	/^  virtual real* getRowBuf(size_t row) { return getRow(row); }$/;"	f	class:paddle::CpuMatrix
getRowBuf	math/Matrix.h	/^  virtual real* getRowBuf(size_t row) { return getRow(row); }$/;"	f	class:paddle::GpuMatrix
getRowBuf	math/Matrix.h	/^  virtual real* getRowBuf(size_t row) {$/;"	f	class:paddle::Matrix
getRowBuf	math/SparseRowMatrix.h	/^  virtual real* getRowBuf(size_t row) { return getRow(row); }$/;"	f	class:paddle::CacheRowCpuMatrix
getRowBuf	math/SparseRowMatrix.h	/^  virtual real* getRowBuf(size_t row) { return getRow(row); }$/;"	f	class:paddle::SparseAutoGrowRowCpuMatrix
getRowBuf	math/SparseRowMatrix.h	/^  virtual real* getRowBuf(size_t row) { return getRow(row); }$/;"	f	class:paddle::SparseRowCpuMatrix
getRowCols	math/CpuSparseMatrix.h	/^  int* getRowCols(size_t i) const {$/;"	f	class:paddle::CpuSparseMatrix
getRowCols	math/SparseMatrix.h	/^  const int* getRowCols(size_t x) const { return cols_ + rows_[x]; }$/;"	f	class:paddle::GpuSparseMatrix
getRowCount	math/RowBuffer.h	/^  inline size_t getRowCount() const {$/;"	f	class:paddle::RowBuffer
getRowNum	math/CpuSparseMatrix.h	/^  size_t getRowNum(size_t i) const {$/;"	f	class:paddle::CpuSparseMatrix
getRowStartIdx	math/CpuSparseMatrix.h	/^  size_t getRowStartIdx(size_t i) const {$/;"	f	class:paddle::CpuSparseMatrix
getRowValues	math/CpuSparseMatrix.h	/^  real* getRowValues(size_t i) const {$/;"	f	class:paddle::CpuSparseMatrix
getRowValues	math/SparseMatrix.h	/^  const real* getRowValues(size_t x) const { return value_ + rows_[x]; }$/;"	f	class:paddle::GpuSparseMatrix
getRows	math/CpuSparseMatrix.h	/^  int* getRows() const { return rows_; }$/;"	f	class:paddle::CpuSparseMatrix
getRows	math/Matrix.h	/^  virtual int* getRows() const {$/;"	f	class:paddle::Matrix
getRows	math/SparseMatrix.h	/^  int* getRows() const {$/;"	f	class:paddle::GpuSparseMatrix
getSaveDir	trainer/TrainerConfigHelper.cpp	/^const std::string &TrainerConfigHelper::getSaveDir() const {$/;"	f	class:paddle::TrainerConfigHelper
getScore	api/SequenceGenerator.cpp	/^  float getScore(size_t id) const throw(RangeError) {$/;"	f	class:PathSequenceResults
getScoreLayer	gserver/layers/CostLayer.h	/^  LayerPtr getScoreLayer() { return inputLayers_[1]; }$/;"	f	class:paddle::LambdaCost
getSeed	utils/ThreadLocal.cpp	/^unsigned int* ThreadLocalRand::getSeed() {$/;"	f	class:paddle::ThreadLocalRand
getSegments	gserver/evaluators/ChunkEvaluator.cpp	/^  void getSegments(int* label, int length, std::vector<Segment>& segments) {$/;"	f	class:paddle::ChunkEvaluator
getSelectiveCols	gserver/layers/SelectiveFullyConnectedLayer.cpp	/^void paddle::SelectiveFullyConnectedLayer::getSelectiveCols() {$/;"	f	class:paddle::paddle::SelectiveFullyConnectedLayer
getSentence	api/SequenceGenerator.cpp	/^  std::string getSentence(size_t id, bool split) const throw(RangeError) {$/;"	f	class:PathSequenceResults
getSeqInfo	parameter/Argument.cpp	/^void Argument::getSeqInfo(std::vector<SeqInfo>* seqInfo) const {$/;"	f	class:paddle::Argument
getSeqOutputFromBatch	gserver/layers/SequenceToBatch.cpp	/^void SequenceToBatch::getSeqOutputFromBatch(Matrix &sequence, Matrix &batch) {$/;"	f	class:paddle::SequenceToBatch
getSeqStartPos_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::function<ICpuGpuVectorPtr&(Argument&)> getSeqStartPos_;$/;"	m	class:paddle::SequenceScanner	file:
getSequence	api/SequenceGenerator.cpp	/^  std::vector<int> getSequence(size_t id) const throw(RangeError) {$/;"	f	class:PathSequenceResults
getSequenceId	function/BufferArg.h	/^  SequenceIdArg& getSequenceId() { return startPositions_; }$/;"	f	class:paddle::SequenceArg
getSequenceId	function/BufferArg.h	/^  const SequenceIdArg& getSequenceId() const { return startPositions_; }$/;"	f	class:paddle::SequenceArg
getSharedCount	parameter/Parameter.h	/^  int getSharedCount() { return sharedCount_; }$/;"	f	class:paddle::Parameter
getSharedPtr	api/Matrix.cpp	/^void* Matrix::getSharedPtr() const { return &m->mat; }$/;"	f	class:Matrix
getSharedPtr	api/Vector.cpp	/^void* IVector::getSharedPtr() const { return &m->vec; }$/;"	f	class:IVector
getSharedPtr	api/Vector.cpp	/^void* Vector::getSharedPtr() { return &m->vec; }$/;"	f	class:Vector
getSignAndExponentOfFloat	math/Vector.cpp	/^static int getSignAndExponentOfFloat(float a) {$/;"	f	namespace:paddle
getSize	api/Parameter.cpp	/^size_t Parameter::getSize() const { return m->getPtr()->getSize(); }$/;"	f	class:Parameter
getSize	api/SequenceGenerator.cpp	/^  size_t getSize() const { return path_->size(); }$/;"	f	class:PathSequenceResults
getSize	api/Vector.cpp	/^size_t IVector::getSize() const { return m->vec->getSize(); }$/;"	f	class:IVector
getSize	api/Vector.cpp	/^size_t Vector::getSize() const { return m->vec->getSize(); }$/;"	f	class:Vector
getSize	gserver/dataproviders/DataProvider.cpp	/^int64_t SimpleDataProviderBase::getSize() {$/;"	f	class:paddle::SimpleDataProviderBase
getSize	gserver/dataproviders/DataProvider.h	/^  int64_t getSize() const { return size_; }$/;"	f	class:paddle::DataBatch
getSize	gserver/dataproviders/DataProvider.h	/^  virtual int64_t getSize() { return 0; }$/;"	f	class:paddle::DummyDataProvider
getSize	gserver/dataproviders/DataProviderGroup.h	/^  virtual int64_t getSize() { return -1; }$/;"	f	class:paddle::DataProviderGroup
getSize	gserver/dataproviders/MultiDataProvider.h	/^  virtual int64_t getSize() { return -1; }$/;"	f	class:paddle::MultiDataProvider
getSize	gserver/dataproviders/ProtoDataProvider.h	/^  virtual int64_t getSize() {$/;"	f	class:paddle::ProtoDataProvider
getSize	gserver/dataproviders/PyDataProvider.h	/^  virtual int64_t getSize() {$/;"	f	class:paddle::PyDataProvider
getSize	gserver/dataproviders/PyDataProvider2.cpp	/^  int64_t getSize() { return -1; }$/;"	f	class:paddle::PyDataProvider2
getSize	gserver/dataproviders/PyDataProvider2.cpp	/^  size_t getSize(PyObject* obj) {$/;"	f	class:paddle::SequenceScanner
getSize	gserver/layers/BilinearInterpLayer.cpp	/^size_t BilinearInterpLayer::getSize() {$/;"	f	class:paddle::BilinearInterpLayer
getSize	gserver/layers/Layer.h	/^  size_t getSize() const { return config_.size(); }$/;"	f	class:paddle::Layer
getSize	gserver/layers/MaxOutLayer.cpp	/^size_t MaxOutLayer::getSize() {$/;"	f	class:paddle::MaxOutLayer
getSize	gserver/layers/NormProjectionLayer.cpp	/^size_t CMRProjectionNormLayer::getSize() {$/;"	f	class:paddle::CMRProjectionNormLayer
getSize	gserver/layers/PoolProjection.cpp	/^size_t PoolProjection::getSize() {$/;"	f	class:paddle::PoolProjection
getSize	gserver/layers/PoolProjectionLayer.cpp	/^size_t PoolProjectionLayer::getSize() {$/;"	f	class:paddle::PoolProjectionLayer
getSize	gserver/layers/SpatialPyramidPoolLayer.cpp	/^size_t SpatialPyramidPoolLayer::getSize() {$/;"	f	class:paddle::SpatialPyramidPoolLayer
getSize	math/MemoryHandle.h	/^  size_t getSize() const { return size_; }$/;"	f	class:paddle::MemoryHandle
getSize	math/Vector.h	/^  size_t getSize() const { return this->size_; }$/;"	f	class:paddle::VectorT
getSize	math/Vector.h	/^  size_t getSize() const {$/;"	f	class:paddle::CpuGpuVectorT
getSize	parameter/Parameter.h	/^  size_t getSize() const { return config_.size(); }$/;"	f	class:paddle::Parameter
getSlaveParameters	gserver/gradientmachines/MultiGradientMachine.cpp	/^MultiGradientMachine::getSlaveParameters() {$/;"	f	class:paddle::MultiGradientMachine
getSlotDim	gserver/tests/test_ProtoDataProvider.cpp	/^inline int getSlotDim(const Argument& arg) {$/;"	f
getSlotGrad	api/Arguments.cpp	/^Matrix* Arguments::getSlotGrad(size_t idx) const throw(RangeError) {$/;"	f	class:Arguments
getSlotIds	api/Arguments.cpp	/^IVector* Arguments::getSlotIds(size_t idx) const throw(RangeError) {$/;"	f	class:Arguments
getSlotIn	api/Arguments.cpp	/^Matrix* Arguments::getSlotIn(size_t idx) const throw(RangeError) {$/;"	f	class:Arguments
getSlotNum	api/Arguments.cpp	/^size_t Arguments::getSlotNum() const { return m->outputs.size(); }$/;"	f	class:Arguments
getSlotSequenceDim	api/Arguments.cpp	/^IVector* Arguments::getSlotSequenceDim(size_t idx) const throw(RangeError) {$/;"	f	class:Arguments
getSlotSequenceStartPositions	api/Arguments.cpp	/^IVector* Arguments::getSlotSequenceStartPositions(size_t idx) const$/;"	f	class:Arguments
getSlotSubSequenceStartPositions	api/Arguments.cpp	/^IVector* Arguments::getSlotSubSequenceStartPositions(size_t idx) const$/;"	f	class:Arguments
getSlotType	gserver/tests/test_ProtoDataProvider.cpp	/^inline SlotDef::SlotType getSlotType(const Argument& arg) {$/;"	f
getSlotValue	api/Arguments.cpp	/^Matrix* Arguments::getSlotValue(size_t idx) const throw(RangeError) {$/;"	f	class:Arguments
getSocketFd	pserver/test/SocketTest.cpp	/^  int getSocketFd() const { return socket_; }$/;"	f	class:SocketChannel
getSourceAddress	pserver/RDMANetwork.h	/^inline sockaddr_in* getSourceAddress(sxi_sock* sock) {$/;"	f	namespace:paddle::rdma
getSpaceBytes	gserver/layers/ConvProjection.cpp	/^void *ConvProjection::getSpaceBytes(size_t size) {$/;"	f	class:paddle::ConvProjection
getSparseFormat	api/Matrix.cpp	/^SparseFormatType Matrix::getSparseFormat() const throw(UnsupportError) {$/;"	f	class:Matrix
getSparseRowCols	api/Matrix.cpp	/^IntArray Matrix::getSparseRowCols(size_t i) const$/;"	f	class:Matrix
getSparseRowColsVal	api/Matrix.cpp	/^IntWithFloatArray Matrix::getSparseRowColsVal(size_t i) const$/;"	f	class:Matrix
getSparseValueType	api/Matrix.cpp	/^SparseValueType Matrix::getSparseValueType() const throw(UnsupportError) {$/;"	f	class:Matrix
getStat	utils/Stat.cpp	/^BarrierStatPtr StatSet::getStat(uint16_t numConnThreads,$/;"	f	class:paddle::StatSet
getStat	utils/Stat.h	/^  StatPtr getStat(const std::string& name) {$/;"	f	class:paddle::StatSet
getStat	utils/Stat.h	/^inline StatPtr getStat(const std::string& name) {$/;"	f	namespace:paddle
getState	gserver/gradientmachines/GradientMachine.h	/^  virtual void getState(MachineState& machineState) {}$/;"	f	class:paddle::GradientMachine
getState	gserver/gradientmachines/NeuralNetwork.cpp	/^void NeuralNetwork::getState(MachineState& machineState) {$/;"	f	class:paddle::NeuralNetwork
getState	gserver/layers/ContextProjection.cpp	/^LayerStatePtr ContextProjection::getState() {$/;"	f	class:paddle::ContextProjection
getState	gserver/layers/GatedRecurrentLayer.cpp	/^LayerStatePtr GatedRecurrentLayer::getState() {$/;"	f	class:paddle::GatedRecurrentLayer
getState	gserver/layers/Layer.h	/^  virtual LayerStatePtr getState() { return nullptr; }$/;"	f	class:paddle::Layer
getState	gserver/layers/LstmLayer.cpp	/^LayerStatePtr LstmLayer::getState() {$/;"	f	class:paddle::LstmLayer
getState	gserver/layers/MixedLayer.cpp	/^LayerStatePtr MixedLayer::getState() {$/;"	f	class:paddle::MixedLayer
getState	gserver/layers/Operator.h	/^  virtual LayerStatePtr getState() { return nullptr; }$/;"	f	class:paddle::Operator
getState	gserver/layers/Projection.h	/^  virtual LayerStatePtr getState() { return nullptr; }$/;"	f	class:paddle::Projection
getState	gserver/layers/RecurrentLayer.cpp	/^LayerStatePtr RecurrentLayer::getState() {$/;"	f	class:paddle::RecurrentLayer
getStats	gserver/gradientmachines/GradientMachine.h	/^  virtual void getStats(real& cost, int64_t& numProcessed) {$/;"	f	class:paddle::GradientMachine
getStats	trainer/TrainerInternalConfig.h	/^  std::string getStats(bool withCurrentCost = true) const {$/;"	f	class:paddle::TrainerStats
getStatus	pserver/ParameterServer2.cpp	/^void ParameterServer2::getStatus(const GetStatusRequest& request,$/;"	f	class:paddle::ParameterServer2
getStatus	pserver/test/test_ProtoServer.cpp	/^  void getStatus(const GetStatusRequest& request,$/;"	f	class:MyServer
getStatusEx	pserver/test/test_ProtoServer.cpp	/^  void getStatusEx(const GetStatusRequest& request,$/;"	f	class:MyServer
getStream	gserver/dataproviders/DataProvider.h	/^  const Argument& getStream(int i) const { return data_[i]; }$/;"	f	class:paddle::DataBatch
getStreams	gserver/dataproviders/DataProvider.h	/^  std::vector<Argument> getStreams() const { return data_; }$/;"	f	class:paddle::DataBatch
getStreams	gserver/dataproviders/DataProvider.h	/^  std::vector<Argument>& getStreams() { return data_; }$/;"	f	class:paddle::DataBatch
getStride	math/Matrix.h	/^  size_t getStride() const { return stride_; }$/;"	f	class:paddle::Matrix
getSubNetworks	gserver/gradientmachines/MultiNetwork.h	/^  const std::vector<std::unique_ptr<NeuralNetwork>>& getSubNetworks() const {$/;"	f	class:paddle::MultiNetwork
getSum	math/CpuSparseMatrix.h	/^  virtual real getSum() {$/;"	f	class:paddle::CpuSparseMatrix
getSum	math/Matrix.cpp	/^real CpuMatrix::getSum() {$/;"	f	class:paddle::CpuMatrix
getSum	math/Matrix.cpp	/^real GpuMatrix::getSum() {$/;"	f	class:paddle::GpuMatrix
getSum	math/Matrix.h	/^  virtual real getSum() {$/;"	f	class:paddle::Matrix
getSum	math/Vector.cpp	/^T CpuVectorT<T>::getSum() {$/;"	f	class:paddle::CpuVectorT
getSum	math/Vector.cpp	/^int GpuVectorT<int>::getSum() {$/;"	f	class:paddle::GpuVectorT
getSum	math/Vector.cpp	/^real CpuVectorT<real>::getSum() {$/;"	f	class:paddle::CpuVectorT
getSum	math/Vector.cpp	/^real GpuVectorT<real>::getSum() {$/;"	f	class:paddle::GpuVectorT
getSync	math/Vector.h	/^  inline SyncedFlag* getSync() const { return sync_; }$/;"	f	class:paddle::CpuGpuVectorT
getTID	utils/Util.cpp	/^pid_t getTID() {$/;"	f	namespace:paddle
getTaskType	gserver/gradientmachines/MultiGradientMachine.h	/^  TaskType getTaskType() const { return taskType_; }$/;"	f	class:paddle::MultiGradientMachine
getTestDataConfig	trainer/TrainerConfigHelper.cpp	/^const DataConfig &TrainerConfigHelper::getTestDataConfig() const {$/;"	f	class:paddle::TrainerConfigHelper
getThread	gserver/gradientmachines/MultiGradientMachine.h	/^  TrainerThreadPtr& getThread(int threadId) { return threads_[threadId]; }$/;"	f	class:paddle::MultiGradientMachine
getThreadInfo	utils/Stat.h	/^  bool getThreadInfo() const { return openThreadInfo_; }$/;"	f	class:paddle::Stat
getThreadLocal	utils/CustomStackTrace.h	/^  inline TYPE& getThreadLocal($/;"	f	class:paddle::CustomStackTrace
getTlsTempBufs	parameter/Parameter.cpp	/^VectorPtr* Parameter::getTlsTempBufs() {$/;"	f	class:paddle::Parameter
getTmpSparseMatrix	math/CpuSparseMatrix.cpp	/^CpuSparseMatrixPtr CpuSparseMatrix::getTmpSparseMatrix(size_t height,$/;"	f	class:paddle::CpuSparseMatrix
getTotalLength	pserver/SocketChannel.h	/^  size_t getTotalLength() const {$/;"	f	class:paddle::MsgReader
getTotalParameterSize	gserver/tests/test_RecurrentGradientMachine.cpp	/^  size_t getTotalParameterSize() const {$/;"	f	class:TrainerForTest
getTransDtype	pserver/BaseClient.h	/^  virtual TransDataType getTransDtype(const std::type_info& info) {$/;"	f	class:paddle::BaseClient
getTranspose	math/CpuSparseMatrix.cpp	/^MatrixPtr CpuSparseMatrix::getTranspose() {$/;"	f	class:paddle::CpuSparseMatrix
getTranspose	math/Matrix.cpp	/^MatrixPtr CpuMatrix::getTranspose() {$/;"	f	class:paddle::CpuMatrix
getTranspose	math/Matrix.cpp	/^MatrixPtr GpuMatrix::getTranspose() {$/;"	f	class:paddle::GpuMatrix
getTranspose	math/SparseMatrix.cpp	/^MatrixPtr GpuSparseMatrix::getTranspose() {$/;"	f	class:paddle::GpuSparseMatrix
getType	gserver/layers/Layer.h	/^  const std::string& getType() const { return config_.type(); }$/;"	f	class:paddle::Layer
getValue	math/CpuSparseMatrix.h	/^  real* getValue() const { return value_; }$/;"	f	class:paddle::CpuSparseMatrix
getValue	math/SparseMatrix.h	/^  real* getValue() const {$/;"	f	class:paddle::GpuSparseMatrix
getValueBuf	gserver/gradientmachines/MultiGradientMachine.h	/^  const VectorPtr& getValueBuf(int paramId) {$/;"	f	class:paddle::TrainerThread
getValueType	math/CpuSparseMatrix.cpp	/^SparseValueType CpuSparseMatrix::getValueType() { return valueType_; }$/;"	f	class:paddle::CpuSparseMatrix
getValueType	math/CpuSparseMatrix.h	/^  SparseValueType getValueType() const { return valueType_; }$/;"	f	class:paddle::CpuSparseMatrix
getValueType	math/Matrix.h	/^  virtual SparseValueType getValueType() const {$/;"	f	class:paddle::Matrix
getValueType	math/SparseMatrix.cpp	/^SparseValueType GpuSparseMatrix::getValueType() const { return valueType_; }$/;"	f	class:paddle::GpuSparseMatrix
getVector	math/Vector.cpp	/^std::shared_ptr<const VectorT<T>> CpuGpuVectorT<T>::getVector($/;"	f	class:paddle::CpuGpuVectorT
getW	parameter/Weight.h	/^  const MatrixPtr& getW() { return weight_; }$/;"	f	class:paddle::Weight
getWGrad	parameter/Weight.h	/^  const MatrixPtr& getWGrad() { return weightGrad_; }$/;"	f	class:paddle::Weight
getWeight	gserver/layers/ConvBaseLayer.h	/^  Weight& getWeight(int idx) { return *weights_[idx]; }$/;"	f	class:paddle::ConvBaseLayer
getWeight	gserver/layers/FullyConnectedLayer.h	/^  Weight& getWeight(int idx) { return *weights_[idx]; }$/;"	f	class:paddle::FullyConnectedLayer
getWeight	gserver/layers/SelectiveFullyConnectedLayer.h	/^  Weight& getWeight(int idx) { return *weights_[idx]; }$/;"	f	class:paddle::SelectiveFullyConnectedLayer
getWeight	gserver/layers/TensorLayer.h	/^  Weight& getWeight(int idx) { return *weights_[idx]; }$/;"	f	class:paddle::TensorLayer
getWidth	api/Matrix.cpp	/^size_t Matrix::getWidth() const { return m->mat->getWidth(); }$/;"	f	class:Matrix
getWidth	math/Matrix.h	/^  size_t getWidth() const { return width_; }$/;"	f	class:paddle::Matrix
getWidth	math/RowBuffer.h	/^  inline size_t getWidth() const { return width_; }$/;"	f	class:paddle::RowBuffer
getWidth	math/TensorApply.h	/^  INLINE size_t getWidth() const { return expr1_.getWidth(); }$/;"	f	class:paddle::TensorApply
getWidth	math/TensorApply.h	/^  INLINE size_t getWidth() const { return expr_.getWidth(); }$/;"	f	class:paddle::TensorApply
getWidth	math/TensorApply.h	/^  INLINE size_t getWidth() const { return lhs_.getWidth(); }$/;"	f	class:paddle::TensorApply
getWidth	math/TensorApply.h	/^  INLINE size_t getWidth() const { return width_; }$/;"	f	class:paddle::TensorApply
getWidth	math/TensorAssign.h	/^  INLINE size_t getWidth() const { return lhs_.getWidth(); }$/;"	f	class:paddle::TensorAssignOp
getWithAutoGrowth	math/RowBuffer.h	/^  inline real* getWithAutoGrowth(int row) {$/;"	f	class:paddle::RowBuffer
get_features	trainer/tests/gen_proto_data.py	/^    def get_features(pos):$/;"	f	function:make_features
get_last_error	trainer/tests/picojson.h	/^inline const std::string& get_last_error() { return last_error_t<bool>::s; }$/;"	f	namespace:picojson
get_size	py_paddle/dataprovider_converter.py	/^    def get_size(self, dat):$/;"	m	class:SequenceScanner
getc	trainer/tests/picojson.h	/^  int getc() {$/;"	f	class:picojson::input
getrf	math/MathFunctions.cpp	/^int getrf<double>(const CBLAS_ORDER order,$/;"	f	namespace:paddle
getrf	math/MathFunctions.cpp	/^int getrf<float>(const CBLAS_ORDER order,$/;"	f	namespace:paddle
getri	math/MathFunctions.cpp	/^int getri<double>(const CBLAS_ORDER order,$/;"	f	namespace:paddle
getri	math/MathFunctions.cpp	/^int getri<float>(const CBLAS_ORDER order,$/;"	f	namespace:paddle
gettid	cuda/src/hl_cuda_device.cc	/^inline pid_t gettid() {$/;"	f
globalIndices	math/SparseRowMatrix.h	/^    std::vector<unsigned int> globalIndices;  \/\/ global id -> local id$/;"	m	struct:paddle::SparseRowCpuMatrix::IndexDict
globalIndices_	math/SparseRowMatrix.h	/^  unsigned int* globalIndices_;  \/\/ =indexDictHandle_->globalIndices.data();$/;"	m	class:paddle::SparseRowCpuMatrix
gpu	cuda/include/hl_activation_functions.h	/^namespace gpu {$/;"	n	namespace:hppl
gpuAllocator_	math/Storage.h	/^  std::vector<PoolAllocator*> gpuAllocator_;$/;"	m	class:paddle::StorageEngine
gpuBatch_	gserver/dataproviders/ProtoDataProvider.h	/^  ThreadLocalD<DataBatch> gpuBatch_;$/;"	m	class:paddle::ProtoDataProvider
gpuBatch_	gserver/dataproviders/PyDataProvider.h	/^  ThreadLocalD<DataBatch> gpuBatch_;$/;"	m	class:paddle::PyDataProvider
gpuFunc_	function/FunctionTest.h	/^  std::shared_ptr<FunctionBase> gpuFunc_;$/;"	m	class:paddle::FunctionCompare
gpuImages_	math/tests/test_perturbation.cpp	/^  real* gpuImages_;$/;"	m	class:PerturbationTest	file:
gpuInputs_	function/FunctionTest.h	/^  std::vector<BufferArgPtr> gpuInputs_;$/;"	m	class:paddle::FunctionCompare
gpuMemory_	function/FunctionTest.h	/^  std::vector<GpuMemHandlePtr> gpuMemory_;$/;"	m	class:paddle::FunctionCompare
gpuOutputs_	function/FunctionTest.h	/^  std::vector<BufferArgPtr> gpuOutputs_;$/;"	m	class:paddle::FunctionCompare
gpuRowFunc	math/Vector.cpp	/^real gpuRowFunc(Func f, GpuVector& v) {$/;"	f	namespace:paddle
gpuSeq_	function/FunctionTest.h	/^  std::shared_ptr<SequenceIdArg> gpuSeq_;$/;"	m	class:paddle::FunctionCompare
gpuSparse_	function/FunctionTest.h	/^  std::shared_ptr<GpuSparseMatrix> gpuSparse_;$/;"	m	class:paddle::FunctionCompare
gpuVectorT_	math/Vector.h	/^  std::shared_ptr<VectorT<T>> gpuVectorT_;$/;"	m	class:paddle::CpuGpuVectorT
gpu_id	gserver/tests/test_BatchNorm.cpp	/^DECLARE_int32(gpu_id);$/;"	v
gpu_id	gserver/tests/test_ConvTrans.cpp	/^DECLARE_int32(gpu_id);$/;"	v
gpu_id	gserver/tests/test_ConvUnify.cpp	/^DECLARE_int32(gpu_id);$/;"	v
gpu_id	gserver/tests/test_Evaluator.cpp	/^DECLARE_int32(gpu_id);$/;"	v
gpu_id	gserver/tests/test_LayerGrad.cpp	/^DECLARE_int32(gpu_id);$/;"	v
gpu_id	trainer/TrainerMain.cpp	/^DECLARE_int32(gpu_id);$/;"	v
gpu_id	trainer/tests/test_Compare.cpp	/^DECLARE_int32(gpu_id);$/;"	v
gpu_id	trainer/tests/test_CompareSparse.cpp	/^DECLARE_int32(gpu_id);$/;"	v
gpu_id	trainer/tests/test_Trainer.cpp	/^DECLARE_int32(gpu_id);$/;"	v
gpu_id	trainer/tests/test_TrainerOnePass.cpp	/^DECLARE_int32(gpu_id);$/;"	v
gpu_id	utils/Flags.h	/^DECLARE_int32(gpu_id);$/;"	v
grad	parameter/Argument.h	/^  MatrixPtr grad;  \/\/ If empty, gradient is not needed.$/;"	m	struct:paddle::Argument
gradBufQueue_	gserver/gradientmachines/MultiGradientMachine.h	/^  PidQueue gradBufQueue_;$/;"	m	class:paddle::TrainerThread
gradBufs_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<std::vector<GradBuffer>> gradBufs_;  \/\/ [threadId][deviceId]$/;"	m	class:paddle::MultiGradientMachine
gradCollectThread	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::gradCollectThread() {$/;"	f	class:paddle::TrainerThread
gradCollectThread_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::unique_ptr<std::thread> gradCollectThread_;$/;"	m	class:paddle::TrainerThread
gradCount	parameter/Argument.h	/^  mutable int gradCount;   \/\/ waiting this member when layer do backward$/;"	m	struct:paddle::Argument
gradQueue_	gserver/gradientmachines/MultiGradientMachine.h	/^  PidQueue gradQueue_;$/;"	m	class:paddle::MultiGradientMachine
gradQueue_	gserver/gradientmachines/MultiGradientMachine.h	/^  PidQueue gradQueue_;$/;"	m	class:paddle::TrainerThread
gradReadyCond	parameter/Argument.h	/^  mutable LockedCondition gradReadyCond;$/;"	m	struct:paddle::Argument
gradSegments_	parameter/Parameter.h	/^  std::vector<Segment> gradSegments_;  \/\/ segments of non-zero gradient$/;"	m	class:paddle::Parameter
gradSem_	parameter/ParallelParameter.h	/^      gradSem_;  \/\/\/ wether the local parameter-gradient is ready$/;"	m	class:paddle::ParallelParameter
gradStream_	gserver/gradientmachines/MultiGradientMachine.h	/^  hl_stream_t gradStream_;$/;"	m	class:paddle::TrainerThread
gradTerms_	gserver/layers/LinearChainCTC.h	/^  MatrixPtr logActs_, forwardVars_, backwardVars_, gradTerms_;$/;"	m	class:paddle::LinearChainCTC
gradientAccum_	parameter/ParallelParameter.h	/^  VectorPtr gradientAccum_;$/;"	m	class:paddle::AsyncParameter
gradientMachine_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::unique_ptr<GradientMachine> gradientMachine_;$/;"	m	class:paddle::MultiGradientMachine
gradientMachine_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::unique_ptr<GradientMachine> gradientMachine_;$/;"	m	class:paddle::TrainerThread
gradientMachine_	trainer/Tester.h	/^  GradientMachinePtr gradientMachine_;$/;"	m	class:paddle::Tester
gradientMachine_	trainer/TrainerInternal.h	/^  GradientMachinePtr gradientMachine_;$/;"	m	class:paddle::TrainerInternal
gradientReadyBarrier_	pserver/ParameterServer2.h	/^  ThreadBarrier gradientReadyBarrier_;$/;"	m	class:paddle::ParameterServer2
greaterPath	gserver/gradientmachines/RecurrentGradientMachine.h	/^    static bool greaterPath(const Path& a, const Path& b) { return (b < a); }$/;"	f	struct:paddle::RecurrentGradientMachine::Path
groups_	gserver/layers/ConvBaseLayer.h	/^  IntV groups_;$/;"	m	class:paddle::ConvBaseLayer
groups_	gserver/layers/ConvProjection.h	/^  int groups_;$/;"	m	class:paddle::ConvProjection
groups_	gserver/layers/MaxOutLayer.h	/^  size_t groups_;$/;"	m	class:paddle::MaxOutLayer
gserver_	trainer/ParamUtil.h	/^  GradientMachinePtr gserver_;$/;"	m	class:paddle::ParameterUtil
guard_	utils/PythonUtil.h	/^  std::lock_guard<std::recursive_mutex> guard_;$/;"	m	class:paddle::PyGuard
guard_	utils/Stat.h	/^  std::lock_guard<std::recursive_mutex> guard_;$/;"	m	class:paddle::final
gzipInput_	gserver/dataproviders/ProtoReader.h	/^  std::unique_ptr<google::protobuf::io::GzipInputStream> gzipInput_;$/;"	m	class:paddle::ProtoReader
gzipOutput_	gserver/dataproviders/ProtoReader.h	/^  std::unique_ptr<google::protobuf::io::GzipOutputStream> gzipOutput_;$/;"	m	class:paddle::ProtoWriter
hInputDataBuf_	gserver/dataproviders/DataProvider.h	/^  CpuMatrixPtr hInputDataBuf_;$/;"	m	class:paddle::SimpleDataProviderBase
hInputInfoBuf_	gserver/dataproviders/DataProvider.h	/^  CpuIVectorPtr hInputInfoBuf_;$/;"	m	class:paddle::SimpleDataProviderBase
hInputLabelBuf_	gserver/dataproviders/DataProvider.h	/^  CpuIVectorPtr hInputLabelBuf_;$/;"	m	class:paddle::SimpleDataProviderBase
handle	pserver/ParameterClient2.h	/^  int64_t handle;$/;"	m	struct:paddle::PServerMatrix
handle	pserver/ParameterClient2.h	/^  int64_t handle;$/;"	m	struct:paddle::PServerVector
handleDenseSlot	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::handleDenseSlot(ProtoSlot& slot,$/;"	f	class:paddle::PyDataProvider
handleIndexSlot	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::handleIndexSlot(ProtoSlot& slot,$/;"	f	class:paddle::PyDataProvider
handleRequest	pserver/ProtoServer.cpp	/^void ProtoServer::handleRequest(std::unique_ptr<MsgReader> msgReader,$/;"	f	class:paddle::ProtoServer
handleRequestBegin_	pserver/ProtoServer.h	/^  ThreadLocal<struct timeval> handleRequestBegin_;$/;"	m	class:paddle::ProtoServer
handleSparseNonValueSlot	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::handleSparseNonValueSlot($/;"	f	class:paddle::PyDataProvider
handleSparseValueSlot	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::handleSparseValueSlot($/;"	f	class:paddle::PyDataProvider
handleStringSlot	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::handleStringSlot(ProtoSlot& slot,$/;"	f	class:paddle::PyDataProvider
hasDataConfig	trainer/TrainerConfigHelper.cpp	/^bool TrainerConfigHelper::hasDataConfig() const {$/;"	f	class:paddle::TrainerConfigHelper
hasNonstaticCpuParamters	gserver/gradientmachines/MultiGradientMachine.h	/^  bool hasNonstaticCpuParamters() const { return hasNonstaticCpuParamters_; }$/;"	f	class:paddle::MultiGradientMachine
hasNonstaticCpuParamters_	gserver/gradientmachines/MultiGradientMachine.h	/^  bool hasNonstaticCpuParamters_;$/;"	m	class:paddle::MultiGradientMachine
hasStaticParameters	gserver/gradientmachines/GradientMachine.h	/^  inline bool hasStaticParameters() {$/;"	f	class:paddle::GradientMachine
hasSubseq	gserver/gradientmachines/RecurrentGradientMachine.h	/^    bool hasSubseq;$/;"	m	struct:paddle::RecurrentGradientMachine::InFrameLine
hasSubseq	parameter/Argument.h	/^  bool hasSubseq() const { return subSequenceStartPositions != nullptr; }$/;"	f	struct:paddle::Argument
hasTestDataConfig	trainer/TrainerConfigHelper.cpp	/^bool TrainerConfigHelper::hasTestDataConfig() const {$/;"	f	class:paddle::TrainerConfigHelper
hasType	parameter/Parameter.h	/^  bool hasType(ParameterType pType) const {$/;"	f	class:paddle::Parameter
headerPtr_	gserver/dataproviders/PyDataProvider2.cpp	/^  SlotHeader* headerPtr_;$/;"	m	class:paddle::IFieldScanner	file:
header_	gserver/dataproviders/ProtoDataProvider.h	/^  DataHeader header_;$/;"	m	class:paddle::ProtoDataProvider
header_creator	gserver/tests/pyDataProvider.py	/^def header_creator():$/;"	f
headers_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::vector<SlotHeader> headers_;$/;"	m	class:paddle::PyDataProvider2	file:
height	math/tests/test_ExecViaCpu.cpp	/^const int height = 10;$/;"	v
height	math/tests/test_SparseMatrix.cpp	/^  size_t height;$/;"	m	struct:MatrixPara	file:
heightEnd	function/PadOp.h	/^  int heightEnd;$/;"	m	struct:paddle::PadConf
heightPadding	gserver/layers/CudnnPoolLayer.h	/^  int heightPadding, widthPadding, strideHeight, strideWidth;$/;"	m	class:paddle::CudnnPoolLayer
heightStart	function/PadOp.h	/^  int heightStart;$/;"	m	struct:paddle::PadConf
height_	gserver/dataproviders/PyDataProvider2.cpp	/^  size_t height_;$/;"	m	class:paddle::DenseScanner	file:
height_	gserver/dataproviders/PyDataProvider2.cpp	/^  size_t height_;$/;"	m	class:paddle::SparseNonValueScanner	file:
height_	gserver/layers/RotateLayer.h	/^  int height_;$/;"	m	class:paddle::RotateLayer
height_	math/BaseMatrix.h	/^  size_t height_, width_;$/;"	m	class:paddle::BaseMatrixT
height_	math/TensorApply.h	/^  size_t height_;$/;"	m	class:paddle::TensorApply
hidden_dim	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^hidden_dim = 8$/;"	v
hidden_dim	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^hidden_dim = 8$/;"	v
histogram	math/Vector.cpp	/^void CpuVectorT<T>::histogram(std::ostream& os, int type) {$/;"	f	class:paddle::CpuVectorT
histogram	math/Vector.cpp	/^void CpuVectorT<real>::histogram(std::ostream& os, int type) {$/;"	f	class:paddle::CpuVectorT
histogram	math/Vector.cpp	/^void GpuVectorT<T>::histogram(std::ostream& os, int type) {$/;"	f	class:paddle::GpuVectorT
hlActiveType	utils/Util.cpp	/^hl_activation_mode_t hlActiveType(const std::string& type) {$/;"	f	namespace:paddle
hlEvent_	gserver/dataproviders/DataProvider.h	/^  hl_event_t hlEvent_;$/;"	m	class:paddle::BufferBatch
hlStream_	gserver/dataproviders/DataProvider.h	/^  hl_stream_t hlStream_;$/;"	m	class:paddle::BufferBatch
hl_activation_mode_t	cuda/include/hl_base.h	/^} hl_activation_mode_t;$/;"	t	typeref:enum:__anon2
hl_avgpool_backward	cuda/include/stub/hl_cnn_stub.h	/^inline void hl_avgpool_backward(const int frameCnt,$/;"	f
hl_avgpool_forward	cuda/include/stub/hl_cnn_stub.h	/^inline void hl_avgpool_forward(const int frameCnt,$/;"	f
hl_batch_norm_backward	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_batch_norm_backward(hl_tensor_descriptor inputDesc,$/;"	f
hl_batch_norm_backward	cuda/src/hl_cuda_cudnn.cc	/^void hl_batch_norm_backward(hl_tensor_descriptor inputDesc,$/;"	f
hl_batch_norm_forward_inference	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_batch_norm_forward_inference(hl_tensor_descriptor inputDesc,$/;"	f
hl_batch_norm_forward_inference	cuda/src/hl_cuda_cudnn.cc	/^void hl_batch_norm_forward_inference(hl_tensor_descriptor inputDesc,$/;"	f
hl_batch_norm_forward_training	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_batch_norm_forward_training(hl_tensor_descriptor inputDesc,$/;"	f
hl_batch_norm_forward_training	cuda/src/hl_cuda_cudnn.cc	/^void hl_batch_norm_forward_training(hl_tensor_descriptor inputDesc,$/;"	f
hl_bilinear_backward	cuda/include/stub/hl_cnn_stub.h	/^inline void hl_bilinear_backward(real* inGrad,$/;"	f
hl_bilinear_forward	cuda/include/stub/hl_cnn_stub.h	/^inline void hl_bilinear_forward(const real* inData,$/;"	f
hl_construct_sparse_matrix	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_construct_sparse_matrix(hl_sparse_matrix_s *A_d,$/;"	f
hl_conv_workspace	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_conv_workspace(hl_tensor_descriptor input,$/;"	f
hl_conv_workspace	cuda/src/hl_cuda_cudnn.cc	/^void hl_conv_workspace(hl_tensor_descriptor input,$/;"	f
hl_convolution_backward_bias	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_convolution_backward_bias(hl_tensor_descriptor bias,$/;"	f
hl_convolution_backward_bias	cuda/src/hl_cuda_cudnn.cc	/^void hl_convolution_backward_bias(hl_tensor_descriptor bias,$/;"	f
hl_convolution_backward_data	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_convolution_backward_data(hl_tensor_descriptor input,$/;"	f
hl_convolution_backward_data	cuda/src/hl_cuda_cudnn.cc	/^void hl_convolution_backward_data(hl_tensor_descriptor input,$/;"	f
hl_convolution_backward_filter	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_convolution_backward_filter(hl_tensor_descriptor input,$/;"	f
hl_convolution_backward_filter	cuda/src/hl_cuda_cudnn.cc	/^void hl_convolution_backward_filter(hl_tensor_descriptor input,$/;"	f
hl_convolution_descriptor	cuda/include/hl_cuda_cudnn.h	/^typedef struct _hl_convolution_descriptor* hl_convolution_descriptor;$/;"	t	typeref:struct:_hl_convolution_descriptor
hl_convolution_forward	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_convolution_forward(hl_tensor_descriptor input,$/;"	f
hl_convolution_forward	cuda/src/hl_cuda_cudnn.cc	/^void hl_convolution_forward(hl_tensor_descriptor input,$/;"	f
hl_convolution_forward_add_bias	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_convolution_forward_add_bias(hl_tensor_descriptor bias,$/;"	f
hl_convolution_forward_add_bias	cuda/src/hl_cuda_cudnn.cc	/^void hl_convolution_forward_add_bias(hl_tensor_descriptor bias,$/;"	f
hl_create_convolution_descriptor	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_create_convolution_descriptor(hl_convolution_descriptor* conv,$/;"	f
hl_create_convolution_descriptor	cuda/src/hl_cuda_cudnn.cc	/^void hl_create_convolution_descriptor(hl_convolution_descriptor* conv,$/;"	f
hl_create_event	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_create_event(hl_event_t *event) {}$/;"	f
hl_create_event	cuda/src/hl_cuda_device.cc	/^void hl_create_event(hl_event_t *event) {$/;"	f
hl_create_filter_descriptor	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_create_filter_descriptor(hl_filter_descriptor* filter,$/;"	f
hl_create_filter_descriptor	cuda/src/hl_cuda_cudnn.cc	/^void hl_create_filter_descriptor(hl_filter_descriptor* filter,$/;"	f
hl_create_global_resources	cuda/src/hl_cuda_device.cc	/^void hl_create_global_resources(hl_device_prop device_prop) {$/;"	f
hl_create_pooling_descriptor	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_create_pooling_descriptor(hl_pooling_descriptor* pooling_desc,$/;"	f
hl_create_pooling_descriptor	cuda/src/hl_cuda_cudnn.cc	/^void hl_create_pooling_descriptor(hl_pooling_descriptor* pooling_desc,$/;"	f
hl_create_tensor_descriptor	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_create_tensor_descriptor(hl_tensor_descriptor* image_desc) {}$/;"	f
hl_create_tensor_descriptor	cuda/src/hl_cuda_cudnn.cc	/^void hl_create_tensor_descriptor(hl_tensor_descriptor* image_desc) {$/;"	f
hl_create_tensor_descriptor	cuda/src/hl_cuda_cudnn.cc	/^void hl_create_tensor_descriptor(hl_tensor_descriptor* image_desc,$/;"	f
hl_create_thread_resources	cuda/src/hl_cuda_device.cc	/^void hl_create_thread_resources(int device,$/;"	f
hl_cublas_get_error_string	cuda/src/hl_cuda_cublas.cc	/^const char *hl_cublas_get_error_string(cublasStatus_t status) {$/;"	f
hl_cublas_init	cuda/src/hl_cuda_cublas.cc	/^void hl_cublas_init(cublasHandle_t *cublas_handle, cudaStream_t stream) {$/;"	f
hl_cuda_event_is_ready	cuda/include/stub/hl_cuda_stub.h	/^inline bool hl_cuda_event_is_ready(hl_event_t event) { return true; }$/;"	f
hl_cuda_event_is_ready	cuda/src/hl_cuda_device.cc	/^bool hl_cuda_event_is_ready(hl_event_t event) {$/;"	f
hl_cudnn_desc_init	cuda/src/hl_cuda_cudnn.cc	/^void hl_cudnn_desc_init(cudnnTensorDescriptor_t* cudnn_desc) {$/;"	f
hl_cudnn_init	cuda/src/hl_cuda_cudnn.cc	/^void hl_cudnn_init(cudnnHandle_t* cudnn_handle, cudaStream_t stream) {$/;"	f
hl_destroy_convolution_descriptor	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_destroy_convolution_descriptor(hl_convolution_descriptor conv) {}$/;"	f
hl_destroy_convolution_descriptor	cuda/src/hl_cuda_cudnn.cc	/^void hl_destroy_convolution_descriptor(hl_convolution_descriptor conv) {$/;"	f
hl_destroy_event	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_destroy_event(hl_event_t event) {}$/;"	f
hl_destroy_event	cuda/src/hl_cuda_device.cc	/^void hl_destroy_event(hl_event_t event) {$/;"	f
hl_destroy_filter_descriptor	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_destroy_filter_descriptor(hl_filter_descriptor filter) {}$/;"	f
hl_destroy_filter_descriptor	cuda/src/hl_cuda_cudnn.cc	/^void hl_destroy_filter_descriptor(hl_filter_descriptor filter) {$/;"	f
hl_destroy_pooling_descriptor	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_destroy_pooling_descriptor(hl_pooling_descriptor pooling_desc) {}$/;"	f
hl_destroy_pooling_descriptor	cuda/src/hl_cuda_cudnn.cc	/^void hl_destroy_pooling_descriptor(hl_pooling_descriptor pooling_desc) {$/;"	f
hl_destroy_tensor_descriptor	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_destroy_tensor_descriptor(hl_tensor_descriptor image_desc) {}$/;"	f
hl_destroy_tensor_descriptor	cuda/src/hl_cuda_cudnn.cc	/^void hl_destroy_tensor_descriptor(hl_tensor_descriptor image_desc) {$/;"	f
hl_destruct_sparse_matrix	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_destruct_sparse_matrix(hl_sparse_matrix_s A_d) {}$/;"	f
hl_device_can_access_peer	cuda/src/hl_cuda_device.cc	/^bool hl_device_can_access_peer(int device, int peerDevice) {$/;"	f
hl_device_enable_peer_access	cuda/src/hl_cuda_device.cc	/^void hl_device_enable_peer_access(int peerDevice) {$/;"	f
hl_device_synchronize	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_device_synchronize() {}$/;"	f
hl_device_synchronize	cuda/src/hl_cuda_device.cc	/^void hl_device_synchronize() { CHECK_CUDA(cudaDeviceSynchronize()); }$/;"	f
hl_event_elapsed_time	cuda/include/stub/hl_cuda_stub.h	/^inline float hl_event_elapsed_time(hl_event_t start, hl_event_t end) {$/;"	f
hl_event_elapsed_time	cuda/src/hl_cuda_device.cc	/^float hl_event_elapsed_time(hl_event_t start, hl_event_t end) {$/;"	f
hl_event_synchronize	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_event_synchronize(hl_event_t event) {}$/;"	f
hl_event_synchronize	cuda/src/hl_cuda_device.cc	/^void hl_event_synchronize(hl_event_t event) {$/;"	f
hl_event_t	cuda/include/hl_cuda.h	/^typedef struct _hl_event_st *hl_event_t;$/;"	t	typeref:struct:_hl_event_st
hl_expand_feature2col	cuda/include/stub/hl_cnn_stub.h	/^inline void hl_expand_feature2col(const real* dataIm,$/;"	f
hl_filter_descriptor	cuda/include/hl_cuda_cudnn.h	/^typedef struct _hl_filter_descriptor* hl_filter_descriptor;$/;"	t	typeref:struct:_hl_filter_descriptor
hl_fini	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_fini() {}$/;"	f
hl_fini	cuda/src/hl_cuda_device.cc	/^void hl_fini() {$/;"	f
hl_free_mem_device	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_free_mem_device(void *dest_d) {}$/;"	f
hl_free_mem_device	cuda/src/hl_cuda_device.cc	/^void hl_free_mem_device(void *dest_d) {$/;"	f
hl_free_mem_host	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_free_mem_host(void *dest_h) {}$/;"	f
hl_free_mem_host	cuda/src/hl_cuda_device.cc	/^void hl_free_mem_host(void *dest_h) {$/;"	f
hl_free_sparse_matrix	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_free_sparse_matrix(hl_sparse_matrix_s A_d) {}$/;"	f
hl_get_cuda_lib_version	cuda/include/stub/hl_cuda_stub.h	/^inline int hl_get_cuda_lib_version(int device) { return 0; }$/;"	f
hl_get_cuda_version	cuda/src/hl_cuda_device.cc	/^int hl_get_cuda_version() { return g_cuda_lib_version; }$/;"	f
hl_get_cudnn_lib_version	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline int hl_get_cudnn_lib_version() { return 0; }$/;"	f
hl_get_cudnn_lib_version	cuda/src/hl_cuda_cudnn.cc	/^int hl_get_cudnn_lib_version() { return g_cudnn_lib_version; }$/;"	f
hl_get_device	cuda/include/stub/hl_cuda_stub.h	/^inline int hl_get_device() { return 0; }$/;"	f
hl_get_device	cuda/src/hl_cuda_device.cc	/^int hl_get_device() {$/;"	f
hl_get_device_compute_capability	cuda/src/hl_cuda_device.cc	/^void hl_get_device_compute_capability(int *major, int *minor, int device) {$/;"	f
hl_get_device_count	cuda/include/stub/hl_cuda_stub.h	/^inline int hl_get_device_count() { return 0; }$/;"	f
hl_get_device_count	cuda/src/hl_cuda_device.cc	/^int hl_get_device_count() { return device_num; }$/;"	f
hl_get_device_error_string	cuda/include/stub/hl_cuda_stub.h	/^inline const char *hl_get_device_error_string() { return NULL; }$/;"	f
hl_get_device_error_string	cuda/include/stub/hl_cuda_stub.h	/^inline const char *hl_get_device_error_string(size_t err) { return NULL; }$/;"	f
hl_get_device_error_string	cuda/src/hl_cuda_device.cc	/^const char *hl_get_device_error_string() {$/;"	f
hl_get_device_error_string	cuda/src/hl_cuda_device.cc	/^const char *hl_get_device_error_string(size_t err) {$/;"	f
hl_get_device_last_error	cuda/include/stub/hl_cuda_stub.h	/^inline int hl_get_device_last_error() { return 0; }$/;"	f
hl_get_device_last_error	cuda/src/hl_cuda_device.cc	/^int hl_get_device_last_error() { return (int)cudaGetLastError(); }$/;"	f
hl_get_device_memory	cuda/src/hl_cuda_device.cc	/^void hl_get_device_memory(size_t *mem_size, int device) {$/;"	f
hl_get_device_name	cuda/src/hl_cuda_device.cc	/^void hl_get_device_name(char *name, int len, int device) {$/;"	f
hl_get_sync_flag	cuda/include/stub/hl_cuda_stub.h	/^inline bool hl_get_sync_flag() { return false; }$/;"	f
hl_get_sync_flag	cuda/src/hl_cuda_device.cc	/^bool hl_get_sync_flag() { return g_sync_flag; }$/;"	f
hl_gru_grad	cuda/include/hl_base.h	/^} hl_gru_grad;$/;"	t	typeref:struct:__anon7
hl_gru_value	cuda/include/hl_base.h	/^} hl_gru_value;$/;"	t	typeref:struct:__anon6
hl_init	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_init(int device) {}$/;"	f
hl_init	cuda/src/hl_cuda_device.cc	/^void hl_init(int device) {$/;"	f
hl_lstm_grad	cuda/include/hl_base.h	/^} hl_lstm_grad;$/;"	t	typeref:struct:__anon5
hl_lstm_parallel_backward_data	cuda/include/stub/hl_lstm_stub.h	/^inline void hl_lstm_parallel_backward_data(real *gateValue,$/;"	f
hl_lstm_parallel_backward_weight	cuda/include/stub/hl_lstm_stub.h	/^inline void hl_lstm_parallel_backward_weight(real *weightGrad,$/;"	f
hl_lstm_parallel_forward	cuda/include/stub/hl_lstm_stub.h	/^inline void hl_lstm_parallel_forward(real *gateValue,$/;"	f
hl_lstm_value	cuda/include/hl_base.h	/^} hl_lstm_value;$/;"	t	typeref:struct:__anon4
hl_malloc_device	cuda/include/stub/hl_cuda_stub.h	/^inline void *hl_malloc_device(size_t size) { return NULL; }$/;"	f
hl_malloc_device	cuda/src/hl_cuda_device.cc	/^void *hl_malloc_device(size_t size) {$/;"	f
hl_malloc_host	cuda/include/stub/hl_cuda_stub.h	/^inline void *hl_malloc_host(size_t size) { return NULL; }$/;"	f
hl_malloc_host	cuda/src/hl_cuda_device.cc	/^void *hl_malloc_host(size_t size) {$/;"	f
hl_malloc_sparse_matrix	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_malloc_sparse_matrix(hl_sparse_matrix_s *A_d,$/;"	f
hl_matrix_add	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_matrix_add(real* A_d,$/;"	f
hl_matrix_add_shared_bias	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_matrix_add_shared_bias(real* A_d,$/;"	f
hl_matrix_classification_error	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_matrix_classification_error($/;"	f
hl_matrix_collect_shared_bias	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_matrix_collect_shared_bias(real* B_d,$/;"	f
hl_matrix_column_max	cuda/include/stub/hl_aggregate_stub.h	/^inline void hl_matrix_column_max(real *A_d, real *C_d, int dimM, int dimN) {}$/;"	f
hl_matrix_column_min	cuda/include/stub/hl_aggregate_stub.h	/^inline void hl_matrix_column_min(real *A_d, real *C_d, int dimM, int dimN) {}$/;"	f
hl_matrix_column_sum	cuda/include/stub/hl_aggregate_stub.h	/^inline void hl_matrix_column_sum(real *A_d, real *C_d, int dimM, int dimN) {}$/;"	f
hl_matrix_cross_entropy	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_matrix_cross_entropy($/;"	f
hl_matrix_cross_entropy_bp	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_matrix_cross_entropy_bp($/;"	f
hl_matrix_csc2dense	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_matrix_csc2dense(hl_sparse_matrix_s A_d,$/;"	f
hl_matrix_csc_mul_dense	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_matrix_csc_mul_dense(hl_sparse_matrix_s A_d,$/;"	f
hl_matrix_csr2dense	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_matrix_csr2dense(hl_sparse_matrix_s A_d,$/;"	f
hl_matrix_csr_add_bias	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_matrix_csr_add_bias(hl_sparse_matrix_s A_d,$/;"	f
hl_matrix_csr_add_dense	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_matrix_csr_add_dense(hl_sparse_matrix_s A_d,$/;"	f
hl_matrix_csr_column_sum	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_matrix_csr_column_sum($/;"	f
hl_matrix_csr_mul_dense	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_matrix_csr_mul_dense(hl_sparse_matrix_s A_d,$/;"	f
hl_matrix_dense_mul_csc	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_matrix_dense_mul_csc(real *A_d,$/;"	f
hl_matrix_dense_mul_csr	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_matrix_dense_mul_csr(real *A_d,$/;"	f
hl_matrix_format_t	cuda/include/hl_base.h	/^} hl_matrix_format_t;$/;"	t	typeref:enum:__anon9
hl_matrix_inverse	cuda/include/stub/hl_cuda_cublas_stub.h	/^inline void hl_matrix_inverse($/;"	f
hl_matrix_inverse	cuda/src/hl_cuda_cublas.cc	/^void hl_matrix_inverse(real *A_d, real *C_d, int dimN, int lda, int ldc) {$/;"	f
hl_matrix_mul	cuda/include/stub/hl_cuda_cublas_stub.h	/^inline void hl_matrix_mul(real *A_d,$/;"	f
hl_matrix_mul	cuda/src/hl_cuda_cublas.cc	/^void hl_matrix_mul(real *A_d,$/;"	f
hl_matrix_mul_vector	cuda/src/hl_cuda_cublas.cc	/^void hl_matrix_mul_vector(real *A_d,$/;"	f
hl_matrix_multi_binary_cross_entropy	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_matrix_multi_binary_cross_entropy($/;"	f
hl_matrix_multi_binary_cross_entropy_bp	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_matrix_multi_binary_cross_entropy_bp($/;"	f
hl_matrix_rotate	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_matrix_rotate($/;"	f
hl_matrix_row_max	cuda/include/stub/hl_aggregate_stub.h	/^inline void hl_matrix_row_max(real *A_d, real *C_d, int dimM, int dimN) {}$/;"	f
hl_matrix_row_min	cuda/include/stub/hl_aggregate_stub.h	/^inline void hl_matrix_row_min(real *A_d, real *C_d, int dimM, int dimN) {}$/;"	f
hl_matrix_row_sum	cuda/include/stub/hl_aggregate_stub.h	/^inline void hl_matrix_row_sum(real *A_d, real *C_d, int dimM, int dimN) {}$/;"	f
hl_matrix_s	cuda/include/hl_base.h	/^typedef struct _hl_matrix_s *hl_matrix_s;$/;"	t	typeref:struct:_hl_matrix_s
hl_matrix_softmax	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_matrix_softmax(real* A_d, real* C_d, int dimM, int dimN) {}$/;"	f
hl_matrix_softmax_derivative	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_matrix_softmax_derivative($/;"	f
hl_matrix_transpose	cuda/include/stub/hl_cuda_cublas_stub.h	/^inline void hl_matrix_transpose($/;"	f
hl_matrix_transpose	cuda/include/stub/hl_cuda_cublas_stub.h	/^inline void hl_matrix_transpose(real *A_d, real *C_d, int dimM, int dimN) {}$/;"	f
hl_matrix_transpose	cuda/src/hl_cuda_cublas.cc	/^void hl_matrix_transpose($/;"	f
hl_matrix_transpose	cuda/src/hl_cuda_cublas.cc	/^void hl_matrix_transpose(real *A_d, real *C_d, int dimM, int dimN) {$/;"	f
hl_matrix_value_t	cuda/include/hl_base.h	/^} hl_matrix_value_t;$/;"	t	typeref:enum:__anon8
hl_matrix_zero_mem	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_matrix_zero_mem(real* data, int num) {}$/;"	f
hl_max_sequence_backward	cuda/include/stub/hl_sequence_stub.h	/^inline void hl_max_sequence_backward($/;"	f
hl_max_sequence_forward	cuda/include/stub/hl_sequence_stub.h	/^inline void hl_max_sequence_forward(real* input,$/;"	f
hl_maxout_backward	cuda/include/stub/hl_cnn_stub.h	/^inline void hl_maxout_backward(real* inGrad,$/;"	f
hl_maxout_forward	cuda/include/stub/hl_cnn_stub.h	/^inline void hl_maxout_forward(const real* inData,$/;"	f
hl_maxpool_backward	cuda/include/stub/hl_cnn_stub.h	/^inline void hl_maxpool_backward(const int frameCnt,$/;"	f
hl_maxpool_forward	cuda/include/stub/hl_cnn_stub.h	/^inline void hl_maxpool_forward(const int frameCnt,$/;"	f
hl_memcpy	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_memcpy(void *dst, void *src, size_t size) {}$/;"	f
hl_memcpy	cuda/src/hl_cuda_device.cc	/^void hl_memcpy(void *dst, void *src, size_t size) {$/;"	f
hl_memcpy_async	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_memcpy_async(void *dst,$/;"	f
hl_memcpy_async	cuda/src/hl_cuda_device.cc	/^void hl_memcpy_async(void *dst, void *src, size_t size, hl_stream_t stream) {$/;"	f
hl_memcpy_csc_matrix	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_memcpy_csc_matrix(hl_sparse_matrix_s csc_matrix,$/;"	f
hl_memcpy_csr_matrix	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_memcpy_csr_matrix(hl_sparse_matrix_s csr_matrix,$/;"	f
hl_memcpy_device2device	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_memcpy_device2device(void *dest_d, void *src_d, size_t size) {}$/;"	f
hl_memcpy_device2device	cuda/src/hl_cuda_device.cc	/^void hl_memcpy_device2device(void *dest_d, void *src_d, size_t size) {$/;"	f
hl_memcpy_device2host	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_memcpy_device2host(void *dest_h, void *src_d, size_t size) {}$/;"	f
hl_memcpy_device2host	cuda/src/hl_cuda_device.cc	/^void hl_memcpy_device2host(void *dest_h, void *src_d, size_t size) {$/;"	f
hl_memcpy_from_csc_matrix	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_memcpy_from_csc_matrix(real *csc_val,$/;"	f
hl_memcpy_from_csr_matrix	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_memcpy_from_csr_matrix(real *csr_val,$/;"	f
hl_memcpy_host2device	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_memcpy_host2device(void *dest_d, void *src_h, size_t size) {}$/;"	f
hl_memcpy_host2device	cuda/src/hl_cuda_device.cc	/^void hl_memcpy_host2device(void *dest_d, void *src_h, size_t size) {$/;"	f
hl_memcpy_sparse_matrix	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_memcpy_sparse_matrix(hl_sparse_matrix_s dst,$/;"	f
hl_memset_device	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_memset_device(void *dest_d, int value, size_t size) {}$/;"	f
hl_memset_device	cuda/src/hl_cuda_device.cc	/^void hl_memset_device(void *dest_d, int value, size_t size) {$/;"	f
hl_param_relu_backward_diff	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_param_relu_backward_diff(real* grad_o,$/;"	f
hl_param_relu_backward_w	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_param_relu_backward_w(real* grad_w,$/;"	f
hl_param_relu_forward	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_param_relu_forward(real* output,$/;"	f
hl_pooling_backward	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_pooling_backward(hl_tensor_descriptor input,$/;"	f
hl_pooling_backward	cuda/src/hl_cuda_cudnn.cc	/^void hl_pooling_backward(hl_tensor_descriptor input,$/;"	f
hl_pooling_descriptor	cuda/include/hl_cuda_cudnn.h	/^typedef struct _hl_pooling_descriptor* hl_pooling_descriptor;$/;"	t	typeref:struct:_hl_pooling_descriptor
hl_pooling_forward	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_pooling_forward(hl_tensor_descriptor input,$/;"	f
hl_pooling_forward	cuda/src/hl_cuda_cudnn.cc	/^void hl_pooling_forward(hl_tensor_descriptor input,$/;"	f
hl_pooling_mode_t	cuda/include/hl_cuda_cudnn.h	/^} hl_pooling_mode_t;$/;"	t	typeref:enum:__anon11
hl_profiler_end	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_profiler_end() {}$/;"	f
hl_profiler_end	cuda/src/hl_cuda_device.cc	/^void hl_profiler_end() { CHECK_CUDA(cudaProfilerStop()); }$/;"	f
hl_profiler_start	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_profiler_start() {}$/;"	f
hl_profiler_start	cuda/src/hl_cuda_device.cc	/^void hl_profiler_start() { CHECK_CUDA(cudaProfilerStart()); }$/;"	f
hl_rand	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_rand(real *dest_d, size_t num) {}$/;"	f
hl_rand	cuda/src/hl_cuda_device.cc	/^void hl_rand(real *dest_d, size_t num) {$/;"	f
hl_reset_convolution_descriptor	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_reset_convolution_descriptor(hl_convolution_descriptor conv,$/;"	f
hl_reset_convolution_descriptor	cuda/src/hl_cuda_cudnn.cc	/^void hl_reset_convolution_descriptor(hl_convolution_descriptor conv,$/;"	f
hl_sequence2batch_add	cuda/include/stub/hl_sequence_stub.h	/^inline void hl_sequence2batch_add(real* batch,$/;"	f
hl_sequence2batch_copy	cuda/include/stub/hl_sequence_stub.h	/^inline void hl_sequence2batch_copy(real* batch,$/;"	f
hl_sequence2batch_copy_padding	cuda/include/stub/hl_sequence_stub.h	/^inline void hl_sequence2batch_copy_padding(real* batch,$/;"	f
hl_sequence_avg_forward	cuda/include/stub/hl_sequence_stub.h	/^inline void hl_sequence_avg_forward(real* dst,$/;"	f
hl_sequence_softmax_forward	cuda/include/stub/hl_matrix_stub.h	/^inline void hl_sequence_softmax_forward(real* A_d,$/;"	f
hl_set_device	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_set_device(int device) {}$/;"	f
hl_set_device	cuda/src/hl_cuda_device.cc	/^void hl_set_device(int device) {$/;"	f
hl_set_device_flags_block	cuda/src/hl_cuda_device.cc	/^void hl_set_device_flags_block() {$/;"	f
hl_set_sync_flag	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_set_sync_flag(bool flag) {}$/;"	f
hl_set_sync_flag	cuda/src/hl_cuda_device.cc	/^void hl_set_sync_flag(bool flag) { g_sync_flag = flag; }$/;"	f
hl_shrink_col2feature	cuda/include/stub/hl_cnn_stub.h	/^inline void hl_shrink_col2feature(const real* dataCol,$/;"	f
hl_softmax_backward	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_softmax_backward(real* output_value,$/;"	f
hl_softmax_backward	cuda/src/hl_cuda_cudnn.cc	/^void hl_softmax_backward(real* output_value,$/;"	f
hl_softmax_forward	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_softmax_forward(real* input,$/;"	f
hl_softmax_forward	cuda/src/hl_cuda_cudnn.cc	/^void hl_softmax_forward(real* input, real* output, int height, int width) {$/;"	f
hl_sparse_matrix_add_bias	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_sparse_matrix_add_bias(hl_sparse_matrix_s A_d,$/;"	f
hl_sparse_matrix_add_dense	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_sparse_matrix_add_dense(hl_sparse_matrix_s A_d,$/;"	f
hl_sparse_matrix_column_sum	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_sparse_matrix_column_sum($/;"	f
hl_sparse_matrix_get_cols	cuda/include/stub/hl_sparse_stub.h	/^inline int *hl_sparse_matrix_get_cols(hl_sparse_matrix_s sMat) { return NULL; }$/;"	f
hl_sparse_matrix_get_rows	cuda/include/stub/hl_sparse_stub.h	/^inline int *hl_sparse_matrix_get_rows(hl_sparse_matrix_s sMat) { return NULL; }$/;"	f
hl_sparse_matrix_get_value	cuda/include/stub/hl_sparse_stub.h	/^inline real *hl_sparse_matrix_get_value(hl_sparse_matrix_s sMat) {$/;"	f
hl_sparse_matrix_mul	cuda/include/stub/hl_sparse_stub.h	/^inline void hl_sparse_matrix_mul(real *A_d,$/;"	f
hl_sparse_matrix_s	cuda/include/hl_base.h	/^} _hl_sparse_matrix_s, *hl_sparse_matrix_s;$/;"	t	typeref:struct:__anon10
hl_sparse_matrix_s_ptr	math/SparseMatrix.h	/^typedef std::shared_ptr<_hl_sparse_matrix_s> hl_sparse_matrix_s_ptr;$/;"	t	namespace:paddle
hl_specify_devices_start	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_specify_devices_start(int *device, int number) {}$/;"	f
hl_specify_devices_start	cuda/src/hl_cuda_device.cc	/^void hl_specify_devices_start(int *device, int number) {$/;"	f
hl_srand	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_srand(unsigned int seed) {}$/;"	f
hl_srand	cuda/src/hl_cuda_device.cc	/^void hl_srand(unsigned int seed) {$/;"	f
hl_start	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_start() {}$/;"	f
hl_start	cuda/src/hl_cuda_device.cc	/^void hl_start() {$/;"	f
hl_start_flag	cuda/src/hl_cuda_device.cc	/^bool hl_start_flag = false;$/;"	v
hl_stream_record_event	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_stream_record_event(hl_stream_t stream, hl_event_t event) {}$/;"	f
hl_stream_record_event	cuda/src/hl_cuda_device.cc	/^void hl_stream_record_event(hl_stream_t stream, hl_event_t event) {$/;"	f
hl_stream_synchronize	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_stream_synchronize(hl_stream_t stream) {}$/;"	f
hl_stream_synchronize	cuda/src/hl_cuda_device.cc	/^void hl_stream_synchronize(hl_stream_t stream) {$/;"	f
hl_stream_t	cuda/include/hl_base.h	/^} hl_stream_t;$/;"	t	typeref:enum:__anon1
hl_stream_wait_event	cuda/include/stub/hl_cuda_stub.h	/^inline void hl_stream_wait_event(hl_stream_t stream, hl_event_t event) {}$/;"	f
hl_stream_wait_event	cuda/src/hl_cuda_device.cc	/^void hl_stream_wait_event(hl_stream_t stream, hl_event_t event) {$/;"	f
hl_tensor_descriptor	cuda/include/hl_cuda_cudnn.h	/^typedef struct _hl_tensor_descriptor* hl_tensor_descriptor;$/;"	t	typeref:struct:_hl_tensor_descriptor
hl_tensor_reshape	cuda/include/stub/hl_cuda_cudnn_stub.h	/^inline void hl_tensor_reshape(hl_tensor_descriptor image_desc,$/;"	f
hl_tensor_reshape	cuda/src/hl_cuda_cudnn.cc	/^void hl_tensor_reshape(hl_tensor_descriptor image_desc,$/;"	f
hl_trans_op_t	cuda/include/hl_base.h	/^} hl_trans_op_t;$/;"	t	typeref:enum:__anon3
hl_vector_abs_sum	cuda/include/stub/hl_aggregate_stub.h	/^inline void hl_vector_abs_sum(real *A_d, real *C_h, int dimM) {}$/;"	f
hl_vector_sum	cuda/include/stub/hl_aggregate_stub.h	/^inline void hl_vector_sum(real *A_d, real *C_h, int dimM) {}$/;"	f
hl_warpctc_compute_loss	cuda/src/hl_warpctc_wrap.cc	/^void hl_warpctc_compute_loss(const real* batchInput,$/;"	f
hl_warpctc_get_workspace_size	cuda/src/hl_warpctc_wrap.cc	/^void hl_warpctc_get_workspace_size(const int* cpuLabelLengths,$/;"	f
hl_warpctc_init	cuda/src/hl_warpctc_wrap.cc	/^void hl_warpctc_init(const size_t blank,$/;"	f
hl_warpctc_options_t	cuda/include/hl_warpctc_wrap.h	/^typedef ctcOptions hl_warpctc_options_t;$/;"	t
hl_warpctc_status_t	cuda/include/hl_warpctc_wrap.h	/^typedef ctcStatus_t hl_warpctc_status_t;$/;"	t
hook	gserver/tests/sequenceGen.py	/^def hook(settings, dict_file, **kwargs):$/;"	f
hook2	gserver/tests/sequenceGen.py	/^def hook2(settings, dict_file, **kwargs):$/;"	f
hppl	cuda/include/hl_activation_functions.h	/^namespace hppl {$/;"	n
hppl	cuda/include/hl_avx_functions.h	/^namespace hppl {$/;"	n
hppl	cuda/include/hl_functions.h	/^namespace hppl {$/;"	n
hppl	cuda/include/hl_tensor_ops.h	/^namespace hppl {$/;"	n
hppl	cuda/src/hl_avx_functions.cc	/^namespace hppl {$/;"	n	file:
hppl	cuda/src/hl_cpu_functions.cc	/^namespace hppl {$/;"	n	file:
hppl	cuda/src/hl_math.cc	/^namespace hppl {$/;"	n	file:
i	function/Function.h	/^    int i;$/;"	m	union:paddle::FuncConfig::value
id	pserver/ParameterClient2.h	/^  size_t id;         \/\/ id of the parameter$/;"	m	struct:paddle::ParameterSegments
idIndex	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::vector<int> idIndex;  \/\/ index of allIds$/;"	m	struct:paddle::RecurrentGradientMachine::Info
idIndex_	gserver/layers/AgentLayer.h	/^  int idIndex_;$/;"	m	class:paddle::ScatterAgentLayer
idIndex_	gserver/layers/AgentLayer.h	/^  std::vector<int> idIndex_;$/;"	m	class:paddle::GatherAgentLayer
idSize_	gserver/layers/AgentLayer.h	/^  int idSize_;$/;"	m	class:paddle::ScatterAgentLayer
ids	api/SequenceGenerator.cpp	/^  std::vector<int> ids;$/;"	m	struct:Path	file:
ids	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::vector<int> ids;  \/\/ store generated sequences$/;"	m	struct:paddle::RecurrentGradientMachine::Generator
ids	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::vector<int> ids;$/;"	m	struct:paddle::RecurrentGradientMachine::Path
ids	parameter/Argument.h	/^  IVectorPtr ids;  \/\/ a sequence of ids. Can be use for class id for costLayer$/;"	m	struct:paddle::Argument
ids	trainer/tests/testPyDataWrapper.py	/^ids = [sparse_id_randomer() for _ in range(seq_count_randomer())]$/;"	v
idsArray_	math/SparseRowMatrix.h	/^  std::vector<std::vector<uint32_t>> idsArray_;$/;"	m	class:paddle::SparseRowIdsCpuMatrix
idsVec_	gserver/layers/AgentLayer.h	/^  std::vector<IVectorPtr> idsVec_;$/;"	m	class:paddle::GatherAgentLayer
ids_	gserver/layers/AgentLayer.h	/^  IVectorPtr ids_;$/;"	m	class:paddle::ScatterAgentLayer
idxBuf	api/PaddleAPI.h	/^  const int* idxBuf;$/;"	m	struct:IntWithFloatArray
iidData	gserver/dataproviders/ProtoDataProvider.h	/^  inline bool iidData() const { return sequenceStartPositions_.empty(); }$/;"	f	class:paddle::ProtoDataProvider
iidData	gserver/dataproviders/PyDataProvider.h	/^  inline bool iidData() const { return isIID_; }$/;"	f	class:paddle::PyDataProvider
imageH_	gserver/layers/BatchNormBaseLayer.h	/^  int imageH_;$/;"	m	class:paddle::BatchNormBaseLayer
imageH_	gserver/layers/ConvOperator.cpp	/^  int imageH_, imageW_, outputH_, outputW_;$/;"	m	class:paddle::ConvOperator	file:
imageH_	gserver/layers/ConvProjection.h	/^  int imageH_, imageW_;$/;"	m	class:paddle::ConvProjection
imageH_	gserver/layers/CudnnPoolLayer.h	/^  int imageH_, imageW_, outputH_, outputW_;$/;"	m	class:paddle::CudnnPoolLayer
imageSize	math/MathUtils.cpp	/^int imageSize($/;"	f	namespace:paddle
imageW_	gserver/layers/BatchNormBaseLayer.h	/^  int imageW_;$/;"	m	class:paddle::BatchNormBaseLayer
imageW_	gserver/layers/ConvOperator.cpp	/^  int imageH_, imageW_, outputH_, outputW_;$/;"	m	class:paddle::ConvOperator	file:
imageW_	gserver/layers/ConvProjection.h	/^  int imageH_, imageW_;$/;"	m	class:paddle::ConvProjection
imageW_	gserver/layers/CudnnPoolLayer.h	/^  int imageH_, imageW_, outputH_, outputW_;$/;"	m	class:paddle::CudnnPoolLayer
imgPixels_	gserver/layers/BatchNormBaseLayer.h	/^  int imgPixels_;$/;"	m	class:paddle::BatchNormBaseLayer
imgPixels_	gserver/layers/ConvOperator.cpp	/^  int imgPixels_, filterPixels_, filterChannels_, outputX_, outputY_, outputs_;$/;"	m	class:paddle::ConvOperator	file:
imgSizeH_	gserver/layers/BlockExpandLayer.h	/^  size_t imgSizeH_, imgSizeW_, outputH_, outputW_, channels_;$/;"	m	class:paddle::BlockExpandLayer
imgSizeH_	gserver/layers/ConvBaseLayer.h	/^  IntV imgSizeH_;$/;"	m	class:paddle::ConvBaseLayer
imgSizeH_	gserver/layers/MaxOutLayer.h	/^  size_t imgSizeH_, imgSizeW_;$/;"	m	class:paddle::MaxOutLayer
imgSizeH_	gserver/layers/NormProjectionLayer.h	/^  size_t imgSizeH_, imgSizeW_;$/;"	m	class:paddle::CMRProjectionNormLayer
imgSizeH_	gserver/layers/PoolProjectionLayer.h	/^  size_t imgSizeH_, imgSizeW_;$/;"	m	class:paddle::PoolProjectionLayer
imgSizeH_	gserver/layers/SpatialPyramidPoolLayer.h	/^  size_t imgSizeH_;$/;"	m	class:paddle::SpatialPyramidPoolLayer
imgSizeW_	gserver/layers/BlockExpandLayer.h	/^  size_t imgSizeH_, imgSizeW_, outputH_, outputW_, channels_;$/;"	m	class:paddle::BlockExpandLayer
imgSizeW_	gserver/layers/ConvBaseLayer.h	/^  IntV imgSizeW_;$/;"	m	class:paddle::ConvBaseLayer
imgSizeW_	gserver/layers/MaxOutLayer.h	/^  size_t imgSizeH_, imgSizeW_;$/;"	m	class:paddle::MaxOutLayer
imgSizeW_	gserver/layers/NormProjectionLayer.h	/^  size_t imgSizeH_, imgSizeW_;$/;"	m	class:paddle::CMRProjectionNormLayer
imgSizeW_	gserver/layers/PoolProjectionLayer.h	/^  size_t imgSizeH_, imgSizeW_;$/;"	m	class:paddle::PoolProjectionLayer
imgSizeW_	gserver/layers/SpatialPyramidPoolLayer.h	/^  size_t imgSizeW_;$/;"	m	class:paddle::SpatialPyramidPoolLayer
imgSizeY_	gserver/layers/ConvOperator.cpp	/^  int padding_, stride_, filterSize_, channels_, imgSize_, imgSizeY_;$/;"	m	class:paddle::ConvOperator	file:
imgSizeY_	gserver/layers/NormLayer.h	/^  size_t channels_, size_, outputX_, imgSize_, outputY_, imgSizeY_;$/;"	m	class:paddle::ResponseNormLayer
imgSizeY_	gserver/layers/PoolLayer.h	/^  size_t imgSizeY_;$/;"	m	class:paddle::PoolLayer
imgSizeY_	gserver/layers/PoolProjection.h	/^  size_t imgSizeY_, imgSize_;$/;"	m	class:paddle::PoolProjection
imgSize_	gserver/layers/ConvOperator.cpp	/^  int padding_, stride_, filterSize_, channels_, imgSize_, imgSizeY_;$/;"	m	class:paddle::ConvOperator	file:
imgSize_	gserver/layers/NormLayer.h	/^  size_t channels_, size_, outputX_, imgSize_, outputY_, imgSizeY_;$/;"	m	class:paddle::ResponseNormLayer
imgSize_	gserver/layers/PoolLayer.h	/^  size_t channels_, sizeX_, stride_, outputX_, imgSize_;$/;"	m	class:paddle::PoolLayer
imgSize_	gserver/layers/PoolProjection.h	/^  size_t imgSizeY_, imgSize_;$/;"	m	class:paddle::PoolProjection
imm	cuda/src/avx_mathfun.h	/^  v8si imm;$/;"	m	union:imm_xmm_union
imm_xmm_union	cuda/src/avx_mathfun.h	/^typedef union imm_xmm_union {$/;"	u
imm_xmm_union	cuda/src/avx_mathfun.h	/^} imm_xmm_union;$/;"	t	typeref:union:imm_xmm_union
in	parameter/Argument.h	/^  MatrixPtr in;  \/\/ used if needed$/;"	m	struct:paddle::Argument
inArgs	gserver/tests/test_NetworkCompare.cpp	/^  std::vector<Argument> inArgs;$/;"	m	struct:DataIn	file:
inArgsCopied_	gserver/gradientmachines/MultiGradientMachine.h	/^  bool inArgsCopied_;$/;"	m	class:paddle::MultiGradientMachine
inArgsCopied_	gserver/gradientmachines/MultiGradientMachine.h	/^  bool inArgsCopied_;$/;"	m	class:paddle::TrainerThread
inArgs_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<Argument> inArgs_;$/;"	m	class:paddle::MultiGradientMachine
inArgs_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<Argument> inArgs_;$/;"	m	class:paddle::TrainerThread
inDims_	gserver/layers/PadLayer.h	/^  TensorShape inDims_;$/;"	m	class:paddle::PadLayer
inFrameLines_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<InFrameLine> inFrameLines_;$/;"	m	class:paddle::RecurrentGradientMachine
inGrad_	gserver/layers/BatchNormalizationLayer.h	/^  MatrixPtr expandedInGrad_, expandedOutGrad_, inGrad_;$/;"	m	class:paddle::BatchNormalizationLayer
inImgH_	gserver/layers/BilinearInterpLayer.h	/^  size_t inImgH_, inImgW_;$/;"	m	class:paddle::BilinearInterpLayer
inImgW_	gserver/layers/BilinearInterpLayer.h	/^  size_t inImgH_, inImgW_;$/;"	m	class:paddle::BilinearInterpLayer
inLayer	gserver/gradientmachines/RecurrentGradientMachine.h	/^    LayerPtr inLayer;$/;"	m	struct:paddle::RecurrentGradientMachine::InFrameLine
inStatus	pserver/ParameterClient2.cpp	/^bool ParameterClient2::inStatus(PServerStatus status) {$/;"	f	class:paddle::ParameterClient2
in_	gserver/layers/Projection.h	/^  const Argument* in_;$/;"	m	class:paddle::Projection
incShared	parameter/Parameter.h	/^  void incShared() { sharedCount_++; }$/;"	f	class:paddle::Parameter
incUpdate	parameter/Parameter.cpp	/^void Parameter::incUpdate(const UpdateCallback& callback) {$/;"	f	class:paddle::Parameter
incUpdate	parameter/Weight.h	/^  void incUpdate(const UpdateCallback& callback) {$/;"	f	class:paddle::Weight
incUpdateCounter	gserver/gradientmachines/MultiGradientMachine.h	/^  void incUpdateCounter(int n = 1) {$/;"	f	class:paddle::TrainerThread
include_dirs	setup.py	/^       include_dirs = include_dirs,$/;"	v
include_dirs	setup.py	/^  include_dirs = include_dirs,$/;"	v
include_dirs	setup.py	/^include_dirs = [np.get_include(), "..\/"]    # include numpy and paddle.$/;"	v
indexData	gserver/dataproviders/ProtoDataProvider.h	/^    std::vector<int> indexData;$/;"	m	struct:paddle::ProtoDataProvider::ProtoSlot
indexData	gserver/dataproviders/PyDataProvider.h	/^    std::vector<int> indexData;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
indexDictHandle_	math/SparseRowMatrix.h	/^  IndexDictPtr indexDictHandle_;$/;"	m	class:paddle::SparseRowCpuMatrix
index_	utils/BarrierStat.h	/^  uint16_t index_;$/;"	m	class:paddle::TimeVectorDelta
index_	utils/BarrierStat.h	/^  uint16_t index_;$/;"	m	class:paddle::TimeVectorEnd
index_value_creator	gserver/tests/pyDataProvider.py	/^def index_value_creator(sample_num):$/;"	f
indices	gserver/dataproviders/ProtoDataProvider.h	/^    std::vector<int64_t> indices;$/;"	m	struct:paddle::ProtoDataProvider::ProtoSlot
indices	gserver/dataproviders/PyDataProvider.h	/^    std::vector<int64_t> indices;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
infoBatch_	gserver/dataproviders/DataProvider.h	/^  ThreadLocal<IVectorPtr> infoBatch_;$/;"	m	class:paddle::SimpleDataProviderBase
info_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<Info> info_;$/;"	m	class:paddle::RecurrentGradientMachine
info_	utils/Stat.h	/^  const char* info_;$/;"	m	class:paddle::TimerOnce
init	api/ParameterOptimizer.cpp	/^void ParameterOptimizer::init(size_t numRows, const ParameterConfig* config) {$/;"	f	class:ParameterOptimizer
init	api/ParameterUpdater.cpp	/^void ParameterUpdater::init(const GradientMachine &gm) {$/;"	f	class:ParameterUpdater
init	function/Function.h	/^  virtual void init(const FuncConfig& config) {}$/;"	f	class:paddle::FunctionBase
init	gserver/evaluators/ChunkEvaluator.cpp	/^  virtual void init(const EvaluatorConfig& config) {$/;"	f	class:paddle::ChunkEvaluator
init	gserver/evaluators/Evaluator.cpp	/^  virtual void init(const EvaluatorConfig& config) {$/;"	f	class:paddle::SequenceTextPrinter
init	gserver/evaluators/Evaluator.h	/^  virtual void init(const EvaluatorConfig& config) { config_ = config; }$/;"	f	class:paddle::Evaluator
init	gserver/evaluators/Evaluator.h	/^  virtual void init(const EvaluatorConfig&) {}$/;"	f	class:paddle::DummyEvaluator
init	gserver/gradientmachines/MultiNetwork.cpp	/^void MultiNetwork::init(const ModelConfig& config,$/;"	f	class:paddle::MultiNetwork
init	gserver/gradientmachines/NeuralNetwork.cpp	/^void NeuralNetwork::init(const ModelConfig& config,$/;"	f	class:paddle::NeuralNetwork
init	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^void ParallelNeuralNetwork::init($/;"	f	class:paddle::ParallelNeuralNetwork
init	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::init($/;"	f	class:paddle::RecurrentGradientMachine
init	gserver/layers/AddtoLayer.cpp	/^bool AddtoLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::AddtoLayer
init	gserver/layers/AgentLayer.cpp	/^bool AgentLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::AgentLayer
init	gserver/layers/AgentLayer.cpp	/^bool GatherAgentLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::GatherAgentLayer
init	gserver/layers/AgentLayer.cpp	/^bool ScatterAgentLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::ScatterAgentLayer
init	gserver/layers/AverageLayer.cpp	/^bool AverageLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::AverageLayer
init	gserver/layers/BatchNormBaseLayer.cpp	/^bool BatchNormBaseLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::BatchNormBaseLayer
init	gserver/layers/BatchNormalizationLayer.cpp	/^bool BatchNormalizationLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::BatchNormalizationLayer
init	gserver/layers/BilinearInterpLayer.cpp	/^bool BilinearInterpLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::BilinearInterpLayer
init	gserver/layers/BlockExpandLayer.cpp	/^bool BlockExpandLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::BlockExpandLayer
init	gserver/layers/CRFDecodingLayer.cpp	/^bool CRFDecodingLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::CRFDecodingLayer
init	gserver/layers/CRFLayer.cpp	/^bool CRFLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::CRFLayer
init	gserver/layers/CTCLayer.cpp	/^bool CTCLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::CTCLayer
init	gserver/layers/ConcatenateLayer.cpp	/^bool ConcatenateLayer2::init(const LayerMap& layerMap,$/;"	f	class:paddle::ConcatenateLayer2
init	gserver/layers/ConcatenateLayer.cpp	/^bool ConcatenateLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::ConcatenateLayer
init	gserver/layers/ContextProjection.cpp	/^bool ContextProjection::init() {$/;"	f	class:paddle::ContextProjection
init	gserver/layers/ConvBaseLayer.cpp	/^bool ConvBaseLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::ConvBaseLayer
init	gserver/layers/ConvShiftLayer.cpp	/^bool ConvShiftLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::ConvShiftLayer
init	gserver/layers/ConvexCombinationLayer.cpp	/^bool ConvexCombinationLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::ConvexCombinationLayer
init	gserver/layers/CosSimLayer.cpp	/^bool CosSimLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::CosSimLayer
init	gserver/layers/CosSimVecMatLayer.cpp	/^bool CosSimVecMatLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::CosSimVecMatLayer
init	gserver/layers/CostLayer.cpp	/^bool CostLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::CostLayer
init	gserver/layers/CostLayer.cpp	/^bool HuberTwoClass::init(const LayerMap& layerMap,$/;"	f	class:paddle::HuberTwoClass
init	gserver/layers/CostLayer.cpp	/^bool LambdaCost::init(const LayerMap& layerMap,$/;"	f	class:paddle::LambdaCost
init	gserver/layers/CostLayer.cpp	/^bool MultiBinaryLabelCrossEntropy::init(const LayerMap& layerMap,$/;"	f	class:paddle::MultiBinaryLabelCrossEntropy
init	gserver/layers/CostLayer.cpp	/^bool MultiClassCrossEntropy::init(const LayerMap& layerMap,$/;"	f	class:paddle::MultiClassCrossEntropy
init	gserver/layers/CostLayer.cpp	/^bool MultiClassCrossEntropyWithSelfNorm::init($/;"	f	class:paddle::MultiClassCrossEntropyWithSelfNorm
init	gserver/layers/CostLayer.cpp	/^bool RankingCost::init(const LayerMap& layerMap,$/;"	f	class:paddle::RankingCost
init	gserver/layers/CostLayer.cpp	/^bool SoftBinaryClassCrossEntropy::init(const LayerMap& layerMap,$/;"	f	class:paddle::SoftBinaryClassCrossEntropy
init	gserver/layers/CostLayer.cpp	/^bool SumOfSquaresCostLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::SumOfSquaresCostLayer
init	gserver/layers/CudnnBatchNormLayer.cpp	/^bool CudnnBatchNormLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::CudnnBatchNormLayer
init	gserver/layers/CudnnConvLayer.cpp	/^bool CudnnConvLayer::init(const LayerMap &layerMap,$/;"	f	class:paddle::CudnnConvLayer
init	gserver/layers/CudnnPoolLayer.cpp	/^bool CudnnPoolLayer::init(const LayerMap &layerMap,$/;"	f	class:paddle::CudnnPoolLayer
init	gserver/layers/DataNormLayer.cpp	/^bool DataNormLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::DataNormLayer
init	gserver/layers/ExpandConvBaseLayer.cpp	/^bool ExpandConvBaseLayer::init(const LayerMap &layerMap,$/;"	f	class:paddle::ExpandConvBaseLayer
init	gserver/layers/ExpandConvLayer.cpp	/^bool ExpandConvLayer::init(const LayerMap &layerMap,$/;"	f	class:paddle::ExpandConvLayer
init	gserver/layers/ExpandConvTransLayer.cpp	/^bool ExpandConvTransLayer::init(const LayerMap &layerMap,$/;"	f	class:paddle::ExpandConvTransLayer
init	gserver/layers/ExpandLayer.cpp	/^bool ExpandLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::ExpandLayer
init	gserver/layers/FeatureMapExpandLayer.cpp	/^bool FeatureMapExpandLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::FeatureMapExpandLayer
init	gserver/layers/FullyConnectedLayer.cpp	/^bool FullyConnectedLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::FullyConnectedLayer
init	gserver/layers/GatedRecurrentLayer.cpp	/^bool GatedRecurrentLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::GatedRecurrentLayer
init	gserver/layers/GruCompute.cpp	/^void GruCompute::init(LayerConfig &config) {$/;"	f	class:paddle::GruCompute
init	gserver/layers/GruStepLayer.cpp	/^bool GruStepLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::GruStepLayer
init	gserver/layers/HierarchicalSigmoidLayer.cpp	/^bool HierarchicalSigmoidLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::HierarchicalSigmoidLayer
init	gserver/layers/InterpolationLayer.cpp	/^bool InterpolationLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::InterpolationLayer
init	gserver/layers/Layer.cpp	/^bool Layer::init(const LayerMap& layerMap, const ParameterMap& parameterMap) {$/;"	f	class:paddle::Layer
init	gserver/layers/LstmCompute.cpp	/^void LstmCompute::init(LayerConfig &config) {$/;"	f	class:paddle::LstmCompute
init	gserver/layers/LstmLayer.cpp	/^bool LstmLayer::init(const LayerMap &layerMap,$/;"	f	class:paddle::LstmLayer
init	gserver/layers/LstmStepLayer.cpp	/^bool LstmStepLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::LstmStepLayer
init	gserver/layers/MDLstmLayer.cpp	/^bool MDLstmLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::MDLstmLayer
init	gserver/layers/MaxOutLayer.cpp	/^bool MaxOutLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::MaxOutLayer
init	gserver/layers/MixedLayer.cpp	/^bool MixedLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::MixedLayer
init	gserver/layers/MultiplexLayer.cpp	/^bool MultiplexLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::MultiplexLayer
init	gserver/layers/NormLayer.cpp	/^bool ResponseNormLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::ResponseNormLayer
init	gserver/layers/NormProjectionLayer.cpp	/^bool CMRProjectionNormLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::CMRProjectionNormLayer
init	gserver/layers/OuterProdLayer.cpp	/^bool OuterProdLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::OuterProdLayer
init	gserver/layers/PadLayer.cpp	/^bool PadLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::PadLayer
init	gserver/layers/ParameterReluLayer.cpp	/^bool ParameterReluLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::ParameterReluLayer
init	gserver/layers/PoolLayer.cpp	/^bool PoolLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::PoolLayer
init	gserver/layers/PowerLayer.cpp	/^bool PowerLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::PowerLayer
init	gserver/layers/PriorBox.cpp	/^bool PriorBoxLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::PriorBoxLayer
init	gserver/layers/Projection.h	/^  virtual bool init() { return true; }$/;"	f	class:paddle::Projection
init	gserver/layers/RecurrentLayer.cpp	/^bool RecurrentLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::RecurrentLayer
init	gserver/layers/ResizeLayer.cpp	/^bool ResizeLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::ResizeLayer
init	gserver/layers/RotateLayer.cpp	/^bool RotateLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::RotateLayer
init	gserver/layers/ScalingLayer.cpp	/^bool ScalingLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::ScalingLayer
init	gserver/layers/SelectiveFullyConnectedLayer.cpp	/^bool SelectiveFullyConnectedLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::SelectiveFullyConnectedLayer
init	gserver/layers/SequenceConcatLayer.cpp	/^bool SequenceConcatLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::SequenceConcatLayer
init	gserver/layers/SequenceLastInstanceLayer.cpp	/^bool SequenceLastInstanceLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::SequenceLastInstanceLayer
init	gserver/layers/SequencePoolLayer.cpp	/^bool SequencePoolLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::SequencePoolLayer
init	gserver/layers/SequenceReshapeLayer.cpp	/^bool SequenceReshapeLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::SequenceReshapeLayer
init	gserver/layers/SlopeInterceptLayer.cpp	/^bool SlopeInterceptLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::SlopeInterceptLayer
init	gserver/layers/SpatialPyramidPoolLayer.cpp	/^bool SpatialPyramidPoolLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::SpatialPyramidPoolLayer
init	gserver/layers/SubSequenceLayer.cpp	/^bool SubSequenceLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::SubSequenceLayer
init	gserver/layers/SumToOneNormLayer.cpp	/^bool SumToOneNormLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::SumToOneNormLayer
init	gserver/layers/TensorLayer.cpp	/^bool TensorLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::TensorLayer
init	gserver/layers/TransLayer.cpp	/^bool TransLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::TransLayer
init	gserver/layers/ValidationLayer.cpp	/^bool AucValidation::init(const LayerMap& layerMap,$/;"	f	class:paddle::AucValidation
init	gserver/layers/ValidationLayer.cpp	/^bool PnpairValidation::init(const LayerMap& layerMap,$/;"	f	class:paddle::PnpairValidation
init	gserver/layers/ValidationLayer.cpp	/^bool ValidationLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::ValidationLayer
init	gserver/layers/WarpCTCLayer.cpp	/^bool WarpCTCLayer::init(const LayerMap& layerMap,$/;"	f	class:paddle::WarpCTCLayer
init	gserver/tests/test_RecurrentLayer.cpp	/^  void init(size_t batchSize) {$/;"	f	class:TestRecurrentLayer
init	math/SparseRowMatrix.cpp	/^void SparseRowCpuMatrix::init(size_t height, size_t width) {$/;"	f	class:paddle::SparseRowCpuMatrix
init	math/tests/TestUtils.h	/^void init(CpuMatrix& v) {$/;"	f	namespace:autotest
init	math/tests/TestUtils.h	/^void init(GpuMatrix& v) {$/;"	f	namespace:autotest
init	math/tests/TestUtils.h	/^void init(T& v) {$/;"	f	namespace:autotest
init	parameter/AverageOptimizer.h	/^  virtual void init(size_t numRows, const ParameterConfig* config) {$/;"	f	class:paddle::AverageOptimizer
init	parameter/AverageOptimizer.h	/^  virtual void init(size_t numRows, const ParameterConfig* config) {$/;"	f	class:paddle::AverageSparseOptimizer
init	parameter/FirstOrderOptimizer.cpp	/^void SparseMomentumParameterOptimizer::init(size_t numRows,$/;"	f	class:paddle::SparseMomentumParameterOptimizer
init	parameter/FirstOrderOptimizer.h	/^  virtual void init(size_t numRows, const ParameterConfig* config) {$/;"	f	class:paddle::DecayedAdagradParameterOptimizer
init	parameter/FirstOrderOptimizer.h	/^  virtual void init(size_t numRows, const ParameterConfig* config) {$/;"	f	class:paddle::OptimizerWithGradientClipping
init	parameter/FirstOrderOptimizer.h	/^  virtual void init(size_t numRows, const ParameterConfig* config) {$/;"	f	class:paddle::RMSPropParameterOptimizer
init	parameter/OptimizerWithRegularizer.cpp	/^void OptimizerWithRegularizerSparse::init(size_t numRows,$/;"	f	class:paddle::OptimizerWithRegularizerSparse
init	parameter/OptimizerWithRegularizer.h	/^  virtual void init(size_t numRows, const ParameterConfig* config) {$/;"	f	class:paddle::OptimizerWithRegularizer
init	parameter/ParameterOptimizer.h	/^  virtual void init(size_t numRows, const ParameterConfig* config) {}$/;"	f	class:paddle::ParameterOptimizer
init	parameter/ParameterUpdaterBase.cpp	/^void ParameterUpdater::init(const std::vector<ParameterPtr>& parameters) {$/;"	f	class:paddle::ParameterUpdater
init	parameter/ParameterUpdaterHook.cpp	/^  void init(Parameter* para) {$/;"	f	class:paddle::StaticPruningHook
init	pserver/ParameterClient2.cpp	/^bool ParameterClient2::init(const std::vector<ParameterPtr>& parameters) {$/;"	f	class:paddle::ParameterClient2
init	pserver/ParameterServer2.cpp	/^bool ParameterServer2::init() {$/;"	f	class:paddle::ParameterServer2
init	pserver/RDMANetwork.h	/^inline void init() {$/;"	f	namespace:paddle::rdma
init	trainer/ParameterUpdater.cpp	/^void SgdUpdaterWithCpuAverager::init($/;"	f	class:paddle::SgdUpdaterWithCpuAverager
init	trainer/ParameterUpdater.h	/^  virtual void init(const std::vector<ParameterPtr>& parameters) {$/;"	f	class:paddle::SgdLocalUpdater
init	trainer/RemoteParameterUpdater.cpp	/^void RemoteParameterUpdater::init(const std::vector<ParameterPtr>& parameters) {$/;"	f	class:paddle::RemoteParameterUpdater
init	trainer/RemoteParameterUpdater.cpp	/^void SparseRemoteParameterUpdater::init($/;"	f	class:paddle::SparseRemoteParameterUpdater
init	trainer/RemoteParameterUpdater.cpp	/^void SparseRemoteParameterUpdaterComposite::init($/;"	f	class:paddle::SparseRemoteParameterUpdaterComposite
init	trainer/ThreadParameterUpdater.cpp	/^void SgdThreadUpdater::init(const std::vector<ParameterPtr>& parameters) {$/;"	f	class:paddle::SgdThreadUpdater
init	trainer/Trainer.cpp	/^void Trainer::init(const std::shared_ptr<TrainerConfigHelper>& config,$/;"	f	class:paddle::Trainer
init	trainer/TrainerInternal.cpp	/^void TrainerInternal::init(const std::shared_ptr<TrainerConfigHelper>& config,$/;"	f	class:paddle::TrainerInternal
initArg	function/FunctionTest.h	/^  void initArg(BufferArg& arg) {$/;"	f	class:paddle::FunctionCompare
initArg	function/FunctionTest.h	/^  void initArg(SequenceArg& arg) {$/;"	f	class:paddle::FunctionCompare
initArg	function/FunctionTest.h	/^  void initArg(SequenceIdArg& arg, size_t batchSize) {$/;"	f	class:paddle::FunctionCompare
initArgument	gserver/tests/test_NetworkCompare.cpp	/^void initArgument(DataIn& data,$/;"	f
initArgument	gserver/tests/test_WarpCTCLayer.cpp	/^void initArgument(size_t batchSize,$/;"	f
initAsyncLoader	gserver/dataproviders/DataProvider.cpp	/^void DataProvider::initAsyncLoader() {$/;"	f	class:paddle::DataProvider
initBatchState	gserver/tests/LayerGradUtil.cpp	/^void initBatchState(LayerPtr dataLayer,$/;"	f	namespace:paddle
initBlock	math/Matrix.cpp	/^void SharedCpuMatrix::initBlock(int blockNum) {$/;"	f	class:paddle::SharedCpuMatrix
initCount_	parameter/ParameterUpdaterHook.cpp	/^  std::atomic<size_t> initCount_;$/;"	m	class:paddle::StaticPruningHook	file:
initCudnn	gserver/layers/ConvProjection.cpp	/^void ConvProjection::initCudnn() {$/;"	f	class:paddle::ConvProjection
initDataFlag_	pserver/LightNetwork.cpp	/^std::once_flag RdmaClientDaemons::initDataFlag_;$/;"	m	class:paddle::RdmaClientDaemons	file:
initDataFlag_	pserver/LightNetwork.h	/^  static std::once_flag initDataFlag_;$/;"	m	class:paddle::RdmaClientDaemons
initDataLayer	gserver/tests/LayerGradUtil.cpp	/^void initDataLayer(TestConfig testConf,$/;"	f	namespace:paddle
initDims	function/TensorShape.h	/^  void initDims(size_t ndims) {$/;"	f	class:paddle::TensorShape
initFcLayer	gserver/tests/test_SelectiveFCLayer.cpp	/^LayerPtr initFcLayer(LayerPtr dataLayer,$/;"	f
initHook	parameter/Parameter.h	/^  void initHook() {$/;"	f	class:paddle::Parameter
initInputs	function/FunctionTest.h	/^  void initInputs() {$/;"	f	class:paddle::FunctionCompare
initMain	utils/Util.cpp	/^void initMain(int argc, char** argv) {$/;"	f	namespace:paddle
initModelPath	trainer/TesterConfig.h	/^  std::string initModelPath;$/;"	m	struct:paddle::TesterConfig
initNeedFlags	gserver/layers/Layer.cpp	/^void Layer::initNeedFlags() {$/;"	f	class:paddle::Layer
initOutputs	function/FunctionTest.h	/^  void initOutputs() {$/;"	f	class:paddle::FunctionCompare
initPaddle	api/Util.cpp	/^void initPaddle(int argc, char** argv) {$/;"	f
initPython	utils/PythonUtil.cpp	/^void initPython(int argc, char** argv) {$/;"	f	namespace:paddle
initRecurrentLayer	gserver/tests/test_RecurrentLayer.cpp	/^LayerPtr initRecurrentLayer(LayerConfig layerConfig,$/;"	f
initSeed	utils/ThreadLocal.h	/^  static void initSeed(unsigned int seed) { defaultSeed_ = seed; }$/;"	f	class:paddle::ThreadLocalRand
initShared	math/Matrix.cpp	/^void SharedCpuMatrix::initShared(int blockNum) {$/;"	f	class:paddle::SharedCpuMatrix
initSubNetwork	gserver/layers/Layer.h	/^  virtual void initSubNetwork(NeuralNetwork* rootNetwork,$/;"	f	class:paddle::Layer
initSubNetwork	gserver/layers/RecurrentLayerGroup.cpp	/^void RecurrentLayerGroup::initSubNetwork($/;"	f	class:paddle::RecurrentLayerGroup
initTestLayer	gserver/tests/LayerGradUtil.cpp	/^void initTestLayer(TestConfig testConf,$/;"	f	namespace:paddle
initThreadSeed	utils/ThreadLocal.h	/^  static void initThreadSeed(int tid) {$/;"	f	class:paddle::ThreadLocalRand
initThreads	pserver/ParameterClient2.cpp	/^void ParameterClient2::initThreads() {$/;"	f	class:paddle::ParameterClient2
initTuple	math/tests/TestUtils.h	/^inline typename std::enable_if<I == sizeof...(Args), void>::type initTuple($/;"	f	namespace:autotest
initWeight	gserver/tests/LayerGradUtil.cpp	/^void initWeight(MatrixPtr& weights) {$/;"	f	namespace:paddle
init_hook	trainer/tests/simple_sparse_neural_network_dp.py	/^def init_hook(settings, is_train, **kwargs):$/;"	f
init_model_path	api/Trainer.cpp	/^DECLARE_string(init_model_path);$/;"	v
init_model_path	gserver/tests/test_SelectiveFCLayer.cpp	/^DECLARE_string(init_model_path);$/;"	v
init_model_path	trainer/TrainerConfigHelper.cpp	/^DECLARE_string(init_model_path);$/;"	v
init_model_path	trainer/TrainerMain.cpp	/^DECLARE_string(init_model_path);$/;"	v
init_model_path	utils/Flags.h	/^DECLARE_string(init_model_path);$/;"	v
init_optimizers	api/test/testTrain.py	/^def init_optimizers(opt_conf, params):$/;"	f
init_param	api/test/testTrain.py	/^    def init_param(p):$/;"	f	function:init_params
init_params	api/test/testTrain.py	/^def init_params(params):$/;"	f
initialize	parameter/Parameter.cpp	/^void Parameter::initialize() {$/;"	f	class:paddle::Parameter
initializeLogging	utils/Logging.cpp	/^void initializeLogging(int argc, char** argv) {$/;"	f	namespace:paddle
initializePaddle	py_paddle/util.py	/^def initializePaddle(*args):$/;"	f
inner_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::unique_ptr<IFieldScanner> inner_;$/;"	m	class:paddle::SequenceScanner	file:
inner_step	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^    def inner_step(ipt):$/;"	f	function:outer_step
inner_step_impl	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^        def inner_step_impl(y):$/;"	f	function:outer_step.inner_step
input	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^    input=[$/;"	v
input	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^    input=[SubsequenceInput(emb1), SubsequenceInput(emb2)],$/;"	v
input	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^    input=[$/;"	v
input	trainer/tests/picojson.h	/^  input(const Iter& first, const Iter& last)$/;"	f	class:picojson::input
input	trainer/tests/picojson.h	/^class input {$/;"	c	namespace:picojson
input	trainer/tests/simple_sparse_neural_network.py	/^    input=data_layer($/;"	v
inputArgument_	gserver/layers/Layer.h	/^  std::vector<std::string> inputArgument_;$/;"	m	class:paddle::Layer
inputDefs	gserver/tests/LayerGradUtil.h	/^  std::vector<InputDef> inputDefs;$/;"	m	struct:paddle::TestConfig
inputDefs	gserver/tests/test_Evaluator.cpp	/^  std::vector<InputDef> inputDefs;$/;"	m	struct:TestConfig	file:
inputDesc_	gserver/layers/ConvOperator.cpp	/^  hl_tensor_descriptor inputDesc_;$/;"	m	class:paddle::ConvOperator	file:
inputDesc_	gserver/layers/ConvProjection.h	/^  hl_tensor_descriptor inputDesc_;$/;"	m	class:paddle::ConvProjection
inputDesc_	gserver/layers/CudnnPoolLayer.h	/^  hl_tensor_descriptor inputDesc_;$/;"	m	class:paddle::CudnnPoolLayer
inputIovs_	pserver/ParameterClient2.h	/^  std::vector<iovec> inputIovs_;$/;"	m	class:paddle::PreparedOperations
inputLayers_	gserver/layers/Layer.h	/^  std::vector<LayerPtr> inputLayers_;$/;"	m	class:paddle::Layer
inputNum_	gserver/layers/SelectiveFullyConnectedLayer.h	/^  size_t inputNum_;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
inputOffset_	gserver/layers/ConvOperator.cpp	/^  int inputOffset_, outputOffset_, weightOffset_;$/;"	m	class:paddle::ConvOperator	file:
inputOffset_	gserver/layers/ConvProjection.h	/^  int inputOffset_;$/;"	m	class:paddle::ConvProjection
inputStartPos_	gserver/layers/AgentLayer.h	/^  ICpuGpuVectorPtr inputStartPos_;$/;"	m	class:paddle::SequenceScatterAgentLayer
inputType	gserver/tests/LayerGradUtil.h	/^  InputType inputType;$/;"	m	struct:paddle::InputDef
inputType	gserver/tests/test_Evaluator.cpp	/^  InputType inputType;$/;"	m	struct:InputDef	file:
input_types	gserver/tests/rnn_data_provider.py	/^    input_types=[$/;"	v
input_types	gserver/tests/rnn_data_provider.py	/^    input_types=[integer_value_sub_sequence(10), integer_value(3)],$/;"	v
input_types	gserver/tests/test_PyDataProvider2.py	/^    input_types=[index_slot(10)],$/;"	v
ins_	gserver/layers/Operator.h	/^  std::vector<const Argument*> ins_;$/;"	m	class:paddle::Operator
insertOneBatch	gserver/dataproviders/DataProvider.cpp	/^void DoubleBuffer::insertOneBatch(DataBatch* batch) {$/;"	f	class:paddle::DoubleBuffer
insertions_	gserver/evaluators/CTCErrorEvaluator.cpp	/^  real deletions_, insertions_, substitutions_;$/;"	m	class:paddle::CTCErrorEvaluator	file:
installFailureFunction	utils/Logging.cpp	/^void installFailureFunction(void (*callback)()) {$/;"	f	namespace:paddle::logging
installFailureWriter	utils/Logging.cpp	/^void installFailureWriter(void (*callback)(const char*, int)) {$/;"	f	namespace:paddle::logging
installLayerStackTracer	utils/CustomStackTrace.cpp	/^void installLayerStackTracer() {$/;"	f	namespace:paddle
installProfilerSwitch	utils/Util.cpp	/^static void installProfilerSwitch() {$/;"	f	file:
installProfilerSwitch	utils/Util.cpp	/^static void installProfilerSwitch() {}$/;"	f	file:
install_requires	setup.py	/^  install_requires = [$/;"	v
instance	utils/CpuId.cpp	/^SIMDFlags const* SIMDFlags::instance() {$/;"	f	class:paddle::SIMDFlags
instance_	gserver/dataproviders/PyDataProvider2.cpp	/^  PyObjectPtr instance_;$/;"	m	class:paddle::PyDataProvider2	file:
int64_	trainer/tests/picojson.h	/^    int64_t int64_;$/;"	m	union:picojson::value::_storage
int64_type	trainer/tests/picojson.h	/^  int64_type$/;"	e	enum:picojson::__anon14
intBufs_	parameter/Parameter.h	/^  IVectorPtr intBufs_[NUM_PARAMETER_TYPES];$/;"	m	class:paddle::Parameter
intConfig_	trainer/ParamUtil.h	/^  std::unique_ptr<ParameterUtilConfig> intConfig_;$/;"	m	class:paddle::ParameterUtil
intHasher_	parameter/ParameterUpdaterHook.cpp	/^  std::hash<int> intHasher_;$/;"	m	class:paddle::StringIntPairHasher	file:
intconfig_	trainer/Tester.h	/^  std::unique_ptr<TesterConfig> intconfig_;$/;"	m	class:paddle::Tester
intconfig_	trainer/TrainerInternal.h	/^  std::unique_ptr<TrainerInternalConfig> intconfig_;$/;"	m	class:paddle::TrainerInternal
interOutGrad_	gserver/layers/SelectiveFullyConnectedLayer.h	/^  MatrixPtr interOutGrad_;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
interOutput_	gserver/layers/SelectiveFullyConnectedLayer.h	/^  MatrixPtr interOutput_;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
internal	math/SIMDFunctions.cpp	/^namespace internal {$/;"	n	namespace:paddle::simd	file:
internal	math/SIMDFunctions.h	/^namespace internal {$/;"	n	namespace:paddle::simd
intervals_	gserver/layers/MultinomialSampler.h	/^  std::vector<Interval> intervals_;$/;"	m	class:paddle::MultinomialSampler
inverse	math/Matrix.cpp	/^void CpuMatrix::inverse(MatrixPtr& matInv, bool memAlloc) {$/;"	f	class:paddle::CpuMatrix
inverse	math/Matrix.cpp	/^void GpuMatrix::inverse(MatrixPtr& matInv, bool memAlloc) {$/;"	f	class:paddle::GpuMatrix
inverse	math/Matrix.h	/^  virtual void inverse(MatrixPtr& matInv, bool memAlloc) {$/;"	f	class:paddle::Matrix
invokeThreadId_	utils/Util.h	/^  std::thread::id invokeThreadId_;$/;"	m	class:paddle::SameThreadChecker
ioDesc_	gserver/layers/CudnnBatchNormLayer.h	/^  hl_tensor_descriptor ioDesc_;$/;"	m	class:paddle::CudnnBatchNormLayer
iovLengths	pserver/SocketChannel.h	/^    int64_t iovLengths[0];$/;"	m	struct:paddle::SocketChannel::MessageHeader
is	trainer/tests/picojson.h	/^inline bool value::is<double>() const {$/;"	f	class:picojson::value
isAutoGrowth	math/RowBuffer.h	/^  inline bool isAutoGrowth() const { return !preallocatedBuf_; }$/;"	f	class:paddle::RowBuffer
isAverageWindowTooLong	parameter/AverageOptimizer.h	/^  bool isAverageWindowTooLong() const {$/;"	f	class:paddle::AverageOptimizer
isCallable	utils/PythonUtil.h	/^inline static bool isCallable(const PyObjectPtr& obj) {$/;"	f	namespace:paddle::py
isChunkBegin	gserver/evaluators/ChunkEvaluator.cpp	/^  bool isChunkBegin(int prevTag, int prevType, int tag, int type) {$/;"	f	class:paddle::ChunkEvaluator
isChunkEnd	gserver/evaluators/ChunkEvaluator.cpp	/^  bool isChunkEnd(int prevTag, int prevType, int tag, int type) {$/;"	f	class:paddle::ChunkEvaluator
isContiguous	math/Matrix.h	/^  bool isContiguous() const { return stride_ == width_ || height_ == 1; }$/;"	f	class:paddle::Matrix
isContiguous	math/TensorApply.h	/^  INLINE bool isContiguous() const { return expr_.isContiguous(); }$/;"	f	class:paddle::TensorApply
isContiguous	math/TensorApply.h	/^  INLINE bool isContiguous() const { return stride_ == width_ || height_ == 1; }$/;"	f	class:paddle::TensorApply
isContiguous	math/TensorApply.h	/^  INLINE bool isContiguous() const { return true; }$/;"	f	class:paddle::TensorApply
isContiguous	math/TensorApply.h	/^  INLINE bool isContiguous() const {$/;"	f	class:paddle::TensorApply
isContiguous	math/TensorAssign.h	/^  INLINE bool isContiguous() const {$/;"	f	class:paddle::TensorAssignOp
isDeconv_	gserver/layers/ConvBaseLayer.h	/^  bool isDeconv_;$/;"	m	class:paddle::ConvBaseLayer
isDir	utils/Util.cpp	/^int isDir(const char* path) {$/;"	f	namespace:paddle
isDropable	gserver/gradientmachines/RecurrentGradientMachine.h	/^    bool isDropable() const { return std::isinf(logProb) && logProb < 0; }$/;"	f	struct:paddle::RecurrentGradientMachine::Path
isEmpty	math/Matrix.h	/^  bool isEmpty() const { return data_ == nullptr; }$/;"	f	class:paddle::Matrix
isEqualTo	math/Vector.cpp	/^void CpuVectorT<T>::isEqualTo(const VectorT<T>& b, const T& value) {$/;"	f	class:paddle::CpuVectorT
isEqualTo	math/Vector.cpp	/^void GpuVectorT<T>::isEqualTo(const VectorT<T>& b, const T& value) {$/;"	f	class:paddle::GpuVectorT
isFirstPass_	trainer/RemoteParameterUpdater.h	/^  bool isFirstPass_;$/;"	m	class:paddle::RemoteParameterUpdater
isFullSize	parameter/Parameter.h	/^  bool isFullSize() const {$/;"	f	class:paddle::Parameter
isGpu	api/Matrix.cpp	/^bool Matrix::isGpu() const {$/;"	f	class:Matrix
isGpu	api/Vector.cpp	/^bool IVector::isGpu() const {$/;"	f	class:IVector
isGpu	api/Vector.cpp	/^bool Vector::isGpu() const {$/;"	f	class:Vector
isGpuVersion	api/Util.cpp	/^bool isGpuVersion() {$/;"	f
isGradShared	parameter/Parameter.cpp	/^bool Parameter::isGradShared(size_t* blockNum) {$/;"	f	class:paddle::Parameter
isGradSparseUpdate	parameter/Parameter.cpp	/^bool Parameter::isGradSparseUpdate() const {$/;"	f	class:paddle::Parameter
isIID_	gserver/dataproviders/PyDataProvider.h	/^  bool isIID_;$/;"	m	class:paddle::PyDataProvider
isInvalid_	gserver/layers/LinearChainCTC.h	/^  bool isInvalid_;$/;"	m	class:paddle::LinearChainCTC
isMultiBinaryLabel_	gserver/evaluators/Evaluator.h	/^  bool isMultiBinaryLabel_;$/;"	m	class:paddle::PrecisionRecallEvaluator
isPaddleUseDouble	utils/Version.h	/^constexpr bool isPaddleUseDouble() { return sizeofReal() == sizeof(double); }$/;"	f	namespace:paddle::version
isPaddleUseFloat	utils/Version.h	/^constexpr bool isPaddleUseFloat() { return sizeofReal() == sizeof(float); }$/;"	f	namespace:paddle::version
isParameterSparse_	parameter/FirstOrderOptimizer.h	/^  bool isParameterSparse_;$/;"	m	class:paddle::SparseMomentumParameterOptimizer
isPassFinish	pserver/ParameterClient2.h	/^  bool isPassFinish() { return passFinish_; }$/;"	f	class:paddle::ParameterClient2
isPassGrad	gserver/gradientmachines/MultiGradientMachine.h	/^  bool isPassGrad() { return isPassGrad_; }$/;"	f	class:paddle::MultiGradientMachine
isPassGrad_	gserver/gradientmachines/MultiGradientMachine.h	/^  bool isPassGrad_;$/;"	m	class:paddle::MultiGradientMachine
isPointerAlign	math/SIMDFunctions.h	/^inline bool isPointerAlign(void* ptr) {$/;"	f	namespace:paddle::simd
isPushing_	utils/CustomStackTrace.h	/^  ThreadLocal<bool> isPushing_;$/;"	m	class:paddle::CustomStackTrace
isRegularizationBatch	parameter/OptimizerWithRegularizer.h	/^  bool isRegularizationBatch(const ParameterConfig& config) const {$/;"	f	class:paddle::OptimizerWithRegularizerEveryNumBatches
isSelectAlgo_	gserver/layers/ConvOperator.cpp	/^  bool isSelectAlgo_;$/;"	m	class:paddle::ConvOperator	file:
isSelectAlgo_	gserver/layers/ConvProjection.h	/^  bool isSelectAlgo_;$/;"	m	class:paddle::ConvProjection
isSequenceArg	function/BufferArg.h	/^  bool isSequenceArg() const { return TENSOR_SEQUENCE_DATA == bufferType_; }$/;"	f	class:paddle::BufferArg
isSet_	utils/Util.h	/^  bool isSet_;$/;"	m	class:paddle::SetDevice
isSparse	api/Matrix.cpp	/^bool Matrix::isSparse() const {$/;"	f	class:Matrix
isSparse	math/BaseMatrix.h	/^  virtual bool isSparse() const { return false; }$/;"	f	class:paddle::BaseMatrixT
isSparse	math/CpuSparseMatrix.h	/^  bool isSparse() const { return true; }$/;"	f	class:paddle::CpuSparseMatrix
isSparse	math/SparseMatrix.h	/^  bool isSparse() const { return true; }$/;"	f	class:paddle::GpuSparseMatrix
isSparse	parameter/Parameter.h	/^  bool isSparse() { return config_.is_sparse(); }$/;"	f	class:paddle::Parameter
isSparseArg	function/BufferArg.h	/^  bool isSparseArg() const { return TENSOR_SPARSE == bufferType_; }$/;"	f	class:paddle::BufferArg
isSparseRemoteUpdate	parameter/Parameter.h	/^  bool isSparseRemoteUpdate() const {$/;"	f	class:paddle::Parameter
isSparseServer_	pserver/ParameterServer2.h	/^  bool isSparseServer_;$/;"	m	class:paddle::ParameterServer2
isStatic	gserver/tests/LayerGradUtil.h	/^  bool isStatic;$/;"	m	struct:paddle::InputDef
isStatic	parameter/Parameter.h	/^  bool isStatic() const { return config_.is_static(); }$/;"	f	class:paddle::Parameter
isTestMode	gserver/dataproviders/MultiDataProvider.h	/^  bool isTestMode() const { return isTestMode_; }$/;"	f	class:paddle::MultiDataProvider
isTestMode_	gserver/dataproviders/MultiDataProvider.h	/^  bool isTestMode_;$/;"	m	class:paddle::MultiDataProvider
isTransposed	math/Matrix.h	/^  bool isTransposed() const { return trans_; }$/;"	f	class:paddle::Matrix
isUpdatable	parameter/Parameter.h	/^  bool isUpdatable() { return (updateCounter_ == sharedCount_); }$/;"	f	class:paddle::Parameter
isUsingGpu	api/Util.cpp	/^bool isUsingGpu() { return FLAGS_use_gpu; }$/;"	f
isValid	utils/GlobalConstants.h	/^  static inline bool isValid(const std::string& algo) {$/;"	f	class:paddle::TrainAlgorithm
isValidMatrixHandle	pserver/ParameterServer2.h	/^  bool isValidMatrixHandle(int64_t handle, Response* response) {$/;"	f	class:paddle::ParameterServer2
isValidVectorHandle	pserver/ParameterServer2.h	/^  bool isValidVectorHandle(int64_t handle, Response* response) {$/;"	f	class:paddle::ParameterServer2
isValueShared	parameter/Parameter.cpp	/^bool Parameter::isValueShared() {$/;"	f	class:paddle::Parameter
isValueUpdated	parameter/Parameter.h	/^  bool isValueUpdated() const { return updated_; }$/;"	f	class:paddle::Parameter
isWithAvx	utils/Version.h	/^constexpr bool isWithAvx() {$/;"	f	namespace:paddle::version
isWithFpga	utils/Version.h	/^constexpr bool isWithFpga() {$/;"	f	namespace:paddle::version
isWithGpu	utils/Version.h	/^constexpr bool isWithGpu() {$/;"	f	namespace:paddle::version
isWithPyDataProvider	utils/Version.h	/^constexpr bool isWithPyDataProvider() {$/;"	f	namespace:paddle::version
isWithTimer	utils/Version.h	/^constexpr bool isWithTimer() {$/;"	f	namespace:paddle::version
is_lin	api/paddle_ld_flags.py	/^    is_lin = (system == 'linux')$/;"	v
is_lin	setup.py	/^is_lin = (system == 'linux')$/;"	v
is_osx	api/paddle_ld_flags.py	/^    is_osx = (system == 'darwin')$/;"	v
is_osx	setup.py	/^is_osx = (system == 'darwin')$/;"	v
is_padding_	function/ContextProjectionOp.cpp	/^  bool is_padding_;$/;"	m	class:paddle::ContextProjectionBackwardFunc	file:
is_sequence	gserver/gradientmachines/RecurrentGradientMachine.h	/^    bool is_sequence;$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
is_win	api/paddle_ld_flags.py	/^    is_win = (system == 'windows')$/;"	v
is_win	setup.py	/^is_win = (system == 'windows')$/;"	v
istreamInput_	gserver/dataproviders/ProtoReader.h	/^  std::unique_ptr<google::protobuf::io::ZeroCopyInputStream> istreamInput_;$/;"	m	class:paddle::ProtoReader
iterNext	utils/PythonUtil.h	/^inline static PyObject* iterNext(const PyObjectPtr& context, bool* atEnd) {$/;"	f	namespace:paddle::py
jobAdding_	utils/Thread.h	/^  bool jobAdding_;$/;"	m	class:paddle::MultiThreadWorker
jobEnqueue	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^void ParallelThread::jobEnqueue(LayerPtr layer, TaskType task) {$/;"	f	class:paddle::ParallelThread
jobFinishBarrier_	utils/Thread.h	/^  ThreadBarrier jobFinishBarrier_;$/;"	m	class:paddle::SyncThreadPool
jobFunc_	utils/Thread.h	/^  JobFunc jobFunc_;$/;"	m	class:paddle::SyncThreadPool
jobStartBarrier_	utils/Thread.h	/^  ThreadBarrier jobStartBarrier_;$/;"	m	class:paddle::SyncThreadPool
job_all	scripts/cluster_train/paddle.py	/^def job_all(job_package, jobdir=None, train_args_dict=None):$/;"	f
job_clean	scripts/cluster_train/paddle.py	/^def job_clean():$/;"	f
job_create_workspace	scripts/cluster_train/paddle.py	/^    def job_create_workspace(jobdir, data=None):$/;"	f	function:job_prepare
job_prepare	scripts/cluster_train/paddle.py	/^def job_prepare(jobdir, data=None):$/;"	f
job_pserver	scripts/cluster_train/paddle.py	/^def job_pserver(jobdir, pids=None):$/;"	f
job_trainer	scripts/cluster_train/paddle.py	/^def job_trainer(jobdir, train_args_dict, pids=None):$/;"	f
jobs_	utils/Thread.h	/^  Queue<JobFunc> jobs_;$/;"	m	class:paddle::AsyncThreadPool
jobs_	utils/Thread.h	/^  Queue<JobFunc> jobs_;$/;"	m	class:paddle::MultiThreadWorker
jobs_	utils/Thread.h	/^  Queue<JobFunc> jobs_;$/;"	m	class:paddle::ThreadWorker
join	cuda/src/hl_dso_loader.cc	/^static inline std::string join(const std::string& part1,$/;"	f	file:
join	utils/Thread.h	/^  void join() { thread_->join(); }$/;"	f	class:paddle::Thread
join	utils/Util.cpp	/^std::string join(const std::string& part1, const std::string& part2) {$/;"	f	namespace:paddle::path
join	utils/Util.h	/^std::string join(const std::string& part1,$/;"	f	namespace:paddle::path
kAverage	gserver/layers/AverageLayer.h	/^  enum AverageStrategy { kAverage = 0, kSum = 1, kAverageSquareRootN = 2 };$/;"	e	enum:paddle::AverageLayer::AverageStrategy
kAverage	trainer/RemoteParameterUpdater.cpp	/^const std::string RemoteParameterUpdater::kAverage = "average";$/;"	m	class:paddle::RemoteParameterUpdater	file:
kAverage	trainer/RemoteParameterUpdater.h	/^  static const std::string kAverage;$/;"	m	class:paddle::RemoteParameterUpdater
kAverageSquareRootN	gserver/layers/AverageLayer.h	/^  enum AverageStrategy { kAverage = 0, kSum = 1, kAverageSquareRootN = 2 };$/;"	e	enum:paddle::AverageLayer::AverageStrategy
kBinNum_	gserver/evaluators/Evaluator.h	/^  static const uint32_t kBinNum_ = (1 << 24) - 1;$/;"	m	class:paddle::AucEvaluator
kConfigParserFuncName	trainer/TrainerConfigHelper.cpp	/^const char *kConfigParserFuncName = "parse_config_and_serialize";$/;"	v
kConfigParserModuleName	trainer/TrainerConfigHelper.cpp	/^const char *kConfigParserModuleName = "paddle.trainer.config_parser";$/;"	v
kCustom	gserver/gradientmachines/GradientMachine.h	/^    kCustom = 10$/;"	e	enum:paddle::GradientMachine::CreateMode
kDecimalScaling	gserver/layers/DataNormLayer.h	/^  enum NormalizationStrategy { kZScore = 0, kMinMax = 1, kDecimalScaling = 2 };$/;"	e	enum:paddle::DataNormLayer::NormalizationStrategy
kDefaultTotalBytesLimit	gserver/dataproviders/ProtoReader.h	/^  static const int kDefaultTotalBytesLimit = 64 << 20;  \/\/ 64MB$/;"	m	class:paddle::ProtoReader
kDeviceToHostStream	trainer/ParameterUpdater.cpp	/^static const hl_stream_t kDeviceToHostStream = HPPL_STREAM_1;$/;"	m	namespace:paddle	file:
kDeviceToHostStream	trainer/RemoteParameterUpdater.cpp	/^static const hl_stream_t kDeviceToHostStream = HPPL_STREAM_1;$/;"	m	namespace:paddle	file:
kDir	trainer/tests/test_PyDataProviderWrapper.cpp	/^const std::string kDir = ".\/trainer\/tests\/pydata_provider_wrapper_dir\/";$/;"	v
kElasticAverage	trainer/RemoteParameterUpdater.cpp	/^const std::string RemoteParameterUpdater::kElasticAverage = "elastic_average";$/;"	m	class:paddle::RemoteParameterUpdater	file:
kElasticAverage	trainer/RemoteParameterUpdater.h	/^  static const std::string kElasticAverage;$/;"	m	class:paddle::RemoteParameterUpdater
kExecuteCMDBufLength	utils/PythonUtil.cpp	/^constexpr int kExecuteCMDBufLength = 204800;$/;"	m	namespace:paddle	file:
kFinishBatchPid	trainer/RemoteParameterUpdater.cpp	/^static const int kFinishBatchPid = -1;$/;"	m	namespace:paddle	file:
kFormatVersion	parameter/Parameter.h	/^  static const int kFormatVersion = 0;$/;"	m	class:paddle::Parameter
kHostToDeviceStream	trainer/ParameterUpdater.cpp	/^static const hl_stream_t kHostToDeviceStream = HPPL_STREAM_2;$/;"	m	namespace:paddle	file:
kHostToDeviceStream	trainer/RemoteParameterUpdater.cpp	/^static const hl_stream_t kHostToDeviceStream = HPPL_STREAM_2;$/;"	m	namespace:paddle	file:
kMaxLimitBytes	gserver/dataproviders/ProtoReader.h	/^  static const int kMaxLimitBytes = 55 << 20;$/;"	m	class:paddle::ProtoReader
kMaxNumAccumulates	parameter/AverageOptimizer.h	/^  static const int64_t kMaxNumAccumulates = 16384;$/;"	m	class:paddle::AverageOptimizer
kMaxNumAccumulates	parameter/FirstOrderOptimizer.h	/^  static const int64_t kMaxNumAccumulates = 16384;$/;"	m	class:paddle::AdagradParameterOptimizer
kMinDims	function/TensorShape.h	/^  static const size_t kMinDims = 4;$/;"	m	class:paddle::TensorShape
kMinMax	gserver/layers/DataNormLayer.h	/^  enum NormalizationStrategy { kZScore = 0, kMinMax = 1, kDecimalScaling = 2 };$/;"	e	enum:paddle::DataNormLayer::NormalizationStrategy
kMissParameterFail	parameter/Parameter.cpp	/^const std::string Parameter::kMissParameterFail = "fail";$/;"	m	class:paddle::Parameter	file:
kMissParameterFail	parameter/Parameter.h	/^  static const std::string kMissParameterFail;$/;"	m	class:paddle::Parameter
kMissParameterRand	parameter/Parameter.cpp	/^const std::string Parameter::kMissParameterRand = "rand";$/;"	m	class:paddle::Parameter	file:
kMissParameterRand	parameter/Parameter.h	/^  static const std::string kMissParameterRand;$/;"	m	class:paddle::Parameter
kMissParameterZero	parameter/Parameter.cpp	/^const std::string Parameter::kMissParameterZero = "zero";$/;"	m	class:paddle::Parameter	file:
kMissParameterZero	parameter/Parameter.h	/^  static const std::string kMissParameterZero;$/;"	m	class:paddle::Parameter
kNegativeLabel_	gserver/evaluators/Evaluator.h	/^  static const int kNegativeLabel_ = 0;$/;"	m	class:paddle::AucEvaluator
kNonSeq	gserver/layers/ExpandLayer.h	/^  enum ExpandLevel { kNonSeq = 0, kSeq = 1 };$/;"	e	enum:paddle::ExpandLayer::ExpandLevel
kNonSeq	gserver/layers/SequencePoolLayer.h	/^  enum SequenceLevel { kNonSeq = 0, kSeq = 1 };$/;"	e	enum:paddle::SequencePoolLayer::SequenceLevel
kNormal	gserver/gradientmachines/GradientMachine.h	/^    kNormal = 0,$/;"	e	enum:paddle::GradientMachine::CreateMode
kPairArrayNum_	gserver/evaluators/Evaluator.h	/^  static const uint32_t kPairArrayNum_ = 2;$/;"	m	class:paddle::PnpairEvaluator
kProtoFileList	gserver/tests/test_ProtoDataProvider.cpp	/^const char kProtoFileList[] = "gserver\/tests\/proto_files.txt";$/;"	v
kProtoFileListCompressed	gserver/tests/test_ProtoDataProvider.cpp	/^const char kProtoFileListCompressed[] =$/;"	v
kRetMsgInvalidMatrixHandle	pserver/ParameterServer2.cpp	/^const std::string ParameterServer2::kRetMsgInvalidMatrixHandle =$/;"	m	class:paddle::ParameterServer2	file:
kRetMsgInvalidMatrixHandle	pserver/ParameterServer2.h	/^  static const std::string kRetMsgInvalidMatrixHandle;$/;"	m	class:paddle::ParameterServer2
kRetMsgInvalidVectorHandle	pserver/ParameterServer2.cpp	/^const std::string ParameterServer2::kRetMsgInvalidVectorHandle =$/;"	m	class:paddle::ParameterServer2	file:
kRetMsgInvalidVectorHandle	pserver/ParameterServer2.h	/^  static const std::string kRetMsgInvalidVectorHandle;$/;"	m	class:paddle::ParameterServer2
kRetMsgUnknownOperation	pserver/ParameterServer2.cpp	/^const std::string ParameterServer2::kRetMsgUnknownOperation =$/;"	m	class:paddle::ParameterServer2	file:
kRetMsgUnknownOperation	pserver/ParameterServer2.h	/^  static const std::string kRetMsgUnknownOperation;$/;"	m	class:paddle::ParameterServer2
kSeq	gserver/layers/ExpandLayer.h	/^  enum ExpandLevel { kNonSeq = 0, kSeq = 1 };$/;"	e	enum:paddle::ExpandLayer::ExpandLevel
kSeq	gserver/layers/SequencePoolLayer.h	/^  enum SequenceLevel { kNonSeq = 0, kSeq = 1 };$/;"	e	enum:paddle::SequencePoolLayer::SequenceLevel
kSgdSparseCpuTraining	gserver/gradientmachines/GradientMachine.h	/^    kSgdSparseCpuTraining = 3,$/;"	e	enum:paddle::GradientMachine::CreateMode
kSpraseMatrixDim	gserver/tests/test_ProtoDataProvider.cpp	/^const int kSpraseMatrixDim = 1024;$/;"	v
kSum	gserver/layers/AverageLayer.h	/^  enum AverageStrategy { kAverage = 0, kSum = 1, kAverageSquareRootN = 2 };$/;"	e	enum:paddle::AverageLayer::AverageStrategy
kTestDir	gserver/tests/test_ProtoDataProvider.cpp	/^const char* kTestDir = ".\/test_ProtoDataProvider";$/;"	v
kTesting	gserver/gradientmachines/GradientMachine.h	/^    kTesting = 4,$/;"	e	enum:paddle::GradientMachine::CreateMode
kUnusedId_	math/SparseRowMatrix.cpp	/^const unsigned int SparseRowCpuMatrix::kUnusedId_ = -1U;$/;"	m	class:paddle::SparseRowCpuMatrix	file:
kUnusedId_	math/SparseRowMatrix.h	/^  static const unsigned int kUnusedId_;$/;"	m	class:paddle::SparseRowCpuMatrix
kZScore	gserver/layers/DataNormLayer.h	/^  enum NormalizationStrategy { kZScore = 0, kMinMax = 1, kDecimalScaling = 2 };$/;"	e	enum:paddle::DataNormLayer::NormalizationStrategy
kill_process	scripts/cluster_train/paddle.py	/^        def kill_process():$/;"	f	function:job_clean.signal_handler
kill_process	scripts/cluster_train/paddle.py	/^def kill_process():$/;"	f
kwargs	utils/PythonUtil.h	/^  PyObjectPtr kwargs;$/;"	m	class:paddle::py::CallableHelper
label	gserver/evaluators/Evaluator.h	/^    int label;$/;"	m	struct:paddle::PnpairEvaluator::PredictionResult
label	gserver/layers/ValidationLayer.h	/^    int label;$/;"	m	struct:paddle::AucValidation::PredictionResult
labelBatch_	gserver/dataproviders/DataProvider.h	/^  ThreadLocal<IVectorPtr> labelBatch_;$/;"	m	class:paddle::SimpleDataProviderBase
labelBuf_	gserver/layers/CostLayer.h	/^  MatrixPtr labelBuf_;$/;"	m	class:paddle::RankingCost
labelId	gserver/layers/NCELayer.cpp	/^    int labelId;$/;"	m	struct:paddle::NCELayer::Sample	file:
labelIds_	gserver/layers/NCELayer.cpp	/^  IVectorPtr labelIds_;$/;"	m	class:paddle::NCELayer	file:
labelInitValue	gserver/tests/LayerGradUtil.h	/^  std::vector<int> labelInitValue;$/;"	m	struct:paddle::InputDef
labelLayer_	gserver/layers/NCELayer.cpp	/^  LayerPtr labelLayer_;$/;"	m	class:paddle::NCELayer	file:
labelSegments_	gserver/evaluators/ChunkEvaluator.cpp	/^  std::vector<Segment> labelSegments_;$/;"	m	class:paddle::ChunkEvaluator	file:
labelSeqStartPositions	gserver/tests/LayerGradUtil.h	/^  std::vector<int> labelSeqStartPositions;$/;"	m	struct:paddle::InputDef
label_dim	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^label_dim = 2$/;"	v
label_dim	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^label_dim = 2$/;"	v
labels_	gserver/dataproviders/DataProvider.h	/^  std::vector<int> labels_;$/;"	m	class:paddle::SimpleDataProvider
language	setup.py	/^       language = "c++",$/;"	v
lastNum_	parameter/LearningRateScheduler.cpp	/^  int64_t lastNum_;$/;"	m	class:paddle::ManualLRS	file:
last_ch_	trainer/tests/picojson.h	/^  int last_ch_;$/;"	m	class:picojson::input
last_error_t	trainer/tests/picojson.h	/^struct last_error_t {$/;"	s	namespace:picojson
layerConfig	gserver/tests/LayerGradUtil.h	/^  LayerConfig layerConfig;$/;"	m	struct:paddle::TestConfig
layerMap_	gserver/gradientmachines/NeuralNetwork.h	/^  LayerMap layerMap_;$/;"	m	class:paddle::NeuralNetwork
layerMap_	gserver/tests/test_RecurrentLayer.cpp	/^  LayerMap layerMap_;$/;"	m	class:TestRecurrentLayer	file:
layerName	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::string layerName;$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
layerName	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::string layerName;$/;"	m	struct:paddle::RecurrentGradientMachine::OutFrameLine
layer_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^    LayerPtr layer_;$/;"	m	struct:paddle::ParallelThread::Job
layers	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::vector<LayerPtr> layers;$/;"	m	struct:paddle::RecurrentGradientMachine::EosFrameLine
layers_	gserver/gradientmachines/NeuralNetwork.h	/^  std::vector<LayerPtr> layers_;$/;"	m	class:paddle::NeuralNetwork
lazyAssign	math/TensorExpression.h	/^  TensorAssignOp<Derived, ExpressionType, T> lazyAssign($/;"	f	class:paddle::TensorExpression
ldflag_str	api/paddle_ld_flags.py	/^        def ldflag_str(self):$/;"	m	class:PaddleLDFlag
ldflags	setup.py	/^ldflags = obj.ldflag_str()$/;"	v
learningRateScheduler_	parameter/ParameterOptimizer.h	/^  std::unique_ptr<LearningRateScheduler> learningRateScheduler_;$/;"	m	class:paddle::ParameterOptimizer
learningRate_	parameter/FirstOrderOptimizer.h	/^  real learningRate_;$/;"	m	class:paddle::AdamParameterOptimizer
learningRate_	parameter/FirstOrderOptimizer.h	/^  real learningRate_;$/;"	m	class:paddle::AdamaxParameterOptimizer
learningRate_	parameter/LearningRateScheduler.cpp	/^  real learningRate_;$/;"	m	class:paddle::BaseLRS	file:
learningRate_	parameter/ParameterOptimizer.h	/^  real learningRate_;$/;"	m	class:paddle::ParameterOptimizer
learningRate_	parameter/tests/test_common.cpp	/^  real learningRate_;$/;"	m	class:CommonTest	file:
leftMul	math/Matrix.cpp	/^void CpuMatrix::leftMul(Matrix& a) { return leftMul(a, 1.0, 0.0); }$/;"	f	class:paddle::CpuMatrix
leftMul	math/Matrix.cpp	/^void CpuMatrix::leftMul(Matrix& a, real scaleAB, real scaleT) {$/;"	f	class:paddle::CpuMatrix
leftMul	math/Matrix.cpp	/^void GpuMatrix::leftMul(Matrix& a) { leftMul(a, 1.0, 0.0); }$/;"	f	class:paddle::GpuMatrix
leftMul	math/Matrix.cpp	/^void GpuMatrix::leftMul(Matrix& a, real scaleAB, real scaleT) {$/;"	f	class:paddle::GpuMatrix
leftMul	math/Matrix.h	/^  virtual void leftMul(Matrix& a) { LOG(FATAL) << "Not implemented"; }$/;"	f	class:paddle::Matrix
leftMul	math/Matrix.h	/^  virtual void leftMul(Matrix& a, real scaleAB, real scaleT) {$/;"	f	class:paddle::Matrix
length	api/PaddleAPI.h	/^  const size_t length;$/;"	m	struct:FloatArray
length	api/PaddleAPI.h	/^  const size_t length;$/;"	m	struct:IntArray
length	api/PaddleAPI.h	/^  const size_t length;$/;"	m	struct:IntWithFloatArray
length	gserver/layers/MultiplexLayer.cpp	/^    int length;$/;"	m	struct:paddle::MultiplexLayer::CopyInfo	file:
lhs_	math/TensorApply.h	/^  TensorApply<LhsType, T> lhs_;$/;"	m	class:paddle::TensorApply
lhs_	math/TensorAssign.h	/^  TensorApply<LhsType, T> lhs_;$/;"	m	class:paddle::TensorAssignOp
lhs_	math/TensorExpression.h	/^  const LhsType lhs_;$/;"	m	class:paddle::TensorBinaryOp
libs_dir_str	api/paddle_ld_flags.py	/^        def libs_dir_str(self):$/;"	m	class:PaddleLDFlag
libs_str	api/paddle_ld_flags.py	/^        def libs_str(self):$/;"	m	class:PaddleLDFlag
line	trainer/tests/picojson.h	/^  int line() const { return line_; }$/;"	f	class:picojson::input
line_	trainer/tests/picojson.h	/^  int line_;$/;"	m	class:picojson::input
linear	cuda/src/hl_avx_functions.cc	/^__m256 linear(const __m256 a) { return a; }$/;"	f	namespace:hppl
linear	cuda/src/hl_avx_functions.cc	/^__m256 linear(const __m256 a, const __m256 b) { return a; }$/;"	f	namespace:hppl
linear	cuda/src/hl_cpu_functions.cc	/^real linear(const real a) { return a; }$/;"	f	namespace:hppl
linear	cuda/src/hl_cpu_functions.cc	/^real linear(const real a, const real b) { return a; }$/;"	f	namespace:hppl
linkName	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::string linkName;$/;"	m	struct:paddle::RecurrentGradientMachine::InFrameLine
linkName	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::string linkName;$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
listen	pserver/RDMANetwork.h	/^inline int listen(sxi_socket* s) {$/;"	f	namespace:paddle::rdma
load	api/Parameter.cpp	/^bool Parameter::load(const std::string& filename) const {$/;"	f	class:Parameter
load	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual std::deque<PyObjectPtr>* load() { return nullptr; }$/;"	f	class:paddle::NoCacheStrategy
load	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual std::deque<PyObjectPtr>* load() { return objPool_.get(); }$/;"	f	class:paddle::CacheOnePassInMemory
load	parameter/Parameter.cpp	/^bool Parameter::load(const std::string& filename) {$/;"	f	class:paddle::Parameter
load	parameter/Parameter.cpp	/^bool Parameter::load(std::istream& s) {$/;"	f	class:paddle::Parameter
loadData	gserver/dataproviders/DataProvider.cpp	/^void SimpleDataProvider::loadData(const std::string& fileName) {$/;"	f	class:paddle::SimpleDataProvider
loadData	gserver/dataproviders/ProtoDataProvider.cpp	/^void ProtoDataProvider::loadData(const std::string& fileName) {$/;"	f	class:paddle::ProtoDataProvider
loadData	gserver/dataproviders/ProtoDataProvider.cpp	/^void ProtoDataProvider::loadData(const std::vector<std::string>& fileList) {$/;"	f	class:paddle::ProtoDataProvider
loadData	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::loadData(const std::vector<std::string>& fileList) {$/;"	f	class:paddle::PyDataProvider
loadDataFile	gserver/dataproviders/DataProvider.cpp	/^void SimpleDataProvider::loadDataFile(const std::string& fileName) {$/;"	f	class:paddle::SimpleDataProvider
loadDataFile	gserver/dataproviders/ProtoDataProvider.cpp	/^void ProtoDataProvider::loadDataFile(const std::string& fileName) {$/;"	f	class:paddle::ProtoDataProvider
loadDiySymbol	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^static inline SymbolType loadDiySymbol(const char* symbolName) {$/;"	f	namespace:paddle
loadFile	gserver/dataproviders/DataProviderGroup.h	/^std::shared_ptr<T> DataProviderGroup<T>::loadFile($/;"	f	class:paddle::DataProviderGroup
loadFileList	utils/Util.cpp	/^void loadFileList(const std::string& fileListFileName,$/;"	f	namespace:paddle
loadGradientMachine	py_paddle/util.py	/^def loadGradientMachine(config_filename, model_dir=None):$/;"	f
loadMNISTTrainData	api/test/util.py	/^def loadMNISTTrainData(batch_size=100):$/;"	f
loadMaskFile	parameter/ParameterUpdaterHook.cpp	/^  bool loadMaskFile(const std::string& mask_filename) {$/;"	f	class:paddle::StaticPruningHook	file:
loadParameterFile	py_paddle/util.py	/^def loadParameterFile(fn):$/;"	f
loadParameters	api/GradientMachine.cpp	/^void GradientMachine::loadParameters(const std::string& path) {$/;"	f	class:GradientMachine
loadParameters	gserver/gradientmachines/GradientMachine.cpp	/^void GradientMachine::loadParameters(const std::string& dir) {$/;"	f	class:paddle::GradientMachine
loadParameters	trainer/ParamUtil.cpp	/^bool ParameterUtil::loadParameters(int passId, bool local, bool remote) {$/;"	f	class:paddle::ParameterUtil
loadParametersRemote	parameter/ParameterUpdaterBase.h	/^  virtual void loadParametersRemote(const std::string& dirName) {$/;"	f	class:paddle::ParameterUpdaterComposite
loadParametersRemote	parameter/ParameterUpdaterBase.h	/^  virtual void loadParametersRemote(const std::string& dirName) {}$/;"	f	class:paddle::ParameterUpdater
loadParametersRemote	trainer/RemoteParameterUpdater.cpp	/^void SparseRemoteParameterUpdater::loadParametersRemote($/;"	f	class:paddle::SparseRemoteParameterUpdater
loadParametersWithPath	trainer/ParamUtil.cpp	/^void ParameterUtil::loadParametersWithPath(const std::string &dir,$/;"	f	class:paddle::ParameterUtil
loadPyFileLists	gserver/dataproviders/PyDataProvider2.cpp	/^  PyObjectPtr loadPyFileLists(const std::string& fileListName) {$/;"	f	class:paddle::PyDataProvider2	file:
loadThread	gserver/dataproviders/PyDataProvider2.cpp	/^  void loadThread() {$/;"	f	class:paddle::PyDataProvider2	file:
loadThread_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::unique_ptr<std::thread> loadThread_;$/;"	m	class:paddle::PyDataProvider2	file:
loadValueVector	pserver/ParameterClient2.cpp	/^void ParameterClient2::loadValueVector(const std::string& dirName) {$/;"	f	class:paddle::ParameterClient2
loadValueVector	pserver/ParameterServer2.cpp	/^void ParameterServer2::loadValueVector(const LoadValueRequest& request,$/;"	f	class:paddle::ParameterServer2
load_missing_parameter_strategy	utils/Flags.h	/^DECLARE_string(load_missing_parameter_strategy);$/;"	v
load_save_param_pserver_	trainer/ParamUtil.h	/^  bool load_save_param_pserver_;$/;"	m	struct:paddle::ParameterUtilConfig
loader_	gserver/dataproviders/DataProviderGroup.h	/^  std::unique_ptr<MultiThreadWorker<ProviderType>> loader_;$/;"	m	class:paddle::DataProviderGroup
loadsaveParametersInPserver	trainer/TesterConfig.h	/^  bool loadsaveParametersInPserver;$/;"	m	struct:paddle::TesterConfig
loadsave_parameters_in_pserver	trainer/TrainerInternalConfig.h	/^  bool loadsave_parameters_in_pserver;$/;"	m	struct:paddle::TrainerInternalConfig
loadsave_parameters_in_pserver	utils/Flags.h	/^DECLARE_bool(loadsave_parameters_in_pserver);$/;"	v
local	trainer/TrainerConfigHelper.cpp	/^DECLARE_bool(local);$/;"	v
local	trainer/TrainerInternalConfig.cpp	/^DECLARE_bool(local);$/;"	v
local	trainer/TrainerInternalConfig.h	/^  bool local;$/;"	m	struct:paddle::TrainerInternalConfig
local	trainer/tests/test_CompareSparse.cpp	/^DECLARE_bool(local);$/;"	v
local	trainer/tests/test_CompareTwoNets.cpp	/^DECLARE_bool(local);$/;"	v
local	trainer/tests/test_CompareTwoOpts.cpp	/^DECLARE_bool(local);$/;"	v
local	trainer/tests/test_TrainerOnePass.cpp	/^DECLARE_bool(local);$/;"	v
localBiasGrad_	gserver/layers/LstmLayer.h	/^  MatrixPtr localBiasGrad_;$/;"	m	class:paddle::LstmLayer
localBias_	gserver/layers/LstmLayer.h	/^  MatrixPtr localBias_;$/;"	m	class:paddle::LstmLayer
localBlockBitset_	pserver/ParameterServer2.cpp	/^static ThreadLocal<std::vector<bool>> localBlockBitset_;$/;"	m	namespace:paddle	file:
localBufRows_	math/Matrix.h	/^  ThreadLocal<std::vector<int>> localBufRows_;$/;"	m	class:paddle::SharedCpuMatrix
localBuf_	math/Matrix.h	/^  ThreadLocal<CpuMatrixPtr> localBuf_;$/;"	m	class:paddle::SharedCpuMatrix
localIndices	math/SparseRowMatrix.h	/^    std::vector<unsigned int> localIndices;   \/\/ local id -> global id$/;"	m	struct:paddle::SparseRowCpuMatrix::IndexDict
localIndices_	math/SparseRowMatrix.h	/^  std::vector<unsigned int>* localIndices_;  \/\/ =&indexDictHandle_->localIndices$/;"	m	class:paddle::SparseRowCpuMatrix
localParam_	parameter/ParallelParameter.h	/^  ParameterPtr localParam_;$/;"	m	class:paddle::ParallelParameter
localResult_	pserver/ParameterClient2.h	/^    LocalOperationResult* localResult_;$/;"	m	class:paddle::PreparedOperations::ResultsAdder
localResults_	pserver/ParameterClient2.h	/^  std::vector<LocalOperationResult> localResults_;$/;"	m	class:paddle::PreparedOperations
localUpdater_	trainer/RemoteParameterUpdater.h	/^  std::unique_ptr<ParameterUpdater> localUpdater_;$/;"	m	class:paddle::RemoteParameterUpdater
lock	pserver/ParameterServer2.h	/^    std::unique_ptr<std::mutex> lock;$/;"	m	struct:paddle::ParameterServer2::BlockInfo
lock	utils/Locks.h	/^  void lock() { pthread_rwlock_wrlock(&rwlock_); }$/;"	f	class:paddle::RWLock
lock	utils/arch/linux/Locks.cpp	/^void SpinLock::lock() { pthread_spin_lock(&m->lock_); }$/;"	f	class:paddle::SpinLock
lock	utils/arch/osx/Locks.cpp	/^void SpinLock::lock() {$/;"	f	class:paddle::SpinLock
lock_	gserver/dataproviders/DataProvider.h	/^  RWLock lock_;$/;"	m	class:paddle::SimpleDataProviderBase
lock_	gserver/dataproviders/DataProviderGroup.h	/^  std::mutex lock_;$/;"	m	class:paddle::DataProviderGroup
lock_	gserver/dataproviders/ProtoDataProvider.h	/^  RWLock lock_;$/;"	m	class:paddle::ProtoDataProvider
lock_	math/Storage.h	/^  RWLock lock_;$/;"	m	class:paddle::StorageEngine
lock_	utils/BarrierStat.h	/^  mutable std::mutex lock_;$/;"	m	class:paddle::BarrierStatBase
lock_	utils/Stat.h	/^  RWLock lock_;$/;"	m	class:paddle::StatSet
lock_	utils/Stat.h	/^  std::mutex lock_;$/;"	m	class:paddle::Stat
lock_	utils/Util.h	/^  std::mutex lock_;$/;"	m	class:paddle::WeakKVCache
lock_	utils/arch/linux/Locks.cpp	/^  pthread_spinlock_t lock_;$/;"	m	class:paddle::SpinLockPrivate	file:
lock_	utils/arch/osx/Locks.cpp	/^  std::atomic_flag lock_ = ATOMIC_FLAG_INIT;$/;"	m	class:paddle::SpinLockPrivate	file:
lock_shared	utils/Locks.h	/^  void lock_shared() { pthread_rwlock_rdlock(&rwlock_); }$/;"	f	class:paddle::RWLock
log	cuda/src/hl_math.cc	/^__m256 log(__m256 a) { return log256_ps(a); }$/;"	f	namespace:hppl
log	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::log_op<T>, const Derived, T> log() const {$/;"	f	class:paddle::TensorExpression
log256_ps	cuda/src/avx_mathfun.h	/^v8sf log256_ps(v8sf x) {$/;"	f
logActs_	gserver/layers/LinearChainCTC.h	/^  MatrixPtr logActs_, forwardVars_, backwardVars_, gradTerms_;$/;"	m	class:paddle::LinearChainCTC
logAdd	gserver/layers/LinearChainCTC.cpp	/^static inline real logAdd(real x, real y) {$/;"	f	namespace:paddle
logDiv	gserver/layers/LinearChainCTC.cpp	/^static inline real logDiv(real x, real y) {$/;"	f	namespace:paddle
logMul	gserver/layers/LinearChainCTC.cpp	/^static inline real logMul(real x, real y) {$/;"	f	namespace:paddle
logPeriod	trainer/TesterConfig.h	/^  int logPeriod;$/;"	m	struct:paddle::TesterConfig
logProb	api/SequenceGenerator.cpp	/^  float logProb;$/;"	m	struct:Path	file:
logProb	gserver/gradientmachines/RecurrentGradientMachine.h	/^    real logProb;$/;"	m	struct:paddle::RecurrentGradientMachine::Path
logProb_	gserver/layers/LinearChainCTC.h	/^  real logProb_;$/;"	m	class:paddle::LinearChainCTC
logStack_	utils/CustomStackTrace.h	/^  ThreadLocal<std::stack<T>> logStack_;$/;"	m	class:paddle::CustomStackTrace
log_op	cuda/include/hl_tensor_ops.h	/^class log_op {$/;"	c	namespace:hppl::unary
log_period	trainer/TrainerInternalConfig.h	/^  int log_period;$/;"	m	struct:paddle::TrainerInternalConfig
log_period	utils/Flags.h	/^DECLARE_int32(log_period);$/;"	v
log_period_server	utils/Flags.h	/^DECLARE_int32(log_period_server);$/;"	v
logger	trainer/tests/gen_proto_data.py	/^logger = logging.getLogger('paddle')$/;"	v
logging	utils/Logging.cpp	/^namespace logging {$/;"	n	namespace:paddle	file:
logging	utils/Logging.h	/^namespace logging {$/;"	n	namespace:paddle
logicalDeviceId2RealDeviceId	gserver/gradientmachines/MultiGradientMachine.h	/^  int logicalDeviceId2RealDeviceId(int logicalId, int threadId = 0) const {$/;"	f	class:paddle::MultiGradientMachine
m	api/PaddleAPI.h	/^  ArgumentsPrivate* m;$/;"	m	class:Arguments
m	api/PaddleAPI.h	/^  EvaluatorPrivate* m;$/;"	m	class:Evaluator
m	api/PaddleAPI.h	/^  GradientMachinePrivate* m;$/;"	m	class:GradientMachine
m	api/PaddleAPI.h	/^  IVectorPrivate* m;$/;"	m	class:IVector
m	api/PaddleAPI.h	/^  MatrixPrivate* m;$/;"	m	class:Matrix
m	api/PaddleAPI.h	/^  ModelConfigPrivate* m;$/;"	m	class:ModelConfig
m	api/PaddleAPI.h	/^  OptimizationConfigPrivate* m;$/;"	m	class:OptimizationConfig
m	api/PaddleAPI.h	/^  ParameterConfigPrivate* m;$/;"	m	class:ParameterConfig
m	api/PaddleAPI.h	/^  ParameterOptimizerPrivate* m;$/;"	m	class:ParameterOptimizer
m	api/PaddleAPI.h	/^  ParameterPrivate* m;$/;"	m	class:Parameter
m	api/PaddleAPI.h	/^  ParameterTraverseCallbackPrivate* m;$/;"	m	class:ParameterTraverseCallback
m	api/PaddleAPI.h	/^  ParameterUpdaterPrivate* m;$/;"	m	class:ParameterUpdater
m	api/PaddleAPI.h	/^  SequenceGeneratorPrivate* m;$/;"	m	class:SequenceGenerator
m	api/PaddleAPI.h	/^  TrainerConfigPrivate* m;$/;"	m	class:TrainerConfig
m	api/PaddleAPI.h	/^  TrainerPrivate* m;$/;"	m	class:Trainer
m	api/PaddleAPI.h	/^  VectorPrivate* m;$/;"	m	class:Vector
m	trainer/TrainerConfigHelper.h	/^  TrainerConfigHelperPrivate* m;$/;"	m	class:paddle::TrainerConfigHelper
m	utils/Locks.h	/^  SemaphorePrivate* m;$/;"	m	class:paddle::Semaphore
m	utils/Locks.h	/^  SpinLockPrivate* m;$/;"	m	class:paddle::SpinLock
m	utils/Locks.h	/^  ThreadBarrierPrivate* m;$/;"	m	class:paddle::ThreadBarrier
machine	api/PaddleAPIPrivate.h	/^  std::shared_ptr<paddle::GradientMachine> machine;$/;"	m	struct:GradientMachinePrivate
machine	api/SequenceGenerator.cpp	/^  std::shared_ptr<paddle::GradientMachine> machine;$/;"	m	struct:SequenceGeneratorPrivate	file:
machineId	gserver/gradientmachines/RecurrentGradientMachine.h	/^    int machineId;  \/\/ index of sample in frame$/;"	m	struct:paddle::RecurrentGradientMachine::Path
machineIdVec	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::vector<int> machineIdVec;$/;"	m	struct:paddle::RecurrentGradientMachine::Path
machineIds_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<int> machineIds_;$/;"	m	class:paddle::RecurrentGradientMachine
machineState	api/SequenceGenerator.cpp	/^  paddle::MachineState machineState;$/;"	m	struct:Path	file:
main	api/test/testTrain.py	/^def main():$/;"	f
main	api/test/testTrainer.py	/^def main():$/;"	f
main	gserver/tests/test_ActivationGrad.cpp	/^int main(int argc, char** argv) {$/;"	f
main	gserver/tests/test_BatchNorm.cpp	/^int main(int argc, char** argv) {$/;"	f
main	gserver/tests/test_ConvTrans.cpp	/^int main(int argc, char** argv) {$/;"	f
main	gserver/tests/test_ConvUnify.cpp	/^int main(int argc, char** argv) {$/;"	f
main	gserver/tests/test_Evaluator.cpp	/^int main(int argc, char** argv) {$/;"	f
main	gserver/tests/test_LayerGrad.cpp	/^int main(int argc, char** argv) {$/;"	f
main	gserver/tests/test_MultinomialSampler.cpp	/^int main(int argc, char** argv) {$/;"	f
main	gserver/tests/test_NetworkCompare.cpp	/^int main(int argc, char** argv) {$/;"	f
main	gserver/tests/test_PriorBox.cpp	/^int main(int argc, char** argv) {$/;"	f
main	gserver/tests/test_PyDataProvider.cpp	/^int main(int argc, char** argv) {$/;"	f
main	gserver/tests/test_PyDataProvider2.cpp	/^int main(int argc, char **argv) {$/;"	f
main	gserver/tests/test_RecurrentGradientMachine.cpp	/^int main(int argc, char** argv) {$/;"	f
main	gserver/tests/test_RecurrentLayer.cpp	/^int main(int argc, char** argv) {$/;"	f
main	gserver/tests/test_SelectiveFCLayer.cpp	/^int main(int argc, char** argv) {$/;"	f
main	math/tests/test_FPException.cpp	/^int main(int argc, char** argv) {$/;"	f
main	math/tests/test_GpuProfiler.cpp	/^int main(int argc, char** argv) {$/;"	f
main	pserver/ParameterServer2Main.cpp	/^int main(int argc, char** argv) {$/;"	f
main	pserver/test/SocketTest.cpp	/^int main(int argc, char** argv) {$/;"	f
main	pserver/test/test_ParameterServer2.cpp	/^int main(int argc, char** argv) {$/;"	f
main	pserver/test/test_ProtoServer.cpp	/^int main(int argc, char** argv) {$/;"	f
main	scripts/cpplint.py	/^def main():$/;"	f
main	testing/TestMain.cpp	/^int main(int argc, char** argv) {$/;"	f
main	trainer/MergeModel.cpp	/^int main(int argc, char** argv) {$/;"	f
main	trainer/TrainerMain.cpp	/^int main(int argc, char** argv) {$/;"	f
main	trainer/tests/test_Compare.cpp	/^int main(int argc, char** argv) {$/;"	f
main	trainer/tests/test_CompareSparse.cpp	/^int main(int argc, char** argv) {$/;"	f
main	trainer/tests/test_CompareTwoNets.cpp	/^int main(int argc, char** argv) {$/;"	f
main	trainer/tests/test_CompareTwoOpts.cpp	/^int main(int argc, char** argv) {$/;"	f
main	trainer/tests/test_PyDataProviderWrapper.cpp	/^int main() { return 0; }$/;"	f
main	trainer/tests/test_PyDataProviderWrapper.cpp	/^int main(int argc, char** argv) {$/;"	f
main	trainer/tests/test_Trainer.cpp	/^int main(int argc, char** argv) {$/;"	f
main	trainer/tests/test_TrainerOnePass.cpp	/^int main(int argc, char** argv) {$/;"	f
main	trainer/tests/test_recurrent_machine_generation.cpp	/^int main(int argc, char** argv) {$/;"	f
main	utils/tests/test_CustomStackTracePrint.cpp	/^int main(int argc, char** argv) {$/;"	f
majorPartners_	parameter/ParallelParameter.h	/^  std::vector<ParallelParameterPtr> majorPartners_;$/;"	m	class:paddle::SyncParameter
majorUpdate	parameter/ParallelParameter.cpp	/^void SyncParameter::majorUpdate(real learnRate) {$/;"	f	class:paddle::SyncParameter
majorUpdate	parameter/ParallelParameter.h	/^  virtual void majorUpdate(real learnRate) { (void)learnRate; }$/;"	f	class:paddle::ParallelParameter
makeEvaluator	api/GradientMachine.cpp	/^Evaluator* GradientMachine::makeEvaluator() {$/;"	f	class:GradientMachine
makeEvaluator	gserver/gradientmachines/MultiGradientMachine.cpp	/^Evaluator* MultiGradientMachine::makeEvaluator() const {$/;"	f	class:paddle::MultiGradientMachine
makeEvaluator	gserver/gradientmachines/MultiNetwork.cpp	/^Evaluator* MultiNetwork::makeEvaluator() const {$/;"	f	class:paddle::MultiNetwork
makeEvaluator	gserver/gradientmachines/NeuralNetwork.cpp	/^Evaluator* NeuralNetwork::makeEvaluator() const {$/;"	f	class:paddle::NeuralNetwork
makeRandomSparseMatrix	testing/TestUtil.cpp	/^MatrixPtr makeRandomSparseMatrix(size_t height,$/;"	f	namespace:paddle
makeSample	gserver/tests/test_ProtoDataProvider.cpp	/^void makeSample(const vector<Argument>& arguments,$/;"	f
make_features	trainer/tests/gen_proto_data.py	/^def make_features(sequence):$/;"	f
mapGet	utils/Util.h	/^bool mapGet(const K& k, const C& c, V* value) {$/;"	f	namespace:paddle
marginGrad_	gserver/layers/CostLayer.h	/^  MatrixPtr marginGrad_;$/;"	m	class:paddle::LambdaCost
marginGrad_	gserver/layers/CostLayer.h	/^  MatrixPtr marginGrad_;$/;"	m	class:paddle::RankingCost
margin_	gserver/layers/CostLayer.h	/^  MatrixPtr margin_;$/;"	m	class:paddle::RankingCost
markAllInputGrad	gserver/layers/Layer.cpp	/^void Layer::markAllInputGrad() {$/;"	f	class:paddle::Layer
markInBackward_	gserver/layers/Layer.h	/^  std::vector<bool> markInBackward_;$/;"	m	class:paddle::Layer
markInputGrad	gserver/layers/Layer.cpp	/^void Layer::markInputGrad(int inputIndex) {$/;"	f	class:paddle::Layer
maskVec_	parameter/ParameterUpdaterHook.cpp	/^  VectorPtr maskVec_;$/;"	m	class:paddle::StaticPruningHook	file:
mask_	parameter/ParameterUpdaterHook.cpp	/^  std::vector<bool> mask_;$/;"	m	class:paddle::StaticPruningHook	file:
masterUpdate	parameter/ParallelParameter.cpp	/^bool AsyncParameter::masterUpdate(ParallelParameterPtr slaveParam,$/;"	f	class:paddle::AsyncParameter
mat	api/Matrix.cpp	/^  std::shared_ptr<paddle::Matrix> mat;$/;"	m	struct:MatrixPrivate	file:
match	trainer/tests/picojson.h	/^  bool match(const std::string& pattern) {$/;"	f	class:picojson::input
matrices_	pserver/ParameterServer2.h	/^  std::vector<CpuMatrixPtr> matrices_;$/;"	m	class:paddle::ParameterServer2
matrix	cuda/include/hl_base.h	/^  hl_matrix_s matrix;$/;"	m	struct:__anon10
matrix	function/BufferArg.h	/^  typename Tensor<real, DType>::Matrix matrix() const {$/;"	f	class:paddle::BufferArg
mats_	parameter/Parameter.h	/^  MatrixPtr mats_[NUM_PARAMETER_TYPES];$/;"	m	class:paddle::Parameter
max	cuda/include/hl_tensor_ops.h	/^  INLINE max(const T s) : p(s) {}$/;"	f	class:hppl::unary::max
max	cuda/include/hl_tensor_ops.h	/^class max {$/;"	c	namespace:hppl::binary
max	cuda/include/hl_tensor_ops.h	/^class max {$/;"	c	namespace:hppl::unary
max	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::max<T>, const Derived, T> max(T p) const {$/;"	f	class:paddle::TensorExpression
max	math/TensorExpression.h	/^  max(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
maxAbsGrad	trainer/TrainerInternal.h	/^    real maxAbsGrad;$/;"	m	struct:paddle::TrainerInternal::ParaStat
maxAverageWindow_	parameter/AverageOptimizer.h	/^  int64_t maxAverageWindow_;$/;"	m	class:paddle::AverageOptimizer
maxCodeLength_	math/MatrixBitCode.cpp	/^  int maxCodeLength_;$/;"	m	struct:paddle::__anon17::SimpleCodeTable	file:
maxDelta	utils/BarrierStat.h	/^  uint64_t maxDelta;$/;"	m	struct:paddle::Abstract
maxIds_	gserver/evaluators/Evaluator.cpp	/^  IVectorPtr maxIds_;$/;"	m	class:paddle::MaxFramePrinter	file:
maxIds_	gserver/evaluators/Evaluator.cpp	/^  IVectorPtr maxIds_;$/;"	m	class:paddle::MaxIdPrinter	file:
maxIndex_	gserver/layers/MaxLayer.h	/^  IVectorPtr maxIndex_;$/;"	m	class:paddle::MaxLayer
maxLength	api/SequenceGenerator.cpp	/^  size_t maxLength;$/;"	m	struct:SequenceGeneratorPrivate	file:
maxPendingConnections_	pserver/LightNetwork.h	/^  int maxPendingConnections_;$/;"	m	class:paddle::SocketServer
maxPendingConnections_	pserver/test/SocketTest.cpp	/^  int maxPendingConnections_;$/;"	m	class:SocketServer	file:
maxPoolBackward	math/Matrix.cpp	/^void CpuMatrix::maxPoolBackward(Matrix& image,$/;"	f	class:paddle::CpuMatrix
maxPoolBackward	math/Matrix.cpp	/^void GpuMatrix::maxPoolBackward(Matrix& inputMat,$/;"	f	class:paddle::GpuMatrix
maxPoolBackward	math/Matrix.h	/^  virtual void maxPoolBackward(Matrix& image,$/;"	f	class:paddle::Matrix
maxPoolForward	math/Matrix.cpp	/^void CpuMatrix::maxPoolForward(Matrix& inputMat,$/;"	f	class:paddle::CpuMatrix
maxPoolForward	math/Matrix.cpp	/^void GpuMatrix::maxPoolForward(Matrix& inputMat,$/;"	f	class:paddle::GpuMatrix
maxPoolForward	math/Matrix.h	/^  virtual void maxPoolForward(Matrix& inputMat,$/;"	f	class:paddle::Matrix
maxSequenceBackward	math/Matrix.cpp	/^void CpuMatrix::maxSequenceBackward(Matrix& outputGrad,$/;"	f	class:paddle::CpuMatrix
maxSequenceBackward	math/Matrix.cpp	/^void GpuMatrix::maxSequenceBackward(Matrix& outputGrad,$/;"	f	class:paddle::GpuMatrix
maxSequenceBackward	math/Matrix.h	/^  virtual void maxSequenceBackward(Matrix& outputGrad,$/;"	f	class:paddle::Matrix
maxSequenceForward	math/Matrix.cpp	/^void CpuMatrix::maxSequenceForward(Matrix& input,$/;"	f	class:paddle::CpuMatrix
maxSequenceForward	math/Matrix.cpp	/^void GpuMatrix::maxSequenceForward(Matrix& input,$/;"	f	class:paddle::GpuMatrix
maxSequenceForward	math/Matrix.h	/^  virtual void maxSequenceForward(Matrix& input,$/;"	f	class:paddle::Matrix
maxSequenceLength_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  int maxSequenceLength_;$/;"	m	class:paddle::RecurrentGradientMachine
maxSequenceLength_	gserver/layers/WarpCTCLayer.h	/^  size_t maxSequenceLength_;$/;"	m	class:paddle::WarpCTCLayer
maxSize_	gserver/layers/PriorBox.cpp	/^  std::vector<int> maxSize_;$/;"	m	class:paddle::PriorBoxLayer	file:
maxSortSize_	gserver/layers/CostLayer.h	/^  int maxSortSize_;$/;"	m	class:paddle::LambdaCost
maxTrainerId_	utils/BarrierStat.h	/^  int32_t maxTrainerId_;$/;"	m	class:paddle::TimeVectorDelta
maxValues_	gserver/evaluators/Evaluator.cpp	/^  MatrixPtr maxValues_;$/;"	m	class:paddle::MaxFramePrinter	file:
maxValues_	gserver/evaluators/Evaluator.cpp	/^  MatrixPtr maxValues_;$/;"	m	class:paddle::MaxIdPrinter	file:
maxX_	gserver/layers/LinearChainCRF.h	/^  MatrixPtr maxX_;$/;"	m	class:paddle::LinearChainCRF
max_	utils/BarrierStat.h	/^  uint64_t max_;$/;"	m	class:paddle::TimeVectorDelta
max_	utils/Stat.h	/^  uint64_t max_;$/;"	m	class:paddle::StatInfo
max_diff_	math/tests/test_TrainingAlgorithm.cpp	/^  double max_diff_;$/;"	m	class:SetMaxDiff	file:
max_size	utils/Util.h	/^  size_t max_size() const {$/;"	f	class:paddle::AlignedAllocator
maxoutBackward	math/Matrix.cpp	/^void CpuMatrix::maxoutBackward(Matrix& a,$/;"	f	class:paddle::CpuMatrix
maxoutBackward	math/Matrix.cpp	/^void GpuMatrix::maxoutBackward(Matrix& a,$/;"	f	class:paddle::GpuMatrix
maxoutBackward	math/Matrix.h	/^  virtual void maxoutBackward(Matrix& a,$/;"	f	class:paddle::Matrix
maxoutForward	math/Matrix.cpp	/^void CpuMatrix::maxoutForward(Matrix& a,$/;"	f	class:paddle::CpuMatrix
maxoutForward	math/Matrix.cpp	/^void GpuMatrix::maxoutForward(Matrix& a,$/;"	f	class:paddle::GpuMatrix
maxoutForward	math/Matrix.h	/^  virtual void maxoutForward(Matrix& a,$/;"	f	class:paddle::Matrix
maxoutId_	gserver/layers/MaxOutLayer.h	/^  IVectorPtr maxoutId_;$/;"	m	class:paddle::MaxOutLayer
meanGrad_	gserver/layers/BatchNormalizationLayer.h	/^  MatrixPtr normIn_, normInGrad_, meanGrad_, stdGrad_;$/;"	m	class:paddle::BatchNormalizationLayer
mean_	gserver/layers/DataNormLayer.h	/^  MatrixPtr mean_;$/;"	m	class:paddle::DataNormLayer
memcpyWithCheck	utils/Util.cpp	/^void memcpyWithCheck(void* dest,$/;"	f	namespace:paddle
memoryFrameLines_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<MemoryFrameLine> memoryFrameLines_;$/;"	m	class:paddle::RecurrentGradientMachine
memoryHandle_	math/Matrix.h	/^  MemoryHandlePtr memoryHandle_;$/;"	m	class:paddle::Matrix
memoryHandle_	math/Vector.h	/^  MemoryHandlePtr memoryHandle_;$/;"	m	class:paddle::VectorT
mergeBlockSegmentTest	pserver/test/test_ParameterServer2.cpp	/^void ParameterServer2Tester::mergeBlockSegmentTest() {$/;"	f	class:ParameterServer2Tester
mergeCpuGradients	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::mergeCpuGradients() {$/;"	f	class:paddle::TrainerThread
mergeGradDense	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::mergeGradDense($/;"	f	class:paddle::TrainerThread
mergeGradSparse	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::mergeGradSparse($/;"	f	class:paddle::TrainerThread
mergeGradSparseRemote	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::mergeGradSparseRemote($/;"	f	class:paddle::TrainerThread
mergeResultsOfAllClients	gserver/evaluators/Evaluator.h	/^  void mergeResultsOfAllClients(ParameterClient2* client) {$/;"	f	class:paddle::Evaluator
mergeSegments	pserver/ParameterServer2.cpp	/^void ParameterServer2::mergeSegments(BlockSegments* segments) {$/;"	f	class:paddle::ParameterServer2
mergeThreadStat	utils/Stat.cpp	/^void Stat::mergeThreadStat(StatInfo& allThreadStat) {$/;"	f	class:paddle::Stat
mergeTypes_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<ParameterType> mergeTypes_;$/;"	m	class:paddle::MultiGradientMachine
mergeTypes_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<ParameterType> mergeTypes_;$/;"	m	class:paddle::TrainerThread
min	cuda/include/hl_tensor_ops.h	/^  INLINE min(const T s) : p(s) {}$/;"	f	class:hppl::unary::min
min	cuda/include/hl_tensor_ops.h	/^class min {$/;"	c	namespace:hppl::binary
min	cuda/include/hl_tensor_ops.h	/^class min {$/;"	c	namespace:hppl::unary
min	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::min<T>, const Derived, T> min(T p) const {$/;"	f	class:paddle::TensorExpression
min	math/TensorExpression.h	/^  min(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
minAverageWindow_	parameter/AverageOptimizer.h	/^  int64_t minAverageWindow_;$/;"	m	class:paddle::AverageOptimizer
minDelta	utils/BarrierStat.h	/^  uint64_t minDelta;$/;"	m	struct:paddle::Abstract
minFinalPathLogProb_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<real> minFinalPathLogProb_;$/;"	m	class:paddle::RecurrentGradientMachine
minPoolSize_	gserver/dataproviders/PyDataProvider2.cpp	/^  size_t minPoolSize_;$/;"	m	class:paddle::PyDataProvider2	file:
minSize_	gserver/layers/PriorBox.cpp	/^  std::vector<int> minSize_;$/;"	m	class:paddle::PriorBoxLayer	file:
min_	gserver/layers/DataNormLayer.h	/^  MatrixPtr min_;$/;"	m	class:paddle::DataNormLayer
min_	utils/BarrierStat.h	/^  uint64_t min_;$/;"	m	class:paddle::TimeVectorDelta
min_	utils/Stat.h	/^  uint64_t min_;$/;"	m	class:paddle::StatInfo
min_pool_size	gserver/tests/test_PyDataProvider2.py	/^    min_pool_size=1000,$/;"	v
minorDeviceIds_	parameter/ParallelParameter.h	/^  std::vector<int> minorDeviceIds_;$/;"	m	class:paddle::SyncParameter
minorPartners_	parameter/ParallelParameter.h	/^  std::vector<ParallelParameterPtr> minorPartners_;$/;"	m	class:paddle::SyncParameter
minorUpdate	parameter/ParallelParameter.cpp	/^void SyncParameter::minorUpdate(real learnRate) {$/;"	f	class:paddle::SyncParameter
minorUpdate	parameter/ParallelParameter.h	/^  virtual void minorUpdate(real learnRate) { (void)learnRate; }$/;"	f	class:paddle::ParallelParameter
mkDir	utils/Util.cpp	/^void mkDir(const char* filename) {$/;"	f	namespace:paddle
mkDirRecursively	utils/Util.cpp	/^void mkDirRecursively(const char* dir) {$/;"	f	namespace:paddle
mmat_	gserver/layers/SelectiveFullyConnectedLayer.h	/^  MatrixPtr mmat_;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
mod	utils/Util.h	/^inline int mod(int a, int b) {$/;"	f	namespace:paddle
mode	gserver/gradientmachines/GradientMachineMode.h	/^  static IGradientMachineMode* mode(int32_t mode) {$/;"	f	class:paddle::IGradientMachineMode
mode	trainer/TesterConfig.h	/^  int mode;$/;"	m	struct:paddle::TesterConfig
mode	trainer/TrainerInternalConfig.h	/^  GradientMachine::CreateMode mode;$/;"	m	struct:paddle::TrainerInternalConfig
mode_	gserver/layers/AverageLayer.h	/^  int mode_;$/;"	m	class:paddle::AverageLayer
mode_	gserver/layers/CudnnPoolLayer.h	/^  hl_pooling_mode_t mode_;$/;"	m	class:paddle::CudnnPoolLayer
mode_	gserver/layers/DataNormLayer.h	/^  int mode_;$/;"	m	class:paddle::DataNormLayer
mode_	trainer/Trainer.h	/^  GradientMachine::CreateMode mode_;$/;"	m	class:paddle::Trainer
modelDir	trainer/tests/test_recurrent_machine_generation.cpp	/^static string modelDir = "trainer\/tests\/rnn_gen_test_model_dir\/t1";  \/\/ NOLINT$/;"	v	file:
modelList	trainer/TesterConfig.h	/^  std::string modelList;$/;"	m	struct:paddle::TesterConfig
modes_	gserver/gradientmachines/GradientMachineMode.cpp	/^    IGradientMachineMode::modes_;$/;"	m	class:paddle::IGradientMachineMode	file:
modes_	gserver/gradientmachines/GradientMachineMode.h	/^      modes_;$/;"	m	class:paddle::IGradientMachineMode
module	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^    module='rnn_data_provider',$/;"	v
module	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^    module='rnn_data_provider',$/;"	v
module	trainer/tests/simple_sparse_neural_network.py	/^    module="simple_sparse_neural_network_dp",$/;"	v
momentum_	parameter/FirstOrderOptimizer.h	/^  real momentum_;$/;"	m	class:paddle::SparseMomentumParameterOptimizer
monkeypatches	py_paddle/util.py	/^def monkeypatches():$/;"	f
movingAvgFraction_	gserver/layers/BatchNormBaseLayer.h	/^  real movingAvgFraction_;$/;"	m	class:paddle::BatchNormBaseLayer
movingMean_	gserver/layers/BatchNormBaseLayer.h	/^  std::unique_ptr<Weight> movingMean_;$/;"	m	class:paddle::BatchNormBaseLayer
movingVar_	gserver/layers/BatchNormBaseLayer.h	/^  std::unique_ptr<Weight> movingVar_;$/;"	m	class:paddle::BatchNormBaseLayer
mpiSize_	pserver/ParameterServer2.h	/^  int mpiSize_;$/;"	m	class:paddle::ParameterServer2
msg	utils/Error.h	/^  const char* msg() const {$/;"	f	class:paddle::Error
msg_	utils/Error.h	/^  std::shared_ptr<std::string> msg_;$/;"	m	class:paddle::Error
mtx_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::mutex mtx_;$/;"	m	class:paddle::PyDataProvider2	file:
mtx_	utils/CustomStackTrace.h	/^  mutable std::mutex mtx_;$/;"	m	class:paddle::CustomStackTrace
mul	cuda/include/hl_tensor_ops.h	/^class mul {$/;"	c	namespace:hppl::binary
mul	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::mul(const Matrix& a,$/;"	f	class:paddle::CpuSparseMatrix
mul	math/Matrix.cpp	/^void CpuMatrix::mul($/;"	f	class:paddle::CpuMatrix
mul	math/Matrix.cpp	/^void CpuMatrix::mul(CpuMatrix* a, CpuMatrix* b, real scaleAB, real scaleT) {$/;"	f	class:paddle::CpuMatrix
mul	math/Matrix.cpp	/^void CpuMatrix::mul(CpuMatrix* a,$/;"	f	class:paddle::CpuMatrix
mul	math/Matrix.cpp	/^void CpuMatrix::mul(CpuSparseMatrix* a,$/;"	f	class:paddle::CpuMatrix
mul	math/Matrix.cpp	/^void CpuMatrix::mul(const Matrix& a, const Matrix& b) {$/;"	f	class:paddle::CpuMatrix
mul	math/Matrix.cpp	/^void CpuMatrix::mul(const Matrix& a,$/;"	f	class:paddle::CpuMatrix
mul	math/Matrix.cpp	/^void GpuMatrix::mul(const GpuMatrix& a,$/;"	f	class:paddle::GpuMatrix
mul	math/Matrix.cpp	/^void GpuMatrix::mul(const GpuSparseMatrix& a,$/;"	f	class:paddle::GpuMatrix
mul	math/Matrix.cpp	/^void GpuMatrix::mul(const Matrix& a, const Matrix& b) { mul(a, b, 1.0, 0.0); }$/;"	f	class:paddle::GpuMatrix
mul	math/Matrix.cpp	/^void GpuMatrix::mul(const Matrix& a,$/;"	f	class:paddle::GpuMatrix
mul	math/Matrix.cpp	/^void SharedCpuMatrix::mul(CpuSparseMatrix* a,$/;"	f	class:paddle::SharedCpuMatrix
mul	math/Matrix.h	/^  virtual void mul(const Matrix& a, const Matrix& b) {$/;"	f	class:paddle::Matrix
mul	math/Matrix.h	/^  virtual void mul(const Matrix& a,$/;"	f	class:paddle::Matrix
mul	math/SparseMatrix.cpp	/^void GpuSparseMatrix::mul(const GpuMatrix& a,$/;"	f	class:paddle::GpuSparseMatrix
mul	math/SparseMatrix.cpp	/^void GpuSparseMatrix::mul(const Matrix& a,$/;"	f	class:paddle::GpuSparseMatrix
mul	math/SparseRowMatrix.cpp	/^void CacheRowCpuMatrix::mul(CpuSparseMatrix* a,$/;"	f	class:paddle::CacheRowCpuMatrix
mul	math/SparseRowMatrix.cpp	/^void SparseAutoGrowRowCpuMatrix::mul(CpuSparseMatrix* a,$/;"	f	class:paddle::SparseAutoGrowRowCpuMatrix
mul	math/SparseRowMatrix.cpp	/^void SparseRowCpuMatrix::mul(CpuSparseMatrix* a,$/;"	f	class:paddle::SparseRowCpuMatrix
mulByBitCode	math/Matrix.h	/^  virtual void mulByBitCode(size_t numClasses,$/;"	f	class:paddle::Matrix
mulByBitCode	math/MatrixBitCode.cpp	/^void CpuMatrix::mulByBitCode(size_t numClasses,$/;"	f	class:paddle::CpuMatrix
mulByBitCodeBackwardError	math/Matrix.h	/^  virtual void mulByBitCodeBackwardError(size_t numClasses,$/;"	f	class:paddle::Matrix
mulByBitCodeBackwardError	math/MatrixBitCode.cpp	/^void CpuMatrix::mulByBitCodeBackwardError(size_t numClasses,$/;"	f	class:paddle::CpuMatrix
mulByBitCodeBackwardWeight	math/Matrix.h	/^  virtual void mulByBitCodeBackwardWeight(size_t numClasses,$/;"	f	class:paddle::Matrix
mulByBitCodeBackwardWeight	math/MatrixBitCode.cpp	/^void CpuMatrix::mulByBitCodeBackwardWeight(size_t numClasses,$/;"	f	class:paddle::CpuMatrix
mulByBitCodeT	math/MatrixBitCode.cpp	/^void mulByBitCodeT(Op op,$/;"	f	namespace:paddle
mul_scale	cuda/include/hl_tensor_ops.h	/^  INLINE mul_scale(const T s) : p(s) {}$/;"	f	class:hppl::unary::mul_scale
mul_scale	cuda/include/hl_tensor_ops.h	/^class mul_scale {$/;"	c	namespace:hppl::unary
multiBinaryLabelCrossEntropy	math/Matrix.cpp	/^void CpuMatrix::multiBinaryLabelCrossEntropy(Matrix& output, Matrix& label) {$/;"	f	class:paddle::CpuMatrix
multiBinaryLabelCrossEntropy	math/Matrix.cpp	/^void GpuMatrix::multiBinaryLabelCrossEntropy(Matrix& output, Matrix& label) {$/;"	f	class:paddle::GpuMatrix
multiBinaryLabelCrossEntropy	math/Matrix.h	/^  virtual void multiBinaryLabelCrossEntropy(Matrix& output, Matrix& label) {$/;"	f	class:paddle::Matrix
multiBinaryLabelCrossEntropyBp	math/Matrix.cpp	/^void CpuMatrix::multiBinaryLabelCrossEntropyBp(Matrix& output, Matrix& label) {$/;"	f	class:paddle::CpuMatrix
multiBinaryLabelCrossEntropyBp	math/Matrix.cpp	/^void GpuMatrix::multiBinaryLabelCrossEntropyBp(Matrix& output, Matrix& label) {$/;"	f	class:paddle::GpuMatrix
multiBinaryLabelCrossEntropyBp	math/Matrix.h	/^  virtual void multiBinaryLabelCrossEntropyBp(Matrix& output, Matrix& label) {$/;"	f	class:paddle::Matrix
multiCall	pserver/BaseClient.h	/^  void multiCall(const char* funcName,$/;"	f	class:paddle::BaseClient
multiCall	pserver/ParameterClient2.h	/^  void multiCall(const char* funcName,$/;"	f	class:paddle::ParameterClient2
multiMachine_	gserver/gradientmachines/MultiGradientMachine.h	/^  MultiGradientMachine* multiMachine_;$/;"	m	class:paddle::TrainerThread
mutex	utils/Locks.h	/^  std::mutex* mutex() { return &mutex_; }$/;"	f	class:paddle::LockedCondition
mutexForReset_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::mutex mutexForReset_;$/;"	m	class:paddle::PyDataProvider2	file:
mutex_	math/PoolAllocator.h	/^  std::mutex mutex_;$/;"	m	class:paddle::PoolAllocator
mutex_	utils/Locks.h	/^  std::mutex mutex_;$/;"	m	class:paddle::LockedCondition
mutex_	utils/Queue.h	/^  std::mutex mutex_;$/;"	m	class:paddle::BlockingQueue
mutex_	utils/ThreadLocal.h	/^  std::mutex mutex_;$/;"	m	class:paddle::ThreadLocalD
mutex_	utils/arch/osx/Locks.cpp	/^  pthread_mutex_t mutex_;$/;"	m	class:paddle::ThreadBarrierPrivate	file:
naive	math/SIMDFunctions.h	/^namespace naive {$/;"	n	namespace:paddle::simd
name	gserver/activations/ActivationFunction.cpp	/^  static const std::string name;$/;"	m	class:paddle::IdentityActivation	file:
name	gserver/activations/ActivationFunction.cpp	/^const std::string IdentityActivation::name = "";$/;"	m	class:paddle::IdentityActivation	file:
name	gserver/tests/LayerGradUtil.h	/^  string name;$/;"	m	struct:paddle::InputDef
name	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^    name="outer",$/;"	v
name	gserver/tests/test_Evaluator.cpp	/^  string name;$/;"	m	struct:InputDef	file:
name	pserver/ParameterClient2.h	/^  std::string name;  \/\/ name of the parameter$/;"	m	struct:paddle::ParameterSegments
nameToFuncMap_	pserver/ProtoServer.h	/^  std::map<std::string, ServiceFunction> nameToFuncMap_;$/;"	m	class:paddle::ProtoServer
name_	math/PoolAllocator.h	/^  std::string name_;$/;"	m	class:paddle::PoolAllocator
name_	utils/BarrierStat.h	/^  std::string name_;$/;"	m	class:paddle::BarrierStatBase
name_	utils/Stat.h	/^  const std::string name_;$/;"	m	class:paddle::Stat
name_	utils/Stat.h	/^  const std::string name_;$/;"	m	class:paddle::StatSet
ndims	function/TensorShape.h	/^  size_t ndims() const { return ndims_; }$/;"	f	class:paddle::TensorShape
ndims_	function/TensorShape.h	/^  size_t ndims_;$/;"	m	class:paddle::TensorShape
needFree	api/PaddleAPI.h	/^  bool needFree;  \/\/ true if the buf is dynamic alloced.$/;"	m	struct:FloatArray
needFree	api/PaddleAPI.h	/^  bool needFree;$/;"	m	struct:IntArray
needFree	api/PaddleAPI.h	/^  bool needFree;$/;"	m	struct:IntWithFloatArray
needGradient	gserver/layers/Layer.h	/^  bool needGradient() const { return needGradient_; }$/;"	f	class:paddle::Layer
needGradient_	gserver/layers/Layer.h	/^  bool needGradient_;$/;"	m	class:paddle::Layer
needSequenceInfo_	gserver/layers/Layer.h	/^  bool needSequenceInfo_;$/;"	m	class:paddle::Layer
needSpecialTraversal	api/ParameterOptimizer.cpp	/^ParameterTraverseCallback* ParameterOptimizer::needSpecialTraversal($/;"	f	class:ParameterOptimizer
needSpecialTraversal	parameter/AverageOptimizer.cpp	/^ParameterOptimizer::TraverseCallback AverageOptimizer::needSpecialTraversal($/;"	f	class:paddle::AverageOptimizer
needSpecialTraversal	parameter/FirstOrderOptimizer.cpp	/^AdagradParameterOptimizer::needSpecialTraversal($/;"	f	class:paddle::AdagradParameterOptimizer
needSpecialTraversal	parameter/FirstOrderOptimizer.cpp	/^SparseMomentumParameterOptimizer::needSpecialTraversal($/;"	f	class:paddle::SparseMomentumParameterOptimizer
needSpecialTraversal	parameter/FirstOrderOptimizer.h	/^  virtual TraverseCallback needSpecialTraversal($/;"	f	class:paddle::OptimizerWithGradientClipping
needSpecialTraversal	parameter/OptimizerWithRegularizer.cpp	/^OptimizerWithRegularizerEveryNumBatches::needSpecialTraversal($/;"	f	class:paddle::OptimizerWithRegularizerEveryNumBatches
needSpecialTraversal	parameter/OptimizerWithRegularizer.h	/^  virtual TraverseCallback needSpecialTraversal($/;"	f	class:paddle::OptimizerWithRegularizer
needSpecialTraversal	parameter/ParameterOptimizer.h	/^  virtual TraverseCallback needSpecialTraversal($/;"	f	class:paddle::ParameterOptimizer
needToUpdateRemotely	trainer/RemoteParameterUpdater.h	/^  bool needToUpdateRemotely() {$/;"	f	class:paddle::ConcurrentRemoteParameterUpdater
neg	cuda/include/hl_tensor_ops.h	/^class neg {$/;"	c	namespace:hppl::unary
negPairCount_	gserver/layers/CostLayer.h	/^  double negPairCount_;$/;"	m	class:paddle::RankingCost
nelements_	function/TensorShape.h	/^  size_t nelements_;$/;"	m	class:paddle::TensorShape
network_	gserver/layers/RecurrentLayerGroup.cpp	/^  std::unique_ptr<RecurrentGradientMachine> network_;$/;"	m	class:paddle::RecurrentLayerGroup	file:
newBatchSize_	gserver/layers/SequencePoolLayer.h	/^  size_t newBatchSize_;$/;"	m	class:paddle::SequencePoolLayer
newMemory	math/Vector.h	/^  virtual MemoryHandlePtr newMemory(size_t size) {$/;"	f	class:paddle::CpuVectorT
newMemory	math/Vector.h	/^  virtual MemoryHandlePtr newMemory(size_t size) {$/;"	f	class:paddle::GpuVectorT
newNeuralNetwork	gserver/gradientmachines/NeuralNetwork.cpp	/^NeuralNetwork* NeuralNetwork::newNeuralNetwork(const std::string& name,$/;"	f	class:paddle::NeuralNetwork
nextBlock	pserver/ParameterServer2.h	/^    T* nextBlock(size_t blockSize) {$/;"	f	class:paddle::ParameterServer2::ReadWriteBuffer
nextItemIndex_	gserver/dataproviders/DataProvider.h	/^  int64_t nextItemIndex_;$/;"	m	class:paddle::SimpleDataProviderBase
nics	trainer/tests/test_CompareTwoNets.cpp	/^DECLARE_string(nics);$/;"	v
nics	trainer/tests/test_CompareTwoOpts.cpp	/^DECLARE_string(nics);$/;"	v
nics	utils/Flags.h	/^DECLARE_string(nics);$/;"	v
nnz	cuda/include/hl_base.h	/^  size_t nnz;$/;"	m	struct:__anon10
nnz	function/BufferArg.h	/^  size_t nnz() const { return nnz_; }$/;"	f	class:paddle::SparseMatrixArg
nnz	math/tests/test_SparseMatrix.cpp	/^  size_t nnz;$/;"	m	struct:MatrixPara	file:
nnzStats_	gserver/dataproviders/ProtoDataProvider.h	/^  std::vector<StatPtr> nnzStats_;  \/\/ stats for number of none-zeros entries$/;"	m	class:paddle::ProtoDataProvider
nnz_	function/BufferArg.h	/^  size_t nnz_;$/;"	m	class:paddle::SparseMatrixArg
nnz_	gserver/dataproviders/PyDataProvider2.cpp	/^  size_t nnz_;$/;"	m	class:paddle::SparseNonValueScanner	file:
nonStaticParaIDMap_	parameter/ParameterUpdaterBase.h	/^  std::map<size_t, size_t> nonStaticParaIDMap_;$/;"	m	class:paddle::ParameterUpdater
nonStaticParameters_	gserver/gradientmachines/GradientMachine.h	/^  std::vector<ParameterPtr> nonStaticParameters_;$/;"	m	class:paddle::GradientMachine
normByTimes_	gserver/layers/CTCLayer.h	/^  bool normByTimes_;$/;"	m	class:paddle::CTCLayer
normByTimes_	gserver/layers/LinearChainCTC.h	/^  bool normByTimes_;$/;"	m	class:paddle::LinearChainCTC
normByTimes_	gserver/layers/WarpCTCLayer.h	/^  bool normByTimes_;$/;"	m	class:paddle::WarpCTCLayer
normInGrad_	gserver/layers/BatchNormalizationLayer.h	/^  MatrixPtr normIn_, normInGrad_, meanGrad_, stdGrad_;$/;"	m	class:paddle::BatchNormalizationLayer
normIn_	gserver/layers/BatchNormalizationLayer.h	/^  MatrixPtr normIn_, normInGrad_, meanGrad_, stdGrad_;$/;"	m	class:paddle::BatchNormalizationLayer
normOrDropNode	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^  RecurrentGradientMachine::NormOrDropNodeCallback normOrDropNode;$/;"	m	class:paddle::BeamSearchControlCallbacks	file:
normalizeL1	gserver/layers/LinearChainCRF.cpp	/^static real normalizeL1(real* x, int n) {$/;"	f	namespace:paddle
normalize_flag	api/paddle_ld_flags.py	/^        def normalize_flag(self, cmake_flag):$/;"	m	class:PaddleLDFlag
notEmpty_	utils/Queue.h	/^  std::condition_variable notEmpty_;$/;"	m	class:paddle::BlockingQueue
notFull_	utils/Queue.h	/^  std::condition_variable notFull_;$/;"	m	class:paddle::BlockingQueue
notifyCopyGradToBuffer	gserver/gradientmachines/MultiGradientMachine.h	/^  void notifyCopyGradToBuffer(int paramId) { gradBufQueue_.enqueue(paramId); }$/;"	f	class:paddle::TrainerThread
notifyGradReady	parameter/Argument.h	/^  void notifyGradReady() const {$/;"	f	struct:paddle::Argument
notifyGradientCollect	gserver/gradientmachines/MultiGradientMachine.h	/^  void notifyGradientCollect(int paramId) { gradQueue_.enqueue(paramId); }$/;"	f	class:paddle::TrainerThread
notifyGradientTransfer	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::notifyGradientTransfer(int paramId) {$/;"	f	class:paddle::MultiGradientMachine
notifyTaskReady	gserver/gradientmachines/MultiGradientMachine.h	/^  void notifyTaskReady() { taskReadySem_.post(); }$/;"	f	class:paddle::TrainerThread
notifyValueDispatch	gserver/gradientmachines/MultiGradientMachine.h	/^  void notifyValueDispatch(int paramId) { valueReadyQueue_.enqueue(paramId); }$/;"	f	class:paddle::TrainerThread
notifyValueReady	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::notifyValueReady(int paramId) {$/;"	f	class:paddle::TrainerThread
notifyValueReady	parameter/Argument.h	/^  void notifyValueReady() const {$/;"	f	struct:paddle::Argument
notify_all	utils/Locks.h	/^  void notify_all(Op op) {$/;"	f	class:paddle::LockedCondition
notify_one	utils/Locks.h	/^  void notify_one(Op op) {$/;"	f	class:paddle::LockedCondition
nowInMicroSec	utils/Stat.h	/^inline uint64_t nowInMicroSec() {$/;"	f	namespace:paddle
null	trainer/tests/picojson.h	/^struct null {};$/;"	s	namespace:picojson
nullResultNum_	utils/Thread.h	/^  size_t nullResultNum_;$/;"	m	class:paddle::MultiThreadWorker
null_parse_context	trainer/tests/picojson.h	/^  null_parse_context() {}$/;"	f	class:picojson::null_parse_context
null_parse_context	trainer/tests/picojson.h	/^class null_parse_context {$/;"	c	namespace:picojson
null_type	trainer/tests/picojson.h	/^  null_type,$/;"	e	enum:picojson::__anon14
numAccumulates_	parameter/AverageOptimizer.h	/^  int64_t numAccumulates_;$/;"	m	class:paddle::AverageOptimizer
numAvgTests	trainer/Trainer.h	/^    int64_t numAvgTests;$/;"	m	struct:paddle::Trainer::TrainPassContext
numBatch_	gserver/layers/SequenceToBatch.h	/^  size_t numBatch_;$/;"	m	class:paddle::SequenceToBatch
numBatches_	trainer/RemoteParameterUpdater.h	/^  int64_t numBatches_;$/;"	m	class:paddle::RemoteParameterUpdater
numBlocks_	gserver/layers/MDLstmLayer.cpp	/^  size_t numBlocks_;$/;"	m	class:paddle::MDLstmLayer	file:
numChannels_	gserver/layers/BilinearInterpLayer.h	/^  size_t numChannels_;$/;"	m	class:paddle::BilinearInterpLayer
numChunkTypes_	gserver/evaluators/ChunkEvaluator.cpp	/^  int numChunkTypes_;  \/\/ number of chunk types besides other chunk type$/;"	m	class:paddle::ChunkEvaluator	file:
numClasses_	gserver/evaluators/CTCErrorEvaluator.cpp	/^  int numTimes_, numClasses_, numSequences_, blank_;$/;"	m	class:paddle::CTCErrorEvaluator	file:
numClasses_	gserver/layers/CRFLayer.h	/^  size_t numClasses_;$/;"	m	class:paddle::CRFLayer
numClasses_	gserver/layers/CTCLayer.h	/^  size_t numClasses_;$/;"	m	class:paddle::CTCLayer
numClasses_	gserver/layers/HierarchicalSigmoidLayer.h	/^  size_t numClasses_;$/;"	m	class:paddle::HierarchicalSigmoidLayer
numClasses_	gserver/layers/LinearChainCRF.h	/^  int numClasses_;$/;"	m	class:paddle::LinearChainCRF
numClasses_	gserver/layers/LinearChainCTC.h	/^  int numClasses_, blank_, totalSegments_, totalTime_;$/;"	m	class:paddle::LinearChainCTC
numClasses_	gserver/layers/NCELayer.cpp	/^  int numClasses_;$/;"	m	class:paddle::NCELayer	file:
numClasses_	gserver/layers/WarpCTCLayer.h	/^  size_t numClasses_;$/;"	m	class:paddle::WarpCTCLayer
numClasses_	math/MatrixBitCode.cpp	/^  size_t numClasses_;$/;"	m	struct:paddle::__anon17::SimpleCodeTable	file:
numConnThreads_	utils/BarrierStat.h	/^  uint16_t numConnThreads_;  \/\/ total updates needed$/;"	m	class:paddle::BarrierStatBase
numCorrect_	gserver/evaluators/ChunkEvaluator.cpp	/^  int64_t numCorrect_;$/;"	m	class:paddle::ChunkEvaluator	file:
numCpus	pserver/RDMANetwork.h	/^inline int numCpus() {$/;"	f	namespace:paddle::rdma
numDevices_	gserver/gradientmachines/MultiGradientMachine.h	/^  int numDevices_;         \/* number of gpu devices *\/$/;"	m	class:paddle::MultiGradientMachine
numDevices_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  int numDevices_;$/;"	m	class:paddle::ParallelNeuralNetwork
numDims_	gserver/layers/MDLstmLayer.cpp	/^  int numDims_;$/;"	m	class:paddle::MDLstmLayer	file:
numElements	function/BufferArg.h	/^  virtual size_t numElements() const { return shape_.getElements(); }$/;"	f	class:paddle::BufferArg
numElements	function/TensorShape.h	/^  void numElements() {$/;"	f	class:paddle::TensorShape
numElements_	utils/Queue.h	/^  int numElements_;$/;"	m	class:paddle::Queue
numFilters_	gserver/layers/ConvBaseLayer.h	/^  int numFilters_;$/;"	m	class:paddle::ConvBaseLayer
numFilters_	gserver/layers/ConvOperator.cpp	/^  int numFilters_;$/;"	m	class:paddle::ConvOperator	file:
numFilters_	gserver/layers/ConvProjection.h	/^  int channels_, numFilters_;$/;"	m	class:paddle::ConvProjection
numFilters_	gserver/layers/FeatureMapExpandLayer.cpp	/^  int numFilters_;$/;"	m	class:paddle::FeatureMapExpandLayer	file:
numInputs_	function/Function.h	/^  size_t numInputs_;$/;"	m	class:paddle::FunctionBase
numInputs_	gserver/layers/NCELayer.cpp	/^  int numInputs_;$/;"	m	class:paddle::NCELayer	file:
numIovs	pserver/SocketChannel.h	/^    int64_t numIovs;$/;"	m	struct:paddle::SocketChannel::MessageHeader
numLabelSegments_	gserver/evaluators/ChunkEvaluator.cpp	/^  int64_t numLabelSegments_;$/;"	m	class:paddle::ChunkEvaluator	file:
numLogicalDevices_	gserver/gradientmachines/MultiGradientMachine.h	/^  int numLogicalDevices_;  \/\/ number of GPU used by one NN$/;"	m	class:paddle::MultiGradientMachine
numOutputSegments_	gserver/evaluators/ChunkEvaluator.cpp	/^  int64_t numOutputSegments_;$/;"	m	class:paddle::ChunkEvaluator	file:
numOutputs_	function/Function.h	/^  size_t numOutputs_;$/;"	m	class:paddle::FunctionBase
numPassFinishClients_	pserver/ParameterServer2.h	/^  std::atomic<int> numPassFinishClients_;$/;"	m	class:paddle::ParameterServer2
numPasses	trainer/TesterConfig.h	/^  int numPasses;$/;"	m	struct:paddle::TesterConfig
numPorts_	pserver/BaseClient.h	/^  int numPorts_;$/;"	m	class:paddle::BaseClient
numPriors_	gserver/layers/PriorBox.cpp	/^  int numPriors_;$/;"	m	class:paddle::PriorBoxLayer	file:
numProcessed_	trainer/TrainerInternalConfig.h	/^  int64_t numProcessed_;$/;"	m	class:paddle::TrainerStats
numSamples	trainer/Tester.h	/^    int64_t numSamples;$/;"	m	struct:paddle::Tester::__anon13
numSamplesProcessed_	pserver/ParameterServer2.h	/^  std::atomic<int64_t> numSamplesProcessed_;$/;"	m	class:paddle::ParameterServer2
numSamplesProcessed_	trainer/ParameterUpdater.h	/^  int64_t numSamplesProcessed_;$/;"	m	class:paddle::SgdLocalUpdater
numSamplesProcessed_	trainer/ThreadParameterUpdater.h	/^  int64_t numSamplesProcessed_;$/;"	m	class:paddle::SgdThreadUpdater
numSamples_	gserver/evaluators/Evaluator.h	/^  double numSamples_;$/;"	m	class:paddle::Evaluator
numSamples_	gserver/layers/AgentLayer.h	/^  int numSamples_;$/;"	m	class:paddle::AgentLayer
numSeqs	function/BufferArg.h	/^  size_t numSeqs() const { return numSeqs_; }$/;"	f	class:paddle::SequenceIdArg
numSeqs	function/BufferArg.h	/^  size_t numSeqs() const { return startPositions_.numSeqs(); }$/;"	f	class:paddle::SequenceArg
numSeqs_	function/BufferArg.h	/^  size_t numSeqs_;$/;"	m	class:paddle::SequenceIdArg
numSeqs_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<int> numSeqs_;$/;"	m	class:paddle::RecurrentGradientMachine
numSequences_	gserver/evaluators/CTCErrorEvaluator.cpp	/^  int numTimes_, numClasses_, numSequences_, blank_;$/;"	m	class:paddle::CTCErrorEvaluator	file:
numSequences_	gserver/layers/AgentLayer.h	/^  int numSequences_;  \/\/ number of sequences in this scatterAgentLayer$/;"	m	class:paddle::ScatterAgentLayer
numTagTypes_	gserver/evaluators/ChunkEvaluator.cpp	/^  int numTagTypes_;$/;"	m	class:paddle::ChunkEvaluator	file:
numThreads_	gserver/gradientmachines/MultiGradientMachine.h	/^  int numThreads_;         \/* number of train threads *\/$/;"	m	class:paddle::MultiGradientMachine
numTimes_	gserver/evaluators/CTCErrorEvaluator.cpp	/^  int numTimes_, numClasses_, numSequences_, blank_;$/;"	m	class:paddle::CTCErrorEvaluator	file:
numUpdates_	parameter/AverageOptimizer.h	/^  int64_t numUpdates_;$/;"	m	class:paddle::AverageOptimizer
numUpdates_	parameter/FirstOrderOptimizer.h	/^  int64_t numUpdates_;$/;"	m	class:paddle::AdagradParameterOptimizer
numVecSlots_	gserver/dataproviders/ProtoDataProvider.h	/^  int numVecSlots_;$/;"	m	class:paddle::ProtoDataProvider
num_gradient_servers	trainer/tests/test_CompareSparse.cpp	/^DECLARE_int32(num_gradient_servers);$/;"	v
num_gradient_servers	trainer/tests/test_TrainerOnePass.cpp	/^DECLARE_int32(num_gradient_servers);$/;"	v
num_gradient_servers	utils/Flags.h	/^DECLARE_int32(num_gradient_servers);$/;"	v
num_original_columns	trainer/tests/gen_proto_data.py	/^num_original_columns = 3$/;"	v
num_passes	gserver/tests/test_SelectiveFCLayer.cpp	/^DECLARE_int32(num_passes);$/;"	v
num_passes	trainer/Trainer.h	/^DECLARE_int32(num_passes);$/;"	v
num_passes	trainer/TrainerInternalConfig.cpp	/^DECLARE_int32(num_passes);$/;"	v
num_passes	trainer/TrainerInternalConfig.h	/^  int num_passes;$/;"	m	struct:paddle::TrainerInternalConfig
num_passes	trainer/tests/test_CompareSparse.cpp	/^DECLARE_int32(num_passes);$/;"	v
num_passes	trainer/tests/test_TrainerOnePass.cpp	/^DECLARE_int32(num_passes);$/;"	v
number_	trainer/tests/picojson.h	/^    double number_;$/;"	m	union:picojson::value::_storage
number_type	trainer/tests/picojson.h	/^  number_type,$/;"	e	enum:picojson::__anon14
obj	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^    obj='process_unequalength_subseq')$/;"	v
obj	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^    obj='process_unequalength_seq')$/;"	v
obj	setup.py	/^obj = api.paddle_ld_flags.PaddleLDFlag()$/;"	v
obj	trainer/tests/simple_sparse_neural_network.py	/^    obj="process")$/;"	v
objPool_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::unique_ptr<std::deque<PyObjectPtr>> objPool_;$/;"	m	class:paddle::CacheOnePassInMemory	file:
obj_	utils/PythonUtil.h	/^  const PyObjectPtr& obj_;$/;"	m	class:paddle::py::CallableHelper
obj_	utils/PythonUtil.h	/^  const PyObjectPtr& obj_;$/;"	m	class:paddle::py::ObjectHelper
object	trainer/tests/picojson.h	/^  typedef std::map<std::string, value> object;$/;"	t	class:picojson::value
object	trainer/tests/picojson.h	/^typedef value::object object;$/;"	t	namespace:picojson
object_	trainer/tests/picojson.h	/^    object* object_;$/;"	m	union:picojson::value::_storage
object_type	trainer/tests/picojson.h	/^  object_type$/;"	e	enum:picojson::__anon14
offset	gserver/layers/MDLstmLayer.cpp	/^  int offset() {$/;"	f	class:paddle::CoordIterator
offset	gserver/layers/MDLstmLayer.cpp	/^  int offset(const std::vector<int>& pos) {$/;"	f	class:paddle::CoordIterator
offset	pserver/ParameterServer2.h	/^    uint64_t offset;$/;"	m	struct:paddle::ParameterServer2::BlockInfo
oldNumAccumulates_	parameter/AverageOptimizer.h	/^  int64_t oldNumAccumulates_;$/;"	m	class:paddle::AverageOptimizer
onEachStepStarted	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^  RecurrentGradientMachine::EachStepCallback onEachStepStarted;$/;"	m	class:paddle::BeamSearchStatisticsCallbacks	file:
onEachStepStoped	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^  RecurrentGradientMachine::EachStepCallback onEachStepStoped;$/;"	m	class:paddle::BeamSearchStatisticsCallbacks	file:
onLoadParameter	gserver/gradientmachines/GradientMachine.h	/^  virtual void onLoadParameter() {}$/;"	f	class:paddle::GradientMachine
onPassEnd	api/GradientMachine.cpp	/^void GradientMachine::onPassEnd() { m->machine->onPassEnd(); }$/;"	f	class:GradientMachine
onPassEnd	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::onPassEnd() {$/;"	f	class:paddle::MultiGradientMachine
onPassEnd	gserver/gradientmachines/MultiGradientMachine.h	/^  void onPassEnd() { gradientMachine_->onPassEnd(); }$/;"	f	class:paddle::TrainerThread
onPassEnd	gserver/gradientmachines/MultiNetwork.cpp	/^void MultiNetwork::onPassEnd() {$/;"	f	class:paddle::MultiNetwork
onPassEnd	gserver/gradientmachines/NeuralNetwork.cpp	/^void NeuralNetwork::onPassEnd() {$/;"	f	class:paddle::NeuralNetwork
onPassEnd	gserver/layers/CostLayer.cpp	/^void RankingCost::onPassEnd() {$/;"	f	class:paddle::RankingCost
onPassEnd	gserver/layers/Layer.h	/^  virtual void onPassEnd() {}$/;"	f	class:paddle::Layer
onPassEnd	gserver/layers/ValidationLayer.cpp	/^void AucValidation::onPassEnd() {$/;"	f	class:paddle::AucValidation
onPassEnd	gserver/layers/ValidationLayer.cpp	/^void PnpairValidation::onPassEnd() {$/;"	f	class:paddle::PnpairValidation
onceFlag_	utils/Util.h	/^  std::once_flag onceFlag_;$/;"	m	class:paddle::SameThreadChecker
oneBatchFinished_	trainer/RemoteParameterUpdater.h	/^  bool oneBatchFinished_;$/;"	m	class:paddle::ConcurrentRemoteParameterUpdater
oneHotCrossEntropy	math/Matrix.cpp	/^void CpuMatrix::oneHotCrossEntropy(Matrix& output, IVector& label) {$/;"	f	class:paddle::CpuMatrix
oneHotCrossEntropy	math/Matrix.cpp	/^void GpuMatrix::oneHotCrossEntropy(Matrix& output, IVector& label) {$/;"	f	class:paddle::GpuMatrix
oneHotCrossEntropy	math/Matrix.h	/^  virtual void oneHotCrossEntropy(Matrix& output, IVector& label) {$/;"	f	class:paddle::Matrix
oneHotCrossEntropyBp	math/Matrix.cpp	/^void CpuMatrix::oneHotCrossEntropyBp(Matrix& output, IVector& label) {$/;"	f	class:paddle::CpuMatrix
oneHotCrossEntropyBp	math/Matrix.cpp	/^void GpuMatrix::oneHotCrossEntropyBp(Matrix& outputV, IVector& label) {$/;"	f	class:paddle::GpuMatrix
oneHotCrossEntropyBp	math/Matrix.h	/^  virtual void oneHotCrossEntropyBp(Matrix& outputV, IVector& label) {$/;"	f	class:paddle::Matrix
oneHotCrossEntropyWithSelfNorm	math/Matrix.cpp	/^void CpuMatrix::oneHotCrossEntropyWithSelfNorm(Matrix& output,$/;"	f	class:paddle::CpuMatrix
oneHotCrossEntropyWithSelfNorm	math/Matrix.cpp	/^void GpuMatrix::oneHotCrossEntropyWithSelfNorm(Matrix& output,$/;"	f	class:paddle::GpuMatrix
oneHotCrossEntropyWithSelfNorm	math/Matrix.h	/^  virtual void oneHotCrossEntropyWithSelfNorm(Matrix& output,$/;"	f	class:paddle::Matrix
oneHotCrossEntropyWithSelfNormBp	math/Matrix.cpp	/^void CpuMatrix::oneHotCrossEntropyWithSelfNormBp(Matrix& output,$/;"	f	class:paddle::CpuMatrix
oneHotCrossEntropyWithSelfNormBp	math/Matrix.cpp	/^void GpuMatrix::oneHotCrossEntropyWithSelfNormBp(Matrix& outputV,$/;"	f	class:paddle::GpuMatrix
oneHotCrossEntropyWithSelfNormBp	math/Matrix.h	/^  virtual void oneHotCrossEntropyWithSelfNormBp(Matrix& outputV,$/;"	f	class:paddle::Matrix
oneWaySearch	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::oneWaySearch(size_t batchSize) {$/;"	f	class:paddle::RecurrentGradientMachine
one_	gserver/activations/ActivationFunction.cpp	/^MatrixPtr one_;$/;"	m	namespace:paddle	file:
ones_	gserver/layers/LinearChainCRF.h	/^  MatrixPtr ones_;$/;"	m	class:paddle::LinearChainCRF
onlineCpus_	pserver/LightNetwork.h	/^  int onlineCpus_;$/;"	m	class:paddle::RdmaClientDaemons
opFuncs	pserver/ParameterServer2.cpp	/^ParameterServer2::OperatorFunction ParameterServer2::opFuncs[] = {$/;"	m	class:paddle::ParameterServer2	file:
opFuncs	pserver/ParameterServer2.h	/^  static OperatorFunction opFuncs[];$/;"	m	class:paddle::ParameterServer2
op_	math/TensorApply.h	/^  const OP op_;$/;"	m	class:paddle::TensorApply
op_	math/TensorExpression.h	/^  const OP op_;$/;"	m	class:paddle::TensorBinaryOp
op_	math/TensorExpression.h	/^  const OP op_;$/;"	m	class:paddle::TensorConstant
op_	math/TensorExpression.h	/^  const OP op_;$/;"	m	class:paddle::TensorUnaryOp
op_COPY	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_COPY(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_RESET	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_RESET(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_SGD	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_SGD(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_apply	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_apply(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_au	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_au(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_au_bv	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_au_bv(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_au_bv_cw	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_au_bv_cw(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_cost	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_cost(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_dir_deriv	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_dir_deriv(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_finish_pass	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_finish_pass(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_fix_dir_signs	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_fix_dir_signs(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_fix_omega_signs	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_fix_omega_signs(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_make_steepest_desc_dir	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_make_steepest_desc_dir(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_randomize	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_randomize(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_start_pass	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_start_pass(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
op_utv	pserver/ParameterServer2.cpp	/^void ParameterServer2::op_utv(const Operation& operation,$/;"	f	class:paddle::ParameterServer2
openThreadInfo_	utils/Stat.h	/^  bool openThreadInfo_;$/;"	m	class:paddle::Stat
operationTest	pserver/test/test_ParameterServer2.cpp	/^void ParameterServer2Tester::operationTest() {$/;"	f	class:ParameterServer2Tester
operator !=	function/TensorShape.h	/^  bool operator!=(const TensorShape& t) const { return !(*this == t); }$/;"	f	class:paddle::TensorShape
operator !=	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::cmp_ne<T>, const Derived, T> operator!=($/;"	f	class:paddle::TensorExpression
operator !=	math/TensorExpression.h	/^  operator!=(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
operator !=	trainer/tests/picojson.h	/^inline bool operator!=(const value& x, const value& y) { return !(x == y); }$/;"	f	namespace:picojson
operator !=	utils/Util.h	/^  bool operator!=(const AlignedAllocator& other) const {$/;"	f	class:paddle::AlignedAllocator
operator &&	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::and_op<T>, const Derived, T> operator&&($/;"	f	class:paddle::TensorExpression
operator &&	math/TensorExpression.h	/^  operator&&(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
operator ()	api/GradientMachine.cpp	/^  void operator()(paddle::Parameter* param) {$/;"	f	class:UpdateCallbackWrapper
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return (a > 0) - (a < 0); }$/;"	f	class:hppl::unary::sign
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return -a; }$/;"	f	class:hppl::unary::neg
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return T(1) \/ a; }$/;"	f	class:hppl::unary::reciprocal
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return a * a; }$/;"	f	class:hppl::unary::square
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return a * p; }$/;"	f	class:hppl::unary::mul_scale
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return a + p; }$/;"	f	class:hppl::unary::add_scale
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return a - p; }$/;"	f	class:hppl::unary::sub_scale
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return a < p ? p : a; }$/;"	f	class:hppl::unary::max
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return a > 0 ? a : -a; }$/;"	f	class:hppl::unary::abs
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return a > p ? p : a; }$/;"	f	class:hppl::unary::min
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return a \/ p; }$/;"	f	class:hppl::unary::div_scale
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return std::exp(a); }$/;"	f	class:hppl::unary::exp_op
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return std::log(a); }$/;"	f	class:hppl::unary::log_op
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return std::pow(a, p); }$/;"	f	class:hppl::unary::pow_op
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a) const { return std::sqrt(a); }$/;"	f	class:hppl::unary::sqrt_op
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a, const T b) const { return a * b; }$/;"	f	class:hppl::binary::mul
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a, const T b) const { return a + b; }$/;"	f	class:hppl::binary::add
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a, const T b) const { return a - b; }$/;"	f	class:hppl::binary::sub
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a, const T b) const { return a < b ? b : a; }$/;"	f	class:hppl::binary::max
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a, const T b) const { return a > b ? b : a; }$/;"	f	class:hppl::binary::min
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a, const T b) const { return a \/ b; }$/;"	f	class:hppl::binary::div
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(const T a, const T b) const { return p1 * a + p2 * b; }$/;"	f	class:hppl::binary::add_scale
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(int i) const { return p; }$/;"	f	class:hppl::unary::constant
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE T operator()(int i, int j) const { return p; }$/;"	f	class:hppl::unary::constant
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a) const { return a != p; }$/;"	f	class:hppl::unary::cmp_ne
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a) const { return a && p; }$/;"	f	class:hppl::unary::and_op
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a) const { return a < p; }$/;"	f	class:hppl::unary::cmp_lt
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a) const { return a <= p; }$/;"	f	class:hppl::unary::cmp_le
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a) const { return a == p; }$/;"	f	class:hppl::unary::cmp_eq
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a) const { return a > p; }$/;"	f	class:hppl::unary::cmp_gt
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a) const { return a >= p; }$/;"	f	class:hppl::unary::cmp_ge
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a) const { return a || p; }$/;"	f	class:hppl::unary::or_op
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a, const T b) const { return a != b; }$/;"	f	class:hppl::binary::cmp_ne
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a, const T b) const { return a && b; }$/;"	f	class:hppl::binary::and_op
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a, const T b) const { return a < b; }$/;"	f	class:hppl::binary::cmp_lt
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a, const T b) const { return a <= b; }$/;"	f	class:hppl::binary::cmp_le
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a, const T b) const { return a == b; }$/;"	f	class:hppl::binary::cmp_eq
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a, const T b) const { return a > b; }$/;"	f	class:hppl::binary::cmp_gt
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a, const T b) const { return a >= b; }$/;"	f	class:hppl::binary::cmp_ge
operator ()	cuda/include/hl_tensor_ops.h	/^  INLINE bool operator()(const T a, const T b) const { return a || b; }$/;"	f	class:hppl::binary::or_op
operator ()	gserver/dataproviders/PyDataProvider2.cpp	/^    inline size_t operator()(size_t len) {$/;"	f	class:paddle::PyDataProvider2::PositionRandom
operator ()	math/ExecViaCpu.h	/^  R operator()(F&& f, Args... args) {$/;"	f	class:paddle::detail::GpuFuncWrapperBase
operator ()	math/MatrixBitCode.cpp	/^  SimpleCode operator()(size_t code) const {$/;"	f	struct:paddle::__anon17::SimpleCodeTable
operator ()	math/tests/TensorCheck.h	/^  inline bool operator()(real a, real b) {$/;"	f	class:autotest::AssertEqual
operator ()	math/tests/test_ExecViaCpu.cpp	/^  real operator()(Matrix& mat1,$/;"	f	class:Functor
operator ()	parameter/ParameterUpdaterHook.cpp	/^  size_t operator()(const std::pair<std::string, int>& k) const {$/;"	f	class:paddle::StringIntPairHasher
operator ()	pserver/ParameterClient2.h	/^    void operator()(Args... args) {$/;"	f	class:paddle::PreparedOperations::ResultsAdder
operator ()	pserver/ParameterServer2.h	/^    size_t operator()(const BlockKey& key) const {$/;"	f	struct:paddle::ParameterServer2::BlockKeyHash
operator ()	utils/PythonUtil.h	/^  PyObject* operator()() {$/;"	f	class:paddle::py::CallableHelper
operator ()	utils/PythonUtil.h	/^  void operator()(PyObject* obj) {$/;"	f	struct:paddle::PyObjectDeleter
operator *	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::mul_scale<T>, const Derived, T> operator*($/;"	f	class:paddle::TensorExpression
operator *	math/TensorExpression.h	/^  operator*(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
operator *	math/TensorExpression.h	/^const TensorUnaryOp<hppl::unary::mul_scale<T>, const Derived, T> operator*($/;"	f	namespace:paddle
operator *	utils/ThreadLocal.h	/^  T& operator*() { return *get(); }$/;"	f	class:paddle::ThreadLocal
operator *	utils/ThreadLocal.h	/^  T& operator*() { return *get(); }$/;"	f	class:paddle::ThreadLocalD
operator *=	math/BaseMatrix.h	/^  void operator*=(const ExpressionType& expr) {$/;"	f	class:paddle::BaseMatrixT
operator +	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::add_scale<T>, const Derived, T> operator+($/;"	f	class:paddle::TensorExpression
operator +	math/TensorExpression.h	/^  operator+(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
operator +	math/TensorExpression.h	/^const TensorUnaryOp<hppl::unary::add_scale<T>, const Derived, T> operator+($/;"	f	namespace:paddle
operator ++	gserver/layers/MDLstmLayer.cpp	/^  CoordIterator& operator++() {$/;"	f	class:paddle::CoordIterator
operator +=	math/BaseMatrix.h	/^  void operator+=(const ExpressionType& expr) {$/;"	f	class:paddle::BaseMatrixT
operator +=	trainer/TrainerInternalConfig.h	/^  inline TrainerStats& operator+=(const std::pair<int64_t, real>& p) {$/;"	f	class:paddle::TrainerStats
operator -	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::neg<T>, const Derived, T> operator-() const {$/;"	f	class:paddle::TensorExpression
operator -	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::sub_scale<T>, const Derived, T> operator-($/;"	f	class:paddle::TensorExpression
operator -	math/TensorExpression.h	/^  operator-(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
operator --	gserver/layers/MDLstmLayer.cpp	/^  CoordIterator& operator--() {$/;"	f	class:paddle::CoordIterator
operator -=	math/BaseMatrix.h	/^  void operator-=(const ExpressionType& expr) {$/;"	f	class:paddle::BaseMatrixT
operator /	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::div_scale<T>, const Derived, T> operator\/($/;"	f	class:paddle::TensorExpression
operator /	math/TensorExpression.h	/^  operator\/(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
operator /=	math/BaseMatrix.h	/^  void operator\/=(const ExpressionType& expr) {$/;"	f	class:paddle::BaseMatrixT
operator <	api/SequenceGenerator.cpp	/^  bool operator<(const Path& other) const { return (logProb > other.logProb); }$/;"	f	struct:Path
operator <	gserver/gradientmachines/RecurrentGradientMachine.h	/^    bool operator<(const Path& other) const {$/;"	f	struct:paddle::RecurrentGradientMachine::Path
operator <	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::cmp_lt<T>, const Derived, T> operator<($/;"	f	class:paddle::TensorExpression
operator <	math/TensorExpression.h	/^  operator<(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
operator <<	gserver/dataproviders/PyDataProvider2.cpp	/^inline std::ostream& operator<<(std::ostream& os, const SlotHeader& header) {$/;"	f	namespace:paddle
operator <<	gserver/evaluators/Evaluator.h	/^  friend std::ostream& operator<<(std::ostream& os,$/;"	f	class:paddle::Evaluator
operator <<	gserver/evaluators/Evaluator.h	/^  friend std::ostream&& operator<<(std::ostream&& os,  \/\/ NOLINT$/;"	f	class:paddle::Evaluator
operator <<	math/Matrix.h	/^inline std::ostream& operator<<(std::ostream& os, const Matrix& mat) {$/;"	f	namespace:paddle
operator <<	math/Vector.h	/^std::ostream& operator<<(std::ostream& os, const VectorT<T>& vec) {$/;"	f	namespace:paddle
operator <<	trainer/TrainerInternalConfig.h	/^inline std::ostream& operator<<(std::ostream& os, const TrainerStats& stats) {$/;"	f	namespace:paddle
operator <<	trainer/tests/picojson.h	/^inline std::ostream& operator<<(std::ostream& os, const picojson::value& x) {$/;"	f
operator <<	utils/BarrierStat.cpp	/^std::ostream &operator<<(std::ostream &output, const BarrierStatBase &stat) {$/;"	f	namespace:paddle
operator <<	utils/Stat.cpp	/^std::ostream& operator<<(std::ostream& outPut, const Stat& stat) {$/;"	f	namespace:paddle
operator <=	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::cmp_le<T>, const Derived, T> operator<=($/;"	f	class:paddle::TensorExpression
operator <=	math/TensorExpression.h	/^  operator<=(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
operator =	math/BaseMatrix.h	/^  void operator=(const ExpressionType& expr) {$/;"	f	class:paddle::BaseMatrixT
operator =	math/Matrix.h	/^  void operator=(const ExpressionType& expr) {$/;"	f	class:paddle::CpuMatrix
operator =	math/Matrix.h	/^  void operator=(const ExpressionType& expr) {$/;"	f	class:paddle::GpuMatrix
operator =	math/Matrix.h	/^  void operator=(const ExpressionType& expr) {$/;"	f	class:paddle::Matrix
operator =	math/Vector.h	/^  void operator=(const ExpressionType& expr) {$/;"	f	class:paddle::CpuVectorT
operator =	math/Vector.h	/^  void operator=(const ExpressionType& expr) {$/;"	f	class:paddle::GpuVectorT
operator =	math/Vector.h	/^  void operator=(const ExpressionType& expr) {$/;"	f	class:paddle::VectorT
operator =	parameter/Argument.h	/^  void operator=(const Argument& argument) {$/;"	f	struct:paddle::Argument
operator =	trainer/tests/picojson.h	/^inline value& value::operator=(const value& x) {$/;"	f	class:picojson::value
operator ==	function/TensorShape.h	/^  bool operator==(const TensorShape& t) const {$/;"	f	class:paddle::TensorShape
operator ==	gserver/evaluators/ChunkEvaluator.cpp	/^    bool operator==(const Segment& y) const {$/;"	f	struct:paddle::ChunkEvaluator::Segment
operator ==	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::cmp_eq<T>, const Derived, T> operator==($/;"	f	class:paddle::TensorExpression
operator ==	math/TensorExpression.h	/^  operator==(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
operator ==	trainer/tests/picojson.h	/^inline bool operator==(const value& x, const value& y) {$/;"	f	namespace:picojson
operator ==	utils/Util.h	/^  bool operator==(const AlignedAllocator& other) const { return true; }$/;"	f	class:paddle::AlignedAllocator
operator >	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::cmp_gt<T>, const Derived, T> operator>($/;"	f	class:paddle::TensorExpression
operator >	math/TensorExpression.h	/^  operator>(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
operator >=	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::cmp_ge<T>, const Derived, T> operator>=($/;"	f	class:paddle::TensorExpression
operator >=	math/TensorExpression.h	/^  operator>=(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
operator >>	trainer/tests/picojson.h	/^inline std::istream& operator>>(std::istream& is, picojson::value& x) {$/;"	f
operator T*	utils/ThreadLocal.h	/^  operator T*() { return get(); }$/;"	f	class:paddle::ThreadLocal
operator []	api/Vector.cpp	/^const int& IVector::operator[](const size_t idx) const$/;"	f	class:IVector
operator []	api/Vector.cpp	/^int& IVector::operator[](const size_t idx) throw(RangeError, UnsupportError) {$/;"	f	class:IVector
operator []	function/Function.h	/^  const BufferArg& operator[](size_t num) const {$/;"	f	class:paddle::BufferArgs
operator []	function/TensorShape.h	/^  size_t operator[](size_t dim) const {$/;"	f	class:paddle::TensorShape
operator []	utils/PythonUtil.h	/^  inline PyObject* operator[](size_t i) const {$/;"	f	class:paddle::py::SequenceHelper
operator bool	math/Matrix.h	/^  explicit operator bool() const { return !isEmpty(); }$/;"	f	class:paddle::Matrix
operator bool	utils/Error.h	/^  operator bool() const { return msg_ == nullptr; }$/;"	f	class:paddle::Error
operator const DataConfig&	trainer/TrainerConfigHelper.h	/^  inline operator const DataConfig&() const { return this->getDataConfig(); }$/;"	f	class:paddle::TrainerConfigHelper
operator const ModelConfig&	trainer/TrainerConfigHelper.h	/^  inline operator const ModelConfig&() const { return this->getModelConfig(); }$/;"	f	class:paddle::TrainerConfigHelper
operator const OptimizationConfig&	trainer/TrainerConfigHelper.h	/^  inline operator const OptimizationConfig&() const {$/;"	f	class:paddle::TrainerConfigHelper
operator const TrainerConfig&	trainer/TrainerConfigHelper.h	/^  inline operator const TrainerConfig&() const { return this->getConfig(); }$/;"	f	class:paddle::TrainerConfigHelper
operator ||	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::or_op<T>, const Derived, T> operator||($/;"	f	class:paddle::TensorExpression
operator ||	math/TensorExpression.h	/^  operator||(const ExpressionType& expr) const {$/;"	f	class:paddle::TensorExpression
operators_	gserver/layers/MixedLayer.h	/^  std::vector<std::unique_ptr<Operator>> operators_;$/;"	m	class:paddle::MixedLayer
ops	function/Function.h	/^  virtual size_t ops(const BufferArgs& inputs, const BufferArgs& outputs) {$/;"	f	class:paddle::FunctionBase
opt	api/test/testTrainConfig.py	/^opt = fc_layer(input=fc2, size=10, act=SoftmaxActivation())$/;"	v
optConfig_	parameter/ParameterOptimizer.h	/^  const OptimizationConfig& optConfig_;$/;"	m	class:paddle::ParameterOptimizer
optimizer	api/ParameterOptimizer.cpp	/^  std::unique_ptr<paddle::ParameterOptimizer> optimizer;$/;"	m	struct:ParameterOptimizerPrivate	file:
optimizer	pserver/ParameterServer2.h	/^    std::unique_ptr<ParameterOptimizer> optimizer;$/;"	m	struct:paddle::ParameterServer2::BlockInfo
optimizer_	parameter/AverageOptimizer.h	/^  std::unique_ptr<ParameterOptimizer> optimizer_;$/;"	m	class:paddle::AverageOptimizer
optimizer_	parameter/FirstOrderOptimizer.h	/^  std::unique_ptr<ParameterOptimizer> optimizer_;$/;"	m	class:paddle::OptimizerWithGradientClipping
optimizer_	parameter/OptimizerWithRegularizer.h	/^  std::unique_ptr<ParameterOptimizer> optimizer_;$/;"	m	class:paddle::OptimizerWithRegularizer
optimizer_	trainer/ParameterUpdater.h	/^  std::unique_ptr<ParameterOptimizer> optimizer_;$/;"	m	class:paddle::SgdLocalUpdater
optimizers_	trainer/ThreadParameterUpdater.h	/^  std::vector<std::unique_ptr<ParameterOptimizer>> optimizers_;$/;"	m	class:paddle::SgdThreadUpdater
or_op	cuda/include/hl_tensor_ops.h	/^  INLINE or_op(const T s) : p(s) {}$/;"	f	class:hppl::unary::or_op
or_op	cuda/include/hl_tensor_ops.h	/^class or_op {$/;"	c	namespace:hppl::binary
or_op	cuda/include/hl_tensor_ops.h	/^class or_op {$/;"	c	namespace:hppl::unary
os_	gserver/evaluators/Evaluator.cpp	/^  std::ofstream os_;$/;"	m	class:paddle::SequenceTextPrinter	file:
os_	trainer/Tester.h	/^  std::ofstream os_;$/;"	m	class:paddle::Tester
ostreamOutput_	gserver/dataproviders/ProtoReader.h	/^  std::unique_ptr<google::protobuf::io::ZeroCopyOutputStream> ostreamOutput_;$/;"	m	class:paddle::ProtoWriter
other	gserver/gradientmachines/RecurrentGradientMachine.h	/^  RecurrentGradientMachine& operator=(const RecurrentGradientMachine& other) =$/;"	m	class:paddle::RecurrentGradientMachine
other	gserver/gradientmachines/RecurrentGradientMachine.h	/^  RecurrentGradientMachine(const RecurrentGradientMachine& other) = delete;$/;"	m	class:paddle::RecurrentGradientMachine
other	utils/Locks.h	/^  Semaphore& operator=(const Semaphore&& other) = delete;$/;"	m	class:paddle::Semaphore
other	utils/Locks.h	/^  Semaphore(const Semaphore& other) = delete;$/;"	m	class:paddle::Semaphore
other	utils/PythonUtil.h	/^  PyGuard& operator=(const PyGuard& other) = delete;$/;"	m	class:paddle::PyGuard
other	utils/PythonUtil.h	/^  PyGuard(const PyGuard& other) = delete;$/;"	m	class:paddle::PyGuard
other	utils/Util.h	/^    typedef AlignedAllocator<U, Alignment> other;$/;"	t	struct:paddle::AlignedAllocator::rebind
other	utils/Util.h	/^  SameThreadChecker& operator=(const SameThreadChecker& other) = delete;$/;"	m	class:paddle::SameThreadChecker
other	utils/Util.h	/^  SameThreadChecker(const SameThreadChecker& other) = delete;$/;"	m	class:paddle::SameThreadChecker
other	utils/Util.h	/^  ScopedCallbacks& operator=(const ScopedCallbacks& other) = delete;$/;"	m	class:paddle::ScopedCallbacks
other	utils/Util.h	/^  ScopedCallbacks(const ScopedCallbacks& other) = delete;$/;"	m	class:paddle::ScopedCallbacks
otherChunkType_	gserver/evaluators/ChunkEvaluator.cpp	/^  int otherChunkType_;$/;"	m	class:paddle::ChunkEvaluator	file:
otherId	gserver/layers/MultinomialSampler.h	/^    int otherId;$/;"	m	struct:paddle::MultinomialSampler::Interval
out	gserver/evaluators/Evaluator.h	/^    real out;$/;"	m	struct:paddle::PnpairEvaluator::PredictionResult
out	gserver/layers/ValidationLayer.h	/^    real out;$/;"	m	struct:paddle::AucValidation::PredictionResult
outActivations_	gserver/evaluators/CTCErrorEvaluator.cpp	/^  MatrixPtr outActivations_;$/;"	m	class:paddle::CTCErrorEvaluator	file:
outArg	gserver/gradientmachines/RecurrentGradientMachine.h	/^    Argument outArg;                      \/\/ scatter output argument$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
outArg	gserver/gradientmachines/RecurrentGradientMachine.h	/^    Argument outArg;       \/\/ final output argument$/;"	m	struct:paddle::RecurrentGradientMachine::Generator
outArg	gserver/gradientmachines/RecurrentGradientMachine.h	/^    Argument outArg;  \/\/ scatter output argument$/;"	m	struct:paddle::RecurrentGradientMachine::InFrameLine
outArgStream_	gserver/gradientmachines/MultiGradientMachine.h	/^  hl_stream_t outArgStream_;$/;"	m	class:paddle::MultiGradientMachine
outArgs	gserver/tests/test_SelectiveFCLayer.cpp	/^  vector<Argument> outArgs;$/;"	m	struct:ComData	file:
outArgs	trainer/tests/test_Compare.cpp	/^  vector<Argument> outArgs;$/;"	m	struct:comData	file:
outArgs	trainer/tests/test_CompareTwoNets.cpp	/^  vector<Argument> outArgs;$/;"	m	struct:ComData	file:
outArgs	trainer/tests/test_CompareTwoOpts.cpp	/^  vector<Argument> outArgs;$/;"	m	struct:ComData	file:
outArgsReadySem_	gserver/gradientmachines/MultiGradientMachine.h	/^  Semaphore outArgsReadySem_;$/;"	m	class:paddle::TrainerThread
outArgs_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<Argument> outArgs_;$/;"	m	class:paddle::MultiGradientMachine
outArgs_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<Argument> outArgs_;$/;"	m	class:paddle::TrainerThread
outDims_	gserver/layers/PadLayer.h	/^  TensorShape outDims_;$/;"	m	class:paddle::PadLayer
outFrameLines_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<OutFrameLine> outFrameLines_;$/;"	m	class:paddle::RecurrentGradientMachine
outGrads	gserver/tests/test_NetworkCompare.cpp	/^  std::vector<MatrixPtr> outGrads;$/;"	m	struct:DataIn	file:
outImgH_	gserver/layers/BilinearInterpLayer.h	/^  size_t outImgH_, outImgW_;$/;"	m	class:paddle::BilinearInterpLayer
outImgW_	gserver/layers/BilinearInterpLayer.h	/^  size_t outImgH_, outImgW_;$/;"	m	class:paddle::BilinearInterpLayer
outMtx_	gserver/layers/AverageLayer.h	/^  MatrixPtr outMtx_;$/;"	m	class:paddle::AverageLayer
outVTrans_	gserver/layers/BlockExpandLayer.h	/^  MatrixPtr outVTrans_;$/;"	m	class:paddle::BlockExpandLayer
outValues	gserver/tests/test_NetworkCompare.cpp	/^  std::vector<MatrixPtr> outValues;$/;"	m	struct:DataOut	file:
out_	gserver/layers/Operator.h	/^  Argument* out_;$/;"	m	class:paddle::Operator
out_	gserver/layers/Projection.h	/^  const Argument* out_;$/;"	m	class:paddle::Projection
out_	trainer/tests/picojson.h	/^  value* out_;$/;"	m	class:picojson::default_parse_context
outer_step	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^def outer_step(x1, x2):$/;"	f
outputChannels_	gserver/layers/MaxOutLayer.h	/^  size_t channels_, outputChannels_;$/;"	m	class:paddle::MaxOutLayer
outputDesc_	gserver/layers/ConvOperator.cpp	/^  hl_tensor_descriptor outputDesc_;$/;"	m	class:paddle::ConvOperator	file:
outputDesc_	gserver/layers/ConvProjection.h	/^  hl_tensor_descriptor outputDesc_;$/;"	m	class:paddle::ConvProjection
outputDesc_	gserver/layers/CudnnConvLayer.h	/^  hl_tensor_descriptor outputDesc_;$/;"	m	class:paddle::CudnnConvLayer
outputDesc_	gserver/layers/CudnnPoolLayer.h	/^  hl_tensor_descriptor outputDesc_;$/;"	m	class:paddle::CudnnPoolLayer
outputGrad	cuda/include/hl_base.h	/^  real *outputGrad;$/;"	m	struct:__anon5
outputGrad	cuda/include/hl_base.h	/^  real *outputGrad;$/;"	m	struct:__anon7
outputH_	gserver/layers/BlockExpandLayer.h	/^  size_t imgSizeH_, imgSizeW_, outputH_, outputW_, channels_;$/;"	m	class:paddle::BlockExpandLayer
outputH_	gserver/layers/ConvBaseLayer.h	/^  IntV outputH_;$/;"	m	class:paddle::ConvBaseLayer
outputH_	gserver/layers/ConvOperator.cpp	/^  int imageH_, imageW_, outputH_, outputW_;$/;"	m	class:paddle::ConvOperator	file:
outputH_	gserver/layers/ConvProjection.h	/^  int outputH_, outputW_;$/;"	m	class:paddle::ConvProjection
outputH_	gserver/layers/CudnnPoolLayer.h	/^  int imageH_, imageW_, outputH_, outputW_;$/;"	m	class:paddle::CudnnPoolLayer
outputH_	gserver/layers/NormProjectionLayer.h	/^  size_t outputH_, outputW_;$/;"	m	class:paddle::CMRProjectionNormLayer
outputH_	gserver/layers/PoolProjectionLayer.h	/^  size_t outputH_, outputW_;$/;"	m	class:paddle::PoolProjectionLayer
outputLayers_	gserver/gradientmachines/NeuralNetwork.h	/^  std::vector<LayerPtr> outputLayers_;$/;"	m	class:paddle::NeuralNetwork
outputMap_	gserver/layers/Layer.h	/^  std::map<std::string, Argument*> outputMap_;$/;"	m	class:paddle::Layer
outputOffset_	gserver/layers/ConvOperator.cpp	/^  int inputOffset_, outputOffset_, weightOffset_;$/;"	m	class:paddle::ConvOperator	file:
outputOffset_	gserver/layers/ConvProjection.h	/^  int outputOffset_;$/;"	m	class:paddle::ConvProjection
outputOffset_	gserver/layers/CudnnConvLayer.h	/^  int outputOffset_;$/;"	m	class:paddle::CudnnConvLayer
outputOtherDevice_	gserver/layers/Layer.h	/^  std::vector<Argument> outputOtherDevice_;$/;"	m	class:paddle::Layer
outputPair_	gserver/evaluators/Evaluator.h	/^  std::vector<std::pair<real, int>> outputPair_;$/;"	m	class:paddle::RankAucEvaluator
outputScorePair_	gserver/layers/CostLayer.h	/^  std::vector<std::pair<real, int>> outputScorePair_;$/;"	m	class:paddle::LambdaCost
outputSegments_	gserver/evaluators/ChunkEvaluator.cpp	/^  std::vector<Segment> outputSegments_;$/;"	m	class:paddle::ChunkEvaluator	file:
outputSize	math/MathUtils.cpp	/^int outputSize($/;"	f	namespace:paddle
outputValue	cuda/include/hl_base.h	/^  real *outputValue;$/;"	m	struct:__anon4
outputValue	cuda/include/hl_base.h	/^  real *outputValue;$/;"	m	struct:__anon6
outputW_	gserver/layers/BlockExpandLayer.h	/^  size_t imgSizeH_, imgSizeW_, outputH_, outputW_, channels_;$/;"	m	class:paddle::BlockExpandLayer
outputW_	gserver/layers/ConvBaseLayer.h	/^  IntV outputW_;$/;"	m	class:paddle::ConvBaseLayer
outputW_	gserver/layers/ConvOperator.cpp	/^  int imageH_, imageW_, outputH_, outputW_;$/;"	m	class:paddle::ConvOperator	file:
outputW_	gserver/layers/ConvProjection.h	/^  int outputH_, outputW_;$/;"	m	class:paddle::ConvProjection
outputW_	gserver/layers/CudnnPoolLayer.h	/^  int imageH_, imageW_, outputH_, outputW_;$/;"	m	class:paddle::CudnnPoolLayer
outputW_	gserver/layers/NormProjectionLayer.h	/^  size_t outputH_, outputW_;$/;"	m	class:paddle::CMRProjectionNormLayer
outputW_	gserver/layers/PoolProjectionLayer.h	/^  size_t outputH_, outputW_;$/;"	m	class:paddle::PoolProjectionLayer
outputX_	gserver/layers/ConvOperator.cpp	/^  int imgPixels_, filterPixels_, filterChannels_, outputX_, outputY_, outputs_;$/;"	m	class:paddle::ConvOperator	file:
outputX_	gserver/layers/NormLayer.h	/^  size_t channels_, size_, outputX_, imgSize_, outputY_, imgSizeY_;$/;"	m	class:paddle::ResponseNormLayer
outputX_	gserver/layers/PoolLayer.h	/^  size_t channels_, sizeX_, stride_, outputX_, imgSize_;$/;"	m	class:paddle::PoolLayer
outputX_	gserver/layers/PoolProjection.h	/^  size_t outputY_, outputX_;$/;"	m	class:paddle::PoolProjection
outputY_	gserver/layers/ConvOperator.cpp	/^  int imgPixels_, filterPixels_, filterChannels_, outputX_, outputY_, outputs_;$/;"	m	class:paddle::ConvOperator	file:
outputY_	gserver/layers/NormLayer.h	/^  size_t channels_, size_, outputX_, imgSize_, outputY_, imgSizeY_;$/;"	m	class:paddle::ResponseNormLayer
outputY_	gserver/layers/PoolLayer.h	/^  size_t outputY_;$/;"	m	class:paddle::PoolLayer
outputY_	gserver/layers/PoolProjection.h	/^  size_t outputY_, outputX_;$/;"	m	class:paddle::PoolProjection
output_	gserver/evaluators/Evaluator.h	/^  MatrixPtr output_;$/;"	m	class:paddle::RankAucEvaluator
output_	gserver/layers/Layer.h	/^  Argument output_;$/;"	m	class:paddle::Layer
outputs	api/PaddleAPIPrivate.h	/^  std::vector<paddle::Argument> outputs;$/;"	m	struct:ArgumentsPrivate
outputs_	gserver/layers/ConvOperator.cpp	/^  int imgPixels_, filterPixels_, filterChannels_, outputX_, outputY_, outputs_;$/;"	m	class:paddle::ConvOperator	file:
override	gserver/layers/AddtoLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::AddtoLayer
override	gserver/layers/AddtoLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::AddtoLayer
override	gserver/layers/AddtoLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::AddtoLayer
override	gserver/layers/AgentLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::AgentLayer
override	gserver/layers/AgentLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::GatherAgentLayer
override	gserver/layers/AgentLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ScatterAgentLayer
override	gserver/layers/AgentLayer.h	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::GatherAgentLayer
override	gserver/layers/AgentLayer.h	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::ScatterAgentLayer
override	gserver/layers/AgentLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::AgentLayer
override	gserver/layers/AgentLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::GatherAgentLayer
override	gserver/layers/AgentLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::ScatterAgentLayer
override	gserver/layers/AgentLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::SequenceAgentLayer
override	gserver/layers/AverageLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::AverageLayer
override	gserver/layers/AverageLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::AverageLayer
override	gserver/layers/AverageLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::AverageLayer
override	gserver/layers/BatchNormBaseLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::BatchNormBaseLayer
override	gserver/layers/BatchNormalizationLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::BatchNormalizationLayer
override	gserver/layers/BatchNormalizationLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::BatchNormalizationLayer
override	gserver/layers/BatchNormalizationLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::BatchNormalizationLayer
override	gserver/layers/BilinearInterpLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::BilinearInterpLayer
override	gserver/layers/BilinearInterpLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::BilinearInterpLayer
override	gserver/layers/BilinearInterpLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::BilinearInterpLayer
override	gserver/layers/BlockExpandLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::BlockExpandLayer
override	gserver/layers/BlockExpandLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::BlockExpandLayer
override	gserver/layers/BlockExpandLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::BlockExpandLayer
override	gserver/layers/CRFDecodingLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::CRFDecodingLayer
override	gserver/layers/CRFDecodingLayer.h	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::CRFDecodingLayer
override	gserver/layers/CRFDecodingLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::CRFDecodingLayer
override	gserver/layers/CRFLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::CRFLayer
override	gserver/layers/CRFLayer.h	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::CRFLayer
override	gserver/layers/CRFLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::CRFLayer
override	gserver/layers/CTCLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::CTCLayer
override	gserver/layers/CTCLayer.h	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::CTCLayer
override	gserver/layers/CTCLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::CTCLayer
override	gserver/layers/ConcatenateLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ConcatenateLayer	file:
override	gserver/layers/ConcatenateLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ConcatenateLayer2	file:
override	gserver/layers/ConcatenateLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::ConcatenateLayer	file:
override	gserver/layers/ConcatenateLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::ConcatenateLayer2	file:
override	gserver/layers/ConcatenateLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::ConcatenateLayer	file:
override	gserver/layers/ConcatenateLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::ConcatenateLayer2	file:
override	gserver/layers/ConvBaseLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ConvBaseLayer
override	gserver/layers/ConvShiftLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ConvShiftLayer	file:
override	gserver/layers/ConvShiftLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::ConvShiftLayer	file:
override	gserver/layers/ConvShiftLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::ConvShiftLayer	file:
override	gserver/layers/ConvexCombinationLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ConvexCombinationLayer	file:
override	gserver/layers/ConvexCombinationLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::ConvexCombinationLayer	file:
override	gserver/layers/ConvexCombinationLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::ConvexCombinationLayer	file:
override	gserver/layers/CosSimLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::CosSimLayer
override	gserver/layers/CosSimLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::CosSimLayer
override	gserver/layers/CosSimLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::CosSimLayer
override	gserver/layers/CosSimVecMatLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::CosSimVecMatLayer	file:
override	gserver/layers/CosSimVecMatLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::CosSimVecMatLayer	file:
override	gserver/layers/CosSimVecMatLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::CosSimVecMatLayer	file:
override	gserver/layers/CostLayer.h	/^                   Matrix& outputGrad) override;$/;"	m	class:paddle::HuberTwoClass
override	gserver/layers/CostLayer.h	/^                   Matrix& outputGrad) override;$/;"	m	class:paddle::MultiBinaryLabelCrossEntropy
override	gserver/layers/CostLayer.h	/^                   Matrix& outputGrad) override;$/;"	m	class:paddle::MultiClassCrossEntropy
override	gserver/layers/CostLayer.h	/^                   Matrix& outputGrad) override;$/;"	m	class:paddle::MultiClassCrossEntropyWithSelfNorm
override	gserver/layers/CostLayer.h	/^                   Matrix& outputGrad) override;$/;"	m	class:paddle::SoftBinaryClassCrossEntropy
override	gserver/layers/CostLayer.h	/^                   Matrix& outputGrad) override;$/;"	m	class:paddle::SumOfSquaresCostLayer
override	gserver/layers/CostLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::CostLayer
override	gserver/layers/CostLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::HuberTwoClass
override	gserver/layers/CostLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::LambdaCost
override	gserver/layers/CostLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::MultiBinaryLabelCrossEntropy
override	gserver/layers/CostLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::MultiClassCrossEntropy
override	gserver/layers/CostLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::MultiClassCrossEntropyWithSelfNorm
override	gserver/layers/CostLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::RankingCost
override	gserver/layers/CostLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::SoftBinaryClassCrossEntropy
override	gserver/layers/CostLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::SumOfSquaresCostLayer
override	gserver/layers/CostLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::CostLayer
override	gserver/layers/CostLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::LambdaCost
override	gserver/layers/CostLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::RankingCost
override	gserver/layers/CostLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::CostLayer
override	gserver/layers/CostLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::LambdaCost
override	gserver/layers/CostLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::RankingCost
override	gserver/layers/CostLayer.h	/^  void forwardImp(Matrix& output, Argument& label, Matrix& cost) override;$/;"	m	class:paddle::HuberTwoClass
override	gserver/layers/CostLayer.h	/^  void forwardImp(Matrix& output, Argument& label, Matrix& cost) override;$/;"	m	class:paddle::MultiBinaryLabelCrossEntropy
override	gserver/layers/CostLayer.h	/^  void forwardImp(Matrix& output, Argument& label, Matrix& cost) override;$/;"	m	class:paddle::MultiClassCrossEntropy
override	gserver/layers/CostLayer.h	/^  void forwardImp(Matrix& output, Argument& label, Matrix& cost) override;$/;"	m	class:paddle::MultiClassCrossEntropyWithSelfNorm
override	gserver/layers/CostLayer.h	/^  void forwardImp(Matrix& output, Argument& label, Matrix& cost) override;$/;"	m	class:paddle::SoftBinaryClassCrossEntropy
override	gserver/layers/CostLayer.h	/^  void forwardImp(Matrix& output, Argument& label, Matrix& cost) override;$/;"	m	class:paddle::SumOfSquaresCostLayer
override	gserver/layers/CostLayer.h	/^  void onPassEnd() override;$/;"	m	class:paddle::RankingCost
override	gserver/layers/CudnnBatchNormLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::CudnnBatchNormLayer
override	gserver/layers/CudnnBatchNormLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::CudnnBatchNormLayer
override	gserver/layers/CudnnBatchNormLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::CudnnBatchNormLayer
override	gserver/layers/CudnnConvLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::CudnnConvLayer
override	gserver/layers/CudnnConvLayer.h	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::CudnnConvLayer
override	gserver/layers/CudnnConvLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::CudnnConvLayer
override	gserver/layers/CudnnPoolLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::CudnnPoolLayer
override	gserver/layers/CudnnPoolLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::CudnnPoolLayer
override	gserver/layers/CudnnPoolLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::CudnnPoolLayer
override	gserver/layers/DataNormLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::DataNormLayer
override	gserver/layers/DataNormLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::DataNormLayer
override	gserver/layers/DataNormLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::DataNormLayer
override	gserver/layers/ExpandConvBaseLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ExpandConvBaseLayer
override	gserver/layers/ExpandConvLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ExpandConvLayer
override	gserver/layers/ExpandConvLayer.h	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::ExpandConvLayer
override	gserver/layers/ExpandConvLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::ExpandConvLayer
override	gserver/layers/ExpandConvTransLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ExpandConvTransLayer
override	gserver/layers/ExpandConvTransLayer.h	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::ExpandConvTransLayer
override	gserver/layers/ExpandConvTransLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::ExpandConvTransLayer
override	gserver/layers/ExpandLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ExpandLayer
override	gserver/layers/ExpandLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::ExpandLayer
override	gserver/layers/ExpandLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::ExpandLayer
override	gserver/layers/FeatureMapExpandLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::FeatureMapExpandLayer	file:
override	gserver/layers/FeatureMapExpandLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::FeatureMapExpandLayer	file:
override	gserver/layers/FeatureMapExpandLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::FeatureMapExpandLayer	file:
override	gserver/layers/FullyConnectedLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::FullyConnectedLayer
override	gserver/layers/FullyConnectedLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::FullyConnectedLayer
override	gserver/layers/FullyConnectedLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::FullyConnectedLayer
override	gserver/layers/FullyConnectedLayer.h	/^  void prefetch() override;$/;"	m	class:paddle::FullyConnectedLayer
override	gserver/layers/GatedRecurrentLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::GatedRecurrentLayer
override	gserver/layers/GatedRecurrentLayer.h	/^  LayerStatePtr getState() override;$/;"	m	class:paddle::GatedRecurrentLayer
override	gserver/layers/GatedRecurrentLayer.h	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::GatedRecurrentLayer
override	gserver/layers/GatedRecurrentLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::GatedRecurrentLayer
override	gserver/layers/GatedRecurrentLayer.h	/^  void resetState() override;$/;"	m	class:paddle::GatedRecurrentLayer
override	gserver/layers/GatedRecurrentLayer.h	/^  void setState(LayerStatePtr state) override;$/;"	m	class:paddle::GatedRecurrentLayer
override	gserver/layers/GruStepLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::GruStepLayer	file:
override	gserver/layers/GruStepLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::GruStepLayer	file:
override	gserver/layers/GruStepLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::GruStepLayer	file:
override	gserver/layers/HierarchicalSigmoidLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::HierarchicalSigmoidLayer
override	gserver/layers/HierarchicalSigmoidLayer.h	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::HierarchicalSigmoidLayer
override	gserver/layers/HierarchicalSigmoidLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::HierarchicalSigmoidLayer
override	gserver/layers/InterpolationLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::InterpolationLayer	file:
override	gserver/layers/InterpolationLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::InterpolationLayer	file:
override	gserver/layers/InterpolationLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::InterpolationLayer	file:
override	gserver/layers/LstmLayer.h	/^            const ParameterMap &parameterMap) override;$/;"	m	class:paddle::LstmLayer
override	gserver/layers/LstmLayer.h	/^  LayerStatePtr getState() override;$/;"	m	class:paddle::LstmLayer
override	gserver/layers/LstmLayer.h	/^  void backward(const UpdateCallback &callback) override;$/;"	m	class:paddle::LstmLayer
override	gserver/layers/LstmLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::LstmLayer
override	gserver/layers/LstmLayer.h	/^  void resetState() override;$/;"	m	class:paddle::LstmLayer
override	gserver/layers/LstmLayer.h	/^  void setState(LayerStatePtr state) override;$/;"	m	class:paddle::LstmLayer
override	gserver/layers/LstmStepLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::LstmStepLayer	file:
override	gserver/layers/LstmStepLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::LstmStepLayer	file:
override	gserver/layers/LstmStepLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::LstmStepLayer	file:
override	gserver/layers/MDLstmLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::MDLstmLayer	file:
override	gserver/layers/MDLstmLayer.cpp	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::MDLstmLayer	file:
override	gserver/layers/MDLstmLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::MDLstmLayer	file:
override	gserver/layers/MaxLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::MaxLayer
override	gserver/layers/MaxLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::MaxLayer
override	gserver/layers/MaxOutLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::MaxOutLayer
override	gserver/layers/MaxOutLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::MaxOutLayer
override	gserver/layers/MaxOutLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::MaxOutLayer
override	gserver/layers/MixedLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::MixedLayer
override	gserver/layers/MixedLayer.h	/^  LayerStatePtr getState() override;$/;"	m	class:paddle::MixedLayer
override	gserver/layers/MixedLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::MixedLayer
override	gserver/layers/MixedLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::MixedLayer
override	gserver/layers/MixedLayer.h	/^  void prefetch() override;$/;"	m	class:paddle::MixedLayer
override	gserver/layers/MixedLayer.h	/^  void resetState() override;$/;"	m	class:paddle::MixedLayer
override	gserver/layers/MixedLayer.h	/^  void setState(LayerStatePtr state) override;$/;"	m	class:paddle::MixedLayer
override	gserver/layers/MultiplexLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::MultiplexLayer	file:
override	gserver/layers/MultiplexLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::MultiplexLayer	file:
override	gserver/layers/MultiplexLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::MultiplexLayer	file:
override	gserver/layers/NormLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ResponseNormLayer
override	gserver/layers/NormProjectionLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::CMRProjectionNormLayer
override	gserver/layers/NormProjectionLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::CMRProjectionNormLayer
override	gserver/layers/NormProjectionLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::CMRProjectionNormLayer
override	gserver/layers/OuterProdLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::OuterProdLayer	file:
override	gserver/layers/OuterProdLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::OuterProdLayer	file:
override	gserver/layers/OuterProdLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::OuterProdLayer	file:
override	gserver/layers/PadLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::PadLayer
override	gserver/layers/PadLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::PadLayer
override	gserver/layers/PadLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::PadLayer
override	gserver/layers/ParameterReluLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ParameterReluLayer
override	gserver/layers/ParameterReluLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::ParameterReluLayer
override	gserver/layers/ParameterReluLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::ParameterReluLayer
override	gserver/layers/PoolLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::PoolLayer
override	gserver/layers/PoolProjectionLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::PoolProjectionLayer
override	gserver/layers/PoolProjectionLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::PoolProjectionLayer
override	gserver/layers/PowerLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::PowerLayer	file:
override	gserver/layers/PowerLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::PowerLayer	file:
override	gserver/layers/PowerLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::PowerLayer	file:
override	gserver/layers/PrintLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::PrintLayer	file:
override	gserver/layers/PriorBox.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::PriorBoxLayer	file:
override	gserver/layers/PriorBox.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::PriorBoxLayer	file:
override	gserver/layers/RecurrentLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::RecurrentLayer	file:
override	gserver/layers/RecurrentLayer.cpp	/^  LayerStatePtr getState() override;$/;"	m	class:paddle::RecurrentLayer	file:
override	gserver/layers/RecurrentLayer.cpp	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::RecurrentLayer	file:
override	gserver/layers/RecurrentLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::RecurrentLayer	file:
override	gserver/layers/RecurrentLayer.cpp	/^  void resetState() override;$/;"	m	class:paddle::RecurrentLayer	file:
override	gserver/layers/RecurrentLayer.cpp	/^  void setState(LayerStatePtr state) override;$/;"	m	class:paddle::RecurrentLayer	file:
override	gserver/layers/RecurrentLayerGroup.cpp	/^                      bool useGpu) override;$/;"	m	class:paddle::RecurrentLayerGroup	file:
override	gserver/layers/ResizeLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ResizeLayer	file:
override	gserver/layers/ResizeLayer.cpp	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::ResizeLayer	file:
override	gserver/layers/ResizeLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::ResizeLayer	file:
override	gserver/layers/ScalingLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ScalingLayer	file:
override	gserver/layers/ScalingLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::ScalingLayer	file:
override	gserver/layers/ScalingLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::ScalingLayer	file:
override	gserver/layers/SelectiveFullyConnectedLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
override	gserver/layers/SelectiveFullyConnectedLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
override	gserver/layers/SelectiveFullyConnectedLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
override	gserver/layers/SelectiveFullyConnectedLayer.h	/^  void prefetch() override;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
override	gserver/layers/SequenceConcatLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::SequenceConcatLayer	file:
override	gserver/layers/SequenceConcatLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::SequenceConcatLayer	file:
override	gserver/layers/SequenceConcatLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::SequenceConcatLayer	file:
override	gserver/layers/SequenceLastInstanceLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::SequenceLastInstanceLayer	file:
override	gserver/layers/SequenceLastInstanceLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::SequenceLastInstanceLayer	file:
override	gserver/layers/SequenceLastInstanceLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::SequenceLastInstanceLayer	file:
override	gserver/layers/SequencePoolLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::SequencePoolLayer
override	gserver/layers/SequencePoolLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::SequencePoolLayer
override	gserver/layers/SequencePoolLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::SequencePoolLayer
override	gserver/layers/SequenceReshapeLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::SequenceReshapeLayer	file:
override	gserver/layers/SequenceReshapeLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::SequenceReshapeLayer	file:
override	gserver/layers/SequenceReshapeLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::SequenceReshapeLayer	file:
override	gserver/layers/SlopeInterceptLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::SlopeInterceptLayer	file:
override	gserver/layers/SlopeInterceptLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::SlopeInterceptLayer	file:
override	gserver/layers/SlopeInterceptLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::SlopeInterceptLayer	file:
override	gserver/layers/SpatialPyramidPoolLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::SpatialPyramidPoolLayer
override	gserver/layers/SpatialPyramidPoolLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::SpatialPyramidPoolLayer
override	gserver/layers/SpatialPyramidPoolLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::SpatialPyramidPoolLayer
override	gserver/layers/SubSequenceLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::SubSequenceLayer	file:
override	gserver/layers/SubSequenceLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::SubSequenceLayer	file:
override	gserver/layers/SubSequenceLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::SubSequenceLayer	file:
override	gserver/layers/SumToOneNormLayer.cpp	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::SumToOneNormLayer	file:
override	gserver/layers/SumToOneNormLayer.cpp	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::SumToOneNormLayer	file:
override	gserver/layers/SumToOneNormLayer.cpp	/^  void forward(PassType passType) override;$/;"	m	class:paddle::SumToOneNormLayer	file:
override	gserver/layers/TensorLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::TensorLayer
override	gserver/layers/TensorLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::TensorLayer
override	gserver/layers/TensorLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::TensorLayer
override	gserver/layers/TransLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::TransLayer
override	gserver/layers/TransLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::TransLayer
override	gserver/layers/TransLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::TransLayer
override	gserver/layers/ValidationLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::AucValidation
override	gserver/layers/ValidationLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::PnpairValidation
override	gserver/layers/ValidationLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::ValidationLayer
override	gserver/layers/ValidationLayer.h	/^  void backward(const UpdateCallback& callback = nullptr) override;$/;"	m	class:paddle::ValidationLayer
override	gserver/layers/ValidationLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::ValidationLayer
override	gserver/layers/ValidationLayer.h	/^  void onPassEnd() override = 0;$/;"	m	class:paddle::ValidationLayer
override	gserver/layers/ValidationLayer.h	/^  void onPassEnd() override;$/;"	m	class:paddle::AucValidation
override	gserver/layers/ValidationLayer.h	/^  void onPassEnd() override;$/;"	m	class:paddle::PnpairValidation
override	gserver/layers/ValidationLayer.h	/^  void validationImp(MatrixPtr outputValue, IVectorPtr label) override;$/;"	m	class:paddle::AucValidation
override	gserver/layers/ValidationLayer.h	/^  void validationImp(MatrixPtr outputValue, IVectorPtr label) override;$/;"	m	class:paddle::PnpairValidation
override	gserver/layers/WarpCTCLayer.h	/^            const ParameterMap& parameterMap) override;$/;"	m	class:paddle::WarpCTCLayer
override	gserver/layers/WarpCTCLayer.h	/^  void backward(const UpdateCallback& callback) override;$/;"	m	class:paddle::WarpCTCLayer
override	gserver/layers/WarpCTCLayer.h	/^  void forward(PassType passType) override;$/;"	m	class:paddle::WarpCTCLayer
ownerThreadId_	utils/Thread.h	/^  pid_t ownerThreadId_;$/;"	m	class:paddle::SyncThreadPool
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::add_scale
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::and_op
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::cmp_eq
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::cmp_ge
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::cmp_gt
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::cmp_le
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::cmp_lt
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::cmp_ne
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::constant
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::div_scale
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::max
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::min
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::mul_scale
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::or_op
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::pow_op
p	cuda/include/hl_tensor_ops.h	/^  const T p;$/;"	m	class:hppl::unary::sub_scale
p1	cuda/include/hl_tensor_ops.h	/^  const T p1;$/;"	m	class:hppl::binary::add_scale
p2	cuda/include/hl_tensor_ops.h	/^  const T p2;$/;"	m	class:hppl::binary::add_scale
pUpdater_	trainer/ParamUtil.h	/^  std::shared_ptr<ParameterUpdater> pUpdater_;$/;"	m	class:paddle::ParameterUtil
packages	setup.py	/^  packages=['py_paddle'],$/;"	v
pad_	function/PadOp.cpp	/^  PadConf pad_;$/;"	m	class:paddle::PadFunc	file:
pad_	function/PadOp.cpp	/^  PadConf pad_;$/;"	m	class:paddle::PadGradFunc	file:
padc_	gserver/layers/PadLayer.h	/^  std::vector<int> padc_;$/;"	m	class:paddle::PadLayer
paddingH_	gserver/layers/BlockExpandLayer.h	/^  size_t blockH_, blockW_, strideH_, strideW_, paddingH_, paddingW_;$/;"	m	class:paddle::BlockExpandLayer
paddingH_	gserver/layers/ConvProjection.h	/^  int paddingH_, paddingW_;$/;"	m	class:paddle::ConvProjection
paddingW_	gserver/layers/BlockExpandLayer.h	/^  size_t blockH_, blockW_, strideH_, strideW_, paddingH_, paddingW_;$/;"	m	class:paddle::BlockExpandLayer
paddingW_	gserver/layers/ConvProjection.h	/^  int paddingH_, paddingW_;$/;"	m	class:paddle::ConvProjection
paddingY_	gserver/layers/ConvBaseLayer.h	/^  IntV paddingY_;$/;"	m	class:paddle::ConvBaseLayer
paddingY_	gserver/layers/ConvOperator.cpp	/^  int paddingY_, strideY_, filterSizeY_;$/;"	m	class:paddle::ConvOperator	file:
padding_	gserver/layers/ConvBaseLayer.h	/^  IntV padding_;$/;"	m	class:paddle::ConvBaseLayer
padding_	gserver/layers/ConvOperator.cpp	/^  int padding_, stride_, filterSize_, channels_, imgSize_, imgSizeY_;$/;"	m	class:paddle::ConvOperator	file:
padding_	utils/arch/linux/Locks.cpp	/^  char padding_[64 - sizeof(pthread_spinlock_t)];$/;"	m	class:paddle::SpinLockPrivate	file:
padding_	utils/arch/osx/Locks.cpp	/^  char padding_[64 - sizeof(lock_)];  \/\/ Padding to cache line size$/;"	m	class:paddle::SpinLockPrivate	file:
paddle	function/BufferArg.cpp	/^namespace paddle {$/;"	n	file:
paddle	function/BufferArg.h	/^namespace paddle {$/;"	n
paddle	function/BufferArgTest.cpp	/^namespace paddle {$/;"	n	file:
paddle	function/ContextProjectionOp.cpp	/^namespace paddle {$/;"	n	file:
paddle	function/ContextProjectionOp.h	/^namespace paddle {$/;"	n
paddle	function/CosSimOp.cpp	/^namespace paddle {$/;"	n	file:
paddle	function/CosSimOp.h	/^namespace paddle {$/;"	n
paddle	function/CrossMapNormalOp.cpp	/^namespace paddle {$/;"	n	file:
paddle	function/CrossMapNormalOp.h	/^namespace paddle {$/;"	n
paddle	function/CrossMapNormalOpTest.cpp	/^namespace paddle {$/;"	n	file:
paddle	function/Function.cpp	/^namespace paddle {$/;"	n	file:
paddle	function/Function.h	/^namespace paddle {$/;"	n
paddle	function/FunctionTest.cpp	/^namespace paddle {$/;"	n	file:
paddle	function/FunctionTest.h	/^namespace paddle {$/;"	n
paddle	function/MulOp.cpp	/^namespace paddle {$/;"	n	file:
paddle	function/MulOp.h	/^namespace paddle {$/;"	n
paddle	function/PadOp.cpp	/^namespace paddle {$/;"	n	file:
paddle	function/PadOp.h	/^namespace paddle {$/;"	n
paddle	function/PadOpTest.cpp	/^namespace paddle {$/;"	n	file:
paddle	function/TensorShape.h	/^namespace paddle {$/;"	n
paddle	function/TensorShapeTest.cpp	/^namespace paddle {$/;"	n	file:
paddle	function/TensorType.h	/^namespace paddle {$/;"	n
paddle	function/TensorTypeTest.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/activations/ActivationFunction.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/activations/ActivationFunction.h	/^namespace paddle {$/;"	n
paddle	gserver/dataproviders/DataProvider.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/dataproviders/DataProvider.h	/^namespace paddle {$/;"	n
paddle	gserver/dataproviders/DataProviderGroup.h	/^namespace paddle {$/;"	n
paddle	gserver/dataproviders/MultiDataProvider.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/dataproviders/MultiDataProvider.h	/^namespace paddle {$/;"	n
paddle	gserver/dataproviders/ProtoDataProvider.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/dataproviders/ProtoDataProvider.h	/^namespace paddle {$/;"	n
paddle	gserver/dataproviders/ProtoReader.h	/^namespace paddle {$/;"	n
paddle	gserver/dataproviders/PyDataProvider.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/dataproviders/PyDataProvider.h	/^namespace paddle {$/;"	n
paddle	gserver/dataproviders/PyDataProvider2.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/evaluators/CTCErrorEvaluator.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/evaluators/ChunkEvaluator.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/evaluators/Evaluator.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/evaluators/Evaluator.h	/^namespace paddle {$/;"	n
paddle	gserver/gradientmachines/GradientMachine.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/gradientmachines/GradientMachine.h	/^namespace paddle {$/;"	n
paddle	gserver/gradientmachines/GradientMachineMode.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/gradientmachines/GradientMachineMode.h	/^namespace paddle {$/;"	n
paddle	gserver/gradientmachines/MultiGradientMachine.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/gradientmachines/MultiGradientMachine.h	/^namespace paddle {$/;"	n
paddle	gserver/gradientmachines/MultiNetwork.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/gradientmachines/MultiNetwork.h	/^namespace paddle {$/;"	n
paddle	gserver/gradientmachines/NeuralNetwork.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/gradientmachines/NeuralNetwork.h	/^namespace paddle {$/;"	n
paddle	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/gradientmachines/ParallelNeuralNetwork.h	/^namespace paddle {$/;"	n
paddle	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/gradientmachines/RecurrentGradientMachine.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/AddtoLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/AddtoLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/AgentLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/AgentLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/AverageLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/AverageLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/BatchNormBaseLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/BatchNormBaseLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/BatchNormalizationLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/BatchNormalizationLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/BilinearInterpLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/BilinearInterpLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/BlockExpandLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/BlockExpandLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/CRFDecodingLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/CRFDecodingLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/CRFLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/CRFLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/CTCLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/CTCLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/ConcatenateLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ContextProjection.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ContextProjection.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/ConvBaseLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ConvBaseLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/ConvOperator.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ConvProjection.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ConvProjection.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/ConvShiftLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ConvexCombinationLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/CosSimLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/CosSimLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/CosSimVecMatLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/CostLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/CostLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/CudnnBatchNormLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/CudnnBatchNormLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/CudnnConvLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/CudnnConvLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/CudnnPoolLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/CudnnPoolLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/DataLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/DataLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/DataNormLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/DataNormLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/DotMulOperator.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/DotMulProjection.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/EosIdCheckLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ExpandConvBaseLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ExpandConvBaseLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/ExpandConvLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ExpandConvLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/ExpandConvTransLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ExpandConvTransLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/ExpandLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ExpandLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/FeatureMapExpandLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/FullMatrixProjection.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/FullMatrixProjection.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/FullyConnectedLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/FullyConnectedLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/GatedRecurrentLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/GatedRecurrentLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/GetOutputLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/GruCompute.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/GruCompute.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/GruStepLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/HierarchicalSigmoidLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/HierarchicalSigmoidLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/IdentityProjection.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/InterpolationLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/Layer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/Layer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/LinearChainCRF.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/LinearChainCRF.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/LinearChainCTC.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/LinearChainCTC.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/LstmCompute.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/LstmCompute.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/LstmLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/LstmLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/LstmStepLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/MDLstmLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/MaxIdLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/MaxLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/MaxLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/MaxOutLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/MaxOutLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/MixedLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/MixedLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/MultinomialSampler.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/MultinomialSampler.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/MultiplexLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/NCELayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/NormLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/NormLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/NormProjectionLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/NormProjectionLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/Operator.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/Operator.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/OuterProdLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/PadLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/PadLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/ParameterReluLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ParameterReluLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/PoolLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/PoolLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/PoolProjection.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/PoolProjection.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/PoolProjectionLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/PoolProjectionLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/PowerLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/PrintLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/PriorBox.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/Projection.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/Projection.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/RecurrentLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/RecurrentLayerGroup.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ResizeLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/RotateLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/RotateLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/SamplingIdLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ScalingLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ScalingProjection.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/SelectiveFullyConnectedLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/SelectiveFullyConnectedLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/SequenceConcatLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/SequenceLastInstanceLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/SequencePoolLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/SequencePoolLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/SequenceReshapeLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/SequenceToBatch.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/SequenceToBatch.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/SlopeInterceptLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/SpatialPyramidPoolLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/SpatialPyramidPoolLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/SubSequenceLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/SumToOneNormLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/TableProjection.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/TableProjection.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/TensorLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/TensorLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/TransLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/TransLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/TransposedFullMatrixProjection.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ValidationLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/ValidationLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/layers/WarpCTCLayer.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/layers/WarpCTCLayer.h	/^namespace paddle {$/;"	n
paddle	gserver/tests/LayerGradUtil.cpp	/^namespace paddle {$/;"	n	file:
paddle	gserver/tests/LayerGradUtil.h	/^namespace paddle {$/;"	n
paddle	gserver/tests/test_PyDataProvider2.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/Allocator.h	/^namespace paddle {$/;"	n
paddle	math/BaseMatrix.h	/^namespace paddle {$/;"	n
paddle	math/CpuSparseMatrix.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/CpuSparseMatrix.h	/^namespace paddle {$/;"	n
paddle	math/ExecViaCpu.h	/^namespace paddle {$/;"	n
paddle	math/MathFunctions.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/MathFunctions.h	/^namespace paddle {$/;"	n
paddle	math/MathUtils.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/MathUtils.h	/^namespace paddle {$/;"	n
paddle	math/Matrix.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/Matrix.h	/^namespace paddle {$/;"	n
paddle	math/MatrixBitCode.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/MemoryHandle.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/MemoryHandle.h	/^namespace paddle {$/;"	n
paddle	math/PoolAllocator.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/PoolAllocator.h	/^namespace paddle {$/;"	n
paddle	math/RowBuffer.h	/^namespace paddle {$/;"	n
paddle	math/SIMDFunctions.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/SIMDFunctions.h	/^namespace paddle {$/;"	n
paddle	math/SparseMatrix.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/SparseMatrix.h	/^namespace paddle {$/;"	n
paddle	math/SparseRowMatrix.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/SparseRowMatrix.h	/^namespace paddle {$/;"	n
paddle	math/Storage.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/Storage.h	/^namespace paddle {$/;"	n
paddle	math/TensorApply.h	/^namespace paddle {$/;"	n
paddle	math/TensorAssign.h	/^namespace paddle {$/;"	n
paddle	math/TensorEvaluate.h	/^namespace paddle {$/;"	n
paddle	math/TensorExpression.h	/^namespace paddle {$/;"	n
paddle	math/TrainingAlgorithmOp.h	/^namespace paddle {$/;"	n
paddle	math/Vector.cpp	/^namespace paddle {$/;"	n	file:
paddle	math/Vector.h	/^namespace paddle {$/;"	n
paddle	math/tests/test_matrixUtil.h	/^namespace paddle {$/;"	n
paddle	parameter/Argument.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/Argument.h	/^namespace paddle {$/;"	n
paddle	parameter/AverageOptimizer.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/AverageOptimizer.h	/^namespace paddle {$/;"	n
paddle	parameter/FirstOrderOptimizer.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/FirstOrderOptimizer.h	/^namespace paddle {$/;"	n
paddle	parameter/LearningRateScheduler.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/LearningRateScheduler.h	/^namespace paddle {$/;"	n
paddle	parameter/OptimizerFunctions.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/OptimizerFunctions.h	/^namespace paddle {$/;"	n
paddle	parameter/OptimizerWithRegularizer.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/OptimizerWithRegularizer.h	/^namespace paddle {$/;"	n
paddle	parameter/ParallelParameter.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/ParallelParameter.h	/^namespace paddle {$/;"	n
paddle	parameter/Parameter.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/Parameter.h	/^namespace paddle {$/;"	n
paddle	parameter/ParameterOptimizer.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/ParameterOptimizer.h	/^namespace paddle {$/;"	n
paddle	parameter/ParameterUpdateFunctions.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/ParameterUpdateFunctions.h	/^namespace paddle {$/;"	n
paddle	parameter/ParameterUpdaterBase.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/ParameterUpdaterBase.h	/^namespace paddle {$/;"	n
paddle	parameter/ParameterUpdaterHook.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/ParameterUpdaterHook.h	/^namespace paddle {$/;"	n
paddle	parameter/Regularizer.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/Regularizer.h	/^namespace paddle {$/;"	n
paddle	parameter/Weight.cpp	/^namespace paddle {$/;"	n	file:
paddle	parameter/Weight.h	/^namespace paddle {$/;"	n
paddle	pserver/BaseClient.cpp	/^namespace paddle {$/;"	n	file:
paddle	pserver/BaseClient.h	/^namespace paddle {$/;"	n
paddle	pserver/LightNetwork.cpp	/^namespace paddle {$/;"	n	file:
paddle	pserver/LightNetwork.h	/^namespace paddle {$/;"	n
paddle	pserver/ParameterClient2.cpp	/^namespace paddle {$/;"	n	file:
paddle	pserver/ParameterClient2.h	/^namespace paddle {$/;"	n
paddle	pserver/ParameterServer2.cpp	/^namespace paddle {$/;"	n	file:
paddle	pserver/ParameterServer2.h	/^namespace paddle {$/;"	n
paddle	pserver/ParameterServerController.cpp	/^namespace paddle {$/;"	n	file:
paddle	pserver/ParameterServerController.h	/^namespace paddle {$/;"	n
paddle	pserver/ProtoServer.cpp	/^namespace paddle {$/;"	n	file:
paddle	pserver/ProtoServer.h	/^namespace paddle {$/;"	n
paddle	pserver/RDMANetwork.h	/^namespace paddle {$/;"	n
paddle	pserver/SocketChannel.cpp	/^namespace paddle {$/;"	n	file:
paddle	pserver/SocketChannel.h	/^namespace paddle {$/;"	n
paddle	pserver/SparseParameterDistribution.cpp	/^namespace paddle {$/;"	n	file:
paddle	pserver/SparseParameterDistribution.h	/^namespace paddle {$/;"	n
paddle	testing/TestUtil.cpp	/^namespace paddle {$/;"	n	file:
paddle	testing/TestUtil.h	/^namespace paddle {$/;"	n
paddle	trainer/ParamUtil.cpp	/^namespace paddle {$/;"	n	file:
paddle	trainer/ParamUtil.h	/^namespace paddle {$/;"	n
paddle	trainer/ParameterUpdater.cpp	/^namespace paddle {$/;"	n	file:
paddle	trainer/ParameterUpdater.h	/^namespace paddle {$/;"	n
paddle	trainer/RemoteParameterUpdater.cpp	/^namespace paddle {$/;"	n	file:
paddle	trainer/RemoteParameterUpdater.h	/^namespace paddle {$/;"	n
paddle	trainer/Tester.cpp	/^namespace paddle {$/;"	n	file:
paddle	trainer/Tester.h	/^namespace paddle {$/;"	n
paddle	trainer/TesterConfig.h	/^namespace paddle {$/;"	n
paddle	trainer/ThreadParameterUpdater.cpp	/^namespace paddle {$/;"	n	file:
paddle	trainer/ThreadParameterUpdater.h	/^namespace paddle {$/;"	n
paddle	trainer/Trainer.cpp	/^namespace paddle {$/;"	n	file:
paddle	trainer/Trainer.h	/^namespace paddle {$/;"	n
paddle	trainer/TrainerBenchmark.cpp	/^namespace paddle {$/;"	n	file:
paddle	trainer/TrainerConfigHelper.cpp	/^namespace paddle {$/;"	n	file:
paddle	trainer/TrainerConfigHelper.h	/^namespace paddle {$/;"	n
paddle	trainer/TrainerInternal.cpp	/^namespace paddle {$/;"	n	file:
paddle	trainer/TrainerInternal.h	/^namespace paddle {$/;"	n
paddle	trainer/TrainerInternalConfig.cpp	/^namespace paddle {$/;"	n	file:
paddle	trainer/TrainerInternalConfig.h	/^namespace paddle {$/;"	n
paddle	utils/BarrierStat.cpp	/^namespace paddle {$/;"	n	file:
paddle	utils/BarrierStat.h	/^namespace paddle {$/;"	n
paddle	utils/ClassRegistrar.h	/^namespace paddle {$/;"	n
paddle	utils/Common.h	/^namespace paddle {$/;"	n
paddle	utils/CpuId.cpp	/^namespace paddle {$/;"	n	file:
paddle	utils/CpuId.h	/^namespace paddle {$/;"	n
paddle	utils/CustomStackTrace.cpp	/^namespace paddle {$/;"	n	file:
paddle	utils/CustomStackTrace.h	/^namespace paddle {$/;"	n
paddle	utils/Error.h	/^namespace paddle {$/;"	n
paddle	utils/GlobalConstants.cpp	/^namespace paddle {$/;"	n	file:
paddle	utils/GlobalConstants.h	/^namespace paddle {$/;"	n
paddle	utils/Locks.h	/^namespace paddle {$/;"	n
paddle	utils/Logging.cpp	/^namespace paddle {$/;"	n	file:
paddle	utils/Logging.h	/^namespace paddle {$/;"	n
paddle	utils/PythonUtil.cpp	/^namespace paddle {$/;"	n	file:
paddle	utils/PythonUtil.h	/^namespace paddle {$/;"	n
paddle	utils/Queue.h	/^namespace paddle {$/;"	n
paddle	utils/Stat.cpp	/^namespace paddle {$/;"	n	file:
paddle	utils/Stat.h	/^namespace paddle {$/;"	n
paddle	utils/StringUtil.cpp	/^namespace paddle {$/;"	n	file:
paddle	utils/StringUtil.h	/^namespace paddle {$/;"	n
paddle	utils/Thread.h	/^namespace paddle {$/;"	n
paddle	utils/ThreadLocal.cpp	/^namespace paddle {$/;"	n	file:
paddle	utils/ThreadLocal.h	/^namespace paddle {$/;"	n
paddle	utils/Util.cpp	/^namespace paddle {$/;"	n	file:
paddle	utils/Util.h	/^namespace paddle {$/;"	n
paddle	utils/Version.cpp	/^namespace paddle {$/;"	n	file:
paddle	utils/Version.h	/^namespace paddle {$/;"	n
paddle	utils/arch/linux/Locks.cpp	/^namespace paddle {$/;"	n	file:
paddle	utils/arch/osx/Locks.cpp	/^namespace paddle {$/;"	n	file:
padh_	gserver/layers/PadLayer.h	/^  std::vector<int> padh_;$/;"	m	class:paddle::PadLayer
padw_	gserver/layers/PadLayer.h	/^  std::vector<int> padw_;$/;"	m	class:paddle::PadLayer
pairArray_	gserver/evaluators/Evaluator.h	/^  double pairArray_[kPairArrayNum_];$/;"	m	class:paddle::PnpairEvaluator
paraGrads	gserver/tests/test_NetworkCompare.cpp	/^  std::vector<VectorPtr> paraGrads;$/;"	m	struct:DataOut	file:
paraMainThread	gserver/gradientmachines/MultiGradientMachine.h	/^  int paraMainThread(int pid) const { return paraMainThread_[pid]; }$/;"	f	class:paddle::MultiGradientMachine
paraMainThread_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<int> paraMainThread_;$/;"	m	class:paddle::MultiGradientMachine
paraSize	gserver/tests/LayerGradUtil.h	/^  size_t paraSize;$/;"	m	struct:paddle::InputDef
paraValues	gserver/tests/test_NetworkCompare.cpp	/^  std::vector<VectorPtr> paraValues;$/;"	m	struct:DataIn	file:
para_	gserver/tests/test_RecurrentLayer.cpp	/^  ParameterPtr para_;$/;"	m	class:TestRecurrentLayer	file:
parallelDataRequests	pserver/BaseClient.h	/^    SendDataRequestVec parallelDataRequests;$/;"	m	struct:paddle::BaseClient::SendJob
parallelExec	math/Vector.cpp	/^void ParallelCpuVectorT<T>::parallelExec(ExecFunc func) {$/;"	f	class:paddle::ParallelCpuVectorT
parallelExec	math/Vector.cpp	/^void ParallelCpuVectorT<real>::parallelExec(ExecFunc func) {$/;"	f	class:paddle::ParallelCpuVectorT
parallelExecForEachBlock	pserver/ParameterServer2.cpp	/^void ParameterServer2::parallelExecForEachBlock(ExecFunc func) {$/;"	f	class:paddle::ParameterServer2
parallelInputIovs	pserver/BaseClient.h	/^    InputIovs parallelInputIovs;$/;"	m	struct:paddle::BaseClient::SendJob
parallelRequests	pserver/BaseClient.h	/^    SendRequest parallelRequests;$/;"	m	struct:paddle::BaseClient::SendJob
parallel_nn	trainer/TrainerConfigHelper.cpp	/^DECLARE_bool(parallel_nn);$/;"	v
parallel_nn	trainer/tests/test_CompareSparse.cpp	/^DECLARE_bool(parallel_nn);$/;"	v
parallel_nn	utils/Flags.h	/^DECLARE_bool(parallel_nn);$/;"	v
parallel_thread_num	pserver/ParameterClient2.h	/^DECLARE_int32(parallel_thread_num);$/;"	v
paramId	gserver/gradientmachines/MultiGradientMachine.h	/^  int paramId;$/;"	m	struct:paddle::GradBuffer
paramReluBackwardDiff	math/Matrix.cpp	/^void CpuMatrix::paramReluBackwardDiff(Matrix& oGrad, Matrix& data, Matrix& W) {$/;"	f	class:paddle::CpuMatrix
paramReluBackwardDiff	math/Matrix.cpp	/^void GpuMatrix::paramReluBackwardDiff(Matrix& oGrad, Matrix& data, Matrix& W) {$/;"	f	class:paddle::GpuMatrix
paramReluBackwardDiff	math/Matrix.h	/^  virtual void paramReluBackwardDiff(Matrix& oGrad, Matrix& data, Matrix& W) {$/;"	f	class:paddle::Matrix
paramReluBackwardW	math/Matrix.cpp	/^void CpuMatrix::paramReluBackwardW(Matrix& oGrad, Matrix& data) {$/;"	f	class:paddle::CpuMatrix
paramReluBackwardW	math/Matrix.cpp	/^void GpuMatrix::paramReluBackwardW(Matrix& oGrad, Matrix& data) {$/;"	f	class:paddle::GpuMatrix
paramReluBackwardW	math/Matrix.h	/^  virtual void paramReluBackwardW(Matrix& oGrad, Matrix& data) {$/;"	f	class:paddle::Matrix
paramReluForward	math/Matrix.cpp	/^void CpuMatrix::paramReluForward(Matrix& data, Matrix& W) {$/;"	f	class:paddle::CpuMatrix
paramReluForward	math/Matrix.cpp	/^void GpuMatrix::paramReluForward(Matrix& data, Matrix& W) {$/;"	f	class:paddle::GpuMatrix
paramReluForward	math/Matrix.h	/^  virtual void paramReluForward(Matrix& data, Matrix& W) {$/;"	f	class:paddle::Matrix
paramSelfInited_	gserver/gradientmachines/NeuralNetwork.h	/^  bool paramSelfInited_;$/;"	m	class:paddle::NeuralNetwork
paramUpdateFunctions	parameter/ParallelParameter.cpp	/^UpdateFunction paramUpdateFunctions[UPDATE_TYPE_NUM] = {$/;"	m	namespace:paddle	file:
paramUtil_	trainer/Tester.h	/^  std::unique_ptr<ParameterUtil> paramUtil_;$/;"	m	class:paddle::Tester
paramUtil_	trainer/Trainer.h	/^  std::unique_ptr<ParameterUtil> paramUtil_;$/;"	m	class:paddle::Trainer
param_attr	trainer/tests/simple_sparse_neural_network.py	/^    param_attr=ParamAttr(sparse_update=True))$/;"	v
parameter	api/ConfigParser.cpp	/^  paddle::ParameterPtr parameter;$/;"	m	struct:ParameterConfigPrivate	file:
parameterClient_	trainer/RemoteParameterUpdater.h	/^  std::unique_ptr<ParameterClient2> parameterClient_;$/;"	m	class:paddle::RemoteParameterUpdater
parameterClient_	trainer/RemoteParameterUpdater.h	/^  std::unique_ptr<ParameterClient2> parameterClient_;$/;"	m	class:paddle::SparseRemoteParameterUpdater
parameterIds_	gserver/gradientmachines/RecurrentGradientMachine.h	/^      parameterIds_;  \/\/ parameters actually used by this Layer Group$/;"	m	class:paddle::RecurrentGradientMachine
parameterInitNN	gserver/gradientmachines/NeuralNetwork.cpp	/^void parameterInitNN(int paramId,$/;"	f	namespace:paddle
parameterMap_	gserver/gradientmachines/NeuralNetwork.h	/^  ParameterMap parameterMap_;$/;"	m	class:paddle::NeuralNetwork
parameterMap_	gserver/tests/test_RecurrentLayer.cpp	/^  ParameterMap parameterMap_;$/;"	m	class:TestRecurrentLayer	file:
parameterMap_	pserver/ParameterClient2.h	/^  std::unordered_map<size_t, ParameterPtr> parameterMap_;$/;"	m	class:paddle::ParameterClient2
parameterMutex_	pserver/ParameterServer2.h	/^  RWLock parameterMutex_;$/;"	m	class:paddle::ParameterServer2
parameterReadyBarrier_	pserver/ParameterServer2.h	/^  ThreadBarrier parameterReadyBarrier_;$/;"	m	class:paddle::ParameterServer2
parameterServers_	pserver/ParameterServerController.h	/^  std::vector<std::unique_ptr<ParameterServer2>> parameterServers_;$/;"	m	class:paddle::final
parameterTypes_	parameter/ParameterOptimizer.h	/^  std::vector<ParameterType> parameterTypes_;$/;"	m	class:paddle::ParameterOptimizer
parameterTypes_	parameter/ParameterUpdaterBase.h	/^  std::vector<ParameterType> parameterTypes_;$/;"	m	class:paddle::ParameterUpdater
parameterUpdated_	gserver/gradientmachines/MultiGradientMachine.h	/^  bool parameterUpdated_;$/;"	m	class:paddle::TrainerThread
parameterUpdater_	trainer/Tester.h	/^  std::shared_ptr<ParameterUpdater> parameterUpdater_;$/;"	m	class:paddle::Tester
parameterUpdater_	trainer/TrainerInternal.h	/^  std::shared_ptr<ParameterUpdater> parameterUpdater_;$/;"	m	class:paddle::TrainerInternal
parameter_	gserver/layers/CRFLayer.h	/^  ParameterPtr parameter_;$/;"	m	class:paddle::CRFLayer
parameter_	gserver/layers/Projection.h	/^  ParameterPtr parameter_;$/;"	m	class:paddle::Projection
parameter_	parameter/Weight.h	/^  ParameterPtr parameter_;$/;"	m	class:paddle::Weight
parameters	gserver/tests/test_SelectiveFCLayer.cpp	/^  vector<ParameterPtr> parameters;$/;"	m	struct:ComData	file:
parameters	trainer/tests/test_Compare.cpp	/^  vector<ParameterPtr> parameters;$/;"	m	struct:comData	file:
parameters	trainer/tests/test_CompareTwoNets.cpp	/^  vector<ParameterPtr> parameters;$/;"	m	struct:ComData	file:
parameters	trainer/tests/test_CompareTwoOpts.cpp	/^  vector<ParameterPtr> parameters;$/;"	m	struct:ComData	file:
parameters_	gserver/gradientmachines/GradientMachine.h	/^  std::vector<ParameterPtr> parameters_;$/;"	m	class:paddle::GradientMachine
parameters_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<ParameterPtr> parameters_;$/;"	m	class:paddle::TrainerThread
parameters_	gserver/layers/Layer.h	/^  std::vector<ParameterPtr> parameters_;$/;"	m	class:paddle::Layer
parameters_	parameter/ParameterUpdaterBase.h	/^  std::vector<ParameterPtr> parameters_;$/;"	m	class:paddle::ParameterUpdater
parameters_	pserver/test/test_ParameterServer2.cpp	/^  vector<ParameterPtr> parameters_;$/;"	m	class:ParameterServer2Tester	file:
parent_dir_str	api/paddle_ld_flags.py	/^        def parent_dir_str(self):$/;"	m	class:PaddleLDFlag
parse	trainer/tests/picojson.h	/^inline Iter parse(value& out,$/;"	f	namespace:picojson
parse	trainer/tests/picojson.h	/^inline std::string parse(value& out, Iter& pos, const Iter& last) {$/;"	f	namespace:picojson
parse	trainer/tests/picojson.h	/^inline std::string parse(value& out, const std::string& s) {$/;"	f	namespace:picojson
parse	trainer/tests/picojson.h	/^inline std::string parse(value& out, std::istream& is) {$/;"	f	namespace:picojson
parseHeaderData	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::parseHeaderData(const std::string& headerData) {$/;"	f	class:paddle::PyDataProvider
parse_array_item	trainer/tests/picojson.h	/^  bool parse_array_item(input<Iter>& in, size_t) {$/;"	f	class:picojson::default_parse_context
parse_array_item	trainer/tests/picojson.h	/^  bool parse_array_item(input<Iter>& in, size_t) {$/;"	f	class:picojson::null_parse_context
parse_array_item	trainer/tests/picojson.h	/^  bool parse_array_item(input<Iter>&, size_t) {$/;"	f	class:picojson::deny_parse_context
parse_array_start	trainer/tests/picojson.h	/^  bool parse_array_start() { return false; }$/;"	f	class:picojson::deny_parse_context
parse_array_start	trainer/tests/picojson.h	/^  bool parse_array_start() { return true; }$/;"	f	class:picojson::null_parse_context
parse_array_start	trainer/tests/picojson.h	/^  bool parse_array_start() {$/;"	f	class:picojson::default_parse_context
parse_array_stop	trainer/tests/picojson.h	/^  bool parse_array_stop(size_t) { return false; }$/;"	f	class:picojson::deny_parse_context
parse_array_stop	trainer/tests/picojson.h	/^  bool parse_array_stop(size_t) { return true; }$/;"	f	class:picojson::default_parse_context
parse_array_stop	trainer/tests/picojson.h	/^  bool parse_array_stop(size_t) { return true; }$/;"	f	class:picojson::null_parse_context
parse_object_item	trainer/tests/picojson.h	/^  bool parse_object_item(input<Iter>& in, const std::string& key) {$/;"	f	class:picojson::default_parse_context
parse_object_item	trainer/tests/picojson.h	/^  bool parse_object_item(input<Iter>& in, const std::string&) {$/;"	f	class:picojson::null_parse_context
parse_object_item	trainer/tests/picojson.h	/^  bool parse_object_item(input<Iter>&, const std::string&) {$/;"	f	class:picojson::deny_parse_context
parse_object_start	trainer/tests/picojson.h	/^  bool parse_object_start() { return false; }$/;"	f	class:picojson::deny_parse_context
parse_object_start	trainer/tests/picojson.h	/^  bool parse_object_start() { return true; }$/;"	f	class:picojson::null_parse_context
parse_object_start	trainer/tests/picojson.h	/^  bool parse_object_start() {$/;"	f	class:picojson::default_parse_context
parse_string	trainer/tests/picojson.h	/^  bool parse_string(input<Iter>& in) {$/;"	f	class:picojson::default_parse_context
parse_string	trainer/tests/picojson.h	/^  bool parse_string(input<Iter>& in) {$/;"	f	class:picojson::null_parse_context
parse_string	trainer/tests/picojson.h	/^  bool parse_string(input<Iter>&) {$/;"	f	class:picojson::deny_parse_context
partialSum_	gserver/layers/ParameterReluLayer.h	/^  size_t partialSum_;$/;"	m	class:paddle::ParameterReluLayer
partnerId_	gserver/gradientmachines/MultiGradientMachine.h	/^  int partnerId_;$/;"	m	class:paddle::TrainerThread
partnerParam_	parameter/ParallelParameter.h	/^  ParameterPtr partnerParam_;$/;"	m	class:paddle::SyncParameter
passBarrier_	pserver/ParameterServer2.h	/^  ThreadBarrier passBarrier_;$/;"	m	class:paddle::ParameterServer2
passBegin_	gserver/layers/ValidationLayer.h	/^  bool passBegin_;$/;"	m	class:paddle::AucValidation
passBegin_	gserver/layers/ValidationLayer.h	/^  bool passBegin_;$/;"	m	class:paddle::PnpairValidation
passCount_	trainer/RemoteParameterUpdater.h	/^  int64_t passCount_;$/;"	m	class:paddle::RemoteParameterUpdater
passCount_	trainer/RemoteParameterUpdater.h	/^  int64_t passCount_;$/;"	m	class:paddle::SparseRemoteParameterUpdater
passFinish_	pserver/ParameterClient2.h	/^  bool passFinish_;$/;"	m	class:paddle::ParameterClient2
passId	trainer/Trainer.h	/^    int passId;$/;"	m	struct:paddle::Trainer::TrainPassContext
passInnerId	trainer/Trainer.h	/^    int passInnerId;$/;"	m	struct:paddle::Trainer::TrainPassContext
passType_	gserver/gradientmachines/MultiGradientMachine.h	/^  PassType passType_;$/;"	m	class:paddle::MultiGradientMachine
passType_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  PassType passType_;$/;"	m	class:paddle::ParallelThread
passType_	gserver/layers/Layer.h	/^  PassType passType_;$/;"	m	class:paddle::Layer
passType_	gserver/layers/Operator.h	/^  PassType passType_;$/;"	m	class:paddle::Operator
passType_	gserver/layers/Projection.h	/^  PassType passType_;$/;"	m	class:paddle::Projection
pass_	parameter/ParameterOptimizer.h	/^  int64_t pass_;  \/\/ current training pass (starting from 0)$/;"	m	class:paddle::ParameterOptimizer
path	utils/Util.cpp	/^namespace path {$/;"	n	namespace:paddle	file:
path	utils/Util.h	/^namespace path {$/;"	n	namespace:paddle
path2String	gserver/evaluators/CTCErrorEvaluator.cpp	/^  std::vector<int> path2String(const std::vector<int>& path) {$/;"	f	class:paddle::CTCErrorEvaluator	file:
path_	api/SequenceGenerator.cpp	/^  std::shared_ptr<std::vector<Path>> path_;$/;"	m	class:PathSequenceResults	file:
patterns	trainer/tests/gen_proto_data.py	/^patterns = [$/;"	v
peerName_	pserver/SocketChannel.h	/^  const std::string peerName_;$/;"	m	class:paddle::SocketChannel
pending_	gserver/dataproviders/DataProvider.h	/^  bool pending_;$/;"	m	class:paddle::DoubleBuffer
picojson	trainer/tests/picojson.h	/^namespace picojson {$/;"	n
picojson_h	trainer/tests/picojson.h	30;"	d
pointer	utils/Util.h	/^  typedef T* pointer;$/;"	t	class:paddle::AlignedAllocator
poolActualSize_	gserver/dataproviders/PyDataProvider2.cpp	/^  size_t poolActualSize_;$/;"	m	class:paddle::PyDataProvider2	file:
poolMemorySize_	math/PoolAllocator.h	/^  size_t poolMemorySize_;$/;"	m	class:paddle::PoolAllocator
poolProjection_	gserver/layers/PoolProjectionLayer.h	/^  std::unique_ptr<PoolProjection> poolProjection_;$/;"	m	class:paddle::PoolProjectionLayer
poolProjections_	gserver/layers/SpatialPyramidPoolLayer.h	/^  std::vector<std::unique_ptr<PoolProjection>> poolProjections_;$/;"	m	class:paddle::SpatialPyramidPoolLayer
poolSize_	gserver/dataproviders/PyDataProvider2.cpp	/^  size_t poolSize_;$/;"	m	class:paddle::PyDataProvider2	file:
poolType_	gserver/layers/PoolLayer.h	/^  std::string poolType_;$/;"	m	class:paddle::PoolLayer
poolType_	gserver/layers/PoolProjection.h	/^  std::string poolType_;$/;"	m	class:paddle::PoolProjection
poolType_	gserver/layers/SpatialPyramidPoolLayer.h	/^  std::string poolType_;$/;"	m	class:paddle::SpatialPyramidPoolLayer
pool_	math/PoolAllocator.h	/^  std::unordered_map<size_t, std::vector<void*>> pool_;$/;"	m	class:paddle::PoolAllocator
pool_	math/SparseRowMatrix.h	/^  SyncThreadPool* pool_;$/;"	m	class:paddle::SparsePrefetchRowCpuMatrix
pool_	math/Vector.h	/^  SyncThreadPool* pool_;$/;"	m	class:paddle::ParallelCpuVectorT
poolingDesc_	gserver/layers/CudnnPoolLayer.h	/^  hl_pooling_descriptor poolingDesc_;$/;"	m	class:paddle::CudnnPoolLayer
pop	utils/CustomStackTrace.h	/^  void pop(const T& item) {$/;"	f	class:paddle::CustomStackTrace
pop_get_front	utils/Util.h	/^typename Container::value_type pop_get_front(Container& c) {$/;"	f	namespace:paddle
port	pserver/ParameterServer2.h	/^DECLARE_int32(port);$/;"	v
port	trainer/tests/test_CompareSparse.cpp	/^DECLARE_int32(port);$/;"	v
port	trainer/tests/test_TrainerOnePass.cpp	/^DECLARE_int32(port);$/;"	v
port	utils/Flags.h	/^DECLARE_int32(port);$/;"	v
port_	pserver/LightNetwork.h	/^  int port_;$/;"	m	class:paddle::SocketServer
port_	pserver/ParameterClient2.h	/^  int port_;$/;"	m	class:paddle::ParameterClient2
port_	pserver/test/SocketTest.cpp	/^  int port_;$/;"	m	class:SocketServer	file:
ports_num	utils/Flags.h	/^DECLARE_int32(ports_num);$/;"	v
ports_num_for_sparse	utils/Flags.h	/^DECLARE_int32(ports_num_for_sparse);$/;"	v
posPairCount_	gserver/layers/CostLayer.h	/^  double posPairCount_;$/;"	m	class:paddle::RankingCost
post	utils/arch/linux/Locks.cpp	/^void Semaphore::post() { sem_post(&m->sem); }$/;"	f	class:paddle::Semaphore
post	utils/arch/osx/Locks.cpp	/^void Semaphore::post() { dispatch_semaphore_signal(m->sem); }$/;"	f	class:paddle::Semaphore
postValueReady	parameter/ParallelParameter.h	/^  void postValueReady() { valueSem_->post(); }$/;"	f	class:paddle::ParallelParameter
pow	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::pow_op<T>, const Derived, T> pow(T p) const {$/;"	f	class:paddle::TensorExpression
pow_	function/CrossMapNormalOp.cpp	/^  real pow_;$/;"	m	class:paddle::CrossMapNormalFunc	file:
pow_	function/CrossMapNormalOp.cpp	/^  real pow_;$/;"	m	class:paddle::CrossMapNormalGradFunc	file:
pow_	gserver/layers/NormLayer.h	/^  real scale_, pow_;$/;"	m	class:paddle::ResponseNormLayer
pow_op	cuda/include/hl_tensor_ops.h	/^  INLINE pow_op(const T s) : p(s) {}$/;"	f	class:hppl::unary::pow_op
pow_op	cuda/include/hl_tensor_ops.h	/^class pow_op {$/;"	c	namespace:hppl::unary
preOutput_	gserver/layers/HierarchicalSigmoidLayer.h	/^  Argument preOutput_;$/;"	m	class:paddle::HierarchicalSigmoidLayer
preOutput_	gserver/layers/LstmLayer.h	/^  Argument preOutput_;$/;"	m	class:paddle::LstmLayer
preallocatedBuf_	math/RowBuffer.h	/^  CpuMemHandlePtr preallocatedBuf_;$/;"	m	class:paddle::RowBuffer
predictArray_	gserver/evaluators/Evaluator.h	/^  std::vector<PredictionResult> predictArray_;$/;"	m	class:paddle::PnpairEvaluator
predictArray_	gserver/layers/ValidationLayer.h	/^  std::vector<PredictionResult> predictArray_;$/;"	m	class:paddle::AucValidation
predictOutputDir	trainer/TesterConfig.h	/^  std::string predictOutputDir;$/;"	m	struct:paddle::TesterConfig
predict_file	utils/Flags.h	/^DECLARE_string(predict_file);$/;"	v
prediction	trainer/tests/simple_sparse_neural_network.py	/^prediction = fc_layer(input=embedding, size=10, act=SoftmaxActivation())$/;"	v
prefetch	api/GradientMachine.cpp	/^void GradientMachine::prefetch(const Arguments& inArgs) {$/;"	f	class:GradientMachine
prefetch	gserver/gradientmachines/GradientMachine.h	/^  virtual void prefetch(const std::vector<Argument>& inArgs) { (void)inArgs; }$/;"	f	class:paddle::GradientMachine
prefetch	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::prefetch(const std::vector<Argument>& inArgs) {$/;"	f	class:paddle::MultiGradientMachine
prefetch	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::prefetch() {$/;"	f	class:paddle::TrainerThread
prefetch	gserver/gradientmachines/MultiNetwork.cpp	/^void MultiNetwork::prefetch(const std::vector<Argument>& inArgs) {$/;"	f	class:paddle::MultiNetwork
prefetch	gserver/gradientmachines/NeuralNetwork.cpp	/^void NeuralNetwork::prefetch(const std::vector<Argument>& inArgs) {$/;"	f	class:paddle::NeuralNetwork
prefetch	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::prefetch(const std::vector<Argument>& inArgs) {$/;"	f	class:paddle::RecurrentGradientMachine
prefetch	gserver/layers/FullyConnectedLayer.cpp	/^void FullyConnectedLayer::prefetch() {$/;"	f	class:paddle::FullyConnectedLayer
prefetch	gserver/layers/Layer.h	/^  virtual void prefetch() {}$/;"	f	class:paddle::Layer
prefetch	gserver/layers/MixedLayer.cpp	/^void MixedLayer::prefetch() {$/;"	f	class:paddle::MixedLayer
prefetch	gserver/layers/Operator.h	/^  virtual void prefetch(const Argument* in) {}$/;"	f	class:paddle::Operator
prefetch	gserver/layers/Projection.h	/^  virtual void prefetch(const Argument* in) {}$/;"	f	class:paddle::Projection
prefetch	gserver/layers/SelectiveFullyConnectedLayer.cpp	/^void SelectiveFullyConnectedLayer::prefetch() {}$/;"	f	class:paddle::SelectiveFullyConnectedLayer
prefetch	gserver/layers/TableProjection.cpp	/^void TableProjection::prefetch(const Argument* in) {$/;"	f	class:paddle::TableProjection
prepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void prepare(Argument& argument, PyObject* obj) { ++cnt_; }$/;"	f	class:paddle::IndexScanner
prepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void prepare(Argument& argument, PyObject* obj) { ++height_; }$/;"	f	class:paddle::DenseScanner
prepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void prepare(Argument& argument, PyObject* obj) {$/;"	f	class:paddle::SequenceScanner
prepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void prepare(Argument& argument, PyObject* obj) {$/;"	f	class:paddle::SparseNonValueScanner
prepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void prepare(Argument& argument, PyObject* obj) {}$/;"	f	class:paddle::IFieldScanner
prepareData	gserver/tests/test_ProtoDataProvider.cpp	/^void prepareData(DataBatch* batch,$/;"	f
prepareData	pserver/BaseClient.h	/^  void prepareData(int clientId,$/;"	f	class:paddle::BaseClient
prepareInArgs	trainer/tests/test_recurrent_machine_generation.cpp	/^void prepareInArgs(vector<Argument>& inArgs,$/;"	f
prepareSamples	gserver/layers/NCELayer.cpp	/^  void prepareSamples() {$/;"	f	class:paddle::NCELayer
prepareSendData	pserver/ParameterClient2.cpp	/^void ParameterClient2::prepareSendData($/;"	f	class:paddle::ParameterClient2
prepared_	gserver/layers/NCELayer.cpp	/^  bool prepared_;$/;"	m	class:paddle::NCELayer	file:
prevBatchOutput2_	gserver/layers/LstmLayer.h	/^  MatrixPtr prevBatchOutput2_;$/;"	m	class:paddle::LstmLayer
prevBatchState	trainer/TesterConfig.h	/^  bool prevBatchState;$/;"	m	struct:paddle::TesterConfig
prevNumUpdates_	parameter/AverageOptimizer.h	/^  int64_t prevNumUpdates_;$/;"	m	class:paddle::AverageOptimizer
prevOutGrad	cuda/include/hl_base.h	/^  real *prevOutGrad;$/;"	m	struct:__anon7
prevOutValue	cuda/include/hl_base.h	/^  real *prevOutValue;$/;"	m	struct:__anon6
prevOutput2Batch	gserver/layers/SequenceToBatch.cpp	/^void SequenceToBatch::prevOutput2Batch(Matrix &src, Matrix &dst) {$/;"	f	class:paddle::SequenceToBatch
prevOutput_	gserver/layers/GatedRecurrentLayer.h	/^  MatrixPtr prevOutput_;$/;"	m	class:paddle::GatedRecurrentLayer
prevOutput_	gserver/layers/LstmLayer.h	/^  MatrixPtr prevOutput_;$/;"	m	class:paddle::LstmLayer
prevOutput_	gserver/layers/RecurrentLayer.cpp	/^  MatrixPtr prevOutput_;$/;"	m	class:paddle::RecurrentLayer	file:
prevStateGrad	cuda/include/hl_base.h	/^  real *prevStateGrad;$/;"	m	struct:__anon5
prevStateValue	cuda/include/hl_base.h	/^  real *prevStateValue;$/;"	m	struct:__anon4
prevState_	gserver/layers/LstmLayer.h	/^  MatrixPtr prevState_;$/;"	m	class:paddle::LstmLayer
prev_batch_state	gserver/layers/LstmLayer.cpp	/^DECLARE_bool(prev_batch_state);$/;"	v
prev_batch_state	gserver/tests/test_BatchNorm.cpp	/^DECLARE_bool(prev_batch_state);$/;"	v
prev_batch_state	gserver/tests/test_ConvTrans.cpp	/^DECLARE_bool(prev_batch_state);$/;"	v
prev_batch_state	gserver/tests/test_ConvUnify.cpp	/^DECLARE_bool(prev_batch_state);$/;"	v
prev_batch_state	gserver/tests/test_LayerGrad.cpp	/^DECLARE_bool(prev_batch_state);$/;"	v
prev_batch_state	utils/Flags.h	/^DECLARE_bool(prev_batch_state);$/;"	v
print	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::print(std::ostream& os) const {$/;"	f	class:paddle::CpuSparseMatrix
print	math/Matrix.cpp	/^void CpuMatrix::print(std::ostream& os) const {$/;"	f	class:paddle::CpuMatrix
print	math/Matrix.cpp	/^void CpuMatrix::print(std::ostream& os, size_t height, size_t width) const {$/;"	f	class:paddle::CpuMatrix
print	math/Matrix.cpp	/^void GpuMatrix::print(std::ostream& os) const {$/;"	f	class:paddle::GpuMatrix
print	math/Matrix.cpp	/^void GpuMatrix::print(std::ostream& os, size_t height, size_t width) const {$/;"	f	class:paddle::GpuMatrix
print	math/Matrix.h	/^  virtual void print(std::ostream& os) const {$/;"	f	class:paddle::Matrix
print	math/Matrix.h	/^  virtual void print(std::ostream& os, size_t height, size_t width) const {$/;"	f	class:paddle::Matrix
print	math/SparseMatrix.cpp	/^void GpuSparseMatrix::print(std::ostream& os) const {$/;"	f	class:paddle::GpuSparseMatrix
print	math/Vector.cpp	/^void CpuVectorT<int>::print(std::ostream& os, size_t num) const {$/;"	f	class:paddle::CpuVectorT
print	math/Vector.cpp	/^void CpuVectorT<real>::print(std::ostream& os, size_t num) const {$/;"	f	class:paddle::CpuVectorT
print	math/Vector.cpp	/^void GpuVectorT<int>::print(std::ostream& os, size_t num) const {$/;"	f	class:paddle::GpuVectorT
print	math/Vector.cpp	/^void GpuVectorT<real>::print(std::ostream& os, size_t num) const {$/;"	f	class:paddle::GpuVectorT
printAll	math/PoolAllocator.cpp	/^void PoolAllocator::printAll() {$/;"	f	class:paddle::PoolAllocator
printAllStatus	utils/Stat.cpp	/^void StatSet::printAllStatus() {$/;"	f	class:paddle::StatSet
printAsyncGradientCommitStatAndReset	pserver/ParameterServer2.cpp	/^void ParameterServer2::printAsyncGradientCommitStatAndReset() {$/;"	f	class:paddle::ParameterServer2
printBarrierTimerStatus	utils/Stat.cpp	/^void StatSet::printBarrierTimerStatus() {$/;"	f	class:paddle::StatSet
printBuf	math/CpuSparseMatrix.cpp	/^void printBuf(std::ostream& os, T* a, size_t len, const char* name) {$/;"	f	namespace:paddle
printBuf	math/SparseMatrix.cpp	/^void printBuf(std::ostream& os, T* a, size_t len, const char* name) {$/;"	f	namespace:paddle
printOneElement	math/Vector.cpp	/^void CpuVectorT<int>::printOneElement(std::ostream& os, size_t idx) const {$/;"	f	class:paddle::CpuVectorT
printOneElement	math/Vector.cpp	/^void CpuVectorT<real>::printOneElement(std::ostream& os, size_t idx) const {$/;"	f	class:paddle::CpuVectorT
printOneElement	math/Vector.cpp	/^void GpuVectorT<int>::printOneElement(std::ostream& os, size_t idx) const {$/;"	f	class:paddle::GpuVectorT
printOneElement	math/Vector.cpp	/^void GpuVectorT<real>::printOneElement(std::ostream& os, size_t idx) const {$/;"	f	class:paddle::GpuVectorT
printOneRow	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::printOneRow(std::ostream& os, size_t idx) const {$/;"	f	class:paddle::CpuSparseMatrix
printOneRow	math/Matrix.cpp	/^void CpuMatrix::printOneRow(std::ostream& os, size_t idx) const {$/;"	f	class:paddle::CpuMatrix
printOneRow	math/Matrix.h	/^  virtual void printOneRow(std::ostream& os, size_t idx) const {$/;"	f	class:paddle::Matrix
printOutput	trainer/Tester.cpp	/^void Tester::printOutput(const std::vector<Argument>& outArgs,$/;"	f	class:paddle::Tester
printPredictResults	gserver/evaluators/Evaluator.h	/^  void printPredictResults() {$/;"	f	class:paddle::PnpairEvaluator
printSegTimerStatus	utils/Stat.cpp	/^void StatSet::printSegTimerStatus() {$/;"	f	class:paddle::StatSet
printStats	gserver/evaluators/CTCErrorEvaluator.cpp	/^  virtual void printStats(std::ostream& os) const {$/;"	f	class:paddle::CTCErrorEvaluator
printStats	gserver/evaluators/ChunkEvaluator.cpp	/^  virtual void printStats(std::ostream& os) const {$/;"	f	class:paddle::ChunkEvaluator
printStats	gserver/evaluators/Evaluator.cpp	/^  virtual void printStats(std::ostream& os) const {$/;"	f	class:paddle::ColumnSumEvaluator
printStats	gserver/evaluators/Evaluator.cpp	/^void PrecisionRecallEvaluator::printStats(std::ostream& os) const {$/;"	f	class:paddle::PrecisionRecallEvaluator
printStats	gserver/evaluators/Evaluator.h	/^  virtual void printStats(std::ostream& os) const {$/;"	f	class:paddle::AucEvaluator
printStats	gserver/evaluators/Evaluator.h	/^  virtual void printStats(std::ostream& os) const {$/;"	f	class:paddle::Evaluator
printStats	gserver/evaluators/Evaluator.h	/^  virtual void printStats(std::ostream& os) const {$/;"	f	class:paddle::PnpairEvaluator
printStats	gserver/evaluators/Evaluator.h	/^  virtual void printStats(std::ostream&) const {}$/;"	f	class:paddle::DummyEvaluator
printStats	gserver/gradientmachines/MultiNetwork.cpp	/^  virtual void printStats(std::ostream& os) const {$/;"	f	class:paddle::MultiCombinedEvaluator
printStats	gserver/gradientmachines/NeuralNetwork.cpp	/^  virtual void printStats(std::ostream& os) const {$/;"	f	class:paddle::CombinedEvaluator
printStatus	utils/Stat.cpp	/^void StatSet::printStatus(const std::string& name) {$/;"	f	class:paddle::StatSet
printVersion	utils/Version.cpp	/^void printVersion() {$/;"	f	namespace:paddle::version
printVersion	utils/Version.cpp	/^void printVersion(std::ostream& os) {$/;"	f	namespace:paddle::version
private	math/tests/test_Allocator.cpp	18;"	d	file:
prob	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^prob = fc_layer($/;"	v
prob	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^prob = fc_layer($/;"	v
probHistory	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::vector<real> probHistory;$/;"	m	struct:paddle::RecurrentGradientMachine::Path
probeDistribution	pserver/SparseParameterDistribution.cpp	/^void SparseParameterDistribution::probeDistribution(int serverId,$/;"	f	class:paddle::SparseParameterDistribution
process	gserver/tests/sequenceGen.py	/^def process(settings, file_name):$/;"	f
process	trainer/tests/simple_sparse_neural_network_dp.py	/^def process(settings, filename):$/;"	f
process2	gserver/tests/sequenceGen.py	/^def process2(settings, file_name):$/;"	f
processNonSequenceData	trainer/tests/testPyDataWrapper.py	/^def processNonSequenceData(obj, filename):$/;"	f
processSeqAndGenerateData	trainer/tests/testPyDataWrapper.py	/^def processSeqAndGenerateData(obj, name):$/;"	f
processSeqAndGenerateDataInit	trainer/tests/testPyDataWrapper.py	/^def processSeqAndGenerateDataInit(obj, *args, **kwargs):$/;"	f
processSubSeqAndGenerateData	trainer/tests/testPyDataWrapper.py	/^def processSubSeqAndGenerateData(obj, name):$/;"	f
processSubSeqAndGenerateDataInit	trainer/tests/testPyDataWrapper.py	/^def processSubSeqAndGenerateDataInit(obj, *args, **kwargs):$/;"	f
process_seq	gserver/tests/rnn_data_provider.py	/^def process_seq(settings, file_name):$/;"	f
process_seq2	gserver/tests/rnn_data_provider.py	/^def process_seq2(settings, file_name):$/;"	f
process_subseq	gserver/tests/rnn_data_provider.py	/^def process_subseq(settings, file_name):$/;"	f
process_subseq2	gserver/tests/rnn_data_provider.py	/^def process_subseq2(settings, file_name):$/;"	f
process_unequalength_seq	gserver/tests/rnn_data_provider.py	/^def process_unequalength_seq(settings, file_name):$/;"	f
process_unequalength_subseq	gserver/tests/rnn_data_provider.py	/^def process_unequalength_subseq(settings, file_name):$/;"	f
profilerSwitch	utils/Util.cpp	/^static void profilerSwitch(int signalNumber) {$/;"	f	file:
projCol_	gserver/layers/ConcatenateLayer.cpp	/^  std::vector<std::pair<size_t, size_t>> projCol_;$/;"	m	class:paddle::ConcatenateLayer2	file:
projCol_	gserver/layers/SpatialPyramidPoolLayer.h	/^  std::vector<std::pair<size_t, size_t>> projCol_;$/;"	m	class:paddle::SpatialPyramidPoolLayer
projConf_	gserver/layers/CudnnConvLayer.h	/^  std::vector<std::unique_ptr<ProjectionConfig>> projConf_;$/;"	m	class:paddle::CudnnConvLayer
projOutput_	gserver/layers/ConcatenateLayer.cpp	/^  std::vector<Argument> projOutput_;$/;"	m	class:paddle::ConcatenateLayer2	file:
projOutput_	gserver/layers/SpatialPyramidPoolLayer.h	/^  std::vector<Argument> projOutput_;$/;"	m	class:paddle::SpatialPyramidPoolLayer
projectionConfig_	gserver/layers/PoolProjectionLayer.h	/^  ProjectionConfig projectionConfig_;$/;"	m	class:paddle::PoolProjectionLayer
projectionStateMatrixSize_	gserver/layers/MixedLayer.h	/^  std::vector<int> projectionStateMatrixSize_;$/;"	m	class:paddle::MixedLayer
projections_	gserver/layers/ConcatenateLayer.cpp	/^  std::vector<std::unique_ptr<Projection>> projections_;$/;"	m	class:paddle::ConcatenateLayer2	file:
projections_	gserver/layers/CudnnConvLayer.h	/^  std::vector<std::unique_ptr<Projection>> projections_;$/;"	m	class:paddle::CudnnConvLayer
projections_	gserver/layers/MixedLayer.h	/^  std::vector<std::unique_ptr<Projection>> projections_;$/;"	m	class:paddle::MixedLayer
protected	gserver/tests/test_RecurrentLayer.cpp	222;"	d	file:
provider_	gserver/dataproviders/DataProviderGroup.h	/^  ProviderPtrType provider_;$/;"	m	class:paddle::DataProviderGroup
pservers	pserver/BaseClient.cpp	/^DECLARE_string(pservers);$/;"	v
pullCV_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::condition_variable pullCV_;$/;"	m	class:paddle::PyDataProvider2	file:
push	utils/CustomStackTrace.h	/^  void push(const T& item) {$/;"	f	class:paddle::CustomStackTrace
pushCV_	gserver/dataproviders/PyDataProvider2.cpp	/^  std::condition_variable pushCV_;$/;"	m	class:paddle::PyDataProvider2	file:
push_back	trainer/tests/picojson.h	/^    void push_back(int) {}$/;"	f	struct:picojson::null_parse_context::dummy_str
pushing	utils/CustomStackTrace.h	/^  bool& pushing() {$/;"	f	class:paddle::CustomStackTrace
pushingBuffers_	utils/CustomStackTrace.h	/^  std::unordered_map<std::thread::id, bool*> pushingBuffers_;$/;"	m	class:paddle::CustomStackTrace
putData	pserver/BaseClient.h	/^  void putData(int clientId,$/;"	f	class:paddle::BaseClient
putIntoArg	py_paddle/util.py	/^        def putIntoArg(self, slot_idx, arg, mat):$/;"	m	class:DataProviderWrapperConverter.SparseNonValueConverter
putOwnData	pserver/BaseClient.h	/^  void putOwnData(int clientId,$/;"	f	class:paddle::BaseClient
pv_	gserver/evaluators/Evaluator.h	/^  MatrixPtr pv_;$/;"	m	class:paddle::RankAucEvaluator
pvd	trainer/tests/testPyDataWrapper.py	/^    pvd = processNonSequenceData("test.txt")$/;"	v
pvd	trainer/tests/testPyDataWrapper.py	/^    pvd = processSeqAndGenerateData("_")$/;"	v
pvd	trainer/tests/testPyDataWrapper.py	/^    pvd = processSubSeqAndGenerateData("_")$/;"	v
py	utils/PythonUtil.h	/^namespace py {$/;"	n	namespace:paddle
pyClassName_	gserver/dataproviders/PyDataProvider.h	/^  std::string pyClassName_;$/;"	m	class:paddle::PyDataProvider
pyModuleName_	gserver/dataproviders/PyDataProvider.h	/^  std::string pyModuleName_;$/;"	m	class:paddle::PyDataProvider
pyUserArgs_	gserver/dataproviders/PyDataProvider.h	/^  std::map<std::string, std::string> pyUserArgs_;$/;"	m	class:paddle::PyDataProvider
pydp2	gserver/dataproviders/PyDataProvider2.cpp	/^namespace pydp2 {$/;"	n	namespace:paddle::unittest	file:
pydp2	gserver/tests/test_PyDataProvider2.cpp	/^namespace pydp2 {$/;"	n	namespace:paddle::unittest	file:
pyramidHeight_	gserver/layers/SpatialPyramidPoolLayer.h	/^  size_t pyramidHeight_;$/;"	m	class:paddle::SpatialPyramidPoolLayer
queryid	gserver/evaluators/Evaluator.h	/^    int queryid;$/;"	m	struct:paddle::PnpairEvaluator::PredictionResult
queueCV_	utils/Queue.h	/^  std::condition_variable queueCV_;$/;"	m	class:paddle::Queue
queueLock_	utils/Queue.h	/^  std::mutex queueLock_;$/;"	m	class:paddle::Queue
queue_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  JobQueue queue_;$/;"	m	class:paddle::ParallelThread
queue_	utils/Queue.h	/^  std::deque<T> queue_;$/;"	m	class:paddle::BlockingQueue
r	function/Function.h	/^    real r;$/;"	m	union:paddle::FuncConfig::value
rand	math/Vector.cpp	/^void CpuVectorT<int>::rand() {$/;"	f	class:paddle::CpuVectorT
rand	math/Vector.cpp	/^void CpuVectorT<int>::rand(size_t classNum) {$/;"	f	class:paddle::CpuVectorT
rand	math/Vector.cpp	/^void CpuVectorT<real>::rand() {$/;"	f	class:paddle::CpuVectorT
rand	math/Vector.cpp	/^void CpuVectorT<real>::rand(size_t classNum) {$/;"	f	class:paddle::CpuVectorT
rand	math/Vector.cpp	/^void GpuVectorT<int>::rand() {$/;"	f	class:paddle::GpuVectorT
rand	math/Vector.cpp	/^void GpuVectorT<int>::rand(size_t classNum) {$/;"	f	class:paddle::GpuVectorT
rand	math/Vector.cpp	/^void GpuVectorT<real>::rand() {$/;"	f	class:paddle::GpuVectorT
rand	math/Vector.cpp	/^void GpuVectorT<real>::rand(size_t classNum) {$/;"	f	class:paddle::GpuVectorT
rand	utils/ThreadLocal.h	/^  static int rand() { return rand_r(getSeed()); }$/;"	f	class:paddle::ThreadLocalRand
rand1_	gserver/layers/SamplingIdLayer.cpp	/^  std::uniform_real_distribution<double> rand1_;$/;"	m	class:paddle::SamplingIdLayer	file:
randParameters	api/GradientMachine.cpp	/^void GradientMachine::randParameters() { m->machine->randParameters(); }$/;"	f	class:GradientMachine
randParameters	gserver/gradientmachines/GradientMachine.cpp	/^void GradientMachine::randParameters() {$/;"	f	class:paddle::GradientMachine
randParametersRemote	parameter/ParameterUpdaterBase.h	/^  virtual void randParametersRemote() {$/;"	f	class:paddle::ParameterUpdaterComposite
randParametersRemote	parameter/ParameterUpdaterBase.h	/^  virtual void randParametersRemote() {}$/;"	f	class:paddle::ParameterUpdater
randParametersRemote	trainer/RemoteParameterUpdater.cpp	/^void SparseRemoteParameterUpdater::randParametersRemote() {$/;"	f	class:paddle::SparseRemoteParameterUpdater
randStr	testing/TestUtil.cpp	/^std::string randStr(const int len) {$/;"	f	namespace:paddle
rand_	gserver/layers/MultinomialSampler.h	/^  std::uniform_real_distribution<double> rand_;$/;"	m	class:paddle::MultinomialSampler
rand_	gserver/layers/NCELayer.cpp	/^  std::uniform_int_distribution<int> rand_;$/;"	m	class:paddle::NCELayer	file:
randint	gserver/tests/test_SelectiveFCLayer.cpp	/^int randint(int* data, size_t int_max, size_t size) {$/;"	f
randnorm	math/Vector.cpp	/^void CpuVectorT<T>::randnorm(real, real) {$/;"	f	class:paddle::CpuVectorT
randnorm	math/Vector.cpp	/^void CpuVectorT<real>::randnorm(real mean, real std) {$/;"	f	class:paddle::CpuVectorT
randnorm	math/Vector.cpp	/^void GpuVectorT<T>::randnorm(real, real) {$/;"	f	class:paddle::GpuVectorT
randnorm	math/Vector.cpp	/^void GpuVectorT<real>::randnorm(real mean, real std) {$/;"	f	class:paddle::GpuVectorT
randnorm	math/Vector.h	/^  virtual void randnorm(real mean, real standardDeviation) {$/;"	f	class:paddle::ParallelCpuVectorT
random_str	trainer/tests/testPyDataWrapper.py	/^def random_str(size=8, chars=string.ascii_letters + string.digits):$/;"	f
randomize	parameter/Parameter.cpp	/^void Parameter::randomize() {$/;"	f	class:paddle::Parameter
randomize	parameter/Parameter.cpp	/^void Parameter::randomize(const VectorPtr& value,$/;"	f	class:paddle::Parameter
randomizeUniform	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::randomizeUniform() {$/;"	f	class:paddle::CpuSparseMatrix
randomizeUniform	math/Matrix.cpp	/^void CpuMatrix::randomizeUniform() {$/;"	f	class:paddle::CpuMatrix
randomizeUniform	math/Matrix.cpp	/^void GpuMatrix::randomizeUniform() {$/;"	f	class:paddle::GpuMatrix
randomizeUniform	math/Matrix.h	/^  virtual void randomizeUniform() { LOG(FATAL) << "Not implemented"; }$/;"	f	class:paddle::Matrix
rangeReciprocal_	gserver/layers/DataNormLayer.h	/^  MatrixPtr rangeReciprocal_;  \/\/ 1\/(max-min)$/;"	m	class:paddle::DataNormLayer
rateThreshold_	utils/BarrierStat.h	/^  float rateThreshold_;$/;"	m	class:paddle::BarrierStatBase
rates_	parameter/LearningRateScheduler.cpp	/^  std::vector<real> rates_;$/;"	m	class:paddle::ManualLRS	file:
ratioH_	gserver/layers/BilinearInterpLayer.h	/^  real ratioH_, ratioW_;$/;"	m	class:paddle::BilinearInterpLayer
ratioW_	gserver/layers/BilinearInterpLayer.h	/^  real ratioH_, ratioW_;$/;"	m	class:paddle::BilinearInterpLayer
rawPtr	api/PaddleAPIPrivate.h	/^  paddle::Evaluator* rawPtr;$/;"	m	struct:EvaluatorPrivate
rawPtr	api/PaddleAPIPrivate.h	/^  paddle::Parameter* rawPtr;  \/\/ rawPtr only used in ParameterUpdater,$/;"	m	struct:ParameterPrivate
rbegin	gserver/layers/MDLstmLayer.cpp	/^  std::vector<int>& rbegin() {$/;"	f	class:paddle::CoordIterator
rdma	pserver/RDMANetwork.h	/^namespace rdma {$/;"	n	namespace:paddle
rdmaClientSocket_	pserver/LightNetwork.h	/^  std::vector<struct sxi_socket*> rdmaClientSocket_;$/;"	m	class:paddle::RdmaClientDaemons
rdmaCpu_	pserver/LightNetwork.h	/^  int rdmaCpu_;$/;"	m	class:paddle::SocketServer
rdmaServer	pserver/LightNetwork.cpp	/^void SocketServer::rdmaServer() {$/;"	f	class:paddle::SocketServer
rdmaSocket_	pserver/LightNetwork.h	/^  sxi_socket* rdmaSocket_;$/;"	m	class:paddle::SocketServer
rdmaSocket_	pserver/SocketChannel.h	/^  struct sxi_sock* rdmaSocket_;$/;"	m	class:paddle::SocketChannel	typeref:struct:paddle::SocketChannel::sxi_sock
rdmaUri_	pserver/LightNetwork.h	/^  std::string rdmaUri_;$/;"	m	class:paddle::SocketServer
rdma_tcp	trainer/TrainerMain.cpp	/^DECLARE_string(rdma_tcp);$/;"	v
rdma_tcp	utils/Flags.h	/^DECLARE_string(rdma_tcp);$/;"	v
read	gserver/dataproviders/ProtoReader.h	/^  bool read(google::protobuf::MessageLite* msg) {$/;"	f	class:paddle::ProtoReader
read	pserver/RDMANetwork.h	/^inline ssize_t read(sxi_sock* channel, void* data, size_t len) {$/;"	f	namespace:paddle::rdma
read	pserver/SocketChannel.cpp	/^size_t SocketChannel::read(void* buf, size_t size) {$/;"	f	class:paddle::SocketChannel
readAll	pserver/test/SocketTest.cpp	/^uint64_t SocketChannel::readAll(void* buf, size_t size) {$/;"	f	class:SocketChannel
readAllBlocks	pserver/ParameterServer2.cpp	/^void ParameterServer2::readAllBlocks($/;"	f	class:paddle::ParameterServer2
readBlocks	pserver/SocketChannel.cpp	/^void MsgReader::readBlocks(const std::vector<void*>& bufs) {$/;"	f	class:paddle::MsgReader
readDataBatch	gserver/tests/test_PyDataProvider2.cpp	/^static inline int64_t readDataBatch(paddle::DataBatch *batch,$/;"	f	file:
readFile	utils/Util.cpp	/^std::string readFile(const std::string& fileName) {$/;"	f	namespace:paddle
readMessage	pserver/SocketChannel.cpp	/^std::unique_ptr<MsgReader> SocketChannel::readMessage() {$/;"	f	class:paddle::SocketChannel
readNextBlock	pserver/SocketChannel.cpp	/^void MsgReader::readNextBlock(void* buf) {$/;"	f	class:paddle::MsgReader
readPyFields	gserver/dataproviders/PyDataProvider2.cpp	/^  void readPyFields(bool testing) {$/;"	f	class:paddle::PyDataProvider2	file:
readRetFile	trainer/tests/test_recurrent_machine_generation.cpp	/^vector<float> readRetFile(const string& fname) {$/;"	f
readT	utils/Util.h	/^T readT(char*& p, const char* pEnd) {$/;"	f	namespace:paddle
readWriteBuffer_	pserver/ParameterServer2.h	/^  ThreadLocal<ReadWriteBuffer<real, ALIGN_HINT>> readWriteBuffer_;$/;"	m	class:paddle::ParameterServer2
readv	pserver/RDMANetwork.h	/^inline ssize_t readv(sxi_sock* channel, iovec* iov, int count) {$/;"	f	namespace:paddle::rdma
readv	pserver/SocketChannel.cpp	/^size_t SocketChannel::readv(std::vector<struct iovec>* iovs) {$/;"	f	class:paddle::SocketChannel
readwritev	pserver/SocketChannel.cpp	/^static size_t readwritev(IOFunc iofunc,$/;"	f	namespace:paddle
realColumnIdx_	gserver/evaluators/Evaluator.h	/^  uint32_t realColumnIdx_;$/;"	m	class:paddle::AucEvaluator
realDeviceId2LogicalDeviceId	gserver/gradientmachines/MultiGradientMachine.h	/^  int realDeviceId2LogicalDeviceId(int realId, int threadId = 0) const {$/;"	f	class:paddle::MultiGradientMachine
realLayer_	gserver/layers/AgentLayer.h	/^  LayerPtr realLayer_;$/;"	m	class:paddle::AgentLayer
realLayer_	gserver/layers/AgentLayer.h	/^  LayerPtr realLayer_;$/;"	m	class:paddle::ScatterAgentLayer
realLayers_	gserver/layers/AgentLayer.h	/^  std::vector<LayerPtr> realLayers_;$/;"	m	class:paddle::GatherAgentLayer
realOutArg_	gserver/layers/AgentLayer.h	/^  Argument realOutArg_;$/;"	m	class:paddle::ScatterAgentLayer
rebind	utils/Util.h	/^  struct rebind {$/;"	s	class:paddle::AlignedAllocator
reciprocal	cuda/include/hl_tensor_ops.h	/^class reciprocal {$/;"	c	namespace:hppl::unary
reciprocal	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::reciprocal<T>, const Derived, T> reciprocal()$/;"	f	class:paddle::TensorExpression
reciprocalRowSum_	gserver/layers/SumToOneNormLayer.cpp	/^  MatrixPtr reciprocalRowSum_;$/;"	m	class:paddle::SumToOneNormLayer	file:
recordHistory	gserver/gradientmachines/RecurrentGradientMachine.h	/^    void recordHistory() { this->probHistory.push_back(this->logProb); }$/;"	f	struct:paddle::RecurrentGradientMachine::Path
recv	pserver/ParameterClient2.cpp	/^void ParameterClient2::recv(int threadId) {$/;"	f	class:paddle::ParameterClient2
recv	pserver/ProtoServer.cpp	/^std::unique_ptr<MsgReader> ProtoClient::recv($/;"	f	class:paddle::ProtoClient
recv	trainer/RemoteParameterUpdater.cpp	/^void ConcurrentRemoteParameterUpdater::recv() {$/;"	f	class:paddle::ConcurrentRemoteParameterUpdater
recv	trainer/RemoteParameterUpdater.cpp	/^void ConcurrentRemoteParameterUpdater::recv(Parameter* para) {$/;"	f	class:paddle::ConcurrentRemoteParameterUpdater
recvData	pserver/BaseClient.cpp	/^void BaseClient::recvData() { recvSyncBarrier_->wait(); }$/;"	f	class:paddle::BaseClient
recvDataMems_	pserver/BaseClient.h	/^  std::vector<CpuMemHandlePtr> recvDataMems_;$/;"	m	class:paddle::BaseClient
recvJobQueue_	pserver/BaseClient.h	/^  std::vector<std::unique_ptr<SendQueue>> recvJobQueue_;$/;"	m	class:paddle::BaseClient
recvParameter	pserver/ParameterClient2.cpp	/^void ParameterClient2::recvParameter() { recvSyncBarrier_->wait(); }$/;"	f	class:paddle::ParameterClient2
recvQueue_	trainer/RemoteParameterUpdater.h	/^  Queue<int> recvQueue_;$/;"	m	class:paddle::ConcurrentRemoteParameterUpdater
recvSyncBarrier_	pserver/BaseClient.h	/^  std::unique_ptr<ThreadBarrier> recvSyncBarrier_;$/;"	m	class:paddle::BaseClient
recvThread_	trainer/RemoteParameterUpdater.h	/^  std::unique_ptr<std::thread> recvThread_;$/;"	m	class:paddle::ConcurrentRemoteParameterUpdater
recvThreads_	pserver/BaseClient.h	/^  std::vector<ThreadPtr> recvThreads_;$/;"	m	class:paddle::BaseClient
reduce	pserver/BaseClient.h	/^  void reduce(DataType* sendBuf,$/;"	f	class:paddle::BaseClient
reduceAndSendData	pserver/ParameterServer2.cpp	/^void ParameterServer2::reduceAndSendData(const SendDataRequest& request,$/;"	f	class:paddle::ParameterServer2
reference	utils/Util.h	/^  typedef T& reference;$/;"	t	class:paddle::AlignedAllocator
refine_unknown_args	scripts/cluster_train/paddle.py	/^def refine_unknown_args(cmd_args):$/;"	f
regGradientMachineMode	gserver/gradientmachines/GradientMachineMode.h	/^  static void regGradientMachineMode($/;"	f	class:paddle::IGradientMachineMode
registerBeamSearchControlCallbacks	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::registerBeamSearchControlCallbacks($/;"	f	class:paddle::RecurrentGradientMachine
registerBeamSearchStatisticsCallbacks	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::registerBeamSearchStatisticsCallbacks($/;"	f	class:paddle::RecurrentGradientMachine
registerClass	utils/ClassRegistrar.h	/^  void registerClass(const std::string& type) {$/;"	f	class:paddle::ClassRegistrar
registerClass	utils/ClassRegistrar.h	/^  void registerClass(const std::string& type, ClassCreator creator) {$/;"	f	class:paddle::ClassRegistrar
registerInitFunction	utils/Util.cpp	/^void registerInitFunction(std::function<void()> func, int priority) {$/;"	f	namespace:paddle
registerServiceFunction	pserver/ProtoServer.h	/^void ProtoServer::registerServiceFunction($/;"	f	class:paddle::ProtoServer
registerServiceFunctionEx	pserver/ProtoServer.h	/^void ProtoServer::registerServiceFunctionEx($/;"	f	class:paddle::ProtoServer
registerServiceFunctionImp	pserver/ProtoServer.cpp	/^void ProtoServer::registerServiceFunctionImp(const std::string& funcName,$/;"	f	class:paddle::ProtoServer
registerTimerArg1	utils/Stat.h	/^inline uint64_t registerTimerArg1(uint64_t threshold = -1,$/;"	f	namespace:paddle
registerTimerArg2	utils/Stat.h	/^inline StatSet& registerTimerArg2(uint64_t threshold = -1,$/;"	f	namespace:paddle
registrar_	gserver/dataproviders/DataProvider.cpp	/^    DataProvider::registrar_;$/;"	m	class:paddle::DataProvider	file:
registrar_	gserver/dataproviders/DataProvider.h	/^  static ClassRegistrar<DataProvider, DataConfig, ModelConfig, bool> registrar_;$/;"	m	class:paddle::DataProvider
registrar_	gserver/evaluators/Evaluator.cpp	/^ClassRegistrar<Evaluator> Evaluator::registrar_;$/;"	m	class:paddle::Evaluator	file:
registrar_	gserver/evaluators/Evaluator.h	/^  static ClassRegistrar<Evaluator> registrar_;$/;"	m	class:paddle::Evaluator
registrar_	gserver/layers/Layer.cpp	/^ClassRegistrar<Layer, LayerConfig> Layer::registrar_;$/;"	m	class:paddle::Layer	file:
registrar_	gserver/layers/Layer.h	/^  static ClassRegistrar<Layer, LayerConfig> registrar_;$/;"	m	class:paddle::Layer
registrar_	gserver/layers/Operator.cpp	/^ClassRegistrar<Operator, OperatorConfig, bool> Operator::registrar_;$/;"	m	class:paddle::Operator	file:
registrar_	gserver/layers/Operator.h	/^  static ClassRegistrar<Operator, OperatorConfig, bool> registrar_;$/;"	m	class:paddle::Operator
registrar_	gserver/layers/Projection.cpp	/^    Projection::registrar_;$/;"	m	class:paddle::Projection	file:
registrar_	gserver/layers/Projection.h	/^      registrar_;$/;"	m	class:paddle::Projection
registrar_	parameter/LearningRateScheduler.cpp	/^    LearningRateScheduler::registrar_;$/;"	m	class:paddle::LearningRateScheduler	file:
registrar_	parameter/LearningRateScheduler.h	/^  static ClassRegistrar<LearningRateScheduler, OptimizationConfig> registrar_;$/;"	m	class:paddle::LearningRateScheduler
regularizer_	parameter/OptimizerWithRegularizer.h	/^  Regularizer* regularizer_;$/;"	m	class:paddle::OptimizerWithRegularizer
releaseMatrix	pserver/ParameterClient2.cpp	/^void ParameterClient2::releaseMatrix(PServerMatrix handle) {$/;"	f	class:paddle::ParameterClient2
releaseMatrix	pserver/ParameterServer2.cpp	/^void ParameterServer2::releaseMatrix(const ReleaseMatrixRequest& request,$/;"	f	class:paddle::ParameterServer2
releaseVector	pserver/ParameterClient2.cpp	/^void ParameterClient2::releaseVector(PServerVector handle) {$/;"	f	class:paddle::ParameterClient2
releaseVector	pserver/ParameterServer2.cpp	/^void ParameterServer2::releaseVector(const ReleaseVectorRequest& request,$/;"	f	class:paddle::ParameterServer2
release_ports	.common_test_util.sh	/^release_ports(){$/;"	f
relu	cuda/src/hl_avx_functions.cc	/^__m256 relu(const __m256 a) {$/;"	f	namespace:hppl
relu	cuda/src/hl_avx_functions.cc	/^__m256 relu(const __m256 a, const __m256 b) {$/;"	f	namespace:hppl
relu	cuda/src/hl_cpu_functions.cc	/^real relu(const real a) { return a > 0.0f ? a : 0.0f; }$/;"	f	namespace:hppl
relu	cuda/src/hl_cpu_functions.cc	/^real relu(const real a, const real b) { return a * (b > 0.0f ? 1.0f : 0.0f); }$/;"	f	namespace:hppl
removeBeamSearchControlCallbacks	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::removeBeamSearchControlCallbacks() {$/;"	f	class:paddle::RecurrentGradientMachine
removeBeamSearchStatisticsCallbacks	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::removeBeamSearchStatisticsCallbacks() {$/;"	f	class:paddle::RecurrentGradientMachine
removeOneBatch	gserver/dataproviders/DataProvider.cpp	/^void DoubleBuffer::removeOneBatch(DataBatch* dataBatch) {$/;"	f	class:paddle::DoubleBuffer
rep	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^rep = last_seq(input=context)$/;"	v
rep	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^rep = last_seq(input=context)$/;"	v
repr	utils/PythonUtil.h	/^inline char* repr(const PyObjectPtr& obj) { return repr(obj.get()); }$/;"	f	namespace:paddle::py
requestVec_	pserver/ParameterServer2.h	/^  ThreadLocal<std::vector<SendParameterRequest>> requestVec_;$/;"	m	class:paddle::ParameterServer2
request_	pserver/ParameterClient2.h	/^  DoOperationRequest request_;$/;"	m	class:paddle::PreparedOperations
reserveOutput	gserver/layers/Layer.cpp	/^void Layer::reserveOutput(size_t height, size_t width) {$/;"	f	class:paddle::Layer
reserveOutput	gserver/layers/SelectiveFullyConnectedLayer.cpp	/^void SelectiveFullyConnectedLayer::reserveOutput(size_t height,$/;"	f	class:paddle::SelectiveFullyConnectedLayer
reserveStore	math/SparseRowMatrix.h	/^  void reserveStore() { buf_->resize(localIndices_->size()); }$/;"	f	class:paddle::SparseRowCpuMatrix
reset	gserver/dataproviders/DataProvider.cpp	/^void SimpleDataProvider::reset() {$/;"	f	class:paddle::SimpleDataProvider
reset	gserver/dataproviders/DataProvider.cpp	/^void SimpleDataProviderBase::reset() {$/;"	f	class:paddle::SimpleDataProviderBase
reset	gserver/dataproviders/DataProvider.h	/^  virtual void reset() { DataProvider::reset(); }$/;"	f	class:paddle::DummyDataProvider
reset	gserver/dataproviders/DataProvider.h	/^  virtual void reset() {$/;"	f	class:paddle::DataProvider
reset	gserver/dataproviders/DataProviderGroup.h	/^void DataProviderGroup<T>::reset() {$/;"	f	class:paddle::DataProviderGroup
reset	gserver/dataproviders/MultiDataProvider.cpp	/^void MultiDataProvider::reset() {$/;"	f	class:paddle::MultiDataProvider
reset	gserver/dataproviders/ProtoDataProvider.cpp	/^void ProtoDataProvider::reset() {$/;"	f	class:paddle::ProtoDataProvider
reset	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::reset() {$/;"	f	class:paddle::PyDataProvider
reset	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual bool reset() { return true; }$/;"	f	class:paddle::NoCacheStrategy
reset	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual bool reset() {$/;"	f	class:paddle::CacheOnePassInMemory
reset	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void reset() {$/;"	f	class:paddle::PyDataProvider2
reset	gserver/tests/pyDataProvider.py	/^    def reset(self):$/;"	m	class:SimpleDataProvider
reset	gserver/tests/pyDataProvider.py	/^    def reset(self):$/;"	m	class:SimpleNestDataProvider
reset	math/Vector.cpp	/^void CpuVectorT<T>::reset(const T& value) {$/;"	f	class:paddle::CpuVectorT
reset	math/Vector.cpp	/^void GpuVectorT<T>::reset(const T& value) {$/;"	f	class:paddle::GpuVectorT
reset	trainer/TrainerInternalConfig.h	/^  inline void reset() {$/;"	f	class:paddle::TrainerStats
reset	utils/BarrierStat.cpp	/^void BarrierDeltaStat::reset(bool clearRawData) {$/;"	f	class:paddle::BarrierDeltaStat
reset	utils/BarrierStat.cpp	/^void BarrierEndStat::reset(bool clearRawData) {$/;"	f	class:paddle::BarrierEndStat
reset	utils/BarrierStat.h	/^  virtual void reset(bool clearRawData = true) {}$/;"	f	class:paddle::BarrierStatBase
reset	utils/BarrierStat.h	/^  void reset() { index_ = 0; }$/;"	f	class:paddle::TimeVectorEnd
reset	utils/BarrierStat.h	/^  void reset() {$/;"	f	class:paddle::TimeVectorDelta
reset	utils/Stat.cpp	/^void Stat::reset() {$/;"	f	class:paddle::Stat
reset	utils/Stat.cpp	/^void StatSet::reset(bool clearRawData) {$/;"	f	class:paddle::StatSet
reset	utils/Stat.h	/^  void reset() { total_ = 0; }$/;"	f	class:paddle::Timer
reset	utils/Stat.h	/^  void reset() {$/;"	f	class:paddle::StatInfo
resetAlignAlloc	pserver/ParameterServer2.h	/^    void resetAlignAlloc() { this->curOffset_ = 0; }$/;"	f	class:paddle::ParameterServer2::ReadWriteBuffer
resetCurrentStat	trainer/TrainerInternalConfig.h	/^  inline void resetCurrentStat() {$/;"	f	class:paddle::TrainerStats
resetExpandInput	gserver/layers/ExpandConvBaseLayer.cpp	/^void ExpandConvBaseLayer::resetExpandInput(size_t height, size_t width) {$/;"	f	class:paddle::ExpandConvBaseLayer
resetHeight	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^  void resetHeight(int height) {$/;"	f	class:paddle::BootBiasLayer
resetImpl	gserver/dataproviders/PyDataProvider2.cpp	/^  inline void resetImpl(bool startNewThread) {$/;"	f	class:paddle::PyDataProvider2	file:
resetOne	math/Matrix.cpp	/^void CpuMatrix::resetOne() {$/;"	f	class:paddle::CpuMatrix
resetOne	math/Matrix.cpp	/^void GpuMatrix::resetOne() {$/;"	f	class:paddle::GpuMatrix
resetOne	math/Matrix.h	/^  virtual void resetOne() { LOG(FATAL) << "Not implemented"; }$/;"	f	class:paddle::Matrix
resetOutput	gserver/layers/Layer.cpp	/^void Layer::resetOutput(size_t height, size_t width) {$/;"	f	class:paddle::Layer
resetOutputGrad	cuda/include/hl_base.h	/^  real *resetOutputGrad;$/;"	m	struct:__anon7
resetOutputValue	cuda/include/hl_base.h	/^  real *resetOutputValue;$/;"	m	struct:__anon6
resetOutput_	gserver/layers/GatedRecurrentLayer.h	/^  Argument resetOutput_;$/;"	m	class:paddle::GatedRecurrentLayer
resetOutput_	gserver/layers/GruStepLayer.cpp	/^  Argument resetOutput_;$/;"	m	class:paddle::GruStepLayer	file:
resetSlots	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::resetSlots() {$/;"	f	class:paddle::PyDataProvider
resetSpecifyOutput	gserver/layers/Layer.cpp	/^void Layer::resetSpecifyOutput(Argument& output,$/;"	f	class:paddle::Layer
resetState	gserver/gradientmachines/GradientMachine.h	/^  virtual void resetState() {}$/;"	f	class:paddle::GradientMachine
resetState	gserver/gradientmachines/NeuralNetwork.cpp	/^void NeuralNetwork::resetState() {$/;"	f	class:paddle::NeuralNetwork
resetState	gserver/gradientmachines/RecurrentGradientMachine.h	/^  virtual void resetState() {}$/;"	f	class:paddle::RecurrentGradientMachine
resetState	gserver/layers/ContextProjection.cpp	/^void ContextProjection::resetState() {$/;"	f	class:paddle::ContextProjection
resetState	gserver/layers/GatedRecurrentLayer.cpp	/^void GatedRecurrentLayer::resetState() {$/;"	f	class:paddle::GatedRecurrentLayer
resetState	gserver/layers/Layer.h	/^  virtual void resetState() {}$/;"	f	class:paddle::Layer
resetState	gserver/layers/LstmLayer.cpp	/^void LstmLayer::resetState() {$/;"	f	class:paddle::LstmLayer
resetState	gserver/layers/MixedLayer.cpp	/^void MixedLayer::resetState() {$/;"	f	class:paddle::MixedLayer
resetState	gserver/layers/Operator.h	/^  virtual void resetState() {}$/;"	f	class:paddle::Operator
resetState	gserver/layers/Projection.h	/^  virtual void resetState() {}$/;"	f	class:paddle::Projection
resetState	gserver/layers/RecurrentLayer.cpp	/^void RecurrentLayer::resetState() {$/;"	f	class:paddle::RecurrentLayer
reshape	function/TensorShape.h	/^  void reshape(std::initializer_list<size_t> dims) {$/;"	f	class:paddle::TensorShape
reshape	gserver/layers/ConvOperator.cpp	/^void ConvOperator::reshape(int batchSize) {$/;"	f	class:paddle::ConvOperator
reshape	gserver/layers/ConvProjection.cpp	/^void ConvProjection::reshape(int batchSize) {$/;"	f	class:paddle::ConvProjection
reshape	gserver/layers/CudnnBatchNormLayer.cpp	/^void CudnnBatchNormLayer::reshape(int batchSize) {$/;"	f	class:paddle::CudnnBatchNormLayer
reshape	gserver/layers/CudnnPoolLayer.cpp	/^void CudnnPoolLayer::reshape(int batchSize) {$/;"	f	class:paddle::CudnnPoolLayer
reshape	math/Matrix.cpp	/^void Matrix::reshape(size_t height, size_t width) {$/;"	f	class:paddle::Matrix
reshapeImageDescriptors	gserver/layers/ConvOperator.cpp	/^void ConvOperator::reshapeImageDescriptors() {$/;"	f	class:paddle::ConvOperator
reshapeTensorDesc	gserver/layers/ConvProjection.cpp	/^void ConvProjection::reshapeTensorDesc(int batchSize) {$/;"	f	class:paddle::ConvProjection
reshapedOutputGrad	gserver/layers/SequenceReshapeLayer.cpp	/^  MatrixPtr reshapedOutputGrad;$/;"	m	class:paddle::SequenceReshapeLayer	file:
resize	api/Arguments.cpp	/^void Arguments::resize(size_t slotNum) { m->outputs.resize(slotNum); }$/;"	f	class:Arguments
resize	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::resize(size_t newHeight, size_t newWidth) {$/;"	f	class:paddle::CpuSparseMatrix
resize	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::resize(size_t newHeight,$/;"	f	class:paddle::CpuSparseMatrix
resize	math/Matrix.cpp	/^void CpuMatrix::resize(size_t newHeight, size_t newWidth) {$/;"	f	class:paddle::CpuMatrix
resize	math/Matrix.cpp	/^void GpuMatrix::resize(size_t newHeight, size_t newWidth) {$/;"	f	class:paddle::GpuMatrix
resize	math/Matrix.h	/^  void resize(size_t newHeight,$/;"	f	class:paddle::CpuMatrix
resize	math/Matrix.h	/^  void resize(size_t newHeight,$/;"	f	class:paddle::GpuMatrix
resize	math/RowBuffer.h	/^  inline void resize(int rowCnt) {$/;"	f	class:paddle::RowBuffer
resize	math/SparseMatrix.cpp	/^void GpuSparseMatrix::resize(size_t newHeight, size_t newWidth) {$/;"	f	class:paddle::GpuSparseMatrix
resize	math/SparseMatrix.cpp	/^void GpuSparseMatrix::resize(size_t newHeight,$/;"	f	class:paddle::GpuSparseMatrix
resize	math/Vector.cpp	/^void CpuGpuVectorT<T>::resize(size_t size, bool useGpu) {$/;"	f	class:paddle::CpuGpuVectorT
resize	math/Vector.h	/^  void resize(size_t newSize) {$/;"	f	class:paddle::VectorT
resizeAndCopy	parameter/Argument.cpp	/^static void resizeAndCopy(ICpuGpuVectorPtr& dest,$/;"	f	namespace:paddle
resizeAndCopy	parameter/Argument.cpp	/^static void resizeAndCopy(IVectorPtr& dest,$/;"	f	namespace:paddle
resizeAndCopy	parameter/Argument.cpp	/^static void resizeAndCopy(MatrixPtr& dest,$/;"	f	namespace:paddle
resizeAndCopy	parameter/Argument.cpp	/^static void resizeAndCopy(SVectorPtr& dest,$/;"	f	namespace:paddle
resizeAndCopy	parameter/Argument.cpp	/^static void resizeAndCopy(UserDefinedVectorPtr& dest,$/;"	f	namespace:paddle
resizeAndCopyFrom	parameter/Argument.cpp	/^int32_t Argument::resizeAndCopyFrom(const Argument& src,$/;"	f	class:paddle::Argument
resizeAndCopyFrom	parameter/Argument.cpp	/^void Argument::resizeAndCopyFrom(const Argument& src, bool useGpu) {$/;"	f	class:paddle::Argument
resizeAndCopyFrom	parameter/Argument.cpp	/^void Argument::resizeAndCopyFrom(const Argument& src,$/;"	f	class:paddle::Argument
resizeBootFrame	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::resizeBootFrame(int numSequences) {$/;"	f	class:paddle::RecurrentGradientMachine
resizeCSC	math/SparseMatrix.cpp	/^void GpuSparseMatrix::resizeCSC(size_t newHeight,$/;"	f	class:paddle::GpuSparseMatrix
resizeCSR	math/SparseMatrix.cpp	/^void GpuSparseMatrix::resizeCSR(size_t newHeight,$/;"	f	class:paddle::GpuSparseMatrix
resizeOrCreate	gserver/layers/SequenceToBatch.cpp	/^void SequenceToBatch::resizeOrCreate(Matrix &seqValue) {$/;"	f	class:paddle::SequenceToBatch
resizeOrCreate	math/Matrix.cpp	/^void Matrix::resizeOrCreate($/;"	f	class:paddle::Matrix
resizeOrCreate	math/Vector.cpp	/^void CpuGpuVectorT<T>::resizeOrCreate(size_t size, bool useGpu) {$/;"	f	class:paddle::CpuGpuVectorT
resizeOrCreate	math/Vector.cpp	/^void CpuGpuVectorT<T>::resizeOrCreate(std::shared_ptr<CpuGpuVectorT<T>>& vec,$/;"	f	class:paddle::CpuGpuVectorT
resizeOrCreate	math/Vector.h	/^  static void resizeOrCreate(std::shared_ptr<VectorT<T>>& vec,$/;"	f	class:paddle::VectorT
resizeOrCreateBatch	gserver/layers/SequenceToBatch.cpp	/^void SequenceToBatch::resizeOrCreateBatch(int batchSize,$/;"	f	class:paddle::SequenceToBatch
resizeOrCreateFrames	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::resizeOrCreateFrames(int numFrames) {$/;"	f	class:paddle::RecurrentGradientMachine
resizeOrCreateSparseMatrix	math/Matrix.cpp	/^void Matrix::resizeOrCreateSparseMatrix(MatrixPtr& matrix,$/;"	f	class:paddle::Matrix
resizeOutput	gserver/layers/Layer.cpp	/^void Layer::resizeOutput(size_t height, size_t width) {$/;"	f	class:paddle::Layer
resizeWithAlignHints	pserver/ParameterServer2.h	/^    void resizeWithAlignHints(size_t size, size_t alignBlockCount = 1) {$/;"	f	class:paddle::ParameterServer2::ReadWriteBuffer
restart	gserver/gradientmachines/GradientMachine.h	/^  virtual void restart() {}$/;"	f	class:paddle::GradientMachine
restore	api/ParameterUpdater.cpp	/^void ParameterUpdater::restore() { m->updater->restore(); }$/;"	f	class:ParameterUpdater
restore	parameter/AverageOptimizer.cpp	/^ParameterOptimizer::TraverseCallback AverageOptimizer::restore() {$/;"	f	class:paddle::AverageOptimizer
restore	parameter/ParameterOptimizer.h	/^  virtual TraverseCallback restore() { return nullptr; }$/;"	f	class:paddle::ParameterOptimizer
restore	parameter/ParameterUpdaterBase.h	/^  virtual void restore() {$/;"	f	class:paddle::ParameterUpdaterComposite
restore	parameter/ParameterUpdaterBase.h	/^  virtual void restore() {}$/;"	f	class:paddle::ParameterUpdater
restore	trainer/ParameterUpdater.cpp	/^void SgdUpdaterWithCpuAverager::restore() {$/;"	f	class:paddle::SgdUpdaterWithCpuAverager
restore	trainer/ParameterUpdater.h	/^  virtual void restore() {$/;"	f	class:paddle::SgdLocalUpdater
restore	trainer/RemoteParameterUpdater.cpp	/^void RemoteParameterUpdater::restore() {$/;"	f	class:paddle::RemoteParameterUpdater
restore	trainer/RemoteParameterUpdater.cpp	/^void SparseRemoteParameterUpdater::restore() {}$/;"	f	class:paddle::SparseRemoteParameterUpdater
restore	trainer/ThreadParameterUpdater.cpp	/^void SgdThreadUpdater::restore() {$/;"	f	class:paddle::SgdThreadUpdater
resultMatrices	pserver/ParameterClient2.h	/^    std::vector<CpuMatrixPtr> resultMatrices;$/;"	m	struct:paddle::PreparedOperations::LocalOperationResult
resultScalars	pserver/ParameterClient2.h	/^    std::vector<real*> resultScalars;$/;"	m	struct:paddle::PreparedOperations::LocalOperationResult
resultVectors	pserver/ParameterClient2.h	/^    std::vector<CpuVectorPtr> resultVectors;$/;"	m	struct:paddle::PreparedOperations::LocalOperationResult
results_	utils/Thread.h	/^  BlockingQueue<ResultPtrType> results_;$/;"	m	class:paddle::MultiThreadWorker
reversed_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  bool reversed_;$/;"	m	class:paddle::RecurrentGradientMachine
reversed_	gserver/layers/GatedRecurrentLayer.h	/^  bool reversed_;$/;"	m	class:paddle::GatedRecurrentLayer
reversed_	gserver/layers/LstmLayer.h	/^  bool reversed_;$/;"	m	class:paddle::LstmLayer
reversed_	gserver/layers/RecurrentLayer.cpp	/^  bool reversed_;$/;"	m	class:paddle::RecurrentLayer	file:
rhs_	math/TensorApply.h	/^  TensorApply<RhsType, T> rhs_;$/;"	m	class:paddle::TensorApply
rhs_	math/TensorAssign.h	/^  TensorApply<const RhsType, T> rhs_;$/;"	m	class:paddle::TensorAssignOp
rhs_	math/TensorExpression.h	/^  const RhsType rhs_;$/;"	m	class:paddle::TensorBinaryOp
rightMul	math/Matrix.cpp	/^void CpuMatrix::rightMul(Matrix& b) { return rightMul(b, 1.0, 0.0); }$/;"	f	class:paddle::CpuMatrix
rightMul	math/Matrix.cpp	/^void CpuMatrix::rightMul(Matrix& b, real scaleAB, real scaleT) {$/;"	f	class:paddle::CpuMatrix
rightMul	math/Matrix.cpp	/^void GpuMatrix::rightMul(Matrix& b) { rightMul(b, 1.0, 0.0); }$/;"	f	class:paddle::GpuMatrix
rightMul	math/Matrix.cpp	/^void GpuMatrix::rightMul(Matrix& b, real scaleAB, real scaleT) {$/;"	f	class:paddle::GpuMatrix
rightMul	math/Matrix.h	/^  virtual void rightMul(Matrix& b) { LOG(FATAL) << "Not implemented"; }$/;"	f	class:paddle::Matrix
rightMul	math/Matrix.h	/^  virtual void rightMul(Matrix& b, real scaleAB, real scaleT) {$/;"	f	class:paddle::Matrix
rmDir	utils/Util.cpp	/^void rmDir(const char* folderName) {$/;"	f	namespace:paddle
rnn_use_batch	gserver/tests/test_RecurrentLayer.cpp	/^DECLARE_bool(rnn_use_batch);$/;"	v
role_	parameter/ParallelParameter.h	/^  TrainerRole role_;$/;"	m	class:paddle::ParallelParameter
rootAgent	gserver/gradientmachines/RecurrentGradientMachine.h	/^    LayerPtr rootAgent;  \/\/ agent to link rootLayer$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
rootLayer	gserver/gradientmachines/RecurrentGradientMachine.h	/^    LayerPtr rootLayer;  \/\/ layer in root network to boot this memory$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
rootNetwork_	gserver/gradientmachines/NeuralNetwork.h	/^  NeuralNetwork* rootNetwork_;$/;"	m	class:paddle::NeuralNetwork
rootNetwork_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  NeuralNetwork* rootNetwork_;$/;"	m	class:paddle::RecurrentGradientMachine
rotate	math/Matrix.cpp	/^void CpuMatrix::rotate(MatrixPtr& matRot, bool memAlloc, bool clockWise) {$/;"	f	class:paddle::CpuMatrix
rotate	math/Matrix.cpp	/^void GpuMatrix::rotate(MatrixPtr& matRot, bool memAlloc, bool clockWise) {$/;"	f	class:paddle::GpuMatrix
rotate	math/Matrix.h	/^  virtual void rotate(MatrixPtr& matRot, bool memAlloc, bool clockWise) {$/;"	f	class:paddle::Matrix
rou_	parameter/FirstOrderOptimizer.h	/^  real rou_;$/;"	m	class:paddle::AdaDeltaParameterOptimizer
rou_	parameter/FirstOrderOptimizer.h	/^  real rou_;$/;"	m	class:paddle::DecayedAdagradParameterOptimizer
rou_	parameter/FirstOrderOptimizer.h	/^  real rou_;$/;"	m	class:paddle::RMSPropParameterOptimizer
row	math/SparseMatrix.h	/^    int row;$/;"	m	struct:paddle::GpuSparseMatrix::Element
rowBuf	math/BaseMatrix.h	/^  T* rowBuf(size_t row) { return data_ + width_ * row; }$/;"	f	class:paddle::BaseMatrixT
rowBuf	math/BaseMatrix.h	/^  const T* rowBuf(size_t row) const { return data_ + width_ * row; }$/;"	f	class:paddle::BaseMatrixT
rowMax	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::rowMax(IVector& maxIds, Matrix& maxVal) {$/;"	f	class:paddle::CpuSparseMatrix
rowMax	math/Matrix.cpp	/^void CpuMatrix::rowMax(IVector& maxIds, Matrix& maxVal) {$/;"	f	class:paddle::CpuMatrix
rowMax	math/Matrix.cpp	/^void CpuMatrix::rowMax(Matrix& max) {$/;"	f	class:paddle::CpuMatrix
rowMax	math/Matrix.cpp	/^void GpuMatrix::rowMax(IVector& maxIds, Matrix& maxVal) {$/;"	f	class:paddle::GpuMatrix
rowMax	math/Matrix.cpp	/^void GpuMatrix::rowMax(Matrix& max) {$/;"	f	class:paddle::GpuMatrix
rowMax	math/Matrix.h	/^  virtual void rowMax(IVector& maxIds, Matrix& max) {$/;"	f	class:paddle::Matrix
rowMax	math/Matrix.h	/^  virtual void rowMax(Matrix& max) {$/;"	f	class:paddle::Matrix
rowMax	math/SparseMatrix.cpp	/^void GpuSparseMatrix::rowMax(IVector& maxIds, Matrix& maxVal) {$/;"	f	class:paddle::GpuSparseMatrix
rowMaxId	math/Matrix.cpp	/^void CpuMatrix::rowMaxId(IVector& maxIds) {$/;"	f	class:paddle::CpuMatrix
rowMaxId	math/Matrix.h	/^  virtual void rowMaxId(IVector& maxIds) { LOG(FATAL) << "Not implemented"; }$/;"	f	class:paddle::Matrix
rowNormalizeL1	math/Matrix.cpp	/^void CpuMatrix::rowNormalizeL1(Matrix& out) {$/;"	f	class:paddle::CpuMatrix
rowNormalizeL1	math/Matrix.h	/^  virtual void rowNormalizeL1(Matrix& out) {$/;"	f	class:paddle::Matrix
rowStore_	math/RowBuffer.h	/^  std::vector<real, AlignedAllocator<real, 32>> rowStore_;$/;"	m	class:paddle::RowBuffer
rowSum	math/Matrix.cpp	/^void CpuMatrix::rowSum(Matrix& sum) {$/;"	f	class:paddle::CpuMatrix
rowSum	math/Matrix.cpp	/^void GpuMatrix::rowSum(Matrix& sum) {$/;"	f	class:paddle::GpuMatrix
rowSum	math/Matrix.h	/^  virtual void rowSum(Matrix& sum) {$/;"	f	class:paddle::Matrix
row_	function/BufferArg.h	/^  BufferArg row_;$/;"	m	class:paddle::SparseMatrixArg
rows	cuda/include/hl_base.h	/^  int rows;$/;"	m	struct:__anon10
rows_	math/CpuSparseMatrix.h	/^  int* rows_;$/;"	m	class:paddle::CpuSparseMatrix
rows_	math/SparseMatrix.h	/^  int* rows_;$/;"	m	class:paddle::GpuSparseMatrix
run	function/FunctionTest.h	/^  void run() {$/;"	f	class:paddle::FunctionCompare
run	pserver/LightNetwork.cpp	/^void SocketServer::run() {$/;"	f	class:paddle::SocketServer
run	pserver/LightNetwork.cpp	/^void SocketWorker::run() {$/;"	f	class:paddle::SocketWorker
run	pserver/test/SocketTest.cpp	/^void SocketServer::run() {$/;"	f	class:SocketServer
run	pserver/test/SocketTest.cpp	/^void SocketWorker::run() {$/;"	f	class:SocketWorker
run	utils/Thread.h	/^  virtual void run() {$/;"	f	class:paddle::MultiThreadWorker
run	utils/Thread.h	/^  virtual void run() {$/;"	f	class:paddle::ThreadWorker
run	utils/Thread.h	/^  void run() {$/;"	f	class:paddle::AsyncThreadPool
run	utils/Thread.h	/^  void run(int tid) {$/;"	f	class:paddle::SyncThreadPool
runInitFunctions	utils/Util.cpp	/^void runInitFunctions() {$/;"	f	namespace:paddle
rwlock_	utils/Locks.h	/^  RWLock* rwlock_;$/;"	m	class:paddle::ReadLockGuard
rwlock_	utils/Locks.h	/^  pthread_rwlock_t rwlock_;$/;"	m	class:paddle::RWLock
s	function/Function.h	/^    size_t s;$/;"	m	union:paddle::FuncConfig::value
s	trainer/tests/picojson.h	/^  static std::string s;$/;"	m	struct:picojson::last_error_t
s	trainer/tests/picojson.h	/^std::string last_error_t<T>::s;$/;"	m	class:picojson::last_error_t
sMatrix_	math/SparseMatrix.h	/^  hl_sparse_matrix_s_ptr sMatrix_;$/;"	m	class:paddle::GpuSparseMatrix
sMemoryHandle_	math/SparseMatrix.h	/^  MemoryHandlePtr sMemoryHandle_;$/;"	m	class:paddle::GpuSparseMatrix
safeAccessData	api/Vector.cpp	/^  void safeAccessData(const size_t idx,$/;"	f	struct:VectorPrivate
safeExp	gserver/layers/LinearChainCTC.cpp	/^static inline real safeExp(real x) {$/;"	f	namespace:paddle
safeLog	gserver/layers/LinearChainCTC.cpp	/^static inline real safeLog(real x) {$/;"	f	namespace:paddle
sampleDim_	gserver/dataproviders/DataProvider.h	/^  int64_t sampleDim_;$/;"	m	class:paddle::SimpleDataProviderBase
sampleId	gserver/layers/NCELayer.cpp	/^    int sampleId;$/;"	m	struct:paddle::NCELayer::Sample	file:
sampleLoop	gserver/dataproviders/ProtoDataProvider.cpp	/^int64_t ProtoDataProvider::sampleLoop(Op op, int64_t size) {$/;"	f	class:paddle::ProtoDataProvider
sampleNum	gserver/dataproviders/PyDataProvider.h	/^    unsigned int sampleNum;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
sampleNumInBuf_	gserver/dataproviders/DataProvider.h	/^  int64_t sampleNumInBuf_;$/;"	m	class:paddle::SimpleDataProviderBase
sampleNums_	gserver/dataproviders/ProtoDataProvider.h	/^  size_t sampleNums_;$/;"	m	class:paddle::ProtoDataProvider
sampleOut_	gserver/layers/NCELayer.cpp	/^  Argument sampleOut_;$/;"	m	class:paddle::NCELayer	file:
sampleSequenceIdVec	gserver/dataproviders/PyDataProvider.h	/^    std::vector<int64_t> sampleSequenceIdVec;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
sampler_	gserver/layers/NCELayer.cpp	/^  std::unique_ptr<MultinomialSampler> sampler_;$/;"	m	class:paddle::NCELayer	file:
samples_	gserver/layers/NCELayer.cpp	/^  std::vector<Sample> samples_;$/;"	m	class:paddle::NCELayer	file:
save	api/Parameter.cpp	/^bool Parameter::save(const std::string& filename) const {$/;"	f	class:Parameter
save	parameter/Parameter.cpp	/^bool Parameter::save(const std::string& filename) const {$/;"	f	class:paddle::Parameter
save	parameter/Parameter.cpp	/^bool Parameter::save(std::ostream& s) const {$/;"	f	class:paddle::Parameter
saveConfigWithPath	trainer/ParamUtil.cpp	/^void ParameterUtil::saveConfigWithPath(const std::string &path) {$/;"	f	class:paddle::ParameterUtil
saveOnlyOne	trainer/TesterConfig.h	/^  bool saveOnlyOne;$/;"	m	struct:paddle::TesterConfig
saveParameters	gserver/gradientmachines/GradientMachine.cpp	/^void GradientMachine::saveParameters(const std::string& dir) const {$/;"	f	class:paddle::GradientMachine
saveParameters	trainer/ParamUtil.cpp	/^void ParameterUtil::saveParameters(int passId, int passInnerId) {$/;"	f	class:paddle::ParameterUtil
saveParametersOnePass	trainer/ParamUtil.cpp	/^void ParameterUtil::saveParametersOnePass(int passId, int passInnerId) {$/;"	f	class:paddle::ParameterUtil
saveParametersRemote	parameter/ParameterUpdaterBase.h	/^  virtual void saveParametersRemote(const std::string& dirName) {$/;"	f	class:paddle::ParameterUpdaterComposite
saveParametersRemote	parameter/ParameterUpdaterBase.h	/^  virtual void saveParametersRemote(const std::string& dirName) {}$/;"	f	class:paddle::ParameterUpdater
saveParametersRemote	trainer/RemoteParameterUpdater.cpp	/^void SparseRemoteParameterUpdater::saveParametersRemote($/;"	f	class:paddle::SparseRemoteParameterUpdater
saveValueVector	pserver/ParameterClient2.cpp	/^void ParameterClient2::saveValueVector(const std::string& dirName) {$/;"	f	class:paddle::ParameterClient2
saveValueVector	pserver/ParameterServer2.cpp	/^void ParameterServer2::saveValueVector(const SaveValueRequest& request,$/;"	f	class:paddle::ParameterServer2
save_dir	trainer/RemoteParameterUpdater.cpp	/^DECLARE_string(save_dir);$/;"	v
save_dir	trainer/TrainerConfigHelper.cpp	/^DECLARE_string(save_dir);$/;"	v
save_only_one_	trainer/ParamUtil.h	/^  bool save_only_one_;$/;"	m	struct:paddle::ParameterUtilConfig
savedInvVar_	gserver/layers/BatchNormBaseLayer.h	/^  MatrixPtr savedInvVar_;$/;"	m	class:paddle::BatchNormBaseLayer
savedMean_	gserver/layers/BatchNormBaseLayer.h	/^  MatrixPtr savedMean_;$/;"	m	class:paddle::BatchNormBaseLayer
savingPeriod	trainer/TesterConfig.h	/^  int savingPeriod;$/;"	m	struct:paddle::TesterConfig
saving_period	trainer/tests/test_CompareSparse.cpp	/^DECLARE_int32(saving_period);$/;"	v
saving_period	trainer/tests/test_TrainerOnePass.cpp	/^DECLARE_int32(saving_period);$/;"	v
saving_period_	trainer/ParamUtil.h	/^  int saving_period_;$/;"	m	struct:paddle::ParameterUtilConfig
scale_	function/CosSimOp.cpp	/^  real scale_;$/;"	m	class:paddle::CosSimBackwardFunc	file:
scale_	function/CosSimOp.cpp	/^  real scale_;$/;"	m	class:paddle::CosSimForwardFunc	file:
scale_	function/CrossMapNormalOp.cpp	/^  real scale_;$/;"	m	class:paddle::CrossMapNormalFunc	file:
scale_	function/CrossMapNormalOp.cpp	/^  real scale_;$/;"	m	class:paddle::CrossMapNormalGradFunc	file:
scale_	gserver/layers/NormLayer.h	/^  real scale_, pow_;$/;"	m	class:paddle::ResponseNormLayer
scaledTanh	math/Matrix.cpp	/^void CpuMatrix::scaledTanh(Matrix& output, real p1, real p2) {$/;"	f	class:paddle::CpuMatrix
scaledTanh	math/Matrix.cpp	/^void GpuMatrix::scaledTanh(Matrix& output, real p1, real p2) {$/;"	f	class:paddle::GpuMatrix
scaledTanh	math/Matrix.h	/^  virtual void scaledTanh(Matrix& output, real p1, real p2) {$/;"	f	class:paddle::Matrix
scan	py_paddle/dataprovider_converter.py	/^    def scan(self, dat):$/;"	m	class:DenseScanner
scan	py_paddle/dataprovider_converter.py	/^    def scan(self, dat):$/;"	m	class:IScanner
scan	py_paddle/dataprovider_converter.py	/^    def scan(self, dat):$/;"	m	class:IndexScanner
scan	py_paddle/dataprovider_converter.py	/^    def scan(self, dat):$/;"	m	class:SequenceScanner
scan	py_paddle/dataprovider_converter.py	/^    def scan(self, dat):$/;"	m	class:SparseBinaryScanner
scatterAgents	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::vector<LayerPtr> scatterAgents;  \/\/ scatter agent used by beam search$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
scorePair_	gserver/layers/CostLayer.h	/^  std::vector<std::pair<real, int>> scorePair_;$/;"	m	class:paddle::LambdaCost
scoreVec_	gserver/layers/CostLayer.h	/^  std::vector<real> scoreVec_;$/;"	m	class:paddle::LambdaCost
seed	gserver/tests/test_RecurrentGradientMachine.cpp	/^DECLARE_int32(seed);$/;"	v
seed	trainer/tests/test_CompareSparse.cpp	/^DECLARE_int32(seed);$/;"	v
seed	trainer/tests/test_CompareTwoNets.cpp	/^DECLARE_int32(seed);$/;"	v
seed	trainer/tests/test_TrainerOnePass.cpp	/^DECLARE_int32(seed);$/;"	v
seed_	utils/ThreadLocal.cpp	/^ThreadLocal<unsigned int> ThreadLocalRand::seed_;$/;"	m	class:paddle::ThreadLocalRand	file:
seed_	utils/ThreadLocal.h	/^  static ThreadLocal<unsigned int> seed_;$/;"	m	class:paddle::ThreadLocalRand
segmentRange	gserver/layers/LinearChainCTC.cpp	/^void LinearChainCTC::segmentRange(int& start, int& end, int time) {$/;"	f	class:paddle::LinearChainCTC
segments_	parameter/LearningRateScheduler.cpp	/^  std::vector<int64_t> segments_;$/;"	m	class:paddle::ManualLRS	file:
selCols_	gserver/layers/SelectiveFullyConnectedLayer.h	/^  MatrixPtr selCols_;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
selectDaemon	pserver/LightNetwork.h	/^  struct sxi_socket* selectDaemon() {$/;"	f	class:paddle::RdmaClientDaemons
selectElements	math/Matrix.cpp	/^void CpuMatrix::selectElements(Matrix& table, IVector& ids) {$/;"	f	class:paddle::CpuMatrix
selectElements	math/Matrix.cpp	/^void GpuMatrix::selectElements(Matrix& table, IVector& ids) {$/;"	f	class:paddle::GpuMatrix
selectElements	math/Matrix.h	/^  virtual void selectElements(Matrix& table, IVector& ids) {$/;"	f	class:paddle::Matrix
selectFrom	math/Vector.cpp	/^void CpuVectorT<T>::selectFrom(const VectorT<T>& src, const VectorT<int>& ids) {$/;"	f	class:paddle::CpuVectorT
selectFrom	math/Vector.cpp	/^void GpuVectorT<T>::selectFrom(const VectorT<T>& src, const VectorT<int>& ids) {$/;"	f	class:paddle::GpuVectorT
selectRows	math/Matrix.cpp	/^void CpuMatrix::selectRows(Matrix& table, IVector& ids) {$/;"	f	class:paddle::CpuMatrix
selectRows	math/Matrix.cpp	/^void GpuMatrix::selectRows(Matrix& table, IVector& ids) {$/;"	f	class:paddle::GpuMatrix
selectRows	math/Matrix.h	/^  virtual void selectRows(Matrix& table, IVector& ids) {$/;"	f	class:paddle::Matrix
selectRowsImp	math/Matrix.cpp	/^void CpuMatrix::selectRowsImp(TableMatType& table, IVector& ids) {$/;"	f	class:paddle::CpuMatrix
selectRowsOneTime	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::selectRowsOneTime(LayerPtr layer,$/;"	f	class:paddle::RecurrentGradientMachine
sem	gserver/gradientmachines/MultiGradientMachine.h	/^  Semaphore sem;$/;"	m	struct:paddle::GradBuffer
sem	utils/arch/linux/Locks.cpp	/^  sem_t sem;$/;"	m	class:paddle::SemaphorePrivate	file:
sem	utils/arch/osx/Locks.cpp	/^  dispatch_semaphore_t sem;$/;"	m	class:paddle::SemaphorePrivate	file:
send	pserver/ParameterClient2.cpp	/^void ParameterClient2::send(int threadId) {$/;"	f	class:paddle::ParameterClient2
send	pserver/ProtoServer.cpp	/^void ProtoClient::send(const char* funcName,$/;"	f	class:paddle::ProtoClient
send	trainer/RemoteParameterUpdater.cpp	/^void ConcurrentRemoteParameterUpdater::send() {$/;"	f	class:paddle::ConcurrentRemoteParameterUpdater
send	trainer/RemoteParameterUpdater.cpp	/^void ConcurrentRemoteParameterUpdater::send(Parameter* para) {$/;"	f	class:paddle::ConcurrentRemoteParameterUpdater
sendAndReceiveParameter	pserver/ParameterClient2.cpp	/^void ParameterClient2::sendAndReceiveParameter($/;"	f	class:paddle::ParameterClient2
sendAndReceiveParameter	pserver/ParameterClient2.h	/^  void sendAndReceiveParameter($/;"	f	class:paddle::ParameterClient2
sendAndRecv	pserver/ProtoServer.h	/^  std::unique_ptr<MsgReader> sendAndRecv($/;"	f	class:paddle::ProtoClient
sendBackParameter	pserver/ParameterServer2.cpp	/^void ParameterServer2::sendBackParameter(const ParameterBlock& block,$/;"	f	class:paddle::ParameterServer2
sendBackParameterSparse	pserver/ParameterServer2.cpp	/^void ParameterServer2::sendBackParameterSparse($/;"	f	class:paddle::ParameterServer2
sendData	pserver/BaseClient.h	/^  void sendData(int clientId,$/;"	f	class:paddle::BaseClient
sendData	pserver/ParameterServer2.cpp	/^void ParameterServer2::sendData(const SendDataRequest& request,$/;"	f	class:paddle::ParameterServer2
sendDataTest	pserver/test/test_ParameterServer2.cpp	/^void ParameterServer2Tester::sendDataTest(SendDataType type, size_t size) {$/;"	f	class:ParameterServer2Tester
sendJobQueue_	pserver/BaseClient.h	/^  std::vector<std::unique_ptr<SendQueue>> sendJobQueue_;$/;"	m	class:paddle::BaseClient
sendJob_	pserver/BaseClient.h	/^  SendJob sendJob_;$/;"	m	class:paddle::BaseClient
sendParallel	pserver/ParameterClient2.cpp	/^void ParameterClient2::sendParallel(int tid,$/;"	f	class:paddle::ParameterClient2
sendParameter	pserver/ParameterClient2.cpp	/^void ParameterClient2::sendParameter($/;"	f	class:paddle::ParameterClient2
sendParameter	pserver/ParameterClient2.h	/^  void sendParameter(ParameterUpdateMode updateMode,$/;"	f	class:paddle::ParameterClient2
sendParameter	pserver/ParameterServer2.cpp	/^void ParameterServer2::sendParameter(const SendParameterRequest& request,$/;"	f	class:paddle::ParameterServer2
sendParameterTest	pserver/test/test_ParameterServer2.cpp	/^void ParameterServer2Tester::sendParameterTest() {$/;"	f	class:ParameterServer2Tester
sendQueue_	trainer/RemoteParameterUpdater.h	/^  Queue<int> sendQueue_;$/;"	m	class:paddle::ConcurrentRemoteParameterUpdater
sendThread_	trainer/RemoteParameterUpdater.h	/^  std::unique_ptr<std::thread> sendThread_;$/;"	m	class:paddle::ConcurrentRemoteParameterUpdater
sendThreads_	pserver/BaseClient.h	/^  std::vector<ThreadPtr> sendThreads_;$/;"	m	class:paddle::BaseClient
sep	utils/Util.h	/^const char sep = '\/';$/;"	m	namespace:paddle::path
separateSendAndRecv_	pserver/BaseClient.h	/^  bool separateSendAndRecv_;$/;"	m	class:paddle::BaseClient
separateSendAndRecv_	trainer/RemoteParameterUpdater.h	/^  bool separateSendAndRecv_;$/;"	m	class:paddle::RemoteParameterUpdater
seq2BatchIdx_	gserver/layers/SequenceToBatch.h	/^  IVectorPtr seq2BatchIdx_;$/;"	m	class:paddle::SequenceToBatch
seq2batchPadding	gserver/layers/WarpCTCLayer.cpp	/^void WarpCTCLayer::seq2batchPadding(const MatrixPtr& seqValue,$/;"	f	class:paddle::WarpCTCLayer
seqClassficationError_	gserver/evaluators/CTCErrorEvaluator.cpp	/^  int seqClassficationError_;$/;"	m	class:paddle::CTCErrorEvaluator	file:
seqEndIdxInBatch_	gserver/layers/SequenceToBatch.h	/^  IVectorPtr seqEndIdxInBatch_;$/;"	m	class:paddle::SequenceToBatch
seqId	gserver/gradientmachines/RecurrentGradientMachine.h	/^    int seqId;      \/\/ index of sequence in batch generation$/;"	m	struct:paddle::RecurrentGradientMachine::Path
seqId	parameter/Argument.h	/^    int seqId;$/;"	m	struct:paddle::Argument::SeqInfo
seqIds_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<int> seqIds_;$/;"	m	class:paddle::RecurrentGradientMachine
seqIdx_	gserver/layers/SequenceToBatch.h	/^  IVectorPtr seqIdx_;$/;"	m	class:paddle::SequenceToBatch
seqInfos_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<std::vector<Argument::SeqInfo>> seqInfos_;$/;"	m	class:paddle::RecurrentGradientMachine
seqStart	parameter/Argument.h	/^    int seqStart;$/;"	m	struct:paddle::Argument::SeqInfo
seqStartPosIndex	gserver/gradientmachines/RecurrentGradientMachine.h	/^    std::vector<int> seqStartPosIndex;  \/\/ index of sequenceStartPositions$/;"	m	struct:paddle::RecurrentGradientMachine::Info
seqStartPosIndex_	gserver/layers/AgentLayer.h	/^  int seqStartPosIndex_;$/;"	m	class:paddle::ScatterAgentLayer
seqType	gserver/dataproviders/PyDataProvider2.cpp	/^  SeqType seqType;$/;"	m	struct:paddle::SlotHeader	file:
seq_	utils/PythonUtil.h	/^  PyObject* seq_;$/;"	m	class:paddle::py::SequenceHelper
seq_count_randomer	trainer/tests/testPyDataWrapper.py	/^seq_count_randomer = lambda: random.randrange(1, SEQUENCE_LIMIT)$/;"	v
sequence	function/BufferArg.cpp	/^const SequenceArg& BufferArg::sequence() const {$/;"	f	class:paddle::BufferArg
sequence2BatchAdd	gserver/layers/SequenceToBatch.cpp	/^void SequenceToBatch::sequence2BatchAdd(Matrix &batch,$/;"	f	class:paddle::SequenceToBatch
sequence2BatchCopy	gserver/layers/SequenceToBatch.cpp	/^void SequenceToBatch::sequence2BatchCopy(Matrix &batch,$/;"	f	class:paddle::SequenceToBatch
sequenceAvgForward	math/Matrix.cpp	/^void CpuMatrix::sequenceAvgForward(Matrix& a,$/;"	f	class:paddle::CpuMatrix
sequenceAvgForward	math/Matrix.cpp	/^void GpuMatrix::sequenceAvgForward(Matrix& a,$/;"	f	class:paddle::GpuMatrix
sequenceAvgForward	math/Matrix.h	/^  virtual void sequenceAvgForward(Matrix& a,$/;"	f	class:paddle::Matrix
sequenceLoop	gserver/dataproviders/ProtoDataProvider.cpp	/^int64_t ProtoDataProvider::sequenceLoop(Op op, int64_t size) {$/;"	f	class:paddle::ProtoDataProvider
sequenceNum	gserver/dataproviders/PyDataProvider.h	/^    unsigned int sequenceNum;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
sequenceSoftmax	math/Matrix.cpp	/^void CpuMatrix::sequenceSoftmax(Matrix& output, const IVector& index) {$/;"	f	class:paddle::CpuMatrix
sequenceSoftmax	math/Matrix.cpp	/^void GpuMatrix::sequenceSoftmax(Matrix& output, const IVector& index) {$/;"	f	class:paddle::GpuMatrix
sequenceSoftmax	math/Matrix.h	/^  virtual void sequenceSoftmax(Matrix& output, const IVector& index) {$/;"	f	class:paddle::Matrix
sequenceStartPositions	gserver/dataproviders/PyDataProvider.h	/^    std::vector<size_t> sequenceStartPositions;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
sequenceStartPositions	gserver/gradientmachines/RecurrentGradientMachine.h	/^        sequenceStartPositions;         \/\/ scattered sequenceStartPositions$/;"	m	struct:paddle::RecurrentGradientMachine::Info
sequenceStartPositions	gserver/gradientmachines/RecurrentGradientMachine.h	/^        sequenceStartPositions;  \/\/ scattered sequenceStartPositions$/;"	m	struct:paddle::RecurrentGradientMachine::MemoryFrameLine
sequenceStartPositions	parameter/Argument.h	/^  ICpuGpuVectorPtr sequenceStartPositions;$/;"	m	struct:paddle::Argument
sequenceStartPositions_	gserver/dataproviders/ProtoDataProvider.h	/^  std::vector<size_t> sequenceStartPositions_;$/;"	m	class:paddle::ProtoDataProvider
sequenceStartPositions_creator	gserver/tests/pyDataProvider.py	/^def sequenceStartPositions_creator():$/;"	f
serialize	trainer/tests/picojson.h	/^inline std::string value::serialize(bool prettify) const {$/;"	f	class:picojson::value
serialize	trainer/tests/picojson.h	/^void value::serialize(Iter oi, bool prettify) const {$/;"	f	class:picojson::value
serialize_str	trainer/tests/picojson.h	/^void serialize_str(const std::string& s, Iter oi) {$/;"	f	namespace:picojson
serverId_	pserver/ParameterServer2.h	/^  std::atomic<int> serverId_;$/;"	m	class:paddle::ParameterServer2
server_	pserver/LightNetwork.h	/^  SocketServer* server_;$/;"	m	class:paddle::SocketWorker
serviceNum_	pserver/BaseClient.h	/^  int serviceNum_;$/;"	m	class:paddle::BaseClient
service_arg_type	pserver/ProtoServer.h	/^struct service_arg_type<R (C::*)(  \/\/ NOLINT$/;"	s	namespace:paddle
service_arg_type	pserver/ProtoServer.h	/^struct service_arg_type<R (C::*)(const Arg1&, Arg2)> {$/;"	s	namespace:paddle
set	api/Matrix.cpp	/^void Matrix::set(size_t x, size_t y, float val) throw(RangeError,$/;"	f	class:Matrix
set	api/PaddleAPI.h	/^  inline void set(const size_t idx, int val) throw(RangeError, UnsupportError) {$/;"	f	class:IVector
set	api/Vector.cpp	/^void Vector::set(const size_t idx, float val) throw(RangeError,$/;"	f	class:Vector
set	function/Function.cpp	/^FuncConfig& FuncConfig::set<bool>(const std::string& key, bool v) {$/;"	f	class:paddle::FuncConfig
set	function/Function.cpp	/^FuncConfig& FuncConfig::set<int>(const std::string& key, int v) {$/;"	f	class:paddle::FuncConfig
set	function/Function.cpp	/^FuncConfig& FuncConfig::set<real>(const std::string& key, real v) {$/;"	f	class:paddle::FuncConfig
set	function/Function.cpp	/^FuncConfig& FuncConfig::set<size_t>(const std::string& key, size_t v) {$/;"	f	class:paddle::FuncConfig
set	utils/PythonUtil.h	/^  inline void set(size_t i, PyObject* obj, bool steal = false) {$/;"	f	class:paddle::py::SequenceHelper
set	utils/PythonUtil.h	/^  inline void set(size_t i, const PyObjectPtr& obj, bool steal = false) {$/;"	f	class:paddle::py::SequenceHelper
set	utils/PythonUtil.h	/^  void set(const std::string& key, PyObject* item) {$/;"	f	class:paddle::py::DictHelper
set	utils/ThreadLocal.h	/^  void set(T* p) {$/;"	f	class:paddle::ThreadLocal
set	utils/ThreadLocal.h	/^  void set(T* p) {$/;"	f	class:paddle::ThreadLocalD
setArgType	function/BufferArg.h	/^  void setArgType(ArgType argType) { argType_ = argType; }$/;"	f	class:paddle::BufferArg
setArgsSize	utils/PythonUtil.h	/^  void setArgsSize(size_t sz) { args.reset(PyTuple_New(sz)); }$/;"	f	class:paddle::py::CallableHelper
setBackwardCallback	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  void setBackwardCallback(const UpdateCallback &callback) {$/;"	f	class:paddle::ParallelThread
setBatchSize	gserver/dataproviders/DataProvider.h	/^  void setBatchSize(int64_t newBatchSize) { batchSize_ = newBatchSize; }$/;"	f	class:paddle::DoubleBuffer
setBeamSize	api/SequenceGenerator.cpp	/^void SequenceGenerator::setBeamSize(size_t beamSize) {$/;"	f	class:SequenceGenerator
setBool	utils/PythonUtil.h	/^  void setBool(const std::string& key, bool b) {$/;"	f	class:paddle::py::DictHelper
setBos	api/SequenceGenerator.cpp	/^void SequenceGenerator::setBos(size_t bos) { m->beginPos = bos; }$/;"	f	class:SequenceGenerator
setConfig	pserver/ParameterClient2.cpp	/^void ParameterClient2::setConfig(const OptimizationConfig& optConfig,$/;"	f	class:paddle::ParameterClient2
setConfig	pserver/ParameterServer2.cpp	/^void ParameterServer2::setConfig(const SetConfigRequest& request,$/;"	f	class:paddle::ParameterServer2
setConfigTest	pserver/test/test_ParameterServer2.cpp	/^void ParameterServer2Tester::setConfigTest() {$/;"	f	class:ParameterServer2Tester
setCuEvent	gserver/dataproviders/DataProvider.h	/^  void setCuEvent(hl_event_t event) { hlEvent_ = event; }$/;"	f	class:paddle::BufferBatch
setCuStream	gserver/dataproviders/DataProvider.h	/^  void setCuStream(hl_stream_t stream) { hlStream_ = stream; }$/;"	f	class:paddle::BufferBatch
setCurrentEvaluator	trainer/TrainerInternal.h	/^  inline void setCurrentEvaluator(Evaluator* eval) { currentEvaluator_ = eval; }$/;"	f	class:paddle::TrainerInternal
setData	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void setData(int* col, real* dat, PyObject* obj) {$/;"	f	class:paddle::SparseNonValueScanner
setData	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void setData(int* col, real* dat, PyObject* obj) {$/;"	f	class:paddle::SparseValueScanner
setData	gserver/layers/DataLayer.h	/^  virtual void setData(const Argument& data) { data_ = data; }$/;"	f	class:paddle::DataLayer
setData	math/BaseMatrix.h	/^  void setData(T* data) { data_ = data; }$/;"	f	class:paddle::BaseMatrixT
setData	math/Matrix.h	/^  void setData(real* data) {$/;"	f	class:paddle::Matrix
setData	math/Matrix.h	/^  void setData(real* data, size_t newHeight, size_t newWidth) {$/;"	f	class:paddle::Matrix
setDataBatch	gserver/dataproviders/DataProvider.h	/^  void setDataBatch(DataBatch* batchData) { batchData_ = batchData; }$/;"	f	class:paddle::BufferBatch
setDevice	parameter/Parameter.h	/^  void setDevice(int deviceId) { deviceId_ = deviceId; }$/;"	f	class:paddle::Parameter
setDiag	math/Matrix.cpp	/^void Matrix::setDiag(real value) {$/;"	f	class:paddle::Matrix
setDict	api/SequenceGenerator.cpp	/^void SequenceGenerator::setDict(const std::vector<std::string>& dict) {$/;"	f	class:SequenceGenerator
setDim	function/TensorShape.h	/^  void setDim(size_t dim, size_t size) {$/;"	f	class:paddle::TensorShape
setElement	math/Vector.cpp	/^void CpuGpuVectorT<T>::setElement(size_t i, const T& value, bool useGpu) {$/;"	f	class:paddle::CpuGpuVectorT
setElement	math/Vector.cpp	/^void GpuVectorT<T>::setElement(size_t i, const T& value) {$/;"	f	class:paddle::GpuVectorT
setElement	math/Vector.h	/^  virtual void setElement(size_t i, const T& value) {$/;"	f	class:paddle::CpuVectorT
setEos	api/SequenceGenerator.cpp	/^void SequenceGenerator::setEos(size_t eos) { m->endPos = eos; }$/;"	f	class:SequenceGenerator
setEvaluator	trainer/TrainerInternal.h	/^  inline void setEvaluator(Evaluator* eval) { evaluator_ = eval; }$/;"	f	class:paddle::TrainerInternal
setForwardPassType	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  void setForwardPassType(PassType passType) { passType_ = passType; }$/;"	f	class:paddle::ParallelThread
setForwardbackwardTime	parameter/ParameterUpdaterBase.h	/^  virtual void setForwardbackwardTime(uint64_t delta) {$/;"	f	class:paddle::ParameterUpdaterComposite
setForwardbackwardTime	parameter/ParameterUpdaterBase.h	/^  virtual void setForwardbackwardTime(uint64_t delta) {}$/;"	f	class:paddle::ParameterUpdater
setForwardbackwardTime	pserver/ParameterClient2.h	/^  void setForwardbackwardTime(uint64_t delta) { forwardbackwordTime_ = delta; }$/;"	f	class:paddle::ParameterClient2
setForwardbackwardTime	trainer/RemoteParameterUpdater.h	/^  virtual void setForwardbackwardTime(uint64_t delta) {$/;"	f	class:paddle::RemoteParameterUpdater
setForwardbackwardTime	trainer/RemoteParameterUpdater.h	/^  virtual void setForwardbackwardTime(uint64_t delta) {$/;"	f	class:paddle::SparseRemoteParameterUpdater
setFrameHeight	parameter/Argument.h	/^  void setFrameHeight(size_t h) { frameHeight = h; }$/;"	f	struct:paddle::Argument
setFrameWidth	parameter/Argument.h	/^  void setFrameWidth(size_t w) { frameWidth = w; }$/;"	f	struct:paddle::Argument
setID	parameter/Parameter.h	/^  void setID(size_t id) { config_.set_para_id(id); }$/;"	f	class:paddle::Parameter
setIntBuf	parameter/Parameter.h	/^  void setIntBuf(ParameterType pType, const IVectorPtr& iVec) {$/;"	f	class:paddle::Parameter
setLogZero	gserver/layers/LinearChainCTC.cpp	/^static void setLogZero(MatrixPtr mat) {$/;"	f	namespace:paddle
setMat	parameter/Parameter.cpp	/^void Parameter::setMat(ParameterType pType, int matType) {$/;"	f	class:paddle::Parameter
setMaxLength	api/SequenceGenerator.cpp	/^void SequenceGenerator::setMaxLength(size_t maxLength) {$/;"	f	class:SequenceGenerator
setMeanAndStd	gserver/layers/BatchNormalizationLayer.cpp	/^void BatchNormalizationLayer::setMeanAndStd() {$/;"	f	class:paddle::BatchNormalizationLayer
setMinLogLevel	utils/Logging.cpp	/^void setMinLogLevel(int level) { FLAGS_minloglevel = level; }$/;"	f	namespace:paddle::logging
setNeedGradient	gserver/layers/Layer.h	/^  void setNeedGradient(bool need) { needGradient_ = need; }$/;"	f	class:paddle::Layer
setNeedSequenceInfo	gserver/layers/Layer.h	/^  void setNeedSequenceInfo(bool need) { needSequenceInfo_ = need; }$/;"	f	class:paddle::Layer
setNoDecay	parameter/AverageOptimizer.h	/^  virtual void setNoDecay() { optimizer_->setNoDecay(); }$/;"	f	class:paddle::AverageOptimizer
setNoDecay	parameter/FirstOrderOptimizer.h	/^  virtual void setNoDecay() { optimizer_->setNoDecay(); }$/;"	f	class:paddle::OptimizerWithGradientClipping
setNoDecay	parameter/ParameterOptimizer.h	/^  virtual void setNoDecay() { applyDecay_ = false; }$/;"	f	class:paddle::ParameterOptimizer
setNumOfThreads	math/SparseRowMatrix.h	/^  void setNumOfThreads(size_t numOfThreads) { idsArray_.resize(numOfThreads); }$/;"	f	class:paddle::SparseRowIdsCpuMatrix
setOnPoolFilledHook	gserver/dataproviders/PyDataProvider2.cpp	/^void setOnPoolFilledHook(const std::function<void(size_t)>& callback) {$/;"	f	namespace:paddle::unittest::pydp2
setOption	pserver/LightNetwork.cpp	/^void setOption(int sockfd) {$/;"	f	namespace:paddle
setOutDims	gserver/layers/PadLayer.cpp	/^void PadLayer::setOutDims(const size_t batchSize) {$/;"	f	class:paddle::PadLayer
setOutput	gserver/layers/Layer.h	/^  void setOutput(const std::string& name, Argument* output) {$/;"	f	class:paddle::Layer
setOutputGrad	gserver/gradientmachines/GradientMachine.h	/^  virtual void setOutputGrad(const std::vector<Argument>& args) {$/;"	f	class:paddle::GradientMachine
setOutputGrad	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::setOutputGrad(const std::vector<Argument>& args) {$/;"	f	class:paddle::MultiGradientMachine
setOutputGrad	gserver/gradientmachines/NeuralNetwork.cpp	/^void NeuralNetwork::setOutputGrad(const std::vector<Argument>& args) {$/;"	f	class:paddle::NeuralNetwork
setParameter	pserver/ParameterClient2.h	/^  void setParameter() {$/;"	f	class:paddle::ParameterClient2
setParameter	pserver/ParameterServer2.cpp	/^void ParameterServer2::setParameter(const SendParameterRequest& request,$/;"	f	class:paddle::ParameterServer2
setParameterPtr	parameter/Weight.cpp	/^void Weight::setParameterPtr(ParameterPtr param) { parameter_ = param; }$/;"	f	class:paddle::Weight
setParameterZero	pserver/ParameterClient2.h	/^  void setParameterZero() {$/;"	f	class:paddle::ParameterClient2
setPassGrad	gserver/gradientmachines/MultiGradientMachine.h	/^  void setPassGrad(bool isPass) { isPassGrad_ = isPass; }$/;"	f	class:paddle::MultiGradientMachine
setPending	gserver/dataproviders/DataProvider.h	/^  void setPending(bool pending) { pending_ = pending; }$/;"	f	class:paddle::DoubleBuffer
setPoolConfig	gserver/tests/test_LayerGrad.cpp	/^void setPoolConfig(TestConfig* config,$/;"	f
setRealLayer	gserver/layers/AgentLayer.h	/^  void setRealLayer(LayerPtr layer, int numSamples = 0) {$/;"	f	class:paddle::AgentLayer
setRealLayer	gserver/layers/AgentLayer.h	/^  void setRealLayer(LayerPtr layer,$/;"	f	class:paddle::ScatterAgentLayer
setRealLayerAndOutput	gserver/layers/AgentLayer.h	/^  void setRealLayerAndOutput(LayerPtr layer,$/;"	f	class:paddle::ScatterAgentLayer
setRow	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::setRow(size_t row,$/;"	f	class:paddle::CpuSparseMatrix
setRow	math/Matrix.h	/^  void setRow(size_t row,$/;"	f	class:paddle::CpuMatrix
setRow	math/Matrix.h	/^  void setRow(size_t row,$/;"	f	class:paddle::GpuMatrix
setRow	math/SparseMatrix.cpp	/^void GpuSparseMatrix::setRow(size_t row,$/;"	f	class:paddle::GpuSparseMatrix
setSaveDir	trainer/TrainerConfigHelper.cpp	/^void TrainerConfigHelper::setSaveDir(const std::string &saveDir) {$/;"	f	class:paddle::TrainerConfigHelper
setSequenceStartPositions	gserver/layers/AgentLayer.h	/^  void setSequenceStartPositions(const ICpuGpuVectorPtr& sequenceStartPositions,$/;"	f	class:paddle::ScatterAgentLayer
setSharedCount	parameter/Parameter.h	/^  void setSharedCount(int cnt) { sharedCount_ = cnt; }$/;"	f	class:paddle::Parameter
setSize	gserver/dataproviders/DataProvider.h	/^  void setSize(int64_t size) { size_ = size; }$/;"	f	class:paddle::DataBatch
setSkipShuffle	gserver/dataproviders/DataProvider.h	/^  void setSkipShuffle() { skipShuffle_ = true; }$/;"	f	class:paddle::DataProvider
setSlotGrad	api/Arguments.cpp	/^void Arguments::setSlotGrad(size_t idx, Matrix* mat) throw(RangeError) {$/;"	f	class:Arguments
setSlotIds	api/Arguments.cpp	/^void Arguments::setSlotIds(size_t idx, IVector* vec) throw(RangeError) {$/;"	f	class:Arguments
setSlotIn	api/Arguments.cpp	/^void Arguments::setSlotIn(size_t idx, Matrix* mat) throw(RangeError) {$/;"	f	class:Arguments
setSlotSequenceDim	api/Arguments.cpp	/^void Arguments::setSlotSequenceDim(size_t idx, IVector* vec) throw(RangeError) {$/;"	f	class:Arguments
setSlotSequenceStartPositions	api/Arguments.cpp	/^void Arguments::setSlotSequenceStartPositions(size_t idx,$/;"	f	class:Arguments
setSlotSubSequenceStartPositions	api/Arguments.cpp	/^void Arguments::setSlotSubSequenceStartPositions($/;"	f	class:Arguments
setSlotValue	api/Arguments.cpp	/^void Arguments::setSlotValue(size_t idx, Matrix* mat) throw(RangeError) {$/;"	f	class:Arguments
setSourceData	math/SparseRowMatrix.h	/^  void setSourceData(CpuVectorPtr sourceVec) {$/;"	f	class:paddle::CacheRowCpuMatrix
setStartStamp	utils/Stat.h	/^  void setStartStamp(uint64_t startStamp) { startStamp_ = startStamp; }$/;"	f	class:paddle::Timer
setState	gserver/gradientmachines/GradientMachine.h	/^  virtual void setState(const MachineState& machineState) {}$/;"	f	class:paddle::GradientMachine
setState	gserver/gradientmachines/NeuralNetwork.cpp	/^void NeuralNetwork::setState(const MachineState& machineState) {$/;"	f	class:paddle::NeuralNetwork
setState	gserver/layers/ContextProjection.cpp	/^void ContextProjection::setState(LayerStatePtr state) {$/;"	f	class:paddle::ContextProjection
setState	gserver/layers/GatedRecurrentLayer.cpp	/^void GatedRecurrentLayer::setState(LayerStatePtr state) {$/;"	f	class:paddle::GatedRecurrentLayer
setState	gserver/layers/Layer.h	/^  virtual void setState(LayerStatePtr state) {}$/;"	f	class:paddle::Layer
setState	gserver/layers/LstmLayer.cpp	/^void LstmLayer::setState(LayerStatePtr state) {$/;"	f	class:paddle::LstmLayer
setState	gserver/layers/MixedLayer.cpp	/^void MixedLayer::setState(LayerStatePtr state) {$/;"	f	class:paddle::MixedLayer
setState	gserver/layers/Operator.h	/^  virtual void setState(LayerStatePtr state) {}$/;"	f	class:paddle::Operator
setState	gserver/layers/Projection.h	/^  virtual void setState(LayerStatePtr state) {}$/;"	f	class:paddle::Projection
setState	gserver/layers/RecurrentLayer.cpp	/^void RecurrentLayer::setState(LayerStatePtr state) {$/;"	f	class:paddle::RecurrentLayer
setStatus	pserver/ParameterClient2.cpp	/^void ParameterClient2::setStatus(PServerStatus status) {$/;"	f	class:paddle::ParameterClient2
setStatus	pserver/ParameterServer2.cpp	/^void ParameterServer2::setStatus(const SetStatusRequest& request,$/;"	f	class:paddle::ParameterServer2
setStatus	pserver/test/test_ProtoServer.cpp	/^  void setStatus(const SetStatusRequest& request,$/;"	f	class:MyServer
setStatusTest	pserver/test/test_ParameterServer2.cpp	/^void ParameterServer2Tester::setStatusTest() {$/;"	f	class:ParameterServer2Tester
setStringList	utils/PythonUtil.h	/^  void setStringList(const std::string& key,$/;"	f	class:paddle::py::DictHelper
setSync	math/Vector.h	/^  inline void setSync(SyncedFlag syncFlag) {$/;"	f	class:paddle::CpuGpuVectorT
setSync	math/Vector.h	/^  inline void setSync(SyncedFlag* sync) { sync_ = sync; }$/;"	f	class:paddle::CpuGpuVectorT
setSync	math/Vector.h	/^  inline void setSync(bool useGpu) {$/;"	f	class:paddle::CpuGpuVectorT
setTensorDim	gserver/layers/PadLayer.cpp	/^void PadLayer::setTensorDim(const size_t batchSize) {$/;"	f	class:paddle::PadLayer
setThreadInfo	utils/Stat.cpp	/^void StatSet::setThreadInfo(const std::string& name, bool flag) {$/;"	f	class:paddle::StatSet
setThreadInfo	utils/Stat.h	/^  void setThreadInfo(bool flag) { openThreadInfo_ = flag; }$/;"	f	class:paddle::Stat
setThreadInfo	utils/Stat.h	/^  void setThreadInfo(bool flag) {$/;"	f	class:paddle::StatSet
setTrainerId	pserver/ParameterClient2.h	/^  void setTrainerId(int trainerId) { trainerId_ = trainerId; }$/;"	f	class:paddle::ParameterClient2
setUseGpu	api/Util.cpp	/^void setUseGpu(bool useGpu) { FLAGS_use_gpu = useGpu; }$/;"	f
setValueUpdated	api/Parameter.cpp	/^void Parameter::setValueUpdated() { m->getPtr()->setValueUpdated(); }$/;"	f	class:Parameter
setValueUpdated	parameter/Parameter.h	/^  void setValueUpdated() { updated_ = true; }$/;"	f	class:paddle::Parameter
set_bool	trainer/tests/picojson.h	/^  bool set_bool(bool b) {$/;"	f	class:picojson::default_parse_context
set_bool	trainer/tests/picojson.h	/^  bool set_bool(bool) { return false; }$/;"	f	class:picojson::deny_parse_context
set_bool	trainer/tests/picojson.h	/^  bool set_bool(bool) { return true; }$/;"	f	class:picojson::null_parse_context
set_int64	trainer/tests/picojson.h	/^  bool set_int64(int64_t i) {$/;"	f	class:picojson::default_parse_context
set_int64	trainer/tests/picojson.h	/^  bool set_int64(int64_t) { return false; }$/;"	f	class:picojson::deny_parse_context
set_int64	trainer/tests/picojson.h	/^  bool set_int64(int64_t) { return true; }$/;"	f	class:picojson::null_parse_context
set_last_error	trainer/tests/picojson.h	/^inline void set_last_error(const std::string& s) { last_error_t<bool>::s = s; }$/;"	f	namespace:picojson
set_nodefile	scripts/cluster_train/paddle.py	/^    def set_nodefile(nodeid):$/;"	f	function:job_prepare
set_null	trainer/tests/picojson.h	/^  bool set_null() { return false; }$/;"	f	class:picojson::deny_parse_context
set_null	trainer/tests/picojson.h	/^  bool set_null() { return true; }$/;"	f	class:picojson::null_parse_context
set_null	trainer/tests/picojson.h	/^  bool set_null() {$/;"	f	class:picojson::default_parse_context
set_number	trainer/tests/picojson.h	/^  bool set_number(double f) {$/;"	f	class:picojson::default_parse_context
set_number	trainer/tests/picojson.h	/^  bool set_number(double) { return false; }$/;"	f	class:picojson::deny_parse_context
set_number	trainer/tests/picojson.h	/^  bool set_number(double) { return true; }$/;"	f	class:picojson::null_parse_context
set_port	.common_test_util.sh	/^set_port()$/;"	f
setup	pserver/test/test_ParameterServer2.cpp	/^  void setup() {$/;"	f	class:ParameterServer2Tester
setupIndices	math/SparseRowMatrix.cpp	/^void SparsePrefetchRowCpuMatrix::setupIndices() {$/;"	f	class:paddle::SparsePrefetchRowCpuMatrix
sftMaxDot_	gserver/activations/ActivationFunction.cpp	/^MatrixPtr sftMaxDot_;$/;"	m	namespace:paddle	file:
sftMaxSum_	gserver/activations/ActivationFunction.cpp	/^MatrixPtr sftMaxSum_;$/;"	m	namespace:paddle	file:
sftMaxSum_	gserver/layers/CostLayer.h	/^  MatrixPtr sftMaxSum_;$/;"	m	class:paddle::MultiClassCrossEntropyWithSelfNorm
sgdOptimizerCreate	parameter/OptimizerFunctions.cpp	/^ParameterOptimizer* sgdOptimizerCreate(const OptimizationConfig& optConfig,$/;"	f	namespace:paddle
sgdOptimizerGetTypes	parameter/OptimizerFunctions.cpp	/^std::vector<ParameterType> sgdOptimizerGetTypes($/;"	f	namespace:paddle
sgdUpdate	math/SparseRowMatrix.cpp	/^void SparseRowCpuMatrix::sgdUpdate(BaseMatrix& value,$/;"	f	class:paddle::SparseRowCpuMatrix
sgdUpdate	parameter/ParameterUpdateFunctions.cpp	/^void sgdUpdate(real learningRate,$/;"	f	namespace:paddle
sgdUpdateAvx	parameter/ParameterUpdateFunctions.cpp	/^void sgdUpdateAvx(float learningRate,$/;"	f	namespace:paddle
sgdUpdateCpu	parameter/ParameterUpdateFunctions.cpp	/^void sgdUpdateCpu(real learningRate,$/;"	f	namespace:paddle
shape	function/BufferArg.h	/^  const TensorShape& shape() const { return shape_; }$/;"	f	class:paddle::BufferArg
shape_	function/BufferArg.h	/^  TensorShape shape_;$/;"	m	class:paddle::BufferArg
shape_	gserver/layers/NormProjectionLayer.h	/^  TensorShape shape_;$/;"	m	class:paddle::CMRProjectionNormLayer
shareIndexWith	gserver/layers/SequenceToBatch.h	/^  void shareIndexWith(const SequenceToBatch &seq2batch) {$/;"	f	class:paddle::SequenceToBatch
sharedBias_	gserver/layers/ConcatenateLayer.cpp	/^  bool sharedBias_;$/;"	m	class:paddle::ConcatenateLayer2	file:
sharedBias_	gserver/layers/MixedLayer.h	/^  bool sharedBias_;$/;"	m	class:paddle::MixedLayer
sharedBiases_	gserver/layers/ConvBaseLayer.h	/^  bool sharedBiases_;$/;"	m	class:paddle::ConvBaseLayer
sharedCount_	parameter/Parameter.h	/^  int sharedCount_;$/;"	m	class:paddle::Parameter
sharedPtr	api/PaddleAPIPrivate.h	/^  std::shared_ptr<paddle::Parameter> sharedPtr;$/;"	m	struct:ParameterPrivate
should_shuffle	gserver/tests/rnn_data_provider.py	/^    should_shuffle=False)$/;"	v
showAbstract	utils/BarrierStat.cpp	/^void BarrierDeltaStat::showAbstract(std::ostream &output) const {$/;"	f	class:paddle::BarrierDeltaStat
showAbstract	utils/BarrierStat.cpp	/^void BarrierEndStat::showAbstract(std::ostream &output) const {$/;"	f	class:paddle::BarrierEndStat
showAbstract	utils/BarrierStat.h	/^  virtual void showAbstract(std::ostream &output) const {}$/;"	f	class:paddle::BarrierStatBase
showDataStats	gserver/dataproviders/ProtoDataProvider.cpp	/^void ProtoDataProvider::showDataStats() {$/;"	f	class:paddle::ProtoDataProvider
showOutputStats	gserver/layers/Layer.cpp	/^void Layer::showOutputStats() {$/;"	f	class:paddle::Layer
showParameterStats	trainer/TrainerInternal.cpp	/^void TrainerInternal::showParameterStats($/;"	f	class:paddle::TrainerInternal
showStats	trainer/TrainerInternalConfig.h	/^  void showStats(std::ostream& os, bool withCurrentCost = true) const {$/;"	f	class:paddle::TrainerStats
show_layer_stat	utils/Flags.h	/^DECLARE_bool(show_layer_stat);$/;"	v
show_param_stats_period	trainer/TrainerInternalConfig.h	/^  int show_param_stats_period;$/;"	m	struct:paddle::TrainerInternalConfig
shrinkMat	gserver/layers/BatchNormalizationLayer.cpp	/^void BatchNormalizationLayer::shrinkMat(const MatrixPtr& in, MatrixPtr& out) {$/;"	f	class:paddle::BatchNormalizationLayer
shuffle	gserver/dataproviders/DataProvider.cpp	/^void SimpleDataProviderBase::shuffle() {$/;"	f	class:paddle::SimpleDataProviderBase
shuffle	gserver/dataproviders/DataProvider.h	/^  virtual void shuffle() {}$/;"	f	class:paddle::DummyDataProvider
shuffle	gserver/dataproviders/DataProviderGroup.h	/^  virtual void shuffle() {}$/;"	f	class:paddle::DataProviderGroup
shuffle	gserver/dataproviders/MultiDataProvider.cpp	/^void MultiDataProvider::shuffle() {$/;"	f	class:paddle::MultiDataProvider
shuffle	gserver/dataproviders/ProtoDataProvider.cpp	/^void ProtoDataProvider::shuffle() {$/;"	f	class:paddle::ProtoDataProvider
shuffle	gserver/dataproviders/PyDataProvider.cpp	/^void PyDataProvider::shuffle() {$/;"	f	class:paddle::PyDataProvider
shuffle	gserver/dataproviders/PyDataProvider2.cpp	/^  void shuffle() {}$/;"	f	class:paddle::PyDataProvider2
shuffle	gserver/tests/pyDataProvider.py	/^    def shuffle(self):$/;"	m	class:SimpleDataProvider
shuffle	gserver/tests/pyDataProvider.py	/^    def shuffle(self):$/;"	m	class:SimpleNestDataProvider
shuffledSequenceIds_	gserver/dataproviders/ProtoDataProvider.h	/^  std::vector<size_t> shuffledSequenceIds_;$/;"	m	class:paddle::ProtoDataProvider
sigmoid	cuda/src/hl_avx_functions.cc	/^__m256 sigmoid(const __m256 a) {$/;"	f	namespace:hppl
sigmoid	cuda/src/hl_avx_functions.cc	/^__m256 sigmoid(const __m256 a, const __m256 b) {$/;"	f	namespace:hppl
sigmoid	cuda/src/hl_cpu_functions.cc	/^real sigmoid(const real a) {$/;"	f	namespace:hppl
sigmoid	cuda/src/hl_cpu_functions.cc	/^real sigmoid(const real a, const real b) { return a * b * (1 - b); }$/;"	f	namespace:hppl
sign	cuda/include/hl_tensor_ops.h	/^class sign {$/;"	c	namespace:hppl::unary
sign	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::sign<T>, const Derived, T> sign() const {$/;"	f	class:paddle::TensorExpression
signal_handler	scripts/cluster_train/paddle.py	/^    def signal_handler(signal, frame):$/;"	f	function:job_clean
simd	math/SIMDFunctions.cpp	/^namespace simd {$/;"	n	namespace:paddle	file:
simd	math/SIMDFunctions.h	/^namespace simd {$/;"	n	namespace:paddle
simd_flags_	utils/CpuId.h	/^  int simd_flags_ = SIMD_NONE;$/;"	m	class:paddle::final
simd_t	utils/CpuId.h	/^enum simd_t {$/;"	g	namespace:paddle
simpleSequenceCheck	gserver/tests/test_PyDataProvider.cpp	/^void simpleSequenceCheck(const vector<Argument>& argumentList, int sample_num) {$/;"	f
simpleValueCheck	gserver/tests/test_PyDataProvider.cpp	/^void simpleValueCheck(const vector<Argument>& argumentList, bool useGpu) {$/;"	f
sin	cuda/src/hl_math.cc	/^__m256 sin(__m256 a) { return sin256_ps(a); }$/;"	f	namespace:hppl
sin256_ps	cuda/src/avx_mathfun.h	/^v8sf sin256_ps(v8sf x) {  \/\/ any x$/;"	f
sincos256_ps	cuda/src/avx_mathfun.h	/^void sincos256_ps(v8sf x, v8sf *s, v8sf *c) {$/;"	f
singlePathExpand	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^void RecurrentGradientMachine::singlePathExpand(Path& curPath,$/;"	f	class:paddle::RecurrentGradientMachine
singleUpdate	parameter/ParallelParameter.cpp	/^void SyncParameter::singleUpdate(real learnRate) {$/;"	f	class:paddle::SyncParameter
singleUpdate	parameter/ParallelParameter.h	/^  virtual void singleUpdate(real learnRate) { (void)learnRate; }$/;"	f	class:paddle::ParallelParameter
singleton	math/Storage.cpp	/^StorageEngine* StorageEngine::singleton() {$/;"	f	class:paddle::StorageEngine
size	function/Function.h	/^  size_t size() const { return args_.size(); }$/;"	f	class:paddle::BufferArgs
size	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^    size=hidden_dim)$/;"	v
size	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^    size=hidden_dim)$/;"	v
size	math/MatrixBitCode.cpp	/^  size_t size() const { return numClasses_; }$/;"	f	struct:paddle::__anon17::SimpleCodeTable
size	parameter/Parameter.h	/^    uint64_t size;       \/\/ = getSize()$/;"	m	struct:paddle::Parameter::Header
size	parameter/ParameterUpdaterHook.cpp	/^    size_t size;$/;"	m	struct:paddle::StaticPruningHook::StaticMaskHeader	file:
size	pserver/ParameterServer2.h	/^    size_t size;$/;"	m	struct:paddle::ParameterServer2::Buffer
size	trainer/tests/simple_sparse_neural_network.py	/^    size=128,$/;"	v
size	utils/BarrierStat.h	/^  uint16_t size() { return size_; }$/;"	f	class:paddle::TimeVectorDelta
size	utils/BarrierStat.h	/^  uint16_t size() { return size_; }$/;"	f	class:paddle::TimeVectorEnd
size	utils/PythonUtil.h	/^  inline size_t size() const { return (size_t)PySequence_Size(seq_); }$/;"	f	class:paddle::py::SequenceHelper
size	utils/Queue.h	/^  inline int size() const { return numElements_; }$/;"	f	class:paddle::Queue
size	utils/Queue.h	/^  size_t size() {$/;"	f	class:paddle::BlockingQueue
sizeLimit_	math/PoolAllocator.h	/^  size_t sizeLimit_;$/;"	m	class:paddle::PoolAllocator
sizeOfValuType	function/TensorType.h	/^inline int sizeOfValuType(ValueType valueType) {$/;"	f	namespace:paddle
sizeVec_	parameter/tests/test_common.cpp	/^  std::vector<size_t> sizeVec_;$/;"	m	class:CommonTest	file:
sizeX_	gserver/layers/PoolLayer.h	/^  size_t channels_, sizeX_, stride_, outputX_, imgSize_;$/;"	m	class:paddle::PoolLayer
sizeX_	gserver/layers/PoolProjection.h	/^  size_t sizeY_, sizeX_;$/;"	m	class:paddle::PoolProjection
sizeY_	gserver/layers/PoolLayer.h	/^  size_t sizeY_;$/;"	m	class:paddle::PoolLayer
sizeY_	gserver/layers/PoolProjection.h	/^  size_t sizeY_, sizeX_;$/;"	m	class:paddle::PoolProjection
size_	function/CrossMapNormalOp.cpp	/^  size_t size_;$/;"	m	class:paddle::CrossMapNormalFunc	file:
size_	function/CrossMapNormalOp.cpp	/^  size_t size_;$/;"	m	class:paddle::CrossMapNormalGradFunc	file:
size_	gserver/dataproviders/DataProvider.h	/^  int64_t size_;$/;"	m	class:paddle::DataBatch
size_	gserver/layers/NormLayer.h	/^  size_t channels_, size_, outputX_, imgSize_, outputY_, imgSizeY_;$/;"	m	class:paddle::ResponseNormLayer
size_	gserver/layers/RotateLayer.h	/^  int size_;$/;"	m	class:paddle::RotateLayer
size_	math/MemoryHandle.h	/^  size_t size_;       \/\/ the requested size$/;"	m	class:paddle::MemoryHandle
size_	math/Vector.h	/^  size_t& size_;$/;"	m	class:paddle::BaseVector
size_	pserver/ParameterServer2.h	/^  int64_t size_;$/;"	m	class:paddle::ParameterServer2
size_	utils/BarrierStat.h	/^  uint16_t size_;$/;"	m	class:paddle::TimeVectorDelta
size_	utils/BarrierStat.h	/^  uint16_t size_;$/;"	m	class:paddle::TimeVectorEnd
size_type	utils/Util.h	/^  typedef size_t size_type;$/;"	t	class:paddle::AlignedAllocator
sizeofReal	utils/Version.h	/^constexpr size_t sizeofReal() { return sizeof(real); }$/;"	f	namespace:paddle::version
skipRand_	gserver/dataproviders/PyDataProvider2.cpp	/^    bool skipRand_;$/;"	m	class:paddle::PyDataProvider2::PositionRandom	file:
skipShuffle_	gserver/dataproviders/DataProvider.h	/^  bool skipShuffle_;$/;"	m	class:paddle::DataProvider
skip_ws	trainer/tests/picojson.h	/^  void skip_ws() {$/;"	f	class:picojson::input
slaveUpdate	parameter/ParallelParameter.cpp	/^void AsyncParameter::slaveUpdate(real learnRate) {$/;"	f	class:paddle::AsyncParameter
slaveUpdate	parameter/ParallelParameter.h	/^  virtual void slaveUpdate(real learnRate) { (void)learnRate; }$/;"	f	class:paddle::ParallelParameter
slotNum_	gserver/dataproviders/PyDataProvider.h	/^  unsigned int slotNum_;$/;"	m	class:paddle::PyDataProvider
slotType	gserver/dataproviders/PyDataProvider2.cpp	/^  SlotType slotType;$/;"	m	struct:paddle::SlotHeader	file:
slots_	gserver/dataproviders/ProtoDataProvider.h	/^  std::vector<ProtoSlot> slots_;$/;"	m	class:paddle::ProtoDataProvider
slots_	gserver/dataproviders/PyDataProvider.h	/^  std::vector<ProtoSlot> slots_;$/;"	m	class:paddle::PyDataProvider
socketDaemon_	pserver/LightNetwork.h	/^  struct sxi_socket* socketDaemon_;$/;"	m	class:paddle::SocketClient	typeref:struct:paddle::SocketClient::sxi_socket
socket_	pserver/LightNetwork.h	/^  int socket_;$/;"	m	class:paddle::SocketServer
socket_	pserver/test/SocketTest.cpp	/^  int socket_;$/;"	m	class:SocketChannel	file:
socket_	pserver/test/SocketTest.cpp	/^  int socket_;$/;"	m	class:SocketServer	file:
softmax	math/Matrix.cpp	/^void CpuMatrix::softmax(Matrix& output) {$/;"	f	class:paddle::CpuMatrix
softmax	math/Matrix.cpp	/^void GpuMatrix::softmax(Matrix& output) {$/;"	f	class:paddle::GpuMatrix
softmax	math/Matrix.h	/^  virtual void softmax(Matrix& output) {$/;"	f	class:paddle::Matrix
softmaxBackward	math/Matrix.cpp	/^void GpuMatrix::softmaxBackward(Matrix& outputV) {$/;"	f	class:paddle::GpuMatrix
softmaxBackward	math/Matrix.h	/^  virtual void softmaxBackward(Matrix& outputV) {$/;"	f	class:paddle::Matrix
softmaxDerivative	math/Matrix.cpp	/^void CpuMatrix::softmaxDerivative(Matrix& output, Matrix& sftmaxSum) {$/;"	f	class:paddle::CpuMatrix
softmaxDerivative	math/Matrix.cpp	/^void GpuMatrix::softmaxDerivative(Matrix& output, Matrix& sftmaxSum) {$/;"	f	class:paddle::GpuMatrix
softmaxDerivative	math/Matrix.h	/^  virtual void softmaxDerivative(Matrix& output, Matrix& sftmaxSum) {$/;"	f	class:paddle::Matrix
softmax_	gserver/activations/ActivationFunction.cpp	/^ACTIVATION_CLASS_NAME(softmax) softmax_;$/;"	m	namespace:paddle	file:
softrelu	math/Matrix.cpp	/^void CpuMatrix::softrelu(Matrix& output) {$/;"	f	class:paddle::CpuMatrix
softrelu	math/Matrix.cpp	/^void GpuMatrix::softrelu(Matrix& output) { BaseMatrix::softrelu(output); }$/;"	f	class:paddle::GpuMatrix
softrelu	math/Matrix.h	/^  virtual void softrelu(Matrix& output) { LOG(FATAL) << "Not implemented"; }$/;"	f	class:paddle::Matrix
softreluDerivative	math/Matrix.cpp	/^void CpuMatrix::softreluDerivative(Matrix& output) {$/;"	f	class:paddle::CpuMatrix
softreluDerivative	math/Matrix.cpp	/^void GpuMatrix::softreluDerivative(Matrix& output) {$/;"	f	class:paddle::GpuMatrix
softreluDerivative	math/Matrix.h	/^  virtual void softreluDerivative(Matrix& output) {$/;"	f	class:paddle::Matrix
sourceDataVec_	math/SparseRowMatrix.h	/^  CpuVectorPtr sourceDataVec_;$/;"	m	class:paddle::CacheRowCpuMatrix
sourceData_	math/SparseRowMatrix.h	/^  real* sourceData_;$/;"	m	class:paddle::CacheRowCpuMatrix
sparse	function/BufferArg.cpp	/^const SparseMatrixArg& BufferArg::sparse() const {$/;"	f	class:paddle::BufferArg
sparse	gserver/tests/LayerGradUtil.h	/^  ParaSparse sparse;$/;"	m	struct:paddle::InputDef
sparse	gserver/tests/LayerGradUtil.h	/^  bool sparse;$/;"	m	struct:paddle::ParaSparse
sparse	math/tests/test_SparseMatrix.cpp	/^  bool sparse;$/;"	m	struct:MatrixPara	file:
sparseCopyFrom	api/Matrix.cpp	/^void Matrix::sparseCopyFrom($/;"	f	class:Matrix
sparseDistribution_	pserver/ParameterClient2.h	/^  std::unique_ptr<SparseParameterDistribution> sparseDistribution_;$/;"	m	class:paddle::ParameterClient2
sparseFloatValueData	gserver/dataproviders/ProtoDataProvider.h	/^    std::vector<sparse_float_value_t> sparseFloatValueData;$/;"	m	struct:paddle::ProtoDataProvider::ProtoSlot
sparseFloatValueData	gserver/dataproviders/PyDataProvider.h	/^    std::vector<sparse_float_value_t> sparseFloatValueData;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
sparseNonValueData	gserver/dataproviders/ProtoDataProvider.h	/^    std::vector<sparse_non_value_t> sparseNonValueData;$/;"	m	struct:paddle::ProtoDataProvider::ProtoSlot
sparseNonValueData	gserver/dataproviders/PyDataProvider.h	/^    std::vector<sparse_non_value_t> sparseNonValueData;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
sparseRand	math/MathUtils.cpp	/^void sparseRand($/;"	f	namespace:paddle
sparseResize	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::sparseResize() {$/;"	f	class:paddle::CpuSparseMatrix
sparseResizeCSC	math/SparseMatrix.cpp	/^void GpuSparseMatrix::sparseResizeCSC() {$/;"	f	class:paddle::GpuSparseMatrix
sparseResizeCSR	math/SparseMatrix.cpp	/^void GpuSparseMatrix::sparseResizeCSR() {$/;"	f	class:paddle::GpuSparseMatrix
sparseValid	math/tests/test_SparseMatrix.cpp	/^void sparseValid($/;"	f
sparse_count_randomer	trainer/tests/testPyDataWrapper.py	/^sparse_count_randomer = lambda: random.randrange(1, SPARSE_ID_COUNT)$/;"	v
sparse_creator	trainer/tests/testPyDataWrapper.py	/^def sparse_creator(_):$/;"	f
sparse_float_value_t	math/Matrix.h	/^} sparse_float_value_t;$/;"	t	namespace:paddle	typeref:struct:paddle::__anon19
sparse_id_randomer	trainer/tests/testPyDataWrapper.py	/^sparse_id_randomer = lambda: random.randrange(0, SPARSE_ID_LIMIT - 1)$/;"	v
sparse_non_value_t	math/Matrix.h	/^typedef struct { unsigned int col; } sparse_non_value_t;$/;"	t	namespace:paddle	typeref:struct:paddle::__anon18
sparse_nonvalue	trainer/tests/testPyDataWrapper.py	/^sparse_nonvalue = map(sparse_creator, range(seq_count_randomer()))$/;"	v
sparse_value	trainer/tests/testPyDataWrapper.py	/^sparse_value = map(sparse_value_creator, range(seq_count_randomer()))$/;"	v
sparse_value_creator	gserver/tests/pyDataProvider.py	/^def sparse_value_creator(sample_num):$/;"	f
sparse_value_creator	trainer/tests/testPyDataWrapper.py	/^def sparse_value_creator(_):$/;"	f
speaker1	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^speaker1 = data_layer(name="word1", size=dict_dim)$/;"	v
speaker1	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^speaker1 = data_layer(name="word1", size=dict_dim)$/;"	v
speaker2	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^speaker2 = data_layer(name="word2", size=dict_dim)$/;"	v
speaker2	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^speaker2 = data_layer(name="word2", size=dict_dim)$/;"	v
split	utils/StringUtil.cpp	/^void split(const std::string& str, char sep, std::vector<std::string>* pieces) {$/;"	f	namespace:paddle::str
splitByDataId	parameter/Argument.cpp	/^void Argument::splitByDataId(const std::vector<Argument>& argus,$/;"	f	class:paddle::Argument
sqrt	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::sqrt_op<T>, const Derived, T> sqrt() const {$/;"	f	class:paddle::TensorExpression
sqrt_op	cuda/include/hl_tensor_ops.h	/^class sqrt_op {$/;"	c	namespace:hppl::unary
square	cuda/include/hl_tensor_ops.h	/^class square {$/;"	c	namespace:hppl::unary
square	math/TensorExpression.h	/^  const TensorUnaryOp<hppl::unary::square<T>, const Derived, T> square() const {$/;"	f	class:paddle::TensorExpression
square2	math/CpuSparseMatrix.h	/^  virtual void square2() {$/;"	f	class:paddle::CpuSparseMatrix
ssocket	pserver/RDMANetwork.h	/^inline sxi_socket* ssocket(int cpuId) {$/;"	f	namespace:paddle::rdma
stack	utils/CustomStackTrace.h	/^  std::stack<T>& stack() {$/;"	f	class:paddle::CustomStackTrace
stackBuffers_	utils/CustomStackTrace.h	/^  std::unordered_map<std::thread::id, std::stack<T>*> stackBuffers_;$/;"	m	class:paddle::CustomStackTrace
stanh	gserver/activations/ActivationFunction.cpp	/^ACTIVATION_CLASS_NAME(stanh)() : a(1.7159), b(2. \/ 3.) {}$/;"	f	namespace:paddle
start	api/Evaluator.cpp	/^void Evaluator::start() { m->rawPtr->start(); }$/;"	f	class:Evaluator
start	api/GradientMachine.cpp	/^void GradientMachine::start() { m->machine->start(); }$/;"	f	class:GradientMachine
start	gserver/evaluators/CTCErrorEvaluator.cpp	/^  virtual void start() {$/;"	f	class:paddle::CTCErrorEvaluator
start	gserver/evaluators/ChunkEvaluator.cpp	/^  virtual void start() {$/;"	f	class:paddle::ChunkEvaluator
start	gserver/evaluators/Evaluator.cpp	/^  virtual void start() {$/;"	f	class:paddle::ColumnSumEvaluator
start	gserver/evaluators/Evaluator.cpp	/^void AucEvaluator::start() {$/;"	f	class:paddle::AucEvaluator
start	gserver/evaluators/Evaluator.cpp	/^void PnpairEvaluator::start() {$/;"	f	class:paddle::PnpairEvaluator
start	gserver/evaluators/Evaluator.cpp	/^void PrecisionRecallEvaluator::start() {$/;"	f	class:paddle::PrecisionRecallEvaluator
start	gserver/evaluators/Evaluator.cpp	/^void RankAucEvaluator::start() { Evaluator::start(); }$/;"	f	class:paddle::RankAucEvaluator
start	gserver/evaluators/Evaluator.h	/^  virtual void start() {$/;"	f	class:paddle::Evaluator
start	gserver/evaluators/Evaluator.h	/^  virtual void start() {}$/;"	f	class:paddle::DummyEvaluator
start	gserver/gradientmachines/GradientMachine.h	/^  virtual void start() {}$/;"	f	class:paddle::GradientMachine
start	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::start() {$/;"	f	class:paddle::TrainerThread
start	gserver/gradientmachines/MultiNetwork.cpp	/^  virtual void start() {$/;"	f	class:paddle::MultiCombinedEvaluator
start	gserver/gradientmachines/MultiNetwork.cpp	/^void MultiNetwork::start() {$/;"	f	class:paddle::MultiNetwork
start	gserver/gradientmachines/NeuralNetwork.cpp	/^  virtual void start() {$/;"	f	class:paddle::CombinedEvaluator
start	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^void ParallelNeuralNetwork::start() {$/;"	f	class:paddle::ParallelNeuralNetwork
start	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^void ParallelThread::start() {$/;"	f	class:paddle::ParallelThread
start	pserver/ParameterServerController.cpp	/^void ParameterServerController::start() {$/;"	f	class:paddle::ParameterServerController
start	pserver/test/SocketTest.cpp	/^void Thread::start() {$/;"	f	class:Thread
start	utils/Stat.h	/^  void start() { startStamp_ = nowInMicroSec(); }$/;"	f	class:paddle::Timer
start	utils/Thread.h	/^  void start() {$/;"	f	class:paddle::SyncThreadPool
start	utils/Thread.h	/^  void start() {$/;"	f	class:paddle::Thread
startAsyncLoad	gserver/dataproviders/DataProvider.cpp	/^void DoubleBuffer::startAsyncLoad() {$/;"	f	class:paddle::DoubleBuffer
startBatch	api/ParameterOptimizer.cpp	/^void ParameterOptimizer::startBatch(size_t numSamplesProcessed) {$/;"	f	class:ParameterOptimizer
startBatch	api/ParameterUpdater.cpp	/^PassType ParameterUpdater::startBatch(size_t batchSize) {$/;"	f	class:ParameterUpdater
startBatch	parameter/AverageOptimizer.cpp	/^void AverageOptimizer::startBatch(int64_t numSamplesProcessed) {$/;"	f	class:paddle::AverageOptimizer
startBatch	parameter/FirstOrderOptimizer.cpp	/^void SparseMomentumParameterOptimizer::startBatch(int64_t numSamplesProcessed) {$/;"	f	class:paddle::SparseMomentumParameterOptimizer
startBatch	parameter/FirstOrderOptimizer.h	/^  virtual void startBatch(int64_t numSamplesProcessed) {$/;"	f	class:paddle::AdaDeltaParameterOptimizer
startBatch	parameter/FirstOrderOptimizer.h	/^  virtual void startBatch(int64_t numSamplesProcessed) {$/;"	f	class:paddle::AdagradParameterOptimizer
startBatch	parameter/FirstOrderOptimizer.h	/^  virtual void startBatch(int64_t numSamplesProcessed) {$/;"	f	class:paddle::AddOptimizer
startBatch	parameter/FirstOrderOptimizer.h	/^  virtual void startBatch(int64_t numSamplesProcessed) {$/;"	f	class:paddle::DecayedAdagradParameterOptimizer
startBatch	parameter/FirstOrderOptimizer.h	/^  virtual void startBatch(int64_t numSamplesProcessed) {$/;"	f	class:paddle::OptimizerWithGradientClipping
startBatch	parameter/FirstOrderOptimizer.h	/^  virtual void startBatch(int64_t numSamplesProcessed) {$/;"	f	class:paddle::RMSPropParameterOptimizer
startBatch	parameter/FirstOrderOptimizer.h	/^  virtual void startBatch(int64_t numSamplesProcessed) {$/;"	f	class:paddle::SgdOptimizer
startBatch	parameter/OptimizerWithRegularizer.h	/^  virtual void startBatch(int64_t numSamplesProcessed) {$/;"	f	class:paddle::OptimizerWithRegularizer
startBatch	parameter/ParameterOptimizer.h	/^  virtual void startBatch(int64_t numSamplesProcessed) {$/;"	f	class:paddle::ParameterOptimizer
startBatch	parameter/ParameterUpdaterBase.h	/^  virtual PassType startBatch(int64_t batchSize) {$/;"	f	class:paddle::ParameterUpdater
startBatch	parameter/ParameterUpdaterBase.h	/^  virtual PassType startBatch(int64_t batchSize) {$/;"	f	class:paddle::ParameterUpdaterComposite
startBatch	trainer/ParameterUpdater.h	/^  virtual PassType startBatch(int64_t batchSize) {$/;"	f	class:paddle::SgdLocalUpdater
startBatch	trainer/ParameterUpdater.h	/^  virtual PassType startBatch(int64_t batchSize) {$/;"	f	class:paddle::SgdUpdaterWithCpuAverager
startBatch	trainer/RemoteParameterUpdater.cpp	/^PassType SparseRemoteParameterUpdater::startBatch(int64_t batchSize) {$/;"	f	class:paddle::SparseRemoteParameterUpdater
startBatch	trainer/RemoteParameterUpdater.h	/^  virtual PassType startBatch(int64_t batchSize) {$/;"	f	class:paddle::RemoteParameterUpdater
startBatch	trainer/ThreadParameterUpdater.cpp	/^PassType SgdThreadUpdater::startBatch(int64_t batchSize) {$/;"	f	class:paddle::SgdThreadUpdater
startCatchUpWith	parameter/AverageOptimizer.cpp	/^ParameterOptimizer::TraverseCallback AverageSparseOptimizer::startCatchUpWith()$/;"	f	class:paddle::AverageSparseOptimizer
startCatchUpWith	parameter/AverageOptimizer.h	/^  virtual TraverseCallback startCatchUpWith() const {$/;"	f	class:paddle::AverageOptimizer
startCatchUpWith	parameter/OptimizerWithRegularizer.cpp	/^OptimizerWithRegularizerEveryNumBatches::startCatchUpWith() const {$/;"	f	class:paddle::OptimizerWithRegularizerEveryNumBatches
startCatchUpWith	parameter/OptimizerWithRegularizer.cpp	/^OptimizerWithRegularizerSparse::startCatchUpWith() const {$/;"	f	class:paddle::OptimizerWithRegularizerSparse
startCatchUpWith	parameter/ParameterOptimizer.h	/^  virtual TraverseCallback startCatchUpWith() const { return nullptr; }$/;"	f	class:paddle::ParameterOptimizer
startController	trainer/RemoteParameterUpdater.cpp	/^void RemoteParameterUpdater::startController() {$/;"	f	class:paddle::RemoteParameterUpdater
startController	trainer/RemoteParameterUpdater.cpp	/^void SparseRemoteParameterUpdater::startController() {$/;"	f	class:paddle::SparseRemoteParameterUpdater
startFill	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void startFill(Argument& argument) {$/;"	f	class:paddle::SequenceScanner
startFill	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void startFill(Argument& argument) {$/;"	f	class:paddle::SparseNonValueScanner
startFill	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void startFill(Argument& argument) {}$/;"	f	class:paddle::IFieldScanner
startIdx	gserver/layers/MultiplexLayer.cpp	/^    int startIdx;$/;"	m	struct:paddle::MultiplexLayer::CopyInfo	file:
startLoader	gserver/dataproviders/DataProviderGroup.h	/^void DataProviderGroup<T>::startLoader() {$/;"	f	class:paddle::DataProviderGroup
startPass	api/ParameterOptimizer.cpp	/^void ParameterOptimizer::startPass() { m->optimizer->startPass(); }$/;"	f	class:ParameterOptimizer
startPass	api/ParameterUpdater.cpp	/^void ParameterUpdater::startPass() { m->updater->startPass(); }$/;"	f	class:ParameterUpdater
startPass	parameter/AverageOptimizer.h	/^  virtual void startPass() { optimizer_->startPass(); }$/;"	f	class:paddle::AverageOptimizer
startPass	parameter/FirstOrderOptimizer.h	/^  virtual void startPass() { optimizer_->startPass(); }$/;"	f	class:paddle::OptimizerWithGradientClipping
startPass	parameter/OptimizerWithRegularizer.h	/^  virtual void startPass() {$/;"	f	class:paddle::OptimizerWithRegularizer
startPass	parameter/OptimizerWithRegularizer.h	/^  virtual void startPass() {$/;"	f	class:paddle::OptimizerWithRegularizerEveryNumBatches
startPass	parameter/ParameterOptimizer.h	/^  virtual void startPass() {}$/;"	f	class:paddle::ParameterOptimizer
startPass	parameter/ParameterUpdaterBase.h	/^  virtual void startPass() {$/;"	f	class:paddle::ParameterUpdaterComposite
startPass	parameter/ParameterUpdaterBase.h	/^  virtual void startPass() {}$/;"	f	class:paddle::ParameterUpdater
startPass	trainer/ParameterUpdater.h	/^  virtual void startPass() { optimizer_->startPass(); }$/;"	f	class:paddle::SgdLocalUpdater
startPass	trainer/ParameterUpdater.h	/^  virtual void startPass() {$/;"	f	class:paddle::SgdUpdaterWithCpuAverager
startPass	trainer/RemoteParameterUpdater.cpp	/^void RemoteParameterUpdater::startPass() {$/;"	f	class:paddle::RemoteParameterUpdater
startPass	trainer/RemoteParameterUpdater.cpp	/^void SparseRemoteParameterUpdater::startPass() {$/;"	f	class:paddle::SparseRemoteParameterUpdater
startPass	trainer/ThreadParameterUpdater.cpp	/^void SgdThreadUpdater::startPass() {$/;"	f	class:paddle::SgdThreadUpdater
startPositions_	function/BufferArg.h	/^  SequenceIdArg startPositions_;$/;"	m	class:paddle::SequenceArg
startPositions_	gserver/layers/SequencePoolLayer.h	/^  ICpuGpuVectorPtr startPositions_;$/;"	m	class:paddle::SequencePoolLayer
startPrepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void startPrepare(Argument& argument) {$/;"	f	class:paddle::SequenceScanner
startPrepare	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual void startPrepare(Argument& argument) {}$/;"	f	class:paddle::IFieldScanner
startStamp_	utils/Stat.h	/^  uint64_t startStamp_;$/;"	m	class:paddle::Timer
startTask	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::startTask(TaskType taskType) {$/;"	f	class:paddle::MultiGradientMachine
startTestPeriod	api/Trainer.cpp	/^void Trainer::startTestPeriod() { m->startTestPeriod(); }$/;"	f	class:Trainer
startTestPeriod	api/Trainer.cpp	/^void TrainerPrivate::startTestPeriod() {$/;"	f	class:TrainerPrivate
startTestPeriod	trainer/Tester.cpp	/^void Tester::startTestPeriod() {$/;"	f	class:paddle::Tester
startThreads	pserver/BaseClient.cpp	/^void BaseClient::startThreads() {$/;"	f	class:paddle::BaseClient
startTrain	api/Trainer.cpp	/^void Trainer::startTrain() { m->startTrain(); }$/;"	f	class:Trainer
startTrain	gserver/tests/test_RecurrentGradientMachine.cpp	/^  void startTrain() {$/;"	f	class:TrainerForTest
startTrain	trainer/Trainer.cpp	/^void Trainer::startTrain() {$/;"	f	class:paddle::Trainer
startTrainPass	api/Trainer.cpp	/^void Trainer::startTrainPass() { m->startTrainPass(); }$/;"	f	class:Trainer
startTrainPass	trainer/Trainer.cpp	/^void Trainer::startTrainPass() {$/;"	f	class:paddle::Trainer
start_pass	api/Trainer.cpp	/^DECLARE_int32(start_pass);$/;"	v
start_pass	trainer/TrainerConfigHelper.cpp	/^DECLARE_int32(start_pass);$/;"	v
start_pass	trainer/TrainerMain.cpp	/^DECLARE_int32(start_pass);$/;"	v
start_pserver	scripts/cluster_train/paddle.py	/^    def start_pserver(jobdir, pargs):$/;"	f	function:job_pserver
start_trainer	scripts/cluster_train/paddle.py	/^    def start_trainer(jobdir, args):$/;"	f	function:job_trainer
startsWith	utils/StringUtil.cpp	/^bool startsWith(const std::string& str, const std::string& prefix) {$/;"	f	namespace:paddle::str
stat	gserver/evaluators/Evaluator.cpp	/^void PnpairEvaluator::stat(size_t start,$/;"	f	class:paddle::PnpairEvaluator
statInfo_	utils/Stat.h	/^  ThreadLocal<StatInfo> statInfo_;$/;"	m	class:paddle::Stat
statNeg_	gserver/evaluators/Evaluator.h	/^  double statNeg_[kBinNum_ + 1];$/;"	m	class:paddle::AucEvaluator
statPos_	gserver/evaluators/Evaluator.h	/^  double statPos_[kBinNum_ + 1];$/;"	m	class:paddle::AucEvaluator
statSet_	pserver/ParameterServer2.h	/^  std::unique_ptr<StatSet> statSet_;$/;"	m	class:paddle::ParameterServer2
statSet_	utils/Stat.h	/^  std::unordered_map<std::string, StatPtr> statSet_;$/;"	m	class:paddle::StatSet
stat_	utils/Stat.h	/^  Stat* stat_;$/;"	m	class:paddle::StatInfo
stat_	utils/Stat.h	/^  Stat* stat_;$/;"	m	class:paddle::TimerOnce
state2_	gserver/layers/ContextProjection.h	/^  MatrixPtr state2_;$/;"	m	class:paddle::ContextProjection
stateActiveGrad	cuda/include/hl_base.h	/^  real *stateActiveGrad;$/;"	m	struct:__anon5
stateActiveValue	cuda/include/hl_base.h	/^  real *stateActiveValue;$/;"	m	struct:__anon4
stateActive_	gserver/layers/LstmStepLayer.cpp	/^  Argument stateActive_;$/;"	m	class:paddle::LstmStepLayer	file:
stateGrad	cuda/include/hl_base.h	/^  real *stateGrad;$/;"	m	struct:__anon5
stateValue	cuda/include/hl_base.h	/^  real *stateValue;$/;"	m	struct:__anon4
stateWeight	cuda/include/hl_base.h	/^  real *stateWeight;$/;"	m	struct:__anon6
stateWeightGrad	cuda/include/hl_base.h	/^  real *stateWeightGrad;$/;"	m	struct:__anon7
stateWeight_	gserver/layers/GatedRecurrentLayer.h	/^  std::unique_ptr<Weight> stateWeight_;$/;"	m	class:paddle::GatedRecurrentLayer
state_	gserver/layers/ContextProjection.h	/^  MatrixPtr state_;$/;"	m	class:paddle::ContextProjection
state_	gserver/layers/LstmLayer.h	/^  Argument state_;$/;"	m	class:paddle::LstmLayer
state_	gserver/layers/LstmStepLayer.cpp	/^  Argument state_;$/;"	m	class:paddle::LstmStepLayer	file:
staticBias	gserver/tests/LayerGradUtil.h	/^  bool staticBias;$/;"	m	struct:paddle::TestConfig
staticCastVector	api/Internal.h	/^void staticCastVector(std::vector<T2>* dest, const std::vector<T1>& src) {$/;"	f
statsInfo_	gserver/evaluators/Evaluator.h	/^  std::vector<StatsInfo> statsInfo_;$/;"	m	class:paddle::PrecisionRecallEvaluator
stats_	trainer/Tester.h	/^  TrainerStats stats_;$/;"	m	class:paddle::Tester
stats_	trainer/Trainer.h	/^  std::shared_ptr<TrainerStats> stats_;$/;"	m	class:paddle::Trainer
stats_	trainer/TrainerInternal.h	/^  std::shared_ptr<TrainerStats> stats_;$/;"	m	class:paddle::TrainerInternal
status_	pserver/ParameterServer2.h	/^  PServerStatus status_;$/;"	m	class:paddle::ParameterServer2
status_	pserver/test/test_ProtoServer.cpp	/^  PServerStatus status_;$/;"	m	class:MyServer	file:
std	trainer/tests/picojson.h	/^namespace std {$/;"	n
stdGrad_	gserver/layers/BatchNormalizationLayer.h	/^  MatrixPtr normIn_, normInGrad_, meanGrad_, stdGrad_;$/;"	m	class:paddle::BatchNormalizationLayer
stdReciprocal_	gserver/layers/DataNormLayer.h	/^  MatrixPtr stdReciprocal_;      \/\/ 1\/std$/;"	m	class:paddle::DataNormLayer
step	gserver/layers/MDLstmLayer.cpp	/^  void step(size_t d, bool reversed) {$/;"	f	class:paddle::CoordIterator
step	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^    step=outer_step,$/;"	v
step	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^def step(x1, x2):$/;"	f
step_	parameter/FirstOrderOptimizer.h	/^  int64_t step_;$/;"	m	class:paddle::AdamParameterOptimizer
step_	parameter/FirstOrderOptimizer.h	/^  int64_t step_;$/;"	m	class:paddle::AdamaxParameterOptimizer
stop	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::stop() {$/;"	f	class:paddle::TrainerThread
stop	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^void ParallelThread::stop() {$/;"	f	class:paddle::ParallelThread
stop	utils/Stat.h	/^  uint64_t stop() {$/;"	f	class:paddle::Timer
stop	utils/Thread.h	/^  void stop() {$/;"	f	class:paddle::AsyncThreadPool
stop	utils/Thread.h	/^  void stop() {$/;"	f	class:paddle::MultiThreadWorker
stop	utils/Thread.h	/^  void stop() {$/;"	f	class:paddle::SyncThreadPool
stop	utils/Thread.h	/^  void stop() {$/;"	f	class:paddle::ThreadWorker
stopAddJob	utils/Thread.h	/^  void stopAddJob() {$/;"	f	class:paddle::MultiThreadWorker
stopBeamSearch_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  bool stopBeamSearch_;$/;"	m	class:paddle::RecurrentGradientMachine
stopDetermineCandidates	gserver/gradientmachines/RecurrentGradientMachine.cpp	/^  RecurrentGradientMachine::DropCallback stopDetermineCandidates;$/;"	m	class:paddle::BeamSearchControlCallbacks	file:
stopLoader	gserver/dataproviders/DataProviderGroup.h	/^void DataProviderGroup<T>::stopLoader() {$/;"	f	class:paddle::DataProviderGroup
stopping_	gserver/dataproviders/DataProvider.h	/^  bool stopping_;$/;"	m	class:paddle::DoubleBuffer
stopping_	gserver/gradientmachines/MultiGradientMachine.h	/^  bool stopping_;$/;"	m	class:paddle::TrainerThread
stopping_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  bool stopping_;$/;"	m	class:paddle::ParallelThread
stopping_	pserver/BaseClient.h	/^  bool stopping_;$/;"	m	class:paddle::BaseClient
stopping_	pserver/LightNetwork.h	/^  bool stopping_;$/;"	m	class:paddle::SocketServer
stopping_	trainer/RemoteParameterUpdater.h	/^  bool stopping_;$/;"	m	class:paddle::ConcurrentRemoteParameterUpdater
stopping_	utils/Thread.h	/^  bool stopping_;$/;"	m	class:paddle::AsyncThreadPool
stopping_	utils/Thread.h	/^  bool stopping_;$/;"	m	class:paddle::MultiThreadWorker
stopping_	utils/Thread.h	/^  bool stopping_;$/;"	m	class:paddle::SyncThreadPool
stopping_	utils/Thread.h	/^  bool stopping_;$/;"	m	class:paddle::ThreadWorker
storage_	utils/Util.h	/^  std::unordered_map<KType, std::weak_ptr<VType>, Hash> storage_;$/;"	m	class:paddle::WeakKVCache
str	utils/StringUtil.cpp	/^namespace str {$/;"	n	namespace:paddle	file:
str	utils/StringUtil.h	/^namespace str {$/;"	n	namespace:paddle
str	utils/Version.cpp	34;"	d	file:
strData	gserver/dataproviders/ProtoDataProvider.h	/^    std::vector<std::string> strData;$/;"	m	struct:paddle::ProtoDataProvider::ProtoSlot
strData	gserver/dataproviders/PyDataProvider.h	/^    std::vector<std::string> strData;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
strHasher_	parameter/ParameterUpdaterHook.cpp	/^  std::hash<std::string> strHasher_;$/;"	m	class:paddle::StringIntPairHasher	file:
str_count_randomer	trainer/tests/testPyDataWrapper.py	/^str_count_randomer = lambda: random.randrange(1, STRING_LIMIT)$/;"	v
strideH_	gserver/layers/BlockExpandLayer.h	/^  size_t blockH_, blockW_, strideH_, strideW_, paddingH_, paddingW_;$/;"	m	class:paddle::BlockExpandLayer
strideH_	gserver/layers/ConvProjection.h	/^  int strideH_, strideW_;$/;"	m	class:paddle::ConvProjection
strideHeight	gserver/layers/CudnnPoolLayer.h	/^  int heightPadding, widthPadding, strideHeight, strideWidth;$/;"	m	class:paddle::CudnnPoolLayer
strideW_	gserver/layers/BlockExpandLayer.h	/^  size_t blockH_, blockW_, strideH_, strideW_, paddingH_, paddingW_;$/;"	m	class:paddle::BlockExpandLayer
strideW_	gserver/layers/ConvProjection.h	/^  int strideH_, strideW_;$/;"	m	class:paddle::ConvProjection
strideWidth	gserver/layers/CudnnPoolLayer.h	/^  int heightPadding, widthPadding, strideHeight, strideWidth;$/;"	m	class:paddle::CudnnPoolLayer
strideY_	gserver/layers/ConvBaseLayer.h	/^  IntV strideY_;$/;"	m	class:paddle::ConvBaseLayer
strideY_	gserver/layers/ConvOperator.cpp	/^  int paddingY_, strideY_, filterSizeY_;$/;"	m	class:paddle::ConvOperator	file:
strideY_	gserver/layers/PoolLayer.h	/^  size_t strideY_;$/;"	m	class:paddle::PoolLayer
strideY_	gserver/layers/PoolProjection.h	/^  size_t strideY_, stride_;$/;"	m	class:paddle::PoolProjection
stride_	gserver/layers/ConvBaseLayer.h	/^  IntV stride_;$/;"	m	class:paddle::ConvBaseLayer
stride_	gserver/layers/ConvOperator.cpp	/^  int padding_, stride_, filterSize_, channels_, imgSize_, imgSizeY_;$/;"	m	class:paddle::ConvOperator	file:
stride_	gserver/layers/PoolLayer.h	/^  size_t channels_, sizeX_, stride_, outputX_, imgSize_;$/;"	m	class:paddle::PoolLayer
stride_	gserver/layers/PoolProjection.h	/^  size_t strideY_, stride_;$/;"	m	class:paddle::PoolProjection
stride_	math/BaseMatrix.h	/^  size_t stride_;$/;"	m	class:paddle::BaseMatrixT
stride_	math/TensorApply.h	/^  size_t stride_;$/;"	m	class:paddle::TensorApply
stringAlignment	gserver/evaluators/CTCErrorEvaluator.cpp	/^  real stringAlignment(std::vector<int>& gtStr,$/;"	f	class:paddle::CTCErrorEvaluator	file:
string_	trainer/tests/picojson.h	/^    std::string* string_;$/;"	m	union:picojson::value::_storage
string_type	trainer/tests/picojson.h	/^  string_type,$/;"	e	enum:picojson::__anon14
strs	parameter/Argument.h	/^  SVectorPtr strs;$/;"	m	struct:paddle::Argument
strs	trainer/tests/testPyDataWrapper.py	/^strs = [random_str(str_count_randomer()) for _ in range(seq_count_randomer())]$/;"	v
sub	cuda/include/hl_tensor_ops.h	/^class sub {$/;"	c	namespace:hppl::binary
subArgFrom	parameter/Argument.cpp	/^void Argument::subArgFrom(const Argument& input,$/;"	f	class:paddle::Argument
subByBitCode	math/Matrix.h	/^  virtual void subByBitCode(size_t numClasses_, IVector& codes) {$/;"	f	class:paddle::Matrix
subByBitCode	math/MatrixBitCode.cpp	/^void CpuMatrix::subByBitCode(size_t numClasses, IVector& codes) {$/;"	f	class:paddle::CpuMatrix
subByBitCodeT	math/MatrixBitCode.cpp	/^void subByBitCodeT(CodeTable codeTable, IVector& codes, CpuMatrix& tmat) {$/;"	f	namespace:paddle
subColMatrix	math/Matrix.h	/^  MatrixPtr subColMatrix(size_t startCol, size_t endCol) {$/;"	f	class:paddle::Matrix
subDataProviders_	gserver/dataproviders/MultiDataProvider.h	/^  std::vector<std::unique_ptr<DataProvider>> subDataProviders_;$/;"	m	class:paddle::MultiDataProvider
subIndices	gserver/dataproviders/ProtoDataProvider.h	/^    std::vector<int64_t> subIndices;$/;"	m	struct:paddle::ProtoDataProvider::ProtoSlot
subK_	gserver/layers/ExpandConvBaseLayer.h	/^  IntV subK_;$/;"	m	class:paddle::ExpandConvBaseLayer
subLevelLength	parameter/Argument.h	/^    int subLevelLength;$/;"	m	struct:paddle::Argument::SeqInfo
subM_	gserver/layers/ExpandConvBaseLayer.h	/^  IntV subM_;$/;"	m	class:paddle::ExpandConvBaseLayer
subMatrix	math/CpuSparseMatrix.cpp	/^MatrixPtr CpuSparseMatrix::subMatrix(size_t startRow, size_t numRows) {$/;"	f	class:paddle::CpuSparseMatrix
subMatrix	math/Matrix.cpp	/^MatrixPtr Matrix::subMatrix(size_t startRow,$/;"	f	class:paddle::Matrix
subMatrix	math/Matrix.h	/^  virtual MatrixPtr subMatrix(size_t startRow, size_t numRows) {$/;"	f	class:paddle::Matrix
subMatrix	math/Matrix.h	/^  virtual MatrixPtr subMatrix(size_t startRow, size_t numRows, MatrixPtr dest) {$/;"	f	class:paddle::Matrix
subModelName_	gserver/gradientmachines/NeuralNetwork.h	/^  std::string subModelName_;$/;"	m	class:paddle::NeuralNetwork
subN_	gserver/layers/ExpandConvBaseLayer.h	/^  IntV subN_;$/;"	m	class:paddle::ExpandConvBaseLayer
subNetworks_	gserver/gradientmachines/MultiNetwork.h	/^  std::vector<std::unique_ptr<NeuralNetwork>> subNetworks_;$/;"	m	class:paddle::MultiNetwork
subRowMatrix	math/Matrix.h	/^  MatrixPtr subRowMatrix(size_t startRow, size_t endRow) {$/;"	f	class:paddle::Matrix
subSampleLoop	gserver/dataproviders/ProtoDataProvider.cpp	/^int64_t ProtoDataProvider::subSampleLoop(Op op, int64_t size, int slot) {$/;"	f	class:paddle::ProtoDataProvider
subSeqStart	parameter/Argument.h	/^    int subSeqStart;$/;"	m	struct:paddle::Argument::SeqInfo
subSequenceNum	gserver/dataproviders/PyDataProvider.h	/^    unsigned int subSequenceNum;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
subSequenceStartPositions	gserver/dataproviders/PyDataProvider.h	/^    std::vector<size_t> subSequenceStartPositions;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
subSequenceStartPositions	parameter/Argument.h	/^  ICpuGpuVectorPtr subSequenceStartPositions;$/;"	m	struct:paddle::Argument
subSequenceStartPositions_creator	gserver/tests/pyDataProvider.py	/^def subSequenceStartPositions_creator():$/;"	f
subVec	math/Vector.h	/^  std::shared_ptr<VectorT<T>> subVec(size_t start, size_t size) {$/;"	f	class:paddle::VectorT
subVecFrom	math/Vector.h	/^  void subVecFrom(const T* src, size_t start, size_t size) {$/;"	f	class:paddle::VectorT
subVecFrom	math/Vector.h	/^  void subVecFrom(const VectorT<T>& src, size_t start, size_t size) {$/;"	f	class:paddle::VectorT
subVecFrom	math/Vector.h	/^  void subVecFrom(const VectorT<T>& src, std::pair<size_t, size_t> interval) {$/;"	f	class:paddle::VectorT
sub_scale	cuda/include/hl_tensor_ops.h	/^  INLINE sub_scale(const T s) : p(s) {}$/;"	f	class:hppl::unary::sub_scale
sub_scale	cuda/include/hl_tensor_ops.h	/^class sub_scale {$/;"	c	namespace:hppl::unary
substitutions_	gserver/evaluators/CTCErrorEvaluator.cpp	/^  real deletions_, insertions_, substitutions_;$/;"	m	class:paddle::CTCErrorEvaluator	file:
suite	api/test/testMatrix.py	/^    suite = unittest.TestLoader().loadTestsFromTestCase(TestMatrix)$/;"	v	class:TestMatrix
suite	api/test/testVector.py	/^    suite = unittest.TestLoader().loadTestsFromTestCase(TestVector)$/;"	v	class:TestVector
sumByBitCode	math/Matrix.h	/^  virtual void sumByBitCode(size_t numClasses,$/;"	f	class:paddle::Matrix
sumByBitCode	math/MatrixBitCode.cpp	/^void CpuMatrix::sumByBitCode(size_t numClasses,$/;"	f	class:paddle::CpuMatrix
sumByBitCodeT	math/MatrixBitCode.cpp	/^void sumByBitCodeT(CodeTable codeTable,$/;"	f	namespace:paddle
sumCosts	api/Arguments.cpp	/^float Arguments::sumCosts() const {$/;"	f	class:Arguments
sumCosts	parameter/Argument.h	/^  static inline real sumCosts(const std::vector<Argument>& arguments) {$/;"	f	struct:paddle::Argument
sumInv_	gserver/layers/CostLayer.h	/^  MatrixPtr sumInv_;$/;"	m	class:paddle::MultiClassCrossEntropyWithSelfNorm
sumOfSquares	math/Matrix.cpp	/^void CpuMatrix::sumOfSquares(Matrix& output, Matrix& label) {$/;"	f	class:paddle::CpuMatrix
sumOfSquares	math/Matrix.cpp	/^void GpuMatrix::sumOfSquares(Matrix& output, Matrix& label) {$/;"	f	class:paddle::GpuMatrix
sumOfSquares	math/Matrix.h	/^  virtual void sumOfSquares(Matrix& output, Matrix& label) {$/;"	f	class:paddle::Matrix
sumOfSquaresBp	math/Matrix.cpp	/^void CpuMatrix::sumOfSquaresBp(Matrix& output, Matrix& label) {$/;"	f	class:paddle::CpuMatrix
sumOfSquaresBp	math/Matrix.cpp	/^void GpuMatrix::sumOfSquaresBp(Matrix& outputV, Matrix& label) {$/;"	f	class:paddle::GpuMatrix
sumOfSquaresBp	math/Matrix.h	/^  virtual void sumOfSquaresBp(Matrix& outputV, Matrix& label) {$/;"	f	class:paddle::Matrix
sumVector	pserver/test/test_ParameterServer2.cpp	/^real sumVector(const CpuVector& vec) {$/;"	f
sum_	gserver/evaluators/Evaluator.cpp	/^  MatrixPtr sum_; \/* cpu matrix *\/$/;"	m	class:paddle::ColumnSumEvaluator	file:
swap	gserver/dataproviders/DataProvider.cpp	/^void BufferBatch::swap(BufferBatch* bufBatch) {$/;"	f	class:paddle::BufferBatch
swap	trainer/tests/picojson.h	/^inline void swap(picojson::value& x, picojson::value& y) {$/;"	f	namespace:std
swap	trainer/tests/picojson.h	/^inline void value::swap(value& x) {$/;"	f	class:picojson::value
syncEvent	gserver/dataproviders/DataProvider.h	/^  void syncEvent() {$/;"	f	class:paddle::BufferBatch
syncFlag_	math/Vector.h	/^  SyncedFlag syncFlag_;$/;"	m	class:paddle::CpuGpuVectorT
syncFlag_	utils/Util.h	/^  bool syncFlag_;$/;"	m	class:paddle::AsyncGpuBlock
syncThreadPool_	parameter/ParameterUpdaterBase.h	/^  std::unique_ptr<SyncThreadPool> syncThreadPool_;$/;"	m	class:paddle::ParameterUpdaterComposite
syncThreadPool_	pserver/ParameterClient2.h	/^  std::unique_ptr<SyncThreadPool> syncThreadPool_;$/;"	m	class:paddle::ParameterClient2
syncThreadPool_	pserver/ParameterServer2.h	/^  std::unique_ptr<SyncThreadPool> syncThreadPool_;$/;"	m	class:paddle::ParameterServer2
syncUpdate	parameter/ParallelParameter.cpp	/^void ParallelParameter::syncUpdate(TrainerRole role, real learnRate) {$/;"	f	class:paddle::ParallelParameter
sync_	math/Vector.h	/^  SyncedFlag* sync_;$/;"	m	class:paddle::CpuGpuVectorT
synchronize	pserver/BaseClient.cpp	/^void BaseClient::synchronize(SyncObject syncObjectId) {$/;"	f	class:paddle::BaseClient
synchronize	pserver/ParameterClient2.cpp	/^void ParameterClient2::synchronize(SyncObject syncObjectId) {$/;"	f	class:paddle::ParameterClient2
synchronize	pserver/ParameterServer2.cpp	/^void ParameterServer2::synchronize(const SynchronizeRequest& request,$/;"	f	class:paddle::ParameterServer2
synchronizeBarriers_	pserver/ParameterServer2.h	/^  std::vector<std::unique_ptr<ThreadBarrier>> synchronizeBarriers_;$/;"	m	class:paddle::ParameterServer2
synchronizeParamter	parameter/ParallelParameter.cpp	/^void SyncParameter::synchronizeParamter() {$/;"	f	class:paddle::SyncParameter
synchronizeParamter	parameter/ParallelParameter.h	/^  void synchronizeParamter() {$/;"	f	class:paddle::AsyncParameter
synchronizeTest	pserver/test/test_ParameterServer2.cpp	/^void ParameterServer2Tester::synchronizeTest() {$/;"	f	class:ParameterServer2Tester
system	api/paddle_ld_flags.py	/^    system = platform.system().lower()$/;"	v
system	setup.py	/^system = platform.system().lower()$/;"	v
t0Vec_	parameter/AverageOptimizer.h	/^  mutable std::vector<int32_t> t0Vec_;$/;"	m	class:paddle::AverageSparseOptimizer
t0Vec_	parameter/FirstOrderOptimizer.h	/^  mutable std::vector<int64_t> t0Vec_;$/;"	m	class:paddle::DecayedAdagradParameterOptimizer
t0Vec_	parameter/FirstOrderOptimizer.h	/^  mutable std::vector<int64_t> t0Vec_;$/;"	m	class:paddle::RMSPropParameterOptimizer
t0Vec_	parameter/FirstOrderOptimizer.h	/^  mutable std::vector<int64_t> t0Vec_;$/;"	m	class:paddle::SparseMomentumParameterOptimizer
t0Vec_	parameter/OptimizerWithRegularizer.h	/^  mutable std::vector<int32_t> t0Vec_;$/;"	m	class:paddle::OptimizerWithRegularizerSparse
t_device	cuda/src/hl_cuda_device.cc	/^__thread thread_device_resources *t_device; \/* device resources table *\/$/;"	v
t_resource	cuda/src/hl_cuda_device.cc	/^__thread _hl_thread_resource t_resource = {{0},    \/* stream *\/$/;"	v
table_	gserver/layers/TableProjection.h	/^  std::unique_ptr<Weight> table_;$/;"	m	class:paddle::TableProjection
tagBegin_	gserver/evaluators/ChunkEvaluator.cpp	/^  int tagBegin_;$/;"	m	class:paddle::ChunkEvaluator	file:
tagEnd_	gserver/evaluators/ChunkEvaluator.cpp	/^  int tagEnd_;$/;"	m	class:paddle::ChunkEvaluator	file:
tagInside_	gserver/evaluators/ChunkEvaluator.cpp	/^  int tagInside_;$/;"	m	class:paddle::ChunkEvaluator	file:
tagSingle_	gserver/evaluators/ChunkEvaluator.cpp	/^  int tagSingle_;$/;"	m	class:paddle::ChunkEvaluator	file:
tanh	cuda/src/hl_avx_functions.cc	/^__m256 tanh(const __m256 a) {$/;"	f	namespace:hppl
tanh	cuda/src/hl_avx_functions.cc	/^__m256 tanh(const __m256 a, const __m256 b) {$/;"	f	namespace:hppl
tanh	cuda/src/hl_cpu_functions.cc	/^real tanh(const real a) {$/;"	f	namespace:hppl
tanh	cuda/src/hl_cpu_functions.cc	/^real tanh(const real a, const real b) { return a * (1.0f - b * b); }$/;"	f	namespace:hppl
tanh	math/Matrix.cpp	/^void CpuMatrix::tanh(Matrix& output) {$/;"	f	class:paddle::CpuMatrix
tanh	math/Matrix.cpp	/^void GpuMatrix::tanh(Matrix& output) { BaseMatrix::tanh(output); }$/;"	f	class:paddle::GpuMatrix
tanh	math/Matrix.h	/^  virtual void tanh(Matrix& output) { LOG(FATAL) << "Not implemented"; }$/;"	f	class:paddle::Matrix
tanhDerivative	math/Matrix.cpp	/^void CpuMatrix::tanhDerivative(Matrix& output) {$/;"	f	class:paddle::CpuMatrix
tanhDerivative	math/Matrix.cpp	/^void GpuMatrix::tanhDerivative(Matrix& output) {$/;"	f	class:paddle::GpuMatrix
tanhDerivative	math/Matrix.h	/^  virtual void tanhDerivative(Matrix& output) {$/;"	f	class:paddle::Matrix
target	gserver/layers/NCELayer.cpp	/^    bool target;$/;"	m	struct:paddle::NCELayer::Sample	file:
targetInfoInlinkId_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  int targetInfoInlinkId_;$/;"	m	class:paddle::RecurrentGradientMachine
targetInlink	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^    targetInlink=emb2)$/;"	v
targetPerDim_	gserver/layers/CostLayer.h	/^  MatrixPtr targetPerDim_;$/;"	m	class:paddle::MultiBinaryLabelCrossEntropy
targetPerDim_	gserver/layers/CostLayer.h	/^  MatrixPtr targetPerDim_;$/;"	m	class:paddle::SoftBinaryClassCrossEntropy
taskReadySem_	gserver/dataproviders/DataProvider.h	/^  Semaphore taskReadySem_;$/;"	m	class:paddle::DoubleBuffer
taskReadySem_	gserver/gradientmachines/MultiGradientMachine.h	/^  Semaphore taskReadySem_;$/;"	m	class:paddle::TrainerThread
taskType_	gserver/gradientmachines/MultiGradientMachine.h	/^  TaskType taskType_;$/;"	m	class:paddle::MultiGradientMachine
task_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^    TaskType task_;$/;"	m	struct:paddle::ParallelThread::Job
tau_	parameter/FirstOrderOptimizer.h	/^  real tau_;$/;"	m	class:paddle::SparseMomentumParameterOptimizer
tcpRdma_	pserver/LightNetwork.h	/^  enum ChannelType tcpRdma_;$/;"	m	class:paddle::SocketClient	typeref:enum:paddle::SocketClient::ChannelType
tcpRdma_	pserver/LightNetwork.h	/^  enum ChannelType tcpRdma_;$/;"	m	class:paddle::SocketServer	typeref:enum:paddle::SocketServer::ChannelType
tcpRdma_	pserver/LightNetwork.h	/^  enum ChannelType tcpRdma_;$/;"	m	class:paddle::SocketWorker	typeref:enum:paddle::SocketWorker::ChannelType
tcpRdma_	pserver/SocketChannel.h	/^  enum ChannelType tcpRdma_;$/;"	m	class:paddle::SocketChannel	typeref:enum:paddle::SocketChannel::ChannelType
tcpServer	pserver/LightNetwork.cpp	/^void SocketServer::tcpServer() {$/;"	f	class:paddle::SocketServer
tcpSocket_	pserver/SocketChannel.h	/^  int tcpSocket_;$/;"	m	class:paddle::SocketChannel
templateReduceSum	pserver/ParameterServer2.cpp	/^void ParameterServer2::templateReduceSum(const SendDataRequest& request,$/;"	f	class:paddle::ParameterServer2
test	gserver/tests/test_RecurrentGradientMachine.cpp	/^void test(const string& conf1, const string& conf2, double eps, bool useGpu) {$/;"	f
test	trainer/Tester.cpp	/^void Tester::test() {$/;"	f	class:paddle::Tester
test	trainer/Trainer.cpp	/^void Trainer::test() { tester_->test(); }$/;"	f	class:paddle::Trainer
testAccumulate	gserver/tests/LayerGradUtil.h	/^  bool testAccumulate;$/;"	m	struct:paddle::TestConfig
testAccumulate	gserver/tests/test_Evaluator.cpp	/^  bool testAccumulate;$/;"	m	struct:TestConfig	file:
testActivation	gserver/tests/test_ActivationGrad.cpp	/^void testActivation(const string& act) {$/;"	f
testAdaDelta	math/tests/test_TrainingAlgorithm.cpp	/^void testAdaDelta(size_t size, bool useGpu) {$/;"	f
testAdagrad	math/tests/test_TrainingAlgorithm.cpp	/^void testAdagrad(size_t size, bool useGpu) {$/;"	f
testAdam	math/tests/test_TrainingAlgorithm.cpp	/^void testAdam(size_t size, bool useGpu) {$/;"	f
testAdamax	math/tests/test_TrainingAlgorithm.cpp	/^void testAdamax(size_t size, bool useGpu) {$/;"	f
testAddSharedBias	math/tests/test_Matrix.cpp	/^void testAddSharedBias(int numSamples, int dim, int channel) {$/;"	f
testAvgPoolFwdBwd	math/tests/test_matrixCompare.cpp	/^void testAvgPoolFwdBwd(int numSamples,$/;"	f
testBatchNormLayer	gserver/tests/test_LayerGrad.cpp	/^void testBatchNormLayer(const string& type, bool trans, bool useGpu) {$/;"	f
testBatchState	gserver/tests/LayerGradUtil.cpp	/^void testBatchState(LayerPtr testLayer,$/;"	f	namespace:paddle
testBatchState	gserver/tests/LayerGradUtil.h	/^  bool testBatchState;$/;"	m	struct:paddle::TestConfig
testBilinearFwdBwd	math/tests/test_GpuProfiler.cpp	/^void testBilinearFwdBwd(int numSamples,$/;"	f
testBilinearFwdBwd	math/tests/test_Matrix.cpp	/^void testBilinearFwdBwd(int numSamples,$/;"	f
testBufferArgs	function/FunctionTest.cpp	/^void testBufferArgs(const BufferArgs& inputs, const CheckBufferArg& check) {$/;"	f	namespace:paddle
testBufferArgs	function/FunctionTest.cpp	/^void testBufferArgs(const BufferArgs& inputs,$/;"	f	namespace:paddle
testCase	math/tests/test_TrainingAlgorithm.cpp	/^void testCase(testMatrixFunc matrixFunc) {$/;"	f
testClassificationError	math/tests/test_matrixCompare.cpp	/^void testClassificationError(int numSamples, int dim) {$/;"	f
testCollectSharedBias	math/tests/test_Matrix.cpp	/^void testCollectSharedBias(int numSamples, int dim, int channel) {$/;"	f
testContext_	trainer/Tester.h	/^  } testContext_;$/;"	m	class:paddle::Tester	typeref:struct:paddle::Tester::__anon13
testConvLayer	gserver/tests/test_LayerGrad.cpp	/^void testConvLayer(const string& type, bool trans, bool useGpu) {$/;"	f
testConvTransLayer	gserver/tests/test_LayerGrad.cpp	/^void testConvTransLayer(const string& type, bool trans, bool useGpu) {$/;"	f
testCopyFromNumpy	api/test/testVector.py	/^    def testCopyFromNumpy(self):$/;"	m	class:TestVector
testCosSimBackward	function/CosSimOpTest.cpp	/^void testCosSimBackward(size_t height_x,$/;"	f
testCosSimForward	function/CosSimOpTest.cpp	/^void testCosSimForward(size_t height_x,$/;"	f
testCpuNumpy	api/test/testVector.py	/^    def testCpuNumpy(self):$/;"	m	class:TestVector
testCreate	api/test/testVector.py	/^    def testCreate(self):$/;"	m	class:TestVector
testCreateZero	api/test/testVector.py	/^    def testCreateZero(self):$/;"	m	class:TestVector
testDataProvider_	trainer/Tester.h	/^  DataProviderPtr testDataProvider_;$/;"	m	class:paddle::Tester
testDataProvider_	trainer/Trainer.h	/^  DataProviderPtr testDataProvider_;$/;"	m	class:paddle::Trainer
testDecayedAdagrad	math/tests/test_TrainingAlgorithm.cpp	/^void testDecayedAdagrad(size_t size, bool useGpu) {$/;"	f
testDegradeLayer	gserver/tests/test_LayerGrad.cpp	/^void testDegradeLayer(bool hasSubseq, string layer_type, string trans_type) {$/;"	f
testEvaluator	gserver/tests/test_Evaluator.cpp	/^void testEvaluator(TestConfig testConf,$/;"	f
testEvaluatorAll	gserver/tests/test_Evaluator.cpp	/^void testEvaluatorAll(TestConfig testConf,$/;"	f
testEvaluator_	trainer/Tester.h	/^  std::unique_ptr<Evaluator> testEvaluator_;$/;"	m	class:paddle::Tester
testExpandLayer	gserver/tests/test_LayerGrad.cpp	/^void testExpandLayer(string trans_type, bool hasSubseq) {$/;"	f
testFcLayer	gserver/tests/test_LayerGrad.cpp	/^void testFcLayer(string format, size_t nnz) {$/;"	f
testFuncDDDMatrix	function/MulOpTest.cpp	/^void testFuncDDDMatrix($/;"	f
testFuncDDSparseMatrix	function/MulOpTest.cpp	/^void testFuncDDSparseMatrix($/;"	f
testFuncDSparseDMatrix	function/MulOpTest.cpp	/^void testFuncDSparseDMatrix($/;"	f
testFuncSparseDDMatrix	function/MulOpTest.cpp	/^void testFuncSparseDDMatrix($/;"	f
testGen	gserver/tests/test_MultinomialSampler.cpp	/^  int testGen(Rand1 rand1) {$/;"	f	class:MultinomialSamplerTester
testGeneration	trainer/tests/test_recurrent_machine_generation.cpp	/^void testGeneration(const string& configFile,$/;"	f
testLayerGrad	gserver/tests/LayerGradUtil.cpp	/^void testLayerGrad(TestConfig testConf,$/;"	f	namespace:paddle
testLayerGradKernel	gserver/tests/LayerGradUtil.cpp	/^void testLayerGradKernel(TestConfig testConf,$/;"	f	namespace:paddle
testLayer_	gserver/tests/test_RecurrentLayer.cpp	/^  LayerPtr testLayer_;$/;"	m	class:TestRecurrentLayer	file:
testMatrixAddAtOffset	math/tests/test_Matrix.cpp	/^void testMatrixAddAtOffset(int height, int width1, int width2, int offset) {$/;"	f
testMatrixAddBias	math/tests/test_Matrix.cpp	/^void testMatrixAddBias(int height, int width, real scale) {$/;"	f
testMatrixAddDotMulMMV	math/tests/test_Matrix.cpp	/^void testMatrixAddDotMulMMV(int height, int width) {$/;"	f
testMatrixAddToRows	math/tests/test_matrixCompare.cpp	/^void testMatrixAddToRows(int numSamples, int tableSize, int inputDim) {$/;"	f
testMatrixAssignAtOffset	math/tests/test_Matrix.cpp	/^void testMatrixAssignAtOffset(int height, int width1, int width2, int offset) {$/;"	f
testMatrixCopyByRowIndex	math/tests/test_Matrix.cpp	/^void testMatrixCopyByRowIndex(int outHeight, int inHeight, int width) {$/;"	f
testMatrixDeepSwap	math/tests/test_matrixCompare.cpp	/^void testMatrixDeepSwap(int height, int width) {$/;"	f
testMatrixFunc	math/tests/test_TrainingAlgorithm.cpp	/^typedef std::function<void(size_t size, bool useGpu)> testMatrixFunc;$/;"	t	file:
testMatrixGetMinMax	math/tests/test_matrixCompare.cpp	/^void testMatrixGetMinMax(int height, int width) {$/;"	f
testMatrixGetSum	math/tests/test_matrixCompare.cpp	/^void testMatrixGetSum(int height, int width) {$/;"	f
testMatrixInverse	math/tests/test_matrixCompare.cpp	/^void testMatrixInverse(int height) {$/;"	f
testMatrixMaxSequence	math/tests/test_matrixCompare.cpp	/^void testMatrixMaxSequence(int batchSize, int inputDim) {$/;"	f
testMatrixMul	math/tests/test_matrixCompare.cpp	/^void testMatrixMul(bool transa, bool transb, int dimM, int dimN, int dimK) {$/;"	f
testMatrixProjectionBackward	function/ContextProjectionOpTest.cpp	/^void testMatrixProjectionBackward(int context_start,$/;"	f
testMatrixProjectionForward	function/ContextProjectionOpTest.cpp	/^void testMatrixProjectionForward(int context_start,$/;"	f
testMatrixRotate	math/tests/test_matrixCompare.cpp	/^void testMatrixRotate(int height, int width) {$/;"	f
testMatrixSelectRows	math/tests/test_Matrix.cpp	/^void testMatrixSelectRows(int numSamples, int tableSize, int inputDim) {$/;"	f
testMatrixSequenceAvgForward	math/tests/test_matrixCompare.cpp	/^void testMatrixSequenceAvgForward(int batchSize, int inputDim, int mode) {$/;"	f
testMatrixSoftmax	math/tests/test_matrixCompare.cpp	/^void testMatrixSoftmax(int height, int width) {$/;"	f
testMatrixSoftmaxBp	math/tests/test_matrixCompare.cpp	/^void testMatrixSoftmaxBp(int height, int width) {$/;"	f
testMatrixSoftmaxThreshold	math/tests/test_matrixCompare.cpp	/^void testMatrixSoftmaxThreshold(int height, int width) {$/;"	f
testMatrixTopK	math/tests/test_matrixCompare.cpp	/^void testMatrixTopK(int samples, int dim, int beamSize) {$/;"	f
testMatrixTranspose	math/tests/test_matrixCompare.cpp	/^void testMatrixTranspose(int height, int width) {$/;"	f
testMatrixZeroAtOffset	math/tests/test_matrixCompare.cpp	/^void testMatrixZeroAtOffset(int height, int width) {$/;"	f
testMaxOutFwdBwd	math/tests/test_matrixCompare.cpp	/^void testMaxOutFwdBwd($/;"	f
testMaxPoolFwdBwd	math/tests/test_matrixCompare.cpp	/^void testMaxPoolFwdBwd(int numSamples,$/;"	f
testMultiBinaryLabelCrossEntropy	math/tests/test_Matrix.cpp	/^void testMultiBinaryLabelCrossEntropy(int numSamples, int dim) {$/;"	f
testNormLayer	gserver/tests/test_LayerGrad.cpp	/^void testNormLayer(const string& normType, bool trans, bool useGpu) {$/;"	f
testNormalImpl	utils/tests/test_CustomStackTrace.cpp	/^void testNormalImpl($/;"	f
testNormalImpl	utils/tests/test_SpinLock.cpp	/^void testNormalImpl($/;"	f
testNormalImpl	utils/tests/test_ThreadBarrier.cpp	/^void testNormalImpl($/;"	f
testNumpy	api/test/testVector.py	/^    def testNumpy(self):$/;"	m	class:TestVector
testOneBatchById	trainer/Tester.cpp	/^int64_t Tester::testOneBatchById(int64_t batchId) {$/;"	f	class:paddle::Tester
testOneDataBatch	api/Trainer.cpp	/^void Trainer::testOneDataBatch(size_t batchSize, const Arguments& args) {$/;"	f	class:Trainer
testOneDataBatch	api/Trainer.cpp	/^void TrainerPrivate::testOneDataBatch(const paddle::DataBatch& dataBatch) {$/;"	f	class:TrainerPrivate
testOneDataBatch	trainer/Tester.cpp	/^void Tester::testOneDataBatch(const DataBatch& dataBatch,$/;"	f	class:paddle::Tester
testOnePass	trainer/Tester.cpp	/^void Tester::testOnePass(int passId) {$/;"	f	class:paddle::Tester
testOnePassBatch	trainer/Tester.cpp	/^void Tester::testOnePassBatch(int passId) {$/;"	f	class:paddle::Tester
testOnePeriod	trainer/Tester.cpp	/^void Tester::testOnePeriod() {$/;"	f	class:paddle::Tester
testOperatorGrad	gserver/tests/LayerGradUtil.cpp	/^void testOperatorGrad(TestConfig& config,$/;"	f	namespace:paddle
testParamReluBackwardDiff	math/tests/test_matrixCompare.cpp	/^void testParamReluBackwardDiff(int height,$/;"	f
testParamReluBackwardW	math/tests/test_Matrix.cpp	/^void testParamReluBackwardW(int height, int width, int w_height, int w_width) {$/;"	f
testParamReluForward	math/tests/test_Matrix.cpp	/^void testParamReluForward(int height, int width, int w_height, int w_width) {$/;"	f
testParameterClient_	trainer/Tester.h	/^  std::shared_ptr<ParameterClient2> testParameterClient_;$/;"	m	class:paddle::Tester
testPass	trainer/TesterConfig.h	/^  int testPass;$/;"	m	struct:paddle::TesterConfig
testPeriod	trainer/TesterConfig.h	/^  int testPeriod;$/;"	m	struct:paddle::TesterConfig
testPerturbInput	gserver/tests/LayerGradUtil.cpp	/^void testPerturbInput(TestConfig testConf,$/;"	f	namespace:paddle
testPerturbParameter	gserver/tests/LayerGradUtil.cpp	/^void testPerturbParameter(TestConfig testConf,$/;"	f	namespace:paddle
testPoolAllocator	math/tests/test_Allocator.cpp	/^void testPoolAllocator() {$/;"	f
testPoolLayer	gserver/tests/test_LayerGrad.cpp	/^void testPoolLayer(const string& poolType, bool trans, bool useGpu) {$/;"	f
testPoolLayer2	gserver/tests/test_LayerGrad.cpp	/^void testPoolLayer2(const string& poolType, bool trans, bool useGpu) {$/;"	f
testProjectionConv	gserver/tests/test_LayerGrad.cpp	/^void testProjectionConv(size_t groups) {$/;"	f
testProjectionGrad	gserver/tests/LayerGradUtil.cpp	/^void testProjectionGrad(ProjectionConfig conf,$/;"	f	namespace:paddle
testProtoDataProvider	gserver/tests/test_ProtoDataProvider.cpp	/^void testProtoDataProvider(int* numPerSlotType,$/;"	f
testProtoSequenceDataProvider	gserver/tests/test_ProtoDataProvider.cpp	/^void testProtoSequenceDataProvider(int* numPerSlotType,$/;"	f
testRMSProp	math/tests/test_TrainingAlgorithm.cpp	/^void testRMSProp(size_t size, bool useGpu) {$/;"	f
testResult	utils/Thread.h	/^  bool testResult() { return results_.empty(); }$/;"	f	class:paddle::MultiThreadWorker
testSMatrixTopK	math/tests/test_matrixCompare.cpp	/^void testSMatrixTopK(int samples, int dim, int beamSize, real ratio) {$/;"	f
testSelectiveFcLayerTrainSparseMul	gserver/tests/test_SelectiveFCLayer.cpp	/^void testSelectiveFcLayerTrainSparseMul(const LayerConfig& config,$/;"	f
testSequenceSoftmax	math/tests/test_matrixCompare.cpp	/^void testSequenceSoftmax(int batchSize) {$/;"	f
testSigmoid	math/tests/test_FPException.cpp	/^void testSigmoid(real illegal) {$/;"	f
testSpMatrixAddBias	math/tests/test_sparseMatrixCompare.cpp	/^void testSpMatrixAddBias(int M, int N, real rate, real scale) {$/;"	f
testSpMatrixAddDense	math/tests/test_sparseMatrixCompare.cpp	/^void testSpMatrixAddDense(int M, int N, real rate) {  \/\/ add3$/;"	f
testSpMatrixCollectBias	math/tests/test_sparseMatrixCompare.cpp	/^void testSpMatrixCollectBias(int M, int N, real rate) {$/;"	f
testSpMatrixMul	math/tests/test_sparseMatrixCompare.cpp	/^void testSpMatrixMul(int M, int N, int K, real rate) {$/;"	f
testSparseMomentum	math/tests/test_TrainingAlgorithm.cpp	/^void testSparseMomentum(size_t size, bool useGpu) {$/;"	f
testSppLayer	gserver/tests/test_LayerGrad.cpp	/^void testSppLayer(const string& poolType,$/;"	f
testStat_	parameter/tests/test_common.cpp	/^  StatSet testStat_;$/;"	m	class:CommonTest	file:
testState	gserver/tests/LayerGradUtil.cpp	/^void testState(LayerPtr testLayer,$/;"	f	namespace:paddle
testState	gserver/tests/LayerGradUtil.h	/^  bool testState;$/;"	m	struct:paddle::TestConfig
testState	trainer/TesterConfig.h	/^  MachineState* testState;$/;"	m	struct:paddle::TesterConfig
testState_	trainer/Trainer.h	/^  MachineState testState_;$/;"	m	class:paddle::Trainer
testSubMatrixMul	math/tests/test_matrixCompare.cpp	/^void testSubMatrixMul(bool transa, bool transb, int dimM, int dimN, int dimK) {$/;"	f
testTanh	math/tests/test_FPException.cpp	/^void testTanh(real illegal) {$/;"	f
testVecortSelectFrom	math/tests/test_matrixCompare.cpp	/^void testVecortSelectFrom(int size) {$/;"	f
testVecotrZeroMem	math/tests/test_matrixCompare.cpp	/^void testVecotrZeroMem(int size) {$/;"	f
testVectorIsEqual	math/tests/test_matrixCompare.cpp	/^void testVectorIsEqual(int size) {$/;"	f
testVectorReset	math/tests/test_matrixCompare.cpp	/^void testVectorReset(int size) {$/;"	f
testVectorRowFunc	math/tests/test_matrixCompare.cpp	/^void testVectorRowFunc(int size) {$/;"	f
testWait	trainer/TesterConfig.h	/^  int testWait;$/;"	m	struct:paddle::TesterConfig
testWrapper	math/tests/test_ExecViaCpu.cpp	/^void testWrapper(F&& f) {$/;"	f
test_can_over_batch_size	gserver/tests/test_PyDataProvider2.py	/^def test_can_over_batch_size(setting, filename):$/;"	f
test_check	gserver/tests/test_PyDataProvider2.py	/^def test_check(settings, filename):$/;"	f
test_cpu_numpy	api/test/testVector.py	/^    def test_cpu_numpy(self):$/;"	m	class:TestIVector
test_create	api/test/testVector.py	/^    def test_create(self):$/;"	m	class:TestIVector
test_createDenseMat	api/test/testMatrix.py	/^    def test_createDenseMat(self):$/;"	m	class:TestMatrix
test_createZero	api/test/testVector.py	/^    def test_createZero(self):$/;"	m	class:TestIVector
test_createZero_get_set	api/test/testMatrix.py	/^    def test_createZero_get_set(self):$/;"	m	class:TestMatrix
test_create_gradient_machine	api/test/testGradientMachine.py	/^    def test_create_gradient_machine(self):$/;"	m	class:TestGradientMachine
test_dense_no_seq	gserver/tests/test_PyDataProvider2.py	/^def test_dense_no_seq(setting, filename):$/;"	f
test_gpu_numpy	api/test/testVector.py	/^    def test_gpu_numpy(self):$/;"	m	class:TestIVector
test_index_no_seq	gserver/tests/test_PyDataProvider2.py	/^def test_index_no_seq(setting, filename):$/;"	f
test_index_seq	gserver/tests/test_PyDataProvider2.py	/^def test_index_seq(setting, filename):$/;"	f
test_index_sub_seq	gserver/tests/test_PyDataProvider2.py	/^def test_index_sub_seq(setting, filename):$/;"	f
test_init_hook	gserver/tests/test_PyDataProvider2.py	/^def test_init_hook(setting, filename):$/;"	f
test_init_hooker	gserver/tests/test_PyDataProvider2.py	/^def test_init_hooker(setting, value, **kwargs):$/;"	f
test_input_order	gserver/tests/test_PyDataProvider2.py	/^def test_input_order(setting, filename):$/;"	f
test_list	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^    test_list=None,$/;"	v
test_list	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^    test_list=None,$/;"	v
test_list	trainer/tests/simple_sparse_neural_network.py	/^    test_list=file_list,$/;"	v
test_load_arguments	api/test/testArguments.py	/^    def test_load_arguments(self):$/;"	m	class:TestArguments
test_min_pool_size	gserver/tests/test_PyDataProvider2.py	/^def test_min_pool_size(setting, filename):$/;"	f
test_min_pool_size_with_cache	gserver/tests/test_PyDataProvider2.py	/^def test_min_pool_size_with_cache(settings, filename):$/;"	f
test_numpy	api/test/testMatrix.py	/^    def test_numpy(self):$/;"	m	class:TestMatrix
test_numpy	api/test/testVector.py	/^    def test_numpy(self):$/;"	m	class:TestIVector
test_numpyCpu	api/test/testMatrix.py	/^    def test_numpyCpu(self):$/;"	m	class:TestMatrix
test_numpyGpu	api/test/testMatrix.py	/^    def test_numpyGpu(self):$/;"	m	class:TestMatrix
test_period	trainer/TrainerBenchmark.cpp	/^DECLARE_int32(test_period);$/;"	v
test_sgdUpadate	parameter/tests/test_common.cpp	/^void CommonTest::test_sgdUpadate(real* gradientBuffer,$/;"	f	class:CommonTest
test_sparse	api/test/testMatrix.py	/^    def test_sparse(self):$/;"	m	class:TestMatrix
test_sparse_matrix_mul	math/tests/test_SparseMatrix.cpp	/^void test_sparse_matrix_mul(MatrixPara paraA,$/;"	f
test_sparse_non_value_no_seq	gserver/tests/test_PyDataProvider2.py	/^def test_sparse_non_value_no_seq(setting, filename):$/;"	f
test_sparse_value	api/test/testMatrix.py	/^    def test_sparse_value(self):$/;"	m	class:TestMatrix
test_sparse_value_no_seq	gserver/tests/test_PyDataProvider2.py	/^def test_sparse_value_no_seq(setting, filename):$/;"	f
test_train_one_pass	api/test/testGradientMachine.py	/^    def test_train_one_pass(self):$/;"	m	class:TestGradientMachine
tester_	trainer/Trainer.h	/^  std::unique_ptr<Tester> tester_;$/;"	m	class:paddle::Trainer
testing	trainer/TesterConfig.h	/^  bool testing;$/;"	m	struct:paddle::TesterConfig
testing_	trainer/RemoteParameterUpdater.h	/^  bool testing_;$/;"	m	class:paddle::SparseRemoteParameterUpdater
testing_	trainer/Trainer.h	/^  int testing_;$/;"	m	class:paddle::Trainer
threadId_	gserver/gradientmachines/MultiGradientMachine.h	/^  int threadId_;$/;"	m	class:paddle::TrainerThread
threadId_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  int threadId_;$/;"	m	class:paddle::ParallelThread
threadLocalBuf_	utils/Stat.h	/^  ThreadLocalBuf threadLocalBuf_;$/;"	m	class:paddle::Stat
threadLocalColArray	math/Matrix.cpp	/^static ThreadLocal<std::vector<const real*>> threadLocalColArray;$/;"	m	namespace:paddle	file:
threadMap_	utils/ThreadLocal.h	/^  std::map<pid_t, T*> threadMap_;$/;"	m	class:paddle::ThreadLocalD
threadNum_	pserver/BaseClient.h	/^  int threadNum_;$/;"	m	class:paddle::BaseClient
threadSpecificKey_	utils/ThreadLocal.h	/^  pthread_key_t threadSpecificKey_;$/;"	m	class:paddle::ThreadLocal
threadSpecificKey_	utils/ThreadLocal.h	/^  pthread_key_t threadSpecificKey_;$/;"	m	class:paddle::ThreadLocalD
threadTraverse	trainer/ThreadParameterUpdater.cpp	/^void SgdThreadUpdater::threadTraverse($/;"	f	class:paddle::SgdThreadUpdater
threadUpdateDense	trainer/ThreadParameterUpdater.cpp	/^void SgdThreadUpdater::threadUpdateDense(int tid,$/;"	f	class:paddle::SgdThreadUpdater
threadUpdateSparse	trainer/ThreadParameterUpdater.cpp	/^void SgdThreadUpdater::threadUpdateSparse(int tid,$/;"	f	class:paddle::SgdThreadUpdater
thread_	pserver/test/SocketTest.cpp	/^  std::unique_ptr<std::thread> thread_;$/;"	m	class:Thread	file:
thread_	utils/Thread.h	/^  std::unique_ptr<std::thread> thread_;$/;"	m	class:paddle::Thread
thread_local_rand_use_global_seed	gserver/tests/LayerGradUtil.cpp	/^DECLARE_bool(thread_local_rand_use_global_seed);$/;"	v
thread_local_rand_use_global_seed	gserver/tests/test_ActivationGrad.cpp	/^DECLARE_bool(thread_local_rand_use_global_seed);$/;"	v
thread_local_rand_use_global_seed	gserver/tests/test_BatchNorm.cpp	/^DECLARE_bool(thread_local_rand_use_global_seed);$/;"	v
thread_local_rand_use_global_seed	gserver/tests/test_ConvTrans.cpp	/^DECLARE_bool(thread_local_rand_use_global_seed);$/;"	v
thread_local_rand_use_global_seed	gserver/tests/test_ConvUnify.cpp	/^DECLARE_bool(thread_local_rand_use_global_seed);$/;"	v
thread_local_rand_use_global_seed	gserver/tests/test_Evaluator.cpp	/^DECLARE_bool(thread_local_rand_use_global_seed);$/;"	v
thread_local_rand_use_global_seed	gserver/tests/test_LayerGrad.cpp	/^DECLARE_bool(thread_local_rand_use_global_seed);$/;"	v
thread_local_rand_use_global_seed	trainer/tests/test_CompareTwoNets.cpp	/^DECLARE_bool(thread_local_rand_use_global_seed);$/;"	v
threads_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::vector<TrainerThreadPtr> threads_;$/;"	m	class:paddle::MultiGradientMachine
threads_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  std::vector<std::unique_ptr<ParallelThread>> threads_;$/;"	m	class:paddle::ParallelNeuralNetwork
thresh	gserver/layers/MultinomialSampler.h	/^    real thresh;$/;"	m	struct:paddle::MultinomialSampler::Interval
threshold_	parameter/FirstOrderOptimizer.h	/^  real threshold_;$/;"	m	class:paddle::SparseMomentumParameterOptimizer
threshold_	utils/Stat.h	/^  uint64_t threshold_;$/;"	m	class:paddle::TimerOnce
time	trainer/TrainerBenchmark.cpp	/^void Trainer::time() {$/;"	f	class:paddle::Trainer
timeArray_	utils/BarrierStat.h	/^  std::vector<struct timeval> timeArray_;$/;"	m	class:paddle::TimeVectorEnd
timeArray_	utils/BarrierStat.h	/^  std::vector<uint64_t> timeArray_;$/;"	m	class:paddle::TimeVectorDelta
timeToMicroSecond	utils/BarrierStat.h	/^inline uint64_t timeToMicroSecond(struct timeval time) {$/;"	f	namespace:paddle
timeVector_	utils/BarrierStat.h	/^  std::unique_ptr<TimeVectorDelta> timeVector_;$/;"	m	class:paddle::BarrierDeltaStat
timeVector_	utils/BarrierStat.h	/^  std::unique_ptr<TimeVectorEnd> timeVector_;$/;"	m	class:paddle::BarrierEndStat
timeWait	utils/arch/linux/Locks.cpp	/^bool Semaphore::timeWait(struct timespec* ts) {$/;"	f	class:paddle::Semaphore
timeWait	utils/arch/osx/Locks.cpp	/^bool Semaphore::timeWait(timespec *ts) {$/;"	f	class:paddle::Semaphore
timeWaitGradReady	parameter/ParallelParameter.h	/^  bool timeWaitGradReady(int sec) {$/;"	f	class:paddle::ParallelParameter
timer_	parameter/AverageOptimizer.h	/^  int timer_;$/;"	m	class:paddle::AverageSparseOptimizer
timer_	parameter/FirstOrderOptimizer.h	/^  int64_t timer_;$/;"	m	class:paddle::DecayedAdagradParameterOptimizer
timer_	parameter/FirstOrderOptimizer.h	/^  int64_t timer_;$/;"	m	class:paddle::RMSPropParameterOptimizer
timer_	parameter/FirstOrderOptimizer.h	/^  int64_t timer_;$/;"	m	class:paddle::SparseMomentumParameterOptimizer
timer_	parameter/OptimizerWithRegularizer.h	/^  int timer_;$/;"	m	class:paddle::OptimizerWithRegularizer
timer_	utils/Stat.h	/^  Timer timer_;$/;"	m	class:paddle::TimerOnce
tlsTempBufs_	parameter/Parameter.cpp	/^ThreadLocal<std::vector<VectorPtr>> Parameter::tlsTempBufs_;$/;"	m	class:paddle::Parameter	file:
tlsTempBufs_	parameter/Parameter.h	/^  static ThreadLocal<std::vector<VectorPtr>> tlsTempBufs_;$/;"	m	class:paddle::Parameter
tmpBiasGrad_	gserver/layers/CudnnBatchNormLayer.h	/^  MatrixPtr tmpWGrad_, tmpBiasGrad_;$/;"	m	class:paddle::CudnnBatchNormLayer
tmpCpuInput_	gserver/layers/CTCLayer.h	/^  std::vector<Argument> tmpCpuInput_;$/;"	m	class:paddle::CTCLayer
tmpCpuInput_	gserver/layers/CostLayer.h	/^  std::vector<Argument> tmpCpuInput_;$/;"	m	class:paddle::HuberTwoClass
tmpCpuInput_	gserver/layers/SamplingIdLayer.cpp	/^  std::vector<Argument> tmpCpuInput_;$/;"	m	class:paddle::SamplingIdLayer	file:
tmpDest_	gserver/layers/MultiplexLayer.cpp	/^  MatrixPtr tmpDest_;$/;"	m	class:paddle::MultiplexLayer	file:
tmpDest_	gserver/layers/SequenceLastInstanceLayer.cpp	/^  MatrixPtr tmpDest_;$/;"	m	class:paddle::SequenceLastInstanceLayer	file:
tmpDest_	gserver/layers/SubSequenceLayer.cpp	/^  MatrixPtr tmpDest_;$/;"	m	class:paddle::SubSequenceLayer	file:
tmpGrad_	gserver/layers/BatchNormalizationLayer.h	/^  MatrixPtr tmpMat_, tmpGrad_;$/;"	m	class:paddle::BatchNormalizationLayer
tmpGrad_	gserver/layers/Layer.h	/^  MatrixPtr tmpGrad_;$/;"	m	class:paddle::Layer
tmpMat_	gserver/layers/BatchNormalizationLayer.h	/^  MatrixPtr tmpMat_, tmpGrad_;$/;"	m	class:paddle::BatchNormalizationLayer
tmpMat_	math/Matrix.h	/^  static ThreadLocal<MatrixPtr> tmpMat_;$/;"	m	class:paddle::Matrix
tmpMatrix	gserver/layers/InterpolationLayer.cpp	/^  MatrixPtr tmpMatrix;$/;"	m	class:paddle::InterpolationLayer	file:
tmpMtx	gserver/layers/PowerLayer.cpp	/^  MatrixPtr tmpMtx;$/;"	m	class:paddle::PowerLayer	file:
tmpMtx0	gserver/layers/ConvexCombinationLayer.cpp	/^  MatrixPtr tmpMtx0;$/;"	m	class:paddle::ConvexCombinationLayer	file:
tmpMtx0	gserver/layers/CosSimVecMatLayer.cpp	/^  MatrixPtr tmpMtx0;$/;"	m	class:paddle::CosSimVecMatLayer	file:
tmpMtx0	gserver/layers/OuterProdLayer.cpp	/^  MatrixPtr tmpMtx0;$/;"	m	class:paddle::OuterProdLayer	file:
tmpMtx1	gserver/layers/CosSimVecMatLayer.cpp	/^  MatrixPtr tmpMtx1;$/;"	m	class:paddle::CosSimVecMatLayer	file:
tmpRow0	gserver/layers/ConvexCombinationLayer.cpp	/^  MatrixPtr tmpRow0;$/;"	m	class:paddle::ConvexCombinationLayer	file:
tmpRow0	gserver/layers/CosSimVecMatLayer.cpp	/^  MatrixPtr tmpRow0;$/;"	m	class:paddle::CosSimVecMatLayer	file:
tmpRow0	gserver/layers/OuterProdLayer.cpp	/^  MatrixPtr tmpRow0;$/;"	m	class:paddle::OuterProdLayer	file:
tmpRow1	gserver/layers/ConvexCombinationLayer.cpp	/^  MatrixPtr tmpRow1;$/;"	m	class:paddle::ConvexCombinationLayer	file:
tmpRow1	gserver/layers/CosSimVecMatLayer.cpp	/^  MatrixPtr tmpRow1;$/;"	m	class:paddle::CosSimVecMatLayer	file:
tmpRow1	gserver/layers/OuterProdLayer.cpp	/^  MatrixPtr tmpRow1;$/;"	m	class:paddle::OuterProdLayer	file:
tmpRow2	gserver/layers/CosSimVecMatLayer.cpp	/^  MatrixPtr tmpRow2;$/;"	m	class:paddle::CosSimVecMatLayer	file:
tmpRow3	gserver/layers/CosSimVecMatLayer.cpp	/^  MatrixPtr tmpRow3;$/;"	m	class:paddle::CosSimVecMatLayer	file:
tmpSrc_	gserver/layers/MultiplexLayer.cpp	/^  MatrixPtr tmpSrc_;$/;"	m	class:paddle::MultiplexLayer	file:
tmpSrc_	gserver/layers/SequenceLastInstanceLayer.cpp	/^  MatrixPtr tmpSrc_;$/;"	m	class:paddle::SequenceLastInstanceLayer	file:
tmpSrc_	gserver/layers/SubSequenceLayer.cpp	/^  MatrixPtr tmpSrc_;$/;"	m	class:paddle::SubSequenceLayer	file:
tmpWGrad_	gserver/layers/CudnnBatchNormLayer.h	/^  MatrixPtr tmpWGrad_, tmpBiasGrad_;$/;"	m	class:paddle::CudnnBatchNormLayer
to	utils/StringUtil.h	/^inline T to(const std::string& s) {$/;"	f	namespace:paddle::str
toNumpyArrayInplace	api/Vector.cpp	/^void IVector::toNumpyArrayInplace(int** data, int* dim1) throw(UnsupportError) {$/;"	f	class:IVector
toNumpyArrayInplace	api/Vector.cpp	/^void Vector::toNumpyArrayInplace(float** view_data,$/;"	f	class:Vector
toNumpyMatInplace	api/Matrix.cpp	/^void Matrix::toNumpyMatInplace(float** view_data,$/;"	f	class:Matrix
toOneHotSparseMatrix	math/Vector.cpp	/^MatrixPtr VectorT<int>::toOneHotSparseMatrix(size_t idRange, bool useGpu) {$/;"	f	class:paddle::VectorT
toOneHotSparseMatrix	math/Vector.cpp	/^MatrixPtr VectorT<real>::toOneHotSparseMatrix(size_t idRange, bool useGpu) {$/;"	f	class:paddle::VectorT
toProtoString	api/ConfigParser.cpp	/^std::string OptimizationConfig::toProtoString() {$/;"	f	class:OptimizationConfig
toProtoString	api/ConfigParser.cpp	/^std::string ParameterConfig::toProtoString() const {$/;"	f	class:ParameterConfig
toString	api/Evaluator.cpp	/^std::string Evaluator::toString() {$/;"	f	class:Evaluator
toWithStatus	utils/StringUtil.h	/^inline T toWithStatus(const std::string& s, bool* ok = nullptr) {$/;"	f	namespace:paddle::str
to_str	trainer/tests/picojson.h	/^inline std::string value::to_str() const {$/;"	f	class:picojson::value
topIds_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  std::vector<int> topIds_;$/;"	m	class:paddle::RecurrentGradientMachine
topIndex	gserver/gradientmachines/RecurrentGradientMachine.h	/^    int topIndex;   \/\/ index of MaxIdLayer output in one sample$/;"	m	struct:paddle::RecurrentGradientMachine::Path
topLevelLength	parameter/Argument.h	/^    int topLevelLength;$/;"	m	struct:paddle::Argument::SeqInfo
totAbstract_	utils/BarrierStat.h	/^  struct Abstract totAbstract_;$/;"	m	class:paddle::BarrierStatBase	typeref:struct:paddle::BarrierStatBase::Abstract
totBytes_	pserver/SparseParameterDistribution.h	/^  std::atomic<size_t> totBytes_;$/;"	m	class:paddle::SparseParameterDistribution
totDelta	utils/BarrierStat.h	/^  uint64_t totDelta;$/;"	m	struct:paddle::Abstract
totLastTwoDelta	utils/BarrierStat.h	/^  uint64_t totLastTwoDelta;$/;"	m	struct:paddle::Abstract
totMidDelta	utils/BarrierStat.h	/^  uint64_t totMidDelta;$/;"	m	struct:paddle::Abstract
totSamples_	utils/BarrierStat.h	/^  uint64_t totSamples_;$/;"	m	class:paddle::BarrierStatBase
totSecondDelta	utils/BarrierStat.h	/^  uint64_t totSecondDelta;$/;"	m	struct:paddle::Abstract
totalCost_	trainer/TrainerInternalConfig.h	/^  real totalCost_;$/;"	m	class:paddle::TrainerStats
totalDataRatio_	gserver/dataproviders/MultiDataProvider.h	/^  int totalDataRatio_;$/;"	m	class:paddle::MultiDataProvider
totalLength	pserver/SocketChannel.h	/^    int64_t totalLength;  \/\/\/ include the header$/;"	m	struct:paddle::SocketChannel::MessageHeader
totalScore_	gserver/evaluators/Evaluator.h	/^  double totalScore_;$/;"	m	class:paddle::Evaluator
totalSegments_	gserver/layers/LinearChainCTC.h	/^  int numClasses_, blank_, totalSegments_, totalTime_;$/;"	m	class:paddle::LinearChainCTC
totalState_	gserver/layers/LstmLayer.h	/^  MatrixPtr totalState_;$/;"	m	class:paddle::LstmLayer
totalTime_	gserver/layers/LinearChainCTC.h	/^  int numClasses_, blank_, totalSegments_, totalTime_;$/;"	m	class:paddle::LinearChainCTC
total_	utils/Stat.h	/^  uint64_t total_;$/;"	m	class:paddle::StatInfo
total_	utils/Stat.h	/^  uint64_t total_;$/;"	m	class:paddle::Timer
total_pad_	function/ContextProjectionOp.cpp	/^  size_t total_pad_;$/;"	m	class:paddle::ContextProjectionBackwardFunc	file:
total_pad_	function/ContextProjectionOp.cpp	/^  size_t total_pad_;$/;"	m	class:paddle::ContextProjectionBackwardWeightFunc	file:
touchFile	utils/Util.cpp	/^void touchFile(const char* filename) {$/;"	f	namespace:paddle
track_	gserver/layers/LinearChainCRF.h	/^  IVectorPtr track_;$/;"	m	class:paddle::LinearChainCRF
train	trainer/Trainer.cpp	/^void Trainer::train(size_t numPasses) {$/;"	f	class:paddle::Trainer
trainIsOn	gserver/gradientmachines/GradientMachine.h	/^  virtual bool trainIsOn() { return true; }$/;"	f	class:paddle::GradientMachine
trainOneBatch	api/Trainer.cpp	/^bool Trainer::trainOneBatch(size_t batchSize) {$/;"	f	class:Trainer
trainOneBatch	trainer/TrainerInternal.cpp	/^void TrainerInternal::trainOneBatch(int64_t batchId,$/;"	f	class:paddle::TrainerInternal
trainOneDataBatch	api/Trainer.cpp	/^void Trainer::trainOneDataBatch(size_t batchSize, const Arguments& inArgs) {$/;"	f	class:Trainer
trainOneDataBatch	trainer/Trainer.cpp	/^void Trainer::trainOneDataBatch(DataBatch& dataBatch) {$/;"	f	class:paddle::Trainer
trainOnePass	trainer/Trainer.cpp	/^void Trainer::trainOnePass() {$/;"	f	class:paddle::Trainer
trainOnePassBatch	trainer/Trainer.cpp	/^void Trainer::trainOnePassBatch(int passId) {$/;"	f	class:paddle::Trainer
trainPassContext_	trainer/Trainer.h	/^  TrainPassContext trainPassContext_;$/;"	m	class:paddle::Trainer
trainState	trainer/TesterConfig.h	/^  MachineState* trainState;$/;"	m	struct:paddle::TesterConfig
trainState_	trainer/Trainer.h	/^  MachineState trainState_;$/;"	m	class:paddle::Trainer
trainWholeDataInOneBatch	gserver/gradientmachines/GradientMachineMode.h	/^  static bool trainWholeDataInOneBatch(int32_t mode) {$/;"	f	class:paddle::IGradientMachineMode
train_list	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^    train_list='gserver\/tests\/Sequence\/dummy.list',$/;"	v
train_list	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^    train_list='gserver\/tests\/Sequence\/dummy.list',$/;"	v
train_list	trainer/tests/simple_sparse_neural_network.py	/^    train_list=file_list,$/;"	v
trainerBarrier_	gserver/gradientmachines/MultiGradientMachine.h	/^  ThreadBarrier trainerBarrier_;$/;"	m	class:paddle::MultiGradientMachine
trainerId	trainer/TesterConfig.h	/^  int trainerId;$/;"	m	struct:paddle::TesterConfig
trainerId	utils/BarrierStat.h	/^  int32_t trainerId;$/;"	m	struct:paddle::Abstract
trainerId_	pserver/ParameterClient2.h	/^  int trainerId_;$/;"	m	class:paddle::ParameterClient2
trainerIds_	utils/BarrierStat.h	/^  std::vector<int32_t> trainerIds_;$/;"	m	class:paddle::TimeVectorEnd
trainerInternal_	trainer/Trainer.h	/^  MetricTrainer trainerInternal_;$/;"	m	class:paddle::Trainer
trainerInternal_	trainer/Trainer.h	/^  TrainerInternal trainerInternal_;$/;"	m	class:paddle::Trainer
trainerOnePassTest	trainer/tests/test_CompareSparse.cpp	/^std::vector<ParameterPtr> trainerOnePassTest(const string& configFile,$/;"	f
trainerOnePassTest	trainer/tests/test_TrainerOnePass.cpp	/^void trainerOnePassTest(const string& configFile,$/;"	f
trainer_config	api/PaddleAPIPrivate.h	/^  std::shared_ptr<paddle::TrainerConfigHelper> trainer_config;$/;"	m	struct:OptimizationConfigPrivate
trainer_count	trainer/ThreadParameterUpdater.cpp	/^DECLARE_int32(trainer_count);$/;"	v
trainer_count	trainer/TrainerInternalConfig.h	/^  int trainer_count;$/;"	m	struct:paddle::TrainerInternalConfig
trainer_count	utils/Flags.h	/^DECLARE_int32(trainer_count);$/;"	v
trainer_id	gserver/evaluators/Evaluator.cpp	/^DECLARE_int32(trainer_id);$/;"	v
trainer_id	gserver/layers/ValidationLayer.h	/^DECLARE_int32(trainer_id);$/;"	v
trainer_id	trainer/RemoteParameterUpdater.cpp	/^DECLARE_int32(trainer_id);$/;"	v
trainer_id	trainer/TrainerConfigHelper.cpp	/^DECLARE_int32(trainer_id);$/;"	v
trainer_id	trainer/TrainerInternalConfig.h	/^  int trainer_id;$/;"	m	struct:paddle::TrainerInternalConfig
trainer_id	utils/Flags.h	/^DECLARE_int32(trainer_id);$/;"	v
trans	math/tests/test_SparseMatrix.cpp	/^  bool trans;$/;"	m	struct:MatrixPara	file:
transOutValue_	gserver/layers/ExpandConvBaseLayer.h	/^  MatrixPtr transOutValue_;$/;"	m	class:paddle::ExpandConvBaseLayer
trans_	math/BaseMatrix.h	/^  bool trans_;$/;"	m	class:paddle::BaseMatrixT
transpose	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::transpose(MatrixPtr& matTrans, bool memAlloc) {$/;"	f	class:paddle::CpuSparseMatrix
transpose	math/Matrix.cpp	/^void CpuMatrix::transpose(MatrixPtr& matTrans, bool memAlloc) {$/;"	f	class:paddle::CpuMatrix
transpose	math/Matrix.cpp	/^void GpuMatrix::transpose(MatrixPtr& matTrans, bool memAlloc) {$/;"	f	class:paddle::GpuMatrix
transpose	math/Matrix.h	/^  virtual void transpose(MatrixPtr& matTrans, bool memAlloc) {$/;"	f	class:paddle::Matrix
transpose	math/SparseMatrix.cpp	/^void GpuSparseMatrix::transpose(MatrixPtr& matTrans, bool memAlloc) {$/;"	f	class:paddle::GpuSparseMatrix
trapezoidArea	gserver/evaluators/Evaluator.h	/^  inline static double trapezoidArea(double X1,$/;"	f	class:paddle::AucEvaluator
traverse	trainer/ThreadParameterUpdater.cpp	/^void SgdThreadUpdater::traverse(GetTraverseCallback getTraverseCallback) {$/;"	f	class:paddle::SgdThreadUpdater
trimFrom	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::trimFrom(const CpuSparseMatrix& src) {$/;"	f	class:paddle::CpuSparseMatrix
trimFrom	math/Matrix.h	/^  virtual void trimFrom(const CpuSparseMatrix& src) {$/;"	f	class:paddle::Matrix
trimFrom	math/SparseMatrix.cpp	/^void GpuSparseMatrix::trimFrom(const CpuSparseMatrix& src) {$/;"	f	class:paddle::GpuSparseMatrix
trimFromCSC	math/SparseMatrix.cpp	/^void GpuSparseMatrix::trimFromCSC(const CpuSparseMatrix& src) {$/;"	f	class:paddle::GpuSparseMatrix
trimFromCSR	math/SparseMatrix.cpp	/^void GpuSparseMatrix::trimFromCSR(const CpuSparseMatrix& src) {$/;"	f	class:paddle::GpuSparseMatrix
tripCount_	utils/arch/osx/Locks.cpp	/^  int tripCount_;$/;"	m	class:paddle::ThreadBarrierPrivate	file:
true_type	math/BaseMatrix.h	/^typedef bool_constant<bool, true> true_type;$/;"	t	namespace:paddle
truncationSize_	gserver/layers/CostLayer.h	/^  int truncationSize_;$/;"	m	class:paddle::LambdaCost
tryCreateGradientMachine	gserver/gradientmachines/GradientMachineMode.h	/^  static GradientMachine* tryCreateGradientMachine(int32_t mode,$/;"	f	class:paddle::IGradientMachineMode
tryCreateUpdater	trainer/RemoteParameterUpdater.h	/^  static ParameterUpdater* tryCreateUpdater(const std::string& algo,$/;"	f	class:paddle::ParameterUpdaterCreators
tryGetMode	gserver/gradientmachines/GradientMachineMode.h	/^  static bool tryGetMode(int* mode,$/;"	f	class:paddle::IGradientMachineMode
tryLoadParametersFromConfig	trainer/ParamUtil.h	/^  inline bool tryLoadParametersFromConfig() {$/;"	f	class:paddle::ParameterUtil
tuningAsyncsgdFinished	pserver/ParameterServer2.cpp	/^void ParameterServer2::tuningAsyncsgdFinished() {$/;"	f	class:paddle::ParameterServer2
tuningAsyncsgdMidOutput	pserver/ParameterServer2.cpp	/^void ParameterServer2::tuningAsyncsgdMidOutput() {$/;"	f	class:paddle::ParameterServer2
tuningSgdFinished	pserver/ParameterServer2.cpp	/^void ParameterServer2::tuningSgdFinished() {$/;"	f	class:paddle::ParameterServer2
tuningSgdMidOutput	pserver/ParameterServer2.cpp	/^void ParameterServer2::tuningSgdMidOutput() {$/;"	f	class:paddle::ParameterServer2
type	cuda/include/hl_base.h	/^  hl_matrix_value_t type;$/;"	m	struct:__anon10
type	gserver/dataproviders/ProtoDataProvider.h	/^    SlotDef::SlotType type;$/;"	m	struct:paddle::ProtoDataProvider::ProtoSlot
type	gserver/dataproviders/PyDataProvider.h	/^    SlotDef::SlotType type;$/;"	m	struct:paddle::PyDataProvider::ProtoSlot
type	gserver/evaluators/ChunkEvaluator.cpp	/^    int type;$/;"	m	struct:paddle::ChunkEvaluator::Segment	file:
type	math/tests/TestUtils.h	/^  typedef CpuMatrix type;$/;"	t	class:autotest::ReplaceType
type	math/tests/TestUtils.h	/^  typedef GpuMatrix type;$/;"	t	class:autotest::ReplaceType
type	math/tests/TestUtils.h	/^  typedef T1 type;$/;"	t	class:autotest::ReplaceType
typeCheck	gserver/layers/CudnnPoolLayer.cpp	/^bool CudnnPoolLayer::typeCheck(const std::string &poolType,$/;"	f	class:paddle::CudnnPoolLayer
type_	function/BufferArg.h	/^  SparseDataType type_;$/;"	m	class:paddle::SparseMatrixArg
type_	gserver/layers/ExpandLayer.h	/^  int type_;$/;"	m	class:paddle::ExpandLayer
type_	gserver/layers/SequencePoolLayer.h	/^  int type_;$/;"	m	class:paddle::SequencePoolLayer
type_	trainer/tests/picojson.h	/^  int type_;$/;"	m	class:picojson::value
u_	trainer/tests/picojson.h	/^  _storage u_;$/;"	m	class:picojson::value
udp	parameter/Argument.h	/^  UserDefinedVectorPtr udp;  \/\/ user defined pointer$/;"	m	struct:paddle::Argument
unary	cuda/include/hl_tensor_ops.h	/^namespace unary {$/;"	n	namespace:hppl
unaryExpression	math/TensorExpression.h	/^  const TensorUnaryOp<UnaryOp, const Derived, T> unaryExpression($/;"	f	class:paddle::TensorExpression
unbalanceCnt_	pserver/SparseParameterDistribution.h	/^  int unbalanceCnt_;$/;"	m	class:paddle::SparseParameterDistribution
ungetc	trainer/tests/picojson.h	/^  void ungetc() {$/;"	f	class:picojson::input
ungot_	trainer/tests/picojson.h	/^  bool ungot_;$/;"	m	class:picojson::input
uniform	math/Vector.cpp	/^void CpuVectorT<T>::uniform(real, real) {$/;"	f	class:paddle::CpuVectorT
uniform	math/Vector.cpp	/^void CpuVectorT<real>::uniform(real left, real right) {$/;"	f	class:paddle::CpuVectorT
uniform	math/Vector.cpp	/^void GpuVectorT<T>::uniform(real, real) {$/;"	f	class:paddle::GpuVectorT
uniform	math/Vector.cpp	/^void GpuVectorT<real>::uniform(real left, real right) {$/;"	f	class:paddle::GpuVectorT
uniform	math/Vector.h	/^  virtual void uniform(real left, real right) {$/;"	f	class:paddle::ParallelCpuVectorT
uniformRandom	math/tests/test_sparseMatrixCompare.cpp	/^static inline int uniformRandom(int n) { return n == 0 ? 0 : rand() % n; }$/;"	f	file:
uniformRandom	testing/TestUtil.h	/^inline int uniformRandom(int n) { return n == 0 ? 0 : rand() % n; }$/;"	f	namespace:paddle
uniqueIds	utils/Util.h	/^inline void uniqueIds(std::vector<uint32_t>& ids) {$/;"	f	namespace:paddle
unittest	gserver/dataproviders/PyDataProvider2.cpp	/^namespace unittest {$/;"	n	namespace:paddle	file:
unittest	gserver/tests/test_PyDataProvider2.cpp	/^namespace unittest {$/;"	n	namespace:paddle	file:
unlock	utils/Locks.h	/^  void unlock() { pthread_rwlock_unlock(&rwlock_); }$/;"	f	class:paddle::RWLock
unlock	utils/arch/linux/Locks.cpp	/^void SpinLock::unlock() { pthread_spin_unlock(&m->lock_); }$/;"	f	class:paddle::SpinLock
unlock	utils/arch/osx/Locks.cpp	/^void SpinLock::unlock() { m->lock_.clear(std::memory_order_release); }$/;"	f	class:paddle::SpinLock
update	api/ParameterOptimizer.cpp	/^void ParameterOptimizer::update(const std::vector<Vector*>& vecs,$/;"	f	class:ParameterOptimizer
update	api/ParameterUpdater.cpp	/^void ParameterUpdater::update(Parameter *param) {$/;"	f	class:ParameterUpdater
update	parameter/AverageOptimizer.cpp	/^void AverageSparseOptimizer::update(const VectorPtr vecs[],$/;"	f	class:paddle::AverageSparseOptimizer
update	parameter/AverageOptimizer.h	/^  virtual void update(const VectorPtr vecs[],$/;"	f	class:paddle::AverageOptimizer
update	parameter/FirstOrderOptimizer.cpp	/^void AdaDeltaParameterOptimizer::update(const VectorPtr vecs[],$/;"	f	class:paddle::AdaDeltaParameterOptimizer
update	parameter/FirstOrderOptimizer.cpp	/^void AdagradParameterOptimizer::update(const VectorPtr vecs[],$/;"	f	class:paddle::AdagradParameterOptimizer
update	parameter/FirstOrderOptimizer.cpp	/^void AdamParameterOptimizer::update(const VectorPtr vecs[],$/;"	f	class:paddle::AdamParameterOptimizer
update	parameter/FirstOrderOptimizer.cpp	/^void AdamaxParameterOptimizer::update(const VectorPtr vecs[],$/;"	f	class:paddle::AdamaxParameterOptimizer
update	parameter/FirstOrderOptimizer.cpp	/^void DecayedAdagradParameterOptimizer::update(const VectorPtr vecs[],$/;"	f	class:paddle::DecayedAdagradParameterOptimizer
update	parameter/FirstOrderOptimizer.cpp	/^void OptimizerWithGradientClipping::update(const VectorPtr vecs[],$/;"	f	class:paddle::OptimizerWithGradientClipping
update	parameter/FirstOrderOptimizer.cpp	/^void RMSPropParameterOptimizer::update(const VectorPtr vecs[],$/;"	f	class:paddle::RMSPropParameterOptimizer
update	parameter/FirstOrderOptimizer.cpp	/^void SparseMomentumParameterOptimizer::update(const VectorPtr vecs[],$/;"	f	class:paddle::SparseMomentumParameterOptimizer
update	parameter/FirstOrderOptimizer.h	/^  virtual void update(const VectorPtr vecs[],$/;"	f	class:paddle::AddOptimizer
update	parameter/FirstOrderOptimizer.h	/^  virtual void update(const VectorPtr vecs[],$/;"	f	class:paddle::DummyOptimizer
update	parameter/FirstOrderOptimizer.h	/^  virtual void update(const VectorPtr vecs[],$/;"	f	class:paddle::SgdOptimizer
update	parameter/OptimizerWithRegularizer.cpp	/^void OptimizerWithRegularizerSparse::update(const VectorPtr vecs[],$/;"	f	class:paddle::OptimizerWithRegularizerSparse
update	parameter/OptimizerWithRegularizer.h	/^  virtual void update(const VectorPtr vecs[],$/;"	f	class:paddle::OptimizerWithRegularizer
update	parameter/OptimizerWithRegularizer.h	/^  virtual void update(const VectorPtr vecs[],$/;"	f	class:paddle::OptimizerWithRegularizerEveryNumBatches
update	parameter/ParameterUpdaterBase.h	/^  void update(Parameter* para) {$/;"	f	class:paddle::ParameterUpdater
update	parameter/ParameterUpdaterHook.cpp	/^  void update(Parameter* para) {$/;"	f	class:paddle::StaticPruningHook
update	parameter/Regularizer.h	/^  virtual void update(const VectorPtr vecs[],$/;"	f	class:paddle::L1L2LrRegularizer
update	parameter/Regularizer.h	/^  virtual void update(const VectorPtr vecs[],$/;"	f	class:paddle::L1L2Regularizer
update	parameter/Regularizer.h	/^  virtual void update(const VectorPtr vecs[],$/;"	f	class:paddle::L1LrRegularizer
update	parameter/Regularizer.h	/^  virtual void update(const VectorPtr vecs[],$/;"	f	class:paddle::L1Regularizer
update	parameter/Regularizer.h	/^  virtual void update(const VectorPtr vecs[],$/;"	f	class:paddle::L2LrRegularizer
update	parameter/Regularizer.h	/^  virtual void update(const VectorPtr vecs[],$/;"	f	class:paddle::L2Regularizer
updateAverageWindowLimit	parameter/AverageOptimizer.h	/^  void updateAverageWindowLimit() {$/;"	f	class:paddle::AverageOptimizer
updateConfigFromFlags	trainer/TrainerConfigHelper.cpp	/^void TrainerConfigHelper::updateConfigFromFlags() {$/;"	f	class:paddle::TrainerConfigHelper
updateCounter_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::atomic<int> updateCounter_;$/;"	m	class:paddle::TrainerThread
updateCounter_	parameter/Parameter.h	/^  int updateCounter_;$/;"	m	class:paddle::Parameter
updateFunc	trainer/ParameterUpdater.cpp	/^void SgdUpdaterWithCpuAverager::updateFunc(Parameter* para) {$/;"	f	class:paddle::SgdUpdaterWithCpuAverager
updateHook	parameter/Parameter.h	/^  void updateHook() {$/;"	f	class:paddle::Parameter
updateImpl	parameter/ParameterUpdaterBase.h	/^  virtual void updateImpl(Parameter* para) {}$/;"	f	class:paddle::ParameterUpdaterComposite
updateImpl	trainer/ParameterUpdater.cpp	/^void SgdUpdaterWithCpuAverager::updateImpl(Parameter* para) {$/;"	f	class:paddle::SgdUpdaterWithCpuAverager
updateImpl	trainer/ParameterUpdater.h	/^  virtual void updateImpl(Parameter* para) {$/;"	f	class:paddle::SgdLocalUpdater
updateImpl	trainer/ParameterUpdater.h	/^  virtual void updateImpl(Parameter* para) {}$/;"	f	class:paddle::SgdCpuUpdater
updateImpl	trainer/RemoteParameterUpdater.cpp	/^void ConcurrentRemoteParameterUpdater::updateImpl(Parameter* para) {$/;"	f	class:paddle::ConcurrentRemoteParameterUpdater
updateImpl	trainer/RemoteParameterUpdater.cpp	/^void RemoteParameterUpdater::updateImpl(Parameter* para) {$/;"	f	class:paddle::RemoteParameterUpdater
updateImpl	trainer/RemoteParameterUpdater.h	/^  virtual void updateImpl(Parameter* para) {}$/;"	f	class:paddle::SparseRemoteParameterUpdater
updateImpl	trainer/ThreadParameterUpdater.cpp	/^void SgdThreadUpdater::updateImpl(Parameter* para) {$/;"	f	class:paddle::SgdThreadUpdater
updateMap	utils/ThreadLocal.h	/^  void updateMap(T* p) {$/;"	f	class:paddle::ThreadLocalD
updateSamplesNum	gserver/evaluators/CTCErrorEvaluator.cpp	/^  virtual void updateSamplesNum(const std::vector<Argument>& arguments) {$/;"	f	class:paddle::CTCErrorEvaluator
updateSamplesNum	gserver/evaluators/Evaluator.cpp	/^  virtual void updateSamplesNum(const std::vector<Argument>& arguments) {$/;"	f	class:paddle::ClassificationErrorEvaluator
updateSamplesNum	gserver/evaluators/Evaluator.cpp	/^  virtual void updateSamplesNum(const std::vector<Argument>& arguments) {$/;"	f	class:paddle::ColumnSumEvaluator
updateSamplesNum	gserver/evaluators/Evaluator.cpp	/^  virtual void updateSamplesNum(const std::vector<Argument>& arguments) {$/;"	f	class:paddle::SequenceClassificationErrorEvaluator
updateSamplesNum	gserver/evaluators/Evaluator.cpp	/^  virtual void updateSamplesNum(const std::vector<Argument>& arguments) {$/;"	f	class:paddle::SumEvaluator
updateSamplesNum	gserver/evaluators/Evaluator.cpp	/^  virtual void updateSamplesNum(const std::vector<Argument>& arguments) {}$/;"	f	class:paddle::ClassificationErrorPrinter
updateSamplesNum	gserver/evaluators/Evaluator.cpp	/^  virtual void updateSamplesNum(const std::vector<Argument>& arguments) {}$/;"	f	class:paddle::GradientPrinter
updateSamplesNum	gserver/evaluators/Evaluator.cpp	/^  virtual void updateSamplesNum(const std::vector<Argument>& arguments) {}$/;"	f	class:paddle::MaxFramePrinter
updateSamplesNum	gserver/evaluators/Evaluator.cpp	/^  virtual void updateSamplesNum(const std::vector<Argument>& arguments) {}$/;"	f	class:paddle::MaxIdPrinter
updateSamplesNum	gserver/evaluators/Evaluator.cpp	/^  virtual void updateSamplesNum(const std::vector<Argument>& arguments) {}$/;"	f	class:paddle::SequenceTextPrinter
updateSamplesNum	gserver/evaluators/Evaluator.cpp	/^  virtual void updateSamplesNum(const std::vector<Argument>& arguments) {}$/;"	f	class:paddle::ValuePrinter
updateSamplesNum	gserver/evaluators/Evaluator.cpp	/^void RankAucEvaluator::updateSamplesNum($/;"	f	class:paddle::RankAucEvaluator
updateSamplesNum	gserver/evaluators/Evaluator.h	/^  virtual void updateSamplesNum(const std::vector<Argument>& arguments) {$/;"	f	class:paddle::Evaluator
updateStat	utils/BarrierStat.cpp	/^void BarrierDeltaStat::updateStat(uint64_t delta, int32_t trainerId) {$/;"	f	class:paddle::BarrierDeltaStat
updateStat	utils/BarrierStat.cpp	/^void BarrierEndStat::updateStat(struct timeval &cur, int32_t trainerId) {$/;"	f	class:paddle::BarrierEndStat
updateStat	utils/BarrierStat.h	/^  virtual void updateStat(struct timeval &cur, int32_t trainerId = -1) {$/;"	f	class:paddle::BarrierDeltaStat
updateStat	utils/BarrierStat.h	/^  virtual void updateStat(uint64_t delta, int32_t trainerId = -1) {$/;"	f	class:paddle::BarrierEndStat
updateThreadChecker_	parameter/ParameterUpdaterHook.cpp	/^  SameThreadChecker updateThreadChecker_;$/;"	m	class:paddle::StaticPruningHook	file:
updateThreadParameters	gserver/gradientmachines/MultiGradientMachine.cpp	/^void MultiGradientMachine::updateThreadParameters() {$/;"	f	class:paddle::MultiGradientMachine
updateWithGradient	parameter/Parameter.cpp	/^void Parameter::updateWithGradient(real learningRate) {$/;"	f	class:paddle::Parameter
updateWithGradient	parameter/Parameter.cpp	/^void Parameter::updateWithGradient(real learningRate,$/;"	f	class:paddle::Parameter
updateWorker_	trainer/ParameterUpdater.h	/^  ThreadWorker updateWorker_;$/;"	m	class:paddle::SgdUpdaterWithCpuAverager
update_callback	api/test/testTrain.py	/^        def update_callback(param):$/;"	f	function:main
updated_	parameter/Parameter.h	/^  bool updated_;$/;"	m	class:paddle::Parameter
updater	api/PaddleAPIPrivate.h	/^  std::unique_ptr<paddle::ParameterUpdater> updater;$/;"	m	struct:ParameterUpdaterPrivate
updaterHooks_	parameter/Parameter.h	/^  std::vector<std::shared_ptr<IParameterUpdaterHook>> updaterHooks_;$/;"	m	class:paddle::Parameter
updaters_	parameter/ParameterUpdaterBase.h	/^  std::vector<std::unique_ptr<ParameterUpdater>> updaters_;$/;"	m	class:paddle::ParameterUpdaterComposite
usage	scripts/tools/usage_stat/usage.sh	/^usage()$/;"	f
usageRatio_	gserver/dataproviders/DataProvider.h	/^  float usageRatio_;$/;"	m	class:paddle::DataProvider
useApplyInPserver	parameter/OptimizerFunctions.cpp	/^bool useApplyInPserver(const OptimizationConfig& optConfig) {$/;"	f	namespace:paddle
useApplyInPserver_	trainer/RemoteParameterUpdater.h	/^  bool useApplyInPserver_;$/;"	m	class:paddle::RemoteParameterUpdater
useApplyInPserver_	trainer/RemoteParameterUpdater.h	/^  bool useApplyInPserver_;$/;"	m	class:paddle::SparseRemoteParameterUpdater
useApply_	parameter/AverageOptimizer.h	/^  bool useApply_;$/;"	m	class:paddle::AverageOptimizer
useBatch_	gserver/layers/GatedRecurrentLayer.h	/^  bool useBatch_;$/;"	m	class:paddle::GatedRecurrentLayer
useBatch_	gserver/layers/LstmLayer.h	/^  bool useBatch_;$/;"	m	class:paddle::LstmLayer
useBatch_	gserver/tests/test_RecurrentLayer.cpp	/^  bool useBatch_;$/;"	m	class:TestRecurrentLayer	file:
useGlobalStats_	gserver/layers/BatchNormBaseLayer.h	/^  bool useGlobalStats_;$/;"	m	class:paddle::BatchNormBaseLayer
useGpu	gserver/gradientmachines/MultiGradientMachine.h	/^  bool useGpu() const { return useGpu_; }$/;"	f	class:paddle::MultiGradientMachine
useGpu	math/BaseMatrix.h	/^  bool useGpu() const { return useGpu_; }$/;"	f	class:paddle::BaseMatrixT
useGpu	math/TensorApply.h	/^  INLINE bool useGpu() const { return expr1_.useGpu(); }$/;"	f	class:paddle::TensorApply
useGpu	math/TensorApply.h	/^  INLINE bool useGpu() const { return expr_.useGpu(); }$/;"	f	class:paddle::TensorApply
useGpu	math/TensorApply.h	/^  INLINE bool useGpu() const { return lhs_.useGpu(); }$/;"	f	class:paddle::TensorApply
useGpu	math/TensorApply.h	/^  INLINE bool useGpu() const { return useGpu_; }$/;"	f	class:paddle::TensorApply
useGpu	math/TensorAssign.h	/^  INLINE bool useGpu() const { return lhs_.useGpu(); }$/;"	f	class:paddle::TensorAssignOp
useGpu	parameter/Parameter.h	/^  inline bool useGpu() const { return useGpu_; }$/;"	f	class:paddle::Parameter
useGpu	utils/Util.h	/^inline bool useGpu(int deviceId) {$/;"	f	namespace:paddle
useGpu_	gserver/dataproviders/DataProvider.h	/^  bool useGpu_;$/;"	m	class:paddle::DataProvider
useGpu_	gserver/dataproviders/DataProvider.h	/^  bool useGpu_;$/;"	m	class:paddle::DoubleBuffer
useGpu_	gserver/gradientmachines/MultiGradientMachine.h	/^  bool useGpu_;$/;"	m	class:paddle::MultiGradientMachine
useGpu_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  bool useGpu_;$/;"	m	class:paddle::ParallelNeuralNetwork
useGpu_	gserver/gradientmachines/ParallelNeuralNetwork.h	/^  bool useGpu_;$/;"	m	class:paddle::ParallelThread
useGpu_	gserver/gradientmachines/RecurrentGradientMachine.h	/^  bool useGpu_;$/;"	m	class:paddle::RecurrentGradientMachine
useGpu_	gserver/layers/Layer.h	/^  bool useGpu_;$/;"	m	class:paddle::Layer
useGpu_	gserver/layers/Operator.h	/^  bool useGpu_;$/;"	m	class:paddle::Operator
useGpu_	gserver/layers/Projection.h	/^  bool useGpu_;$/;"	m	class:paddle::Projection
useGpu_	gserver/layers/SequenceToBatch.h	/^  bool useGpu_;$/;"	m	class:paddle::SequenceToBatch
useGpu_	gserver/tests/test_RecurrentLayer.cpp	/^  bool useGpu_;$/;"	m	class:TestRecurrentLayer	file:
useGpu_	math/BaseMatrix.h	/^  bool useGpu_;$/;"	m	class:paddle::BaseMatrixT
useGpu_	math/TensorApply.h	/^  bool useGpu_;$/;"	m	class:paddle::TensorApply
useGpu_	parameter/Parameter.h	/^  bool useGpu_;$/;"	m	class:paddle::Parameter
useSeqParallel_	gserver/layers/LstmLayer.h	/^  bool useSeqParallel_;$/;"	m	class:paddle::LstmLayer
use_gpu	trainer/TrainerInternalConfig.h	/^  bool use_gpu;$/;"	m	struct:paddle::TrainerInternalConfig
use_gpu	trainer/tests/test_Compare.cpp	/^DECLARE_bool(use_gpu);$/;"	v
use_gpu	trainer/tests/test_CompareSparse.cpp	/^DECLARE_bool(use_gpu);$/;"	v
use_gpu	trainer/tests/test_CompareTwoNets.cpp	/^DECLARE_bool(use_gpu);$/;"	v
use_gpu	trainer/tests/test_CompareTwoOpts.cpp	/^DECLARE_bool(use_gpu);$/;"	v
use_gpu	trainer/tests/test_Trainer.cpp	/^DECLARE_bool(use_gpu);$/;"	v
use_gpu	trainer/tests/test_TrainerOnePass.cpp	/^DECLARE_bool(use_gpu);$/;"	v
use_gpu	utils/Flags.h	/^DECLARE_bool(use_gpu);$/;"	v
use_old_updater	trainer/TrainerInternalConfig.h	/^  bool use_old_updater;$/;"	m	struct:paddle::TrainerInternalConfig
use_old_updater	trainer/tests/test_CompareSparse.cpp	/^DECLARE_bool(use_old_updater);$/;"	v
use_old_updater	trainer/tests/test_TrainerOnePass.cpp	/^DECLARE_bool(use_old_updater);$/;"	v
usedSegments_	pserver/ParameterServer2.h	/^  BlockSegments usedSegments_;$/;"	m	class:paddle::ParameterServer2
usingBatch_	gserver/dataproviders/DataProvider.h	/^  ThreadLocal<BufferBatchPtr> usingBatch_;$/;"	m	class:paddle::DoubleBuffer
v4si	cuda/src/avx_mathfun.h	/^typedef __m128i v4si;  \/\/ vector of 8 int   (avx)$/;"	t
v8sf	cuda/src/avx_mathfun.h	/^typedef __m256 v8sf;   \/\/ vector of 8 float (avx)$/;"	t
v8si	cuda/src/avx_mathfun.h	/^typedef __m256i v8si;  \/\/ vector of 8 int   (avx)$/;"	t
vAdd	math/MathFunctions.cpp	/^void vAdd(const int n, const T* a, const T* b, T* r) {$/;"	f	namespace:paddle
vAdd	math/MathFunctions.cpp	/^void vAdd<double>(const int n, const double* a, const double* b, double* r) {$/;"	f	namespace:paddle
vAdd	math/MathFunctions.cpp	/^void vAdd<float>(const int n, const float* a, const float* b, float* r) {$/;"	f	namespace:paddle
vExp	math/MathFunctions.cpp	/^void vExp(const int n, const T* a, T* r) {$/;"	f	namespace:paddle
vExp	math/MathFunctions.cpp	/^void vExp<double>(const int n, const double* a, double* r) {$/;"	f	namespace:paddle
vExp	math/MathFunctions.cpp	/^void vExp<float>(const int n, const float* a, float* r) {$/;"	f	namespace:paddle
vInvSqrt	math/MathFunctions.cpp	/^void vInvSqrt(const int n, const T* a, T* r) {$/;"	f	namespace:paddle
vInvSqrt	math/MathFunctions.cpp	/^void vInvSqrt<double>(const int n, const double* a, double* r) {$/;"	f	namespace:paddle
vInvSqrt	math/MathFunctions.cpp	/^void vInvSqrt<float>(const int n, const float* a, float* r) {$/;"	f	namespace:paddle
vLog	math/MathFunctions.cpp	/^void vLog(const int n, const T* a, T* r) {$/;"	f	namespace:paddle
vLog	math/MathFunctions.cpp	/^void vLog<double>(const int n, const double* a, double* r) {$/;"	f	namespace:paddle
vLog	math/MathFunctions.cpp	/^void vLog<float>(const int n, const float* a, float* r) {$/;"	f	namespace:paddle
vLog1p	math/MathFunctions.cpp	/^void vLog1p(const int n, const T* a, T* r) {$/;"	f	namespace:paddle
vLog1p	math/MathFunctions.cpp	/^void vLog1p<double>(const int n, const double* a, double* r) {$/;"	f	namespace:paddle
vLog1p	math/MathFunctions.cpp	/^void vLog1p<float>(const int n, const float* a, float* r) {$/;"	f	namespace:paddle
vPow	math/MathFunctions.cpp	/^void vPow(const int n, const T* a, const T b, T* r) {$/;"	f	namespace:paddle
vPow	math/MathFunctions.cpp	/^void vPow<double>(const int n, const double* a, const double b, double* r) {$/;"	f	namespace:paddle
vPow	math/MathFunctions.cpp	/^void vPow<float>(const int n, const float* a, const float b, float* r) {$/;"	f	namespace:paddle
vTanh	math/MathFunctions.cpp	/^void vTanh(const int n, const T* a, T* r) {$/;"	f	namespace:paddle
vTanh	math/MathFunctions.cpp	/^void vTanh<double>(const int n, const double* a, double* r) {$/;"	f	namespace:paddle
vTanh	math/MathFunctions.cpp	/^void vTanh<float>(const int n, const float* a, float* r) {$/;"	f	namespace:paddle
val	math/SparseMatrix.h	/^    real val;$/;"	m	struct:paddle::GpuSparseMatrix::Element
valBuf	api/PaddleAPI.h	/^  const float* valBuf;$/;"	m	struct:IntWithFloatArray
val_randomer	trainer/tests/testPyDataWrapper.py	/^val_randomer = lambda: random.uniform(-1.0, 1.0)$/;"	v
validateResponses	pserver/ParameterClient2.cpp	/^static void validateResponses(const std::vector<Proto>& responses) {$/;"	f	namespace:paddle
validationImp	gserver/layers/ValidationLayer.cpp	/^void AucValidation::validationImp(MatrixPtr output, IVectorPtr label) {$/;"	f	class:paddle::AucValidation
validationImp	gserver/layers/ValidationLayer.cpp	/^void PnpairValidation::validationImp(MatrixPtr output, IVectorPtr label) {$/;"	f	class:paddle::PnpairValidation
value	function/Function.h	/^  union value {$/;"	u	class:paddle::FuncConfig
value	function/TensorType.h	/^  static const ValueType value = VALUE_TYPE_DOUBLE;$/;"	m	struct:paddle::DataType
value	function/TensorType.h	/^  static const ValueType value = VALUE_TYPE_FLOAT;$/;"	m	struct:paddle::DataType
value	function/TensorType.h	/^  static const ValueType value = VALUE_TYPE_INT32;$/;"	m	struct:paddle::DataType
value	gserver/layers/Layer.h	/^  std::vector<MatrixPtr> value;$/;"	m	struct:paddle::LayerState
value	math/BaseMatrix.h	/^  static const T value = v;$/;"	m	struct:paddle::bool_constant
value	math/Matrix.h	/^  float value;$/;"	m	struct:paddle::__anon19
value	parameter/Argument.h	/^  MatrixPtr value;$/;"	m	struct:paddle::Argument
value	trainer/tests/picojson.h	/^class value {$/;"	c	namespace:picojson
value	trainer/tests/picojson.h	/^inline value::value() : type_(null_type) {}$/;"	f	class:picojson::value
value	trainer/tests/picojson.h	/^inline value::value(bool b) : type_(boolean_type) { u_.boolean_ = b; }$/;"	f	class:picojson::value
value	trainer/tests/picojson.h	/^inline value::value(const array& a) : type_(array_type) {$/;"	f	class:picojson::value
value	trainer/tests/picojson.h	/^inline value::value(const char* s) : type_(string_type) {$/;"	f	class:picojson::value
value	trainer/tests/picojson.h	/^inline value::value(const char* s, size_t len) : type_(string_type) {$/;"	f	class:picojson::value
value	trainer/tests/picojson.h	/^inline value::value(const object& o) : type_(object_type) {$/;"	f	class:picojson::value
value	trainer/tests/picojson.h	/^inline value::value(const std::string& s) : type_(string_type) {$/;"	f	class:picojson::value
value	trainer/tests/picojson.h	/^inline value::value(const value& x) : type_(x.type_) {$/;"	f	class:picojson::value
value	trainer/tests/picojson.h	/^inline value::value(double n) : type_(number_type) {$/;"	f	class:picojson::value
value	trainer/tests/picojson.h	/^inline value::value(int type, bool) : type_(type) {$/;"	f	class:picojson::value
value	trainer/tests/picojson.h	/^inline value::value(int64_t i) : type_(int64_type) { u_.int64_ = i; }$/;"	f	class:picojson::value
valueCount	parameter/Argument.h	/^  mutable int valueCount;  \/\/ waiting this member when layer do forward$/;"	m	struct:paddle::Argument
valueDispatchThread	gserver/gradientmachines/MultiGradientMachine.cpp	/^void TrainerThread::valueDispatchThread() {$/;"	f	class:paddle::TrainerThread
valueDispatchThread_	gserver/gradientmachines/MultiGradientMachine.h	/^  std::unique_ptr<std::thread> valueDispatchThread_;$/;"	m	class:paddle::TrainerThread
valueMap_	function/Function.h	/^  std::map<std::string, value> valueMap_;$/;"	m	class:paddle::FuncConfig
valueReadyCond	parameter/Argument.h	/^  mutable LockedCondition valueReadyCond;$/;"	m	struct:paddle::Argument
valueReadyCond_	gserver/gradientmachines/MultiGradientMachine.h	/^  LockedCondition valueReadyCond_;$/;"	m	class:paddle::TrainerThread
valueReadyQueue_	gserver/gradientmachines/MultiGradientMachine.h	/^  PidQueue valueReadyQueue_;$/;"	m	class:paddle::TrainerThread
valueSem_	parameter/ParallelParameter.h	/^      valueSem_;  \/\/\/ wether the local parameter-value is updated$/;"	m	class:paddle::ParallelParameter
valueSize	parameter/Parameter.h	/^    uint32_t valueSize;  \/\/ = sizeof(real)$/;"	m	struct:paddle::Parameter::Header
valueStream_	gserver/gradientmachines/MultiGradientMachine.h	/^  hl_stream_t valueStream_;$/;"	m	class:paddle::TrainerThread
valueType	function/BufferArg.h	/^  ValueType valueType() const { return valueType_; }$/;"	f	class:paddle::BufferArg
valueType_	function/BufferArg.h	/^  ValueType valueType_;$/;"	m	class:paddle::BufferArg
valueType_	math/CpuSparseMatrix.h	/^  SparseValueType valueType_; \/*with value or not  *\/$/;"	m	class:paddle::CpuSparseMatrix
valueType_	math/SparseMatrix.h	/^  SparseValueType valueType_;$/;"	m	class:paddle::GpuSparseMatrix
valueUint_	parameter/tests/test_common.cpp	/^  std::vector<std::pair<real, real>> valueUint_;$/;"	m	class:CommonTest	file:
value_	gserver/evaluators/Evaluator.cpp	/^  MatrixPtr value_;$/;"	m	class:paddle::MaxFramePrinter	file:
value_	math/CpuSparseMatrix.h	/^  real* value_;               \/*nonzero value*\/$/;"	m	class:paddle::CpuSparseMatrix
value_	math/SparseMatrix.h	/^  real* value_;$/;"	m	class:paddle::GpuSparseMatrix
value_type	utils/Util.h	/^  typedef T value_type;$/;"	t	class:paddle::AlignedAllocator
varDenseData	gserver/dataproviders/ProtoDataProvider.h	/^    std::vector<ProtoVarSlot> varDenseData;$/;"	m	struct:paddle::ProtoDataProvider::ProtoSlot
varIndices	gserver/dataproviders/ProtoDataProvider.h	/^    std::vector<std::vector<int>> varIndices;$/;"	m	struct:paddle::ProtoDataProvider::ProtoSlot
variance_	gserver/layers/PriorBox.cpp	/^  std::vector<real> variance_;$/;"	m	class:paddle::PriorBoxLayer	file:
vec	api/Vector.cpp	/^  paddle::IVectorPtr vec;$/;"	m	struct:IVectorPrivate	file:
vec	api/Vector.cpp	/^  paddle::VectorPtr vec;$/;"	m	struct:VectorPrivate	file:
vecAddTo	function/MulOp.cpp	/^inline void vecAddTo(real* a, const real* b, real scaleB, size_t len) {$/;"	f	namespace:__anon16
vecAddTo	math/Matrix.cpp	/^inline void vecAddTo(real* a, const real* b, real scaleB, size_t len) {$/;"	f	namespace:paddle
vecAddTo	math/Matrix.cpp	/^inline void vecAddTo(real* a, const real* b, size_t len) {$/;"	f	namespace:paddle
vec_check	math/SIMDFunctions.h	/^inline bool vec_check(size_t len) {$/;"	f	namespace:paddle::simd
vector	function/BufferArg.h	/^  typename Tensor<VType, DType>::Vector vector() const {$/;"	f	class:paddle::BufferArg
vectorAddMult	pserver/ParameterClient2.cpp	/^void ParameterClient2::vectorAddMult(PServerVector u, PServerVector v, real a) {$/;"	f	class:paddle::ParameterClient2
vectorAddMultInto	pserver/ParameterClient2.cpp	/^void ParameterClient2::vectorAddMultInto(PServerVector u,$/;"	f	class:paddle::ParameterClient2
vectorCopy	pserver/ParameterClient2.cpp	/^void ParameterClient2::vectorCopy(PServerVector src, PServerVector dst) {$/;"	f	class:paddle::ParameterClient2
vectorDotProduct	pserver/ParameterClient2.cpp	/^real ParameterClient2::vectorDotProduct(PServerVector u, PServerVector v) {$/;"	f	class:paddle::ParameterClient2
vectorScale	pserver/ParameterClient2.cpp	/^void ParameterClient2::vectorScale(PServerVector u, real a) {$/;"	f	class:paddle::ParameterClient2
vectorScaleInto	pserver/ParameterClient2.cpp	/^void ParameterClient2::vectorScaleInto(PServerVector u,$/;"	f	class:paddle::ParameterClient2
vectors_	pserver/ParameterServer2.h	/^  std::vector<CpuVectorPtr> vectors_;$/;"	m	class:paddle::ParameterServer2
version	parameter/Parameter.h	/^    int32_t version;     \/\/ = 0, file format version$/;"	m	struct:paddle::Parameter::Header
version	parameter/ParameterUpdaterHook.cpp	/^    uint32_t version;$/;"	m	struct:paddle::StaticPruningHook::StaticMaskHeader	file:
version	setup.py	/^  version="0.9.0a0",$/;"	v
version	utils/Version.cpp	/^DECLARE_bool(version);$/;"	v
version	utils/Version.cpp	/^namespace version {$/;"	n	namespace:paddle	file:
version	utils/Version.h	/^namespace version {$/;"	n	namespace:paddle
w_	gserver/layers/LinearChainCRF.h	/^  MatrixPtr w_;$/;"	m	class:paddle::LinearChainCRF
wait	pserver/ParameterServerController.cpp	/^void ParameterServerController::wait() {$/;"	f	class:paddle::ParameterServerController
wait	utils/Locks.h	/^  void wait(Predicate pred) {$/;"	f	class:paddle::LockedCondition
wait	utils/Thread.h	/^  void wait() {$/;"	f	class:paddle::ThreadWorker
wait	utils/arch/linux/Locks.cpp	/^void Semaphore::wait() { sem_wait(&m->sem); }$/;"	f	class:paddle::Semaphore
wait	utils/arch/linux/Locks.cpp	/^void ThreadBarrier::wait() { pthread_barrier_wait(&m->barrier_); }$/;"	f	class:paddle::ThreadBarrier
wait	utils/arch/osx/Locks.cpp	/^  inline bool wait() {$/;"	f	class:paddle::ThreadBarrierPrivate
wait	utils/arch/osx/Locks.cpp	/^void Semaphore::wait() {$/;"	f	class:paddle::Semaphore
wait	utils/arch/osx/Locks.cpp	/^void ThreadBarrier::wait() { m->wait(); }$/;"	f	class:paddle::ThreadBarrier
waitAfterMerge	gserver/gradientmachines/MultiGradientMachine.h	/^  void waitAfterMerge() { allBarrier_.wait(); }$/;"	f	class:paddle::MultiGradientMachine
waitAllMajorGradReady	parameter/ParallelParameter.cpp	/^void SyncParameter::waitAllMajorGradReady() {$/;"	f	class:paddle::SyncParameter
waitAllThread	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^void ParallelNeuralNetwork::waitAllThread() {$/;"	f	class:paddle::ParallelNeuralNetwork
waitAndMergeOutputGrad	gserver/layers/Layer.cpp	/^void Layer::waitAndMergeOutputGrad() {$/;"	f	class:paddle::Layer
waitBeforeMerge	gserver/gradientmachines/MultiGradientMachine.h	/^  void waitBeforeMerge() { trainerBarrier_.wait(); }$/;"	f	class:paddle::MultiGradientMachine
waitEmpty	utils/Queue.h	/^  void waitEmpty() {$/;"	f	class:paddle::Queue
waitForCopyInArgs	gserver/gradientmachines/MultiGradientMachine.h	/^  void waitForCopyInArgs() { allBarrier_.wait(); }$/;"	f	class:paddle::MultiGradientMachine
waitForStatus	pserver/ParameterClient2.cpp	/^void ParameterClient2::waitForStatus(PServerStatus status) {$/;"	f	class:paddle::ParameterClient2
waitGradReady	parameter/Argument.h	/^  void waitGradReady() const {$/;"	f	struct:paddle::Argument
waitGradReady	parameter/ParallelParameter.h	/^  void waitGradReady() { gradSem_->wait(); }$/;"	f	class:paddle::ParallelParameter
waitInputValue	gserver/layers/Layer.cpp	/^void Layer::waitInputValue() {$/;"	f	class:paddle::Layer
waitNotEmptyFor	utils/Queue.h	/^  bool waitNotEmptyFor(int seconds) {$/;"	f	class:paddle::Queue
waitOutArgsReady	gserver/gradientmachines/MultiGradientMachine.h	/^  void waitOutArgsReady() { outArgsReadySem_.wait(); }$/;"	f	class:paddle::TrainerThread
waitPassFinish	pserver/ParameterClient2.cpp	/^void ParameterClient2::waitPassFinish() {$/;"	f	class:paddle::ParameterClient2
waitPassFinish	pserver/ParameterServer2.cpp	/^void ParameterServer2::waitPassFinish(const WaitPassFinishRequest& request,$/;"	f	class:paddle::ParameterServer2
waitPassFinishTest	pserver/test/test_ParameterServer2.cpp	/^void ParameterServer2Tester::waitPassFinishTest() {$/;"	f	class:ParameterServer2Tester
waitPassStart	pserver/ParameterClient2.cpp	/^void ParameterClient2::waitPassStart() {$/;"	f	class:paddle::ParameterClient2
waitPassStart	pserver/ParameterServer2.cpp	/^void ParameterServer2::waitPassStart(const WaitPassStartRequest& request,$/;"	f	class:paddle::ParameterServer2
waitResult	utils/Thread.h	/^  ResultPtrType waitResult() {$/;"	f	class:paddle::MultiThreadWorker
waitValueReady	parameter/Argument.h	/^  void waitValueReady() const {$/;"	f	struct:paddle::Argument
warpctc_dso_flag	cuda/src/hl_warpctc_wrap.cc	/^std::once_flag warpctc_dso_flag;$/;"	m	namespace:dynload	file:
warpctc_dso_handle	cuda/src/hl_warpctc_wrap.cc	/^void* warpctc_dso_handle = nullptr;$/;"	m	namespace:dynload	file:
weight	gserver/evaluators/Evaluator.h	/^    real weight;$/;"	m	struct:paddle::PnpairEvaluator::PredictionResult
weight	gserver/layers/NCELayer.cpp	/^    real weight;$/;"	m	struct:paddle::NCELayer::Sample	file:
weightGrad_	parameter/Weight.h	/^  MatrixPtr weightGrad_;$/;"	m	class:paddle::Weight
weightLast_	gserver/layers/InterpolationLayer.cpp	/^  MatrixPtr weightLast_;$/;"	m	class:paddle::InterpolationLayer	file:
weightLayer_	gserver/layers/CRFLayer.h	/^  LayerPtr weightLayer_;  \/\/ weight for each sequence$/;"	m	class:paddle::CRFLayer
weightLayer_	gserver/layers/CostLayer.h	/^  LayerPtr weightLayer_;$/;"	m	class:paddle::CostLayer
weightLayer_	gserver/layers/CostLayer.h	/^  LayerPtr weightLayer_;$/;"	m	class:paddle::RankingCost
weightLayer_	gserver/layers/NCELayer.cpp	/^  LayerPtr weightLayer_;$/;"	m	class:paddle::NCELayer	file:
weightOffset_	gserver/layers/ConvOperator.cpp	/^  int inputOffset_, outputOffset_, weightOffset_;$/;"	m	class:paddle::ConvOperator	file:
weightOffset_	gserver/layers/ConvProjection.h	/^  int weightOffset_;$/;"	m	class:paddle::ConvProjection
weight_	gserver/layers/BatchNormBaseLayer.h	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::BatchNormBaseLayer
weight_	gserver/layers/ContextProjection.h	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::ContextProjection
weight_	gserver/layers/ConvProjection.h	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::ConvProjection
weight_	gserver/layers/DataNormLayer.h	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::DataNormLayer
weight_	gserver/layers/DotMulProjection.cpp	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::DotMulProjection	file:
weight_	gserver/layers/FullMatrixProjection.h	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::FullMatrixProjection
weight_	gserver/layers/GatedRecurrentLayer.h	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::GatedRecurrentLayer
weight_	gserver/layers/GruStepLayer.cpp	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::GruStepLayer	file:
weight_	gserver/layers/LstmLayer.h	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::LstmLayer
weight_	gserver/layers/LstmStepLayer.cpp	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::LstmStepLayer	file:
weight_	gserver/layers/ParameterReluLayer.h	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::ParameterReluLayer
weight_	gserver/layers/RecurrentLayer.cpp	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::RecurrentLayer	file:
weight_	gserver/layers/ScalingProjection.cpp	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::ScalingProjection	file:
weight_	gserver/layers/TransposedFullMatrixProjection.cpp	/^  std::unique_ptr<Weight> weight_;$/;"	m	class:paddle::TransposedFullMatrixProjection	file:
weight_	parameter/Weight.h	/^  MatrixPtr weight_;$/;"	m	class:paddle::Weight
weights_	gserver/layers/ConvBaseLayer.h	/^  WeightList weights_;$/;"	m	class:paddle::ConvBaseLayer
weights_	gserver/layers/FullyConnectedLayer.h	/^  WeightList weights_;$/;"	m	class:paddle::FullyConnectedLayer
weights_	gserver/layers/HierarchicalSigmoidLayer.h	/^  WeightList weights_;$/;"	m	class:paddle::HierarchicalSigmoidLayer
weights_	gserver/layers/NCELayer.cpp	/^  WeightList weights_;$/;"	m	class:paddle::NCELayer	file:
weights_	gserver/layers/SelectiveFullyConnectedLayer.h	/^  WeightList weights_;$/;"	m	class:paddle::SelectiveFullyConnectedLayer
weights_	gserver/layers/TensorLayer.h	/^  WeightList weights_;$/;"	m	class:paddle::TensorLayer
whole_end	api/paddle_ld_flags.py	/^        whole_end = ""$/;"	v
whole_end	api/paddle_ld_flags.py	/^        whole_end = "-Wl,--no-whole-archive"$/;"	v
whole_start	api/paddle_ld_flags.py	/^        whole_start = ""$/;"	v
whole_start	api/paddle_ld_flags.py	/^        whole_start = "-Wl,--whole-archive"$/;"	v
width	math/tests/test_ExecViaCpu.cpp	/^const int width = 16;$/;"	v
width	math/tests/test_SparseMatrix.cpp	/^  size_t width;$/;"	m	struct:MatrixPara	file:
widthEnd	function/PadOp.h	/^  int widthEnd;$/;"	m	struct:paddle::PadConf
widthPadding	gserver/layers/CudnnPoolLayer.h	/^  int heightPadding, widthPadding, strideHeight, strideWidth;$/;"	m	class:paddle::CudnnPoolLayer
widthStart	function/PadOp.h	/^  int widthStart;$/;"	m	struct:paddle::PadConf
width_	gserver/layers/RotateLayer.h	/^  int width_;$/;"	m	class:paddle::RotateLayer
width_	math/BaseMatrix.h	/^  size_t height_, width_;$/;"	m	class:paddle::BaseMatrixT
width_	math/RowBuffer.h	/^  size_t width_;$/;"	m	class:paddle::RowBuffer
width_	math/TensorApply.h	/^  size_t width_;$/;"	m	class:paddle::TensorApply
windowHeight	gserver/layers/CudnnPoolLayer.h	/^  int windowHeight, windowWidth;$/;"	m	class:paddle::CudnnPoolLayer
windowWidth	gserver/layers/CudnnPoolLayer.h	/^  int windowHeight, windowWidth;$/;"	m	class:paddle::CudnnPoolLayer
withInfo_	gserver/dataproviders/DataProvider.h	/^  bool withInfo_;$/;"	m	class:paddle::SimpleDataProviderBase
with_cost	trainer/TrainerConfigHelper.cpp	/^DECLARE_bool(with_cost);$/;"	v
with_gpu	trainer/TrainerConfigHelper.cpp	/^DECLARE_bool(with_gpu);$/;"	v
word_dim	gserver/tests/sequence_nest_rnn_multi_unequalength_inputs.py	/^word_dim = 8$/;"	v
word_dim	gserver/tests/sequence_rnn_multi_unequalength_inputs.py	/^word_dim = 8$/;"	v
workSpaceInBytes_	gserver/layers/ConvOperator.cpp	/^  size_t workSpaceInBytes_;$/;"	m	class:paddle::ConvOperator	file:
workSpaceInBytes_	gserver/layers/ConvProjection.h	/^  size_t workSpaceInBytes_;$/;"	m	class:paddle::ConvProjection
workSpace_	gserver/layers/ConvOperator.cpp	/^  void *workSpace_;$/;"	m	class:paddle::ConvOperator	file:
workers_	utils/Thread.h	/^  std::vector<std::unique_ptr<std::thread>> workers_;$/;"	m	class:paddle::AsyncThreadPool
workers_	utils/Thread.h	/^  std::vector<std::unique_ptr<std::thread>> workers_;$/;"	m	class:paddle::MultiThreadWorker
workers_	utils/Thread.h	/^  std::vector<std::unique_ptr<std::thread>> workers_;$/;"	m	class:paddle::SyncThreadPool
workspace_	gserver/layers/WarpCTCLayer.h	/^  VectorPtr workspace_;$/;"	m	class:paddle::WarpCTCLayer
wrap	py_paddle/util.py	/^    def wrap(callback):$/;"	m	class:__ParameterCallbackWrapper__
write	gserver/dataproviders/ProtoReader.h	/^  bool write(const google::protobuf::MessageLite& msg) {$/;"	f	class:paddle::ProtoWriter
write	pserver/RDMANetwork.h	/^inline ssize_t write(sxi_sock* channel, void* data, size_t len) {$/;"	f	namespace:paddle::rdma
write	pserver/SocketChannel.cpp	/^size_t SocketChannel::write(const void* buf, size_t size) {$/;"	f	class:paddle::SocketChannel
writeAll	pserver/test/SocketTest.cpp	/^uint64_t SocketChannel::writeAll(const void* buf, size_t size) {$/;"	f	class:SocketChannel
writeData	gserver/tests/test_ProtoDataProvider.cpp	/^void writeData(const DataBatch& batch, bool useGpu, bool dataCompression) {$/;"	f
writeMessage	pserver/SocketChannel.cpp	/^void SocketChannel::writeMessage(const std::vector<struct iovec>& userIovs) {$/;"	f	class:paddle::SocketChannel
write_proto	trainer/tests/gen_proto_data.py	/^def write_proto(file, message):$/;"	f
write_sequence	trainer/tests/gen_proto_data.py	/^    def write_sequence(out, sequence):$/;"	f	function:gen_proto_file
writev	pserver/RDMANetwork.h	/^inline ssize_t writev(sxi_sock* channel, iovec* iov, int count) {$/;"	f	namespace:paddle::rdma
writev	pserver/SocketChannel.cpp	/^size_t SocketChannel::writev(const std::vector<struct iovec>& iovs) {$/;"	f	class:paddle::SocketChannel
xmm	cuda/src/avx_mathfun.h	/^  v4si xmm[2];$/;"	m	union:imm_xmm_union
xstr	utils/Version.cpp	33;"	d	file:
zeroGrad	gserver/layers/Layer.cpp	/^void Layer::zeroGrad() {$/;"	f	class:paddle::Layer
zeroMem	math/CpuSparseMatrix.cpp	/^void CpuSparseMatrix::zeroMem() {$/;"	f	class:paddle::CpuSparseMatrix
zeroMem	math/Matrix.cpp	/^void CpuMatrix::zeroMem() {$/;"	f	class:paddle::CpuMatrix
zeroMem	math/Matrix.cpp	/^void GpuMatrix::zeroMem() {$/;"	f	class:paddle::GpuMatrix
zeroMem	math/Matrix.h	/^  virtual void zeroMem() { LOG(FATAL) << "Not implemented"; }$/;"	f	class:paddle::Matrix
zeroMem	math/SparseMatrix.cpp	/^void GpuSparseMatrix::zeroMem() {$/;"	f	class:paddle::GpuSparseMatrix
zeroMem	math/SparseRowMatrix.cpp	/^void SparseRowCpuMatrix::zeroMem() {$/;"	f	class:paddle::SparseRowCpuMatrix
zeroMem	math/Vector.cpp	/^void CpuGpuVectorT<T>::zeroMem(bool useGpu) {$/;"	f	class:paddle::CpuGpuVectorT
zeroMem	math/Vector.cpp	/^void CpuVectorT<T>::zeroMem() {$/;"	f	class:paddle::CpuVectorT
zeroMem	math/Vector.cpp	/^void GpuVectorT<T>::zeroMem() {$/;"	f	class:paddle::GpuVectorT
zeroMem	math/Vector.h	/^  virtual void zeroMem() {$/;"	f	class:paddle::ParallelCpuVectorT
zeroMem	parameter/Parameter.cpp	/^void Parameter::zeroMem() {$/;"	f	class:paddle::Parameter
zeroMemThread	math/SparseRowMatrix.cpp	/^void SparseRowCpuMatrix::zeroMemThread(size_t tid, size_t numThreads) {$/;"	f	class:paddle::SparseRowCpuMatrix
zeroTuple_	gserver/dataproviders/PyDataProvider2.cpp	/^  static PyObjectPtr zeroTuple_;$/;"	m	class:paddle::PyDataProvider2	file:
~ActivationFunction	gserver/activations/ActivationFunction.h	/^  virtual ~ActivationFunction() {}$/;"	f	class:paddle::ActivationFunction
~AddtoLayer	gserver/layers/AddtoLayer.h	/^  ~AddtoLayer() {}$/;"	f	class:paddle::AddtoLayer
~AgentLayer	gserver/layers/AgentLayer.h	/^  ~AgentLayer() {}$/;"	f	class:paddle::AgentLayer
~AlignedAllocator	utils/Util.h	/^  ~AlignedAllocator() {}$/;"	f	class:paddle::AlignedAllocator
~Allocator	math/Allocator.h	/^  virtual ~Allocator() {}$/;"	f	class:paddle::Allocator
~Argument	parameter/Argument.h	/^  ~Argument() {}$/;"	f	struct:paddle::Argument
~Arguments	api/Arguments.cpp	/^Arguments::~Arguments() { delete m; }$/;"	f	class:Arguments
~AsyncGpuBlock	utils/Util.h	/^  ~AsyncGpuBlock() {$/;"	f	class:paddle::AsyncGpuBlock
~AsyncThreadPool	utils/Thread.h	/^  ~AsyncThreadPool() {$/;"	f	class:paddle::AsyncThreadPool
~BarrierDeltaStat	utils/BarrierStat.h	/^  ~BarrierDeltaStat() {}$/;"	f	class:paddle::BarrierDeltaStat
~BarrierEndStat	utils/BarrierStat.h	/^  ~BarrierEndStat() {}$/;"	f	class:paddle::BarrierEndStat
~BarrierStatBase	utils/BarrierStat.h	/^  virtual ~BarrierStatBase() {}$/;"	f	class:paddle::BarrierStatBase
~BaseClient	pserver/BaseClient.cpp	/^BaseClient::~BaseClient() {}$/;"	f	class:paddle::BaseClient
~BaseMatrixT	math/BaseMatrix.h	/^  virtual ~BaseMatrixT() {}$/;"	f	class:paddle::BaseMatrixT
~BaseVector	math/Vector.h	/^  ~BaseVector() {}$/;"	f	class:paddle::BaseVector
~BatchNormBaseLayer	gserver/layers/BatchNormBaseLayer.h	/^  ~BatchNormBaseLayer() {}$/;"	f	class:paddle::BatchNormBaseLayer
~BatchNormalizationLayer	gserver/layers/BatchNormalizationLayer.h	/^  ~BatchNormalizationLayer() {}$/;"	f	class:paddle::BatchNormalizationLayer
~BilinearInterpLayer	gserver/layers/BilinearInterpLayer.h	/^  virtual ~BilinearInterpLayer() {}$/;"	f	class:paddle::BilinearInterpLayer
~BlockExpandLayer	gserver/layers/BlockExpandLayer.h	/^  ~BlockExpandLayer() {}$/;"	f	class:paddle::BlockExpandLayer
~BufferArg	function/BufferArg.h	/^  virtual ~BufferArg() {}$/;"	f	class:paddle::BufferArg
~BufferArgs	function/Function.h	/^  ~BufferArgs() {$/;"	f	class:paddle::BufferArgs
~BufferBatch	gserver/dataproviders/DataProvider.h	/^  ~BufferBatch() {$/;"	f	class:paddle::BufferBatch
~CMRProjectionNormLayer	gserver/layers/NormProjectionLayer.h	/^  ~CMRProjectionNormLayer() {}$/;"	f	class:paddle::CMRProjectionNormLayer
~CallableHelper	utils/PythonUtil.h	/^  ~CallableHelper() {}$/;"	f	class:paddle::py::CallableHelper
~CommonTest	parameter/tests/test_common.cpp	/^  virtual ~CommonTest() {}$/;"	f	class:CommonTest
~ConcatenateLayer	gserver/layers/ConcatenateLayer.cpp	/^  ~ConcatenateLayer() {}$/;"	f	class:paddle::ConcatenateLayer
~ConcatenateLayer2	gserver/layers/ConcatenateLayer.cpp	/^  ~ConcatenateLayer2() {}$/;"	f	class:paddle::ConcatenateLayer2
~ConcurrentRemoteParameterUpdater	trainer/RemoteParameterUpdater.cpp	/^ConcurrentRemoteParameterUpdater::~ConcurrentRemoteParameterUpdater() {$/;"	f	class:paddle::ConcurrentRemoteParameterUpdater
~ConvOperator	gserver/layers/ConvOperator.cpp	/^  virtual ~ConvOperator() {$/;"	f	class:paddle::ConvOperator
~ConvProjection	gserver/layers/ConvProjection.cpp	/^ConvProjection::~ConvProjection() {$/;"	f	class:paddle::ConvProjection
~ConvShiftLayer	gserver/layers/ConvShiftLayer.cpp	/^  ~ConvShiftLayer() {}$/;"	f	class:paddle::ConvShiftLayer
~ConvexCombinationLayer	gserver/layers/ConvexCombinationLayer.cpp	/^  ~ConvexCombinationLayer() {}$/;"	f	class:paddle::ConvexCombinationLayer
~CopyToCpu	math/ExecViaCpu.h	/^  ~CopyToCpu() {$/;"	f	class:paddle::CopyToCpu
~CosSimLayer	gserver/layers/CosSimLayer.h	/^  ~CosSimLayer() {}$/;"	f	class:paddle::CosSimLayer
~CosSimVecMatLayer	gserver/layers/CosSimVecMatLayer.cpp	/^  ~CosSimVecMatLayer() {}$/;"	f	class:paddle::CosSimVecMatLayer
~CpuAllocator	math/Allocator.h	/^  ~CpuAllocator() {}$/;"	f	class:paddle::CpuAllocator
~CpuGpuVectorT	math/Vector.h	/^  virtual ~CpuGpuVectorT() {}$/;"	f	class:paddle::CpuGpuVectorT
~CpuMatrix	math/Matrix.cpp	/^CpuMatrix::~CpuMatrix() {}$/;"	f	class:paddle::CpuMatrix
~CpuMemoryHandle	math/MemoryHandle.cpp	/^CpuMemoryHandle::~CpuMemoryHandle() { allocator_->free(buf_, allocSize_); }$/;"	f	class:paddle::CpuMemoryHandle
~CpuSparseMatrix	math/CpuSparseMatrix.h	/^  ~CpuSparseMatrix() {}$/;"	f	class:paddle::CpuSparseMatrix
~CudaHostAllocator	math/Allocator.h	/^  ~CudaHostAllocator() {}$/;"	f	class:paddle::CudaHostAllocator
~CudnnBatchNormLayer	gserver/layers/CudnnBatchNormLayer.cpp	/^CudnnBatchNormLayer::~CudnnBatchNormLayer() {$/;"	f	class:paddle::CudnnBatchNormLayer
~CudnnConvLayer	gserver/layers/CudnnConvLayer.cpp	/^CudnnConvLayer::~CudnnConvLayer() {$/;"	f	class:paddle::CudnnConvLayer
~CudnnPoolLayer	gserver/layers/CudnnPoolLayer.cpp	/^CudnnPoolLayer::~CudnnPoolLayer() {$/;"	f	class:paddle::CudnnPoolLayer
~DataNormLayer	gserver/layers/DataNormLayer.h	/^  ~DataNormLayer() {}$/;"	f	class:paddle::DataNormLayer
~DataProvider	gserver/dataproviders/DataProvider.h	/^  virtual ~DataProvider() {}$/;"	f	class:paddle::DataProvider
~DataProviderGroup	gserver/dataproviders/DataProviderGroup.h	/^  ~DataProviderGroup() {}$/;"	f	class:paddle::DataProviderGroup
~DoubleBuffer	gserver/dataproviders/DataProvider.cpp	/^DoubleBuffer::~DoubleBuffer() {$/;"	f	class:paddle::DoubleBuffer
~Evaluator	api/Evaluator.cpp	/^Evaluator::~Evaluator() { delete m; }$/;"	f	class:Evaluator
~Evaluator	gserver/evaluators/Evaluator.h	/^  virtual ~Evaluator() {}$/;"	f	class:paddle::Evaluator
~EvaluatorPrivate	api/PaddleAPIPrivate.h	/^  ~EvaluatorPrivate() { delete rawPtr; }$/;"	f	struct:EvaluatorPrivate
~ExpandConvBaseLayer	gserver/layers/ExpandConvBaseLayer.h	/^  ~ExpandConvBaseLayer() {}$/;"	f	class:paddle::ExpandConvBaseLayer
~ExpandConvLayer	gserver/layers/ExpandConvLayer.h	/^  ~ExpandConvLayer() {}$/;"	f	class:paddle::ExpandConvLayer
~ExpandConvTransLayer	gserver/layers/ExpandConvTransLayer.h	/^  ~ExpandConvTransLayer() {}$/;"	f	class:paddle::ExpandConvTransLayer
~ExpandLayer	gserver/layers/ExpandLayer.h	/^  ~ExpandLayer() {}$/;"	f	class:paddle::ExpandLayer
~FeatureMapExpandLayer	gserver/layers/FeatureMapExpandLayer.cpp	/^  ~FeatureMapExpandLayer() {}$/;"	f	class:paddle::FeatureMapExpandLayer
~FullyConnectedLayer	gserver/layers/FullyConnectedLayer.h	/^  ~FullyConnectedLayer() {}$/;"	f	class:paddle::FullyConnectedLayer
~FunctionBase	function/Function.h	/^  virtual ~FunctionBase() {}$/;"	f	class:paddle::FunctionBase
~FunctionCompare	function/FunctionTest.h	/^  ~FunctionCompare() {}$/;"	f	class:paddle::FunctionCompare
~GatherAgentLayer	gserver/layers/AgentLayer.h	/^  virtual ~GatherAgentLayer() {}$/;"	f	class:paddle::GatherAgentLayer
~GetOutputLayer	gserver/layers/GetOutputLayer.cpp	/^  ~GetOutputLayer() {}$/;"	f	class:paddle::GetOutputLayer
~GpuAllocator	math/Allocator.h	/^  ~GpuAllocator() {}$/;"	f	class:paddle::GpuAllocator
~GpuMatrix	math/Matrix.cpp	/^GpuMatrix::~GpuMatrix() {}$/;"	f	class:paddle::GpuMatrix
~GpuMemoryHandle	math/MemoryHandle.cpp	/^GpuMemoryHandle::~GpuMemoryHandle() { allocator_->free(buf_, allocSize_); }$/;"	f	class:paddle::GpuMemoryHandle
~GpuProfiler	utils/Stat.cpp	/^GpuProfiler::~GpuProfiler() {$/;"	f	class:paddle::GpuProfiler
~GpuSparseMatrix	math/SparseMatrix.h	/^  ~GpuSparseMatrix() {}$/;"	f	class:paddle::GpuSparseMatrix
~GradientMachine	api/GradientMachine.cpp	/^GradientMachine::~GradientMachine() { delete m; }$/;"	f	class:GradientMachine
~GradientMachine	gserver/gradientmachines/GradientMachine.h	/^  virtual ~GradientMachine() {}$/;"	f	class:paddle::GradientMachine
~GruStepLayer	gserver/layers/GruStepLayer.cpp	/^  ~GruStepLayer() {}$/;"	f	class:paddle::GruStepLayer
~IFieldScanner	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual ~IFieldScanner() {}$/;"	f	class:paddle::IFieldScanner
~IGradientMachineMode	gserver/gradientmachines/GradientMachineMode.h	/^  virtual ~IGradientMachineMode() {}$/;"	f	class:paddle::IGradientMachineMode
~IParameterUpdaterHook	parameter/ParameterUpdaterHook.cpp	/^IParameterUpdaterHook::~IParameterUpdaterHook() {}$/;"	f	class:paddle::IParameterUpdaterHook
~IPyDataProviderCache	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual ~IPyDataProviderCache() {}$/;"	f	class:paddle::IPyDataProviderCache
~ISequenceResults	api/SequenceGenerator.cpp	/^ISequenceResults::~ISequenceResults() {}$/;"	f	class:ISequenceResults
~IVector	api/Vector.cpp	/^IVector::~IVector() { delete m; }$/;"	f	class:IVector
~InterpolationLayer	gserver/layers/InterpolationLayer.cpp	/^  ~InterpolationLayer() {}$/;"	f	class:paddle::InterpolationLayer
~Layer	gserver/layers/Layer.h	/^  virtual ~Layer() {}$/;"	f	class:paddle::Layer
~LearningRateScheduler	parameter/LearningRateScheduler.h	/^  virtual ~LearningRateScheduler() {}$/;"	f	class:paddle::LearningRateScheduler
~LstmStepLayer	gserver/layers/LstmStepLayer.cpp	/^  ~LstmStepLayer() {}$/;"	f	class:paddle::LstmStepLayer
~Matrix	api/Matrix.cpp	/^Matrix::~Matrix() { delete m; }$/;"	f	class:Matrix
~Matrix	math/Matrix.h	/^  virtual ~Matrix() {}$/;"	f	class:paddle::Matrix
~MaxOutLayer	gserver/layers/MaxOutLayer.h	/^  virtual ~MaxOutLayer() {}$/;"	f	class:paddle::MaxOutLayer
~MemoryHandle	math/MemoryHandle.h	/^  virtual ~MemoryHandle() {}$/;"	f	class:paddle::MemoryHandle
~MixedLayer	gserver/layers/MixedLayer.h	/^  ~MixedLayer() {}$/;"	f	class:paddle::MixedLayer
~ModelConfig	api/ConfigParser.cpp	/^ModelConfig::~ModelConfig() { delete m; }$/;"	f	class:ModelConfig
~MsgReader	pserver/SocketChannel.h	/^  ~MsgReader() {$/;"	f	class:paddle::MsgReader
~MultiDataProvider	gserver/dataproviders/MultiDataProvider.h	/^  ~MultiDataProvider() {}$/;"	f	class:paddle::MultiDataProvider
~MultiThreadWorker	utils/Thread.h	/^  virtual ~MultiThreadWorker() { forceStop(); }$/;"	f	class:paddle::MultiThreadWorker
~MultiplexLayer	gserver/layers/MultiplexLayer.cpp	/^  ~MultiplexLayer() {}$/;"	f	class:paddle::MultiplexLayer
~Operator	gserver/layers/Operator.h	/^  virtual ~Operator() {}$/;"	f	class:paddle::Operator
~OptimizationConfig	api/ConfigParser.cpp	/^OptimizationConfig::~OptimizationConfig() {$/;"	f	class:OptimizationConfig
~OuterProdLayer	gserver/layers/OuterProdLayer.cpp	/^  ~OuterProdLayer() {}$/;"	f	class:paddle::OuterProdLayer
~PadLayer	gserver/layers/PadLayer.h	/^  ~PadLayer() {}$/;"	f	class:paddle::PadLayer
~ParallelParameter	parameter/ParallelParameter.h	/^  virtual ~ParallelParameter() {}$/;"	f	class:paddle::ParallelParameter
~ParallelThread	gserver/gradientmachines/ParallelNeuralNetwork.cpp	/^ParallelThread::~ParallelThread() { stop(); }$/;"	f	class:paddle::ParallelThread
~Parameter	api/Parameter.cpp	/^Parameter::~Parameter() { delete m; }$/;"	f	class:Parameter
~ParameterClient2	pserver/ParameterClient2.cpp	/^ParameterClient2::~ParameterClient2() { destroy(); }$/;"	f	class:paddle::ParameterClient2
~ParameterConfig	api/ConfigParser.cpp	/^ParameterConfig::~ParameterConfig() {$/;"	f	class:ParameterConfig
~ParameterOptimizer	api/ParameterOptimizer.cpp	/^ParameterOptimizer::~ParameterOptimizer() {$/;"	f	class:ParameterOptimizer
~ParameterOptimizer	parameter/ParameterOptimizer.h	/^  virtual ~ParameterOptimizer() {}$/;"	f	class:paddle::ParameterOptimizer
~ParameterReluLayer	gserver/layers/ParameterReluLayer.h	/^  ~ParameterReluLayer() {}$/;"	f	class:paddle::ParameterReluLayer
~ParameterServer2	pserver/ParameterServer2.h	/^  ~ParameterServer2() {}$/;"	f	class:paddle::ParameterServer2
~ParameterServer2Tester	pserver/test/test_ParameterServer2.cpp	/^  virtual ~ParameterServer2Tester() {}$/;"	f	class:ParameterServer2Tester
~ParameterServerController	pserver/ParameterServerController.cpp	/^ParameterServerController::~ParameterServerController() { this->wait(); }$/;"	f	class:paddle::ParameterServerController
~ParameterTraverseCallback	api/ParameterOptimizer.cpp	/^ParameterTraverseCallback::~ParameterTraverseCallback() {$/;"	f	class:ParameterTraverseCallback
~ParameterUpdater	api/ParameterUpdater.cpp	/^ParameterUpdater::~ParameterUpdater() { delete m; }$/;"	f	class:ParameterUpdater
~ParameterUpdater	parameter/ParameterUpdaterBase.h	/^  virtual ~ParameterUpdater() {}$/;"	f	class:paddle::ParameterUpdater
~ParameterUpdaterComposite	parameter/ParameterUpdaterBase.h	/^  virtual ~ParameterUpdaterComposite() {}$/;"	f	class:paddle::ParameterUpdaterComposite
~PoolAllocator	math/PoolAllocator.cpp	/^PoolAllocator::~PoolAllocator() { freeAll(); }$/;"	f	class:paddle::PoolAllocator
~PowerLayer	gserver/layers/PowerLayer.cpp	/^  ~PowerLayer() {}$/;"	f	class:paddle::PowerLayer
~Projection	gserver/layers/Projection.h	/^  virtual ~Projection() {}$/;"	f	class:paddle::Projection
~ProtoSequenceDataProvider	gserver/dataproviders/ProtoDataProvider.h	/^  ~ProtoSequenceDataProvider() {}$/;"	f	class:paddle::ProtoSequenceDataProvider
~PyDataProvider2	gserver/dataproviders/PyDataProvider2.cpp	/^  virtual ~PyDataProvider2() { resetImpl(false); }$/;"	f	class:paddle::PyDataProvider2
~Queue	utils/Queue.h	/^  ~Queue() {}$/;"	f	class:paddle::Queue
~RWLock	utils/Locks.h	/^  ~RWLock() { pthread_rwlock_destroy(&rwlock_); }$/;"	f	class:paddle::RWLock
~RdmaClientDaemons	pserver/LightNetwork.cpp	/^RdmaClientDaemons::~RdmaClientDaemons() {$/;"	f	class:paddle::RdmaClientDaemons
~ReadLockGuard	utils/Locks.h	/^  ~ReadLockGuard() { rwlock_->unlock(); }$/;"	f	class:paddle::ReadLockGuard
~RecurrentGradientMachine	gserver/gradientmachines/RecurrentGradientMachine.h	/^  virtual ~RecurrentGradientMachine() {$/;"	f	class:paddle::RecurrentGradientMachine
~Regularizer	parameter/Regularizer.h	/^  virtual ~Regularizer() {}$/;"	f	class:paddle::Regularizer
~RemoteParameterUpdater	trainer/RemoteParameterUpdater.h	/^  ~RemoteParameterUpdater() {$/;"	f	class:paddle::RemoteParameterUpdater
~ScalingLayer	gserver/layers/ScalingLayer.cpp	/^  ~ScalingLayer() {}$/;"	f	class:paddle::ScalingLayer
~ScatterAgentLayer	gserver/layers/AgentLayer.h	/^  virtual ~ScatterAgentLayer() {}$/;"	f	class:paddle::ScatterAgentLayer
~ScopedCallbacks	utils/Util.h	/^  ~ScopedCallbacks() { exit_(); }$/;"	f	class:paddle::ScopedCallbacks
~SelectiveFullyConnectedLayer	gserver/layers/SelectiveFullyConnectedLayer.h	/^  ~SelectiveFullyConnectedLayer() {}$/;"	f	class:paddle::SelectiveFullyConnectedLayer
~Semaphore	utils/arch/linux/Locks.cpp	/^Semaphore::~Semaphore() { sem_destroy(&m->sem); }$/;"	f	class:paddle::Semaphore
~Semaphore	utils/arch/osx/Locks.cpp	/^Semaphore::~Semaphore() { delete m; }$/;"	f	class:paddle::Semaphore
~SemaphorePrivate	utils/arch/osx/Locks.cpp	/^  ~SemaphorePrivate() { dispatch_release(sem); }$/;"	f	class:paddle::SemaphorePrivate
~SequenceAgentLayer	gserver/layers/AgentLayer.h	/^  ~SequenceAgentLayer() {}$/;"	f	class:paddle::SequenceAgentLayer
~SequenceArg	function/BufferArg.h	/^  ~SequenceArg() {}$/;"	f	class:paddle::SequenceArg
~SequenceConcatLayer	gserver/layers/SequenceConcatLayer.cpp	/^  ~SequenceConcatLayer() {}$/;"	f	class:paddle::SequenceConcatLayer
~SequenceGatherAgentLayer	gserver/layers/AgentLayer.h	/^  virtual ~SequenceGatherAgentLayer() {}$/;"	f	class:paddle::SequenceGatherAgentLayer
~SequenceGenerator	api/SequenceGenerator.cpp	/^SequenceGenerator::~SequenceGenerator() { delete m; }$/;"	f	class:SequenceGenerator
~SequenceIdArg	function/BufferArg.h	/^  ~SequenceIdArg() {}$/;"	f	class:paddle::SequenceIdArg
~SequenceScatterAgentLayer	gserver/layers/AgentLayer.h	/^  virtual ~SequenceScatterAgentLayer() {}$/;"	f	class:paddle::SequenceScatterAgentLayer
~SetDevice	utils/Util.h	/^  ~SetDevice() {$/;"	f	class:paddle::SetDevice
~SetMaxDiff	math/tests/test_TrainingAlgorithm.cpp	/^  ~SetMaxDiff() { FLAGS_max_diff = max_diff_; }$/;"	f	class:SetMaxDiff
~SgdThreadUpdater	trainer/ThreadParameterUpdater.h	/^  virtual ~SgdThreadUpdater() {}$/;"	f	class:paddle::SgdThreadUpdater
~SgdUpdaterWithCpuAverager	trainer/ParameterUpdater.cpp	/^SgdUpdaterWithCpuAverager::~SgdUpdaterWithCpuAverager() {$/;"	f	class:paddle::SgdUpdaterWithCpuAverager
~SharedCpuMatrix	math/Matrix.h	/^  ~SharedCpuMatrix() {}$/;"	f	class:paddle::SharedCpuMatrix
~SimpleDataProvider	gserver/dataproviders/DataProvider.cpp	/^SimpleDataProvider::~SimpleDataProvider() {}$/;"	f	class:paddle::SimpleDataProvider
~SimpleDataProviderBase	gserver/dataproviders/DataProvider.h	/^  ~SimpleDataProviderBase() {}$/;"	f	class:paddle::SimpleDataProviderBase
~SocketChannel	pserver/SocketChannel.cpp	/^SocketChannel::~SocketChannel() {$/;"	f	class:paddle::SocketChannel
~SocketServer	pserver/LightNetwork.cpp	/^SocketServer::~SocketServer() {$/;"	f	class:paddle::SocketServer
~SocketWorker	pserver/LightNetwork.h	/^  virtual ~SocketWorker() {}$/;"	f	class:paddle::SocketWorker
~SparseMatrixArg	function/BufferArg.h	/^  ~SparseMatrixArg() {}$/;"	f	class:paddle::SparseMatrixArg
~SparseParameterDistribution	pserver/SparseParameterDistribution.h	/^  ~SparseParameterDistribution() {}$/;"	f	class:paddle::SparseParameterDistribution
~SparseRemoteParameterUpdater	trainer/RemoteParameterUpdater.h	/^  ~SparseRemoteParameterUpdater() {$/;"	f	class:paddle::SparseRemoteParameterUpdater
~SparseRowCpuMatrix	math/SparseRowMatrix.h	/^  virtual ~SparseRowCpuMatrix() {}$/;"	f	class:paddle::SparseRowCpuMatrix
~SpinLock	utils/arch/linux/Locks.cpp	/^SpinLock::~SpinLock() { delete m; }$/;"	f	class:paddle::SpinLock
~SpinLock	utils/arch/osx/Locks.cpp	/^SpinLock::~SpinLock() { delete m; }$/;"	f	class:paddle::SpinLock
~SpinLockPrivate	utils/arch/linux/Locks.cpp	/^  inline ~SpinLockPrivate() { pthread_spin_destroy(&lock_); }$/;"	f	class:paddle::SpinLockPrivate
~Stat	utils/Stat.h	/^  ~Stat() {}$/;"	f	class:paddle::Stat
~StatInfo	utils/Stat.cpp	/^StatInfo::~StatInfo() {$/;"	f	class:paddle::StatInfo
~StatSet	utils/Stat.h	/^  ~StatSet() {}$/;"	f	class:paddle::StatSet
~StorageEngine	math/Storage.cpp	/^StorageEngine::~StorageEngine() {$/;"	f	class:paddle::StorageEngine
~SyncParameter	parameter/ParallelParameter.h	/^  ~SyncParameter() {$/;"	f	class:paddle::SyncParameter
~SyncThreadPool	utils/Thread.h	/^  ~SyncThreadPool() {$/;"	f	class:paddle::SyncThreadPool
~Thread	pserver/test/SocketTest.cpp	/^  virtual ~Thread() {}$/;"	f	class:Thread
~Thread	utils/Thread.h	/^  virtual ~Thread() {}$/;"	f	class:paddle::Thread
~ThreadBarrier	utils/arch/linux/Locks.cpp	/^ThreadBarrier::~ThreadBarrier() {$/;"	f	class:paddle::ThreadBarrier
~ThreadBarrier	utils/arch/osx/Locks.cpp	/^ThreadBarrier::~ThreadBarrier() { delete m; }$/;"	f	class:paddle::ThreadBarrier
~ThreadBarrierPrivate	utils/arch/osx/Locks.cpp	/^  inline ~ThreadBarrierPrivate() {$/;"	f	class:paddle::ThreadBarrierPrivate
~ThreadLocal	utils/ThreadLocal.h	/^  ~ThreadLocal() { pthread_key_delete(threadSpecificKey_); }$/;"	f	class:paddle::ThreadLocal
~ThreadLocalD	utils/ThreadLocal.h	/^  ~ThreadLocalD() {$/;"	f	class:paddle::ThreadLocalD
~ThreadWorker	utils/Thread.h	/^  ~ThreadWorker() {$/;"	f	class:paddle::ThreadWorker
~TimeVectorDelta	utils/BarrierStat.h	/^  ~TimeVectorDelta() {}$/;"	f	class:paddle::TimeVectorDelta
~TimeVectorEnd	utils/BarrierStat.h	/^  ~TimeVectorEnd() {}$/;"	f	class:paddle::TimeVectorEnd
~TimerOnce	utils/Stat.h	/^  ~TimerOnce() {$/;"	f	class:paddle::TimerOnce
~Trainer	api/Trainer.cpp	/^Trainer::~Trainer() { delete m; }$/;"	f	class:Trainer
~Trainer	trainer/Trainer.h	/^  virtual ~Trainer() {}$/;"	f	class:paddle::Trainer
~TrainerConfig	api/ConfigParser.cpp	/^TrainerConfig::~TrainerConfig() { delete m; }$/;"	f	class:TrainerConfig
~TrainerConfigHelper	trainer/TrainerConfigHelper.cpp	/^TrainerConfigHelper::~TrainerConfigHelper() {$/;"	f	class:paddle::TrainerConfigHelper
~TrainerInternal	trainer/TrainerInternal.h	/^  virtual ~TrainerInternal() {}$/;"	f	class:paddle::TrainerInternal
~TrainerThread	gserver/gradientmachines/MultiGradientMachine.cpp	/^TrainerThread::~TrainerThread() { stop(); }$/;"	f	class:paddle::TrainerThread
~UpdateCallback	api/GradientMachine.cpp	/^UpdateCallback::~UpdateCallback() {}$/;"	f	class:UpdateCallback
~Vector	api/Vector.cpp	/^Vector::~Vector() {$/;"	f	class:Vector
~VectorT	math/Vector.h	/^  virtual ~VectorT() {}$/;"	f	class:paddle::VectorT
~WarpCTCLayer	gserver/layers/WarpCTCLayer.h	/^  ~WarpCTCLayer() {}$/;"	f	class:paddle::WarpCTCLayer
~value	trainer/tests/picojson.h	/^inline value::~value() {$/;"	f	class:picojson::value
